<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 71]
- [cs.LG](#cs.LG) [Total: 51]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [DesignSense: A Human Preference Dataset and Reward Modeling Framework for Graphic Layout Generation](https://arxiv.org/abs/2602.23438)
*Varun Gopal,Rishabh Jain,Aradhya Mathur,Nikitha SR,Sohan Patnaik,Sudhir Yarram,Mayur Hemani,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: 提出DesignSense-10k数据集和DesignSense模型，专门用于图形布局质量评估，显著优于现有模型，并能提升布局生成质量


<details>
  <summary>Details</summary>
Motivation: 现有布局生成模型常无法符合人类审美判断，而现有的偏好数据集和奖励模型主要针对文本到图像生成，不适用于布局评估（空间排列决定质量）

Method: 1) 创建DesignSense-10k数据集：包含10,235个人工标注的偏好对，采用五阶段流程生成视觉连贯的布局变换；2) 训练DesignSense：基于视觉语言模型的分类器，用于布局质量评估

Result: DesignSense在综合评估指标上大幅优于现有开源和专有模型（Macro F1比最强专有基线提升54.6%）；前沿VLM在四分类任务上表现不可靠且会灾难性失败；使用该奖励模型在RL训练中提升生成器胜率约3%，推理时缩放提供3.6%改进

Conclusion: 需要专门的、偏好感知的模型来评估布局质量；DesignSense-10k数据集和DesignSense模型能显著提升布局生成的实际质量，证明了专门化布局感知偏好建模的实际价值

Abstract: Graphic layouts serve as an important and engaging medium for visual communication across different channels. While recent layout generation models have demonstrated impressive capabilities, they frequently fail to align with nuanced human aesthetic judgment. Existing preference datasets and reward models trained on text-to-image generation do not generalize to layout evaluation, where the spatial arrangement of identical elements determines quality. To address this critical gap, we introduce DesignSense-10k, a large-scale dataset of 10,235 human-annotated preference pairs for graphic layout evaluation. We propose a five-stage curation pipeline that generates visually coherent layout transformations across diverse aspect ratios, using semantic grouping, layout prediction, filtering, clustering, and VLM-based refinement to produce high-quality comparison pairs. Human preferences are annotated using a 4-class scheme (left, right, both good, both bad) to capture subjective ambiguity. Leveraging this dataset, we train DesignSense, a vision-language model-based classifier that substantially outperforms existing open-source and proprietary models across comprehensive evaluation metrics (54.6% improvement in Macro F1 over the strongest proprietary baseline). Our analysis shows that frontier VLMs remain unreliable overall and fail catastrophically on the full four-class task, underscoring the need for specialized, preference-aware models. Beyond the dataset, our reward model DesignSense yields tangible downstream gains in layout generation. Using our judge during RL based training improves generator win rate by about 3%, while inference-time scaling, which involves generating multiple candidates and selecting the best one, provides a 3.6% improvement. These results highlight the practical impact of specialized, layout-aware preference modeling on real-world layout generation quality.

</details>


### [2] [Modelling and Simulation of Neuromorphic Datasets for Anomaly Detection in Computer Vision](https://arxiv.org/abs/2602.23514)
*Mike Middleton,Teymoor Ali,Hakan Kayan,Basabdatta Sen Bhattacharya,Charith Perera,Oliver Rhodes,Elena Gheorghiu,Mark Vousden,Martin A. Trefzer*

Main category: cs.CV

TL;DR: ANTShapes是一个基于Unity引擎的神经形态视觉数据集仿真框架，用于解决动态视觉传感器数据稀缺问题，可生成包含异常行为物体的可配置3D场景数据集。


<details>
  <summary>Details</summary>
Motivation: 动态视觉传感器（DVS）的可用性有限，现有数据集样本数量少、场景有限，研究人员缺乏全面的神经形态视觉数据集仿真工具。

Method: 基于Unity引擎构建，模拟抽象可配置的3D场景，物体具有随机生成的行为属性（如运动和旋转），通过统计过程遵循中心极限定理原则对物体行为进行采样和异常标记。

Result: 开发了ANTShapes框架，可通过调整少量参数创建任意数量的数据集样本，并导出标签和帧数据，支持对象识别、定位和异常检测等应用。

Conclusion: ANTShapes解决了事件式计算机视觉研究中的数据可用性问题，允许研究人员根据特定目的模拟定制化数据集。

Abstract: Limitations on the availability of Dynamic Vision Sensors (DVS) present a fundamental challenge to researchers of neuromorphic computer vision applications. In response, datasets have been created by the research community, but often contain a limited number of samples or scenarios. To address the lack of a comprehensive simulator of neuromorphic vision datasets, we introduce the Anomalous Neuromorphic Tool for Shapes (ANTShapes), a novel dataset simulation framework. Built in the Unity engine, ANTShapes simulates abstract, configurable 3D scenes populated by objects displaying randomly-generated behaviours describing attributes such as motion and rotation. The sampling of object behaviours, and the labelling of anomalously-acting objects, is a statistical process following central limit theorem principles. Datasets containing an arbitrary number of samples can be created and exported from ANTShapes, along with accompanying label and frame data, through the adjustment of a limited number of parameters within the software. ANTShapes addresses the limitations of data availability to researchers of event-based computer vision by allowing for the simulation of bespoke datasets to suit purposes including object recognition and localisation alongside anomaly detection.

</details>


### [3] [All in One: Unifying Deepfake Detection, Tampering Localization, and Source Tracing with a Robust Landmark-Identity Watermark](https://arxiv.org/abs/2602.23523)
*Junjiang Wu,Liejun Wang,Zhiqing Guo*

Main category: cs.CV

TL;DR: 提出LIDMark统一主动取证框架，通过152维地标身份水印同时解决深度伪造检测、篡改定位和来源追踪三个任务


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术快速发展对个人隐私和社会安全构成威胁，现有主动取证方法通常将检测、定位和追踪作为独立任务处理，缺乏统一框架

Method: 提出LIDMark框架：1) 152维地标-身份水印，结构性地交织面部地标和唯一来源标识符；2) 因子化头部解码器，将共享骨干特征分解为回归头和分类头，分别重建地标和标识符

Result: 实验表明LIDMark框架提供了统一、鲁棒且不易察觉的解决方案，能够同时实现深度伪造内容的检测、定位和追踪

Conclusion: LIDMark框架通过创新的水印设计和解码器架构，实现了"三合一"的主动取证解决方案，为深度伪造取证提供了有效的统一框架

Abstract: With the rapid advancement of deepfake technology, malicious face manipulations pose a significant threat to personal privacy and social security. However, existing proactive forensics methods typically treat deepfake detection, tampering localization, and source tracing as independent tasks, lacking a unified framework to address them jointly. To bridge this gap, we propose a unified proactive forensics framework that jointly addresses these three core tasks. Our core framework adopts an innovative 152-dimensional landmark-identity watermark termed LIDMark, which structurally interweaves facial landmarks with a unique source identifier. To robustly extract the LIDMark, we design a novel Factorized-Head Decoder (FHD). Its architecture factorizes the shared backbone features into two specialized heads (i.e., regression and classification), robustly reconstructing the embedded landmarks and identifier, respectively, even when subjected to severe distortion or tampering. This design realizes an "all-in-one" trifunctional forensic solution: the regression head underlies an "intrinsic-extrinsic" consistency check for detection and localization, while the classification head robustly decodes the source identifier for tracing. Extensive experiments show that the proposed LIDMark framework provides a unified, robust, and imperceptible solution for the detection, localization, and tracing of deepfake content. The code is available at https://github.com/vpsg-research/LIDMark.

</details>


### [4] [Synthetic Visual Genome 2: Extracting Large-scale Spatio-Temporal Scene Graphs from Videos](https://arxiv.org/abs/2602.23543)
*Ziqi Gao,Jieyu Zhang,Wisdom Oluchi Ikezogwo,Jae Sung Park,Tario G. You,Daniel Ogbu,Chenhao Zheng,Weikai Huang,Yinuo Yang,Winson Han,Quan Kong,Rajat Saini,Ranjay Krishna*

Main category: cs.CV

TL;DR: SVG2是一个大规模全景视频场景图数据集，包含63.6万个视频、660万个对象、5200万个属性和670万个关系。基于此数据集训练的TRaSER模型在视频场景图生成任务上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有时空场景图数据集规模有限，缺乏多样性，限制了视频场景图生成模型的发展。需要更大规模、更多样化的数据集来推动该领域进步。

Method: 1) 创建SVG2数据集：采用全自动流水线，结合多尺度全景分割、在线-离线轨迹跟踪、自动新对象发现、轨迹语义解析和GPT-5时空关系推断。2) 训练TRaSER模型：引入轨迹对齐的token排列机制，包含对象轨迹重采样器和时间窗口重采样器，将原始视频和全景轨迹转换为紧凑的时空场景图。

Result: TRaSER在多个测试数据集上显著提升性能：关系检测提升15-20%，对象预测提升30-40%（比最强开源基线）和13%（比GPT-5），属性预测提升15%。生成的场景图用于视频问答时，相比仅使用视频或Qwen2.5-VL生成的场景图，准确率绝对提升1.5-4.6%。

Conclusion: SVG2数据集为视频场景图生成提供了大规模资源，TRaSER模型通过创新的轨迹对齐架构显著提升了场景图生成质量，证明了显式时空场景图作为中间表示的有效性。

Abstract: We introduce Synthetic Visual Genome 2 (SVG2), a large-scale panoptic video scene graph dataset. SVG2 contains over 636K videos with 6.6M objects, 52.0M attributes, and 6.7M relations, providing an order-of-magnitude increase in scale and diversity over prior spatio-temporal scene graph datasets. To create SVG2, we design a fully automated pipeline that combines multi-scale panoptic segmentation, online-offline trajectory tracking with automatic new-object discovery, per-trajectory semantic parsing, and GPT-5-based spatio-temporal relation inference. Building on this resource, we train TRaSER, a video scene graph generation model. TRaSER augments VLMs with a trajectory-aligned token arrangement mechanism and new modules: an object-trajectory resampler and a temporal-window resampler to convert raw videos and panoptic trajectories into compact spatio-temporal scene graphs in a single forward pass. The temporal-window resampler binds visual tokens to short trajectory segments to preserve local motion and temporal semantics, while the object-trajectory resampler aggregates entire trajectories to maintain global context for objects. On the PVSG, VIPSeg, VidOR and SVG2 test datasets, TRaSER improves relation detection by +15 to 20%, object prediction by +30 to 40% over the strongest open-source baselines and by +13% over GPT-5, and attribute prediction by +15%. When TRaSER's generated scene graphs are sent to a VLM for video question answering, it delivers a +1.5 to 4.6% absolute accuracy gain over using video only or video augmented with Qwen2.5-VL's generated scene graphs, demonstrating the utility of explicit spatio-temporal scene graphs as an intermediate representation.

</details>


### [5] [LE-NeuS: Latency-Efficient Neuro-Symbolic Video Understanding via Adaptive Temporal Verification](https://arxiv.org/abs/2602.23553)
*Shawn Liang,Sahil Shah,Chengwei Zhou,SP Sharan,Harsh Goel,Arnab Sanyal,Sandeep Chinchali,Gourav Datta*

Main category: cs.CV

TL;DR: LE-NeuS是一个延迟高效的神经符号框架，通过自适应采样和批量命题检测优化，将LVQA的延迟从90倍降低到约10倍，同时保持准确性优势。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号方法在长视频问答中虽然准确性高，但延迟开销过大（高达90倍），不适合延迟敏感的边缘部署，需要解决延迟问题。

Method: 采用两种优化：1) CLIP引导的两阶段自适应采样，利用视觉冗余跳过语义相似帧；2) 批量命题检测，在时间窗口上并行化VLM推理。

Result: 在LongVideoBench和Video-MME基准测试中，LE-NeuS将延迟差距从90倍降低到约10倍，同时在时间复杂查询上保持>10%的准确率提升。

Conclusion: LE-NeuS在保持神经符号方法准确性优势的同时，显著降低了推理延迟，为延迟敏感的边缘部署提供了实用的解决方案。

Abstract: Neuro-symbolic approaches to long-form video question answering (LVQA) have demonstrated significant accuracy improvements by grounding temporal reasoning in formal verification. However, existing methods incur prohibitive latency overheads, up to 90x slower than base VLM prompting, rendering them impractical for latency-sensitive edge deployments. We present LE-NeuS, a latency-efficient neuro-symbolic framework that preserves the accuracy benefits of temporal logic-guided video understanding while drastically reducing inference latency. Our key insight is that the dominant computational bottleneck arises from sequential and dense proposition detection across video frames during automaton construction. We address this through two principled optimizations: (1) CLIP guided two-stage adaptive sampling that exploits visual redundancy to skip semantically similar frames while preserving temporal boundaries, and (2) batched proposition detection that parallelizes VLM inference across temporal windows. Theoretically, we derive latency bounds as a function of video length, proposition complexity, and sampling density, establishing conditions under which latency efficiency is achievable. Empirically, on LongVideoBench and Video-MME benchmarks deployed on NVIDIA H100 GPUs, LE-NeuS reduces the latency gap from 90x to approximately 10x while maintaining >10% accuracy gains on temporally complex queries.

</details>


### [6] [No Calibration, No Depth, No Problem: Cross-Sensor View Synthesis with 3D Consistency](https://arxiv.org/abs/2602.23559)
*Cho-Ying Wu,Zixun Huang,Xinyu Huang,Liu Ren*

Main category: cs.CV

TL;DR: 提出首个跨传感器视图合成研究，解决RGB-X数据对齐的校准难题，通过匹配-稠密化-整合方法实现无需3D先验的跨模态视图合成


<details>
  <summary>Details</summary>
Motivation: 现有RGB-X研究大多假设已存在对齐的RGB-X数据对，专注于模态融合，但实际校准需要大量工程努力。本文旨在消除各种RGB-X传感器的繁琐校准，通过可扩展解决方案突破大规模真实世界RGB-X数据收集的瓶颈

Method: 提出匹配-稠密化-整合方法：1) 执行RGB-X图像匹配和引导点稠密化；2) 使用置信度感知稠密化和自匹配过滤获得更好的视图合成；3) 在3D高斯溅射(3DGS)中整合结果。方法不需要X传感器的3D先验，仅假设使用几乎无成本的COLMAP处理RGB数据

Result: 该方法实现了跨传感器视图合成，能够处理不同模态的RGB-X数据对齐问题，为大规模真实世界RGB-X数据收集提供了可扩展的解决方案

Conclusion: 该方法消除了RGB-X传感器的繁琐校准需求，通过突破数据收集瓶颈，有望推动跨传感器学习的普及和应用

Abstract: We present the first study of cross-sensor view synthesis across different modalities. We examine a practical, fundamental, yet widely overlooked problem: getting aligned RGB-X data, where most RGB-X prior work assumes such pairs exist and focuses on modality fusion, but it empirically requires huge engineering effort in calibration. We propose a match-densify-consolidate method. First, we perform RGB-X image matching followed by guided point densification. Using the proposed confidence-aware densification and self-matching filtering, we attain better view synthesis and later consolidate them in 3D Gaussian Splatting (3DGS). Our method uses no 3D priors for X-sensor and only assumes nearly no-cost COLMAP for RGB. We aim to remove the cumbersome calibration for various RGB-X sensors and advance the popularity of cross-sensor learning by a scalable solution that breaks through the bottleneck in large-scale real-world RGB-X data collection.

</details>


### [7] [Evidential Neural Radiance Fields](https://arxiv.org/abs/2602.23574)
*Ruxiao Duan,Alex Wong*

Main category: cs.CV

TL;DR: 提出Evidential Neural Radiance Fields，一种概率方法，能在单次前向传播中同时量化偶然和认知不确定性，提升NeRF的可信度


<details>
  <summary>Details</summary>
Motivation: 神经辐射场（NeRF）在场景重建和新视角合成方面取得显著进展，但缺乏不确定性估计限制了其在安全关键场景中的应用。现有方法无法同时捕捉偶然和认知不确定性，且往往牺牲渲染质量或计算成本过高

Method: 引入Evidential Neural Radiance Fields，一种概率方法，无缝集成到NeRF渲染过程中，通过单次前向传播直接量化偶然和认知不确定性

Result: 在三个标准化基准测试中，该方法展示了最先进的场景重建保真度和不确定性估计质量

Conclusion: 提出的方法解决了NeRF中不确定性量化的问题，实现了高质量渲染和高效不确定性估计的统一，为安全关键应用提供了可信的三维场景建模

Abstract: Understanding sources of uncertainty is fundamental to trustworthy three-dimensional scene modeling. While recent advances in neural radiance fields (NeRFs) achieve impressive accuracy in scene reconstruction and novel view synthesis, the lack of uncertainty estimation significantly limits their deployment in safety-critical settings. Existing uncertainty quantification methods for NeRFs fail to capture both aleatoric and epistemic uncertainty. Among those that do quantify one or the other, many of them either compromise rendering quality or incur significant computational overhead to obtain uncertainty estimates. To address these issues, we introduce Evidential Neural Radiance Fields, a probabilistic approach that seamlessly integrates with the NeRF rendering process and enables direct quantification of both aleatoric and epistemic uncertainty from a single forward pass. We compare multiple uncertainty quantification methods on three standardized benchmarks, where our approach demonstrates state-of-the-art scene reconstruction fidelity and uncertainty estimation quality.

</details>


### [8] [Hyperdimensional Cross-Modal Alignment of Frozen Language and Image Models for Efficient Image Captioning](https://arxiv.org/abs/2602.23588)
*Abhishek Dalvi,Vasant Honavar*

Main category: cs.CV

TL;DR: HDFLIM是一种无需微调预训练模型即可实现跨模态对齐的框架，通过将单模态嵌入投影到共享超维空间，利用轻量级符号操作构建关联表示，实现性能与端到端训练方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态对齐方法通常需要计算密集的多模态微调，涉及大规模参数更新、资源消耗大，且可能干扰预训练表示。研究发现独立训练的基座模型可能已存在潜在语义兼容性，这引发了一个基本问题：能否在不修改模型本身的情况下实现跨模态对齐？

Method: HDFLIM框架将预训练的视觉和语言模型完全冻结，将单模态嵌入投影到共享超维空间，利用绑定、捆绑和基于相似性的检索等轻量级符号操作，在单次数据遍历中构建关联的跨模态表示。标题生成通过高维记忆检索而非迭代的基于梯度的优化实现。

Result: HDFLIM实现了与端到端视觉语言训练方法相当的性能，生成的标题比零样本基线更具语义基础。通过将对齐与参数调优解耦，表明跨基座模型的语义映射可以通过对各自嵌入的超维编码进行符号操作来实现。

Conclusion: 这项工作指向了一种替代性的基座模型对齐范式，其中冻结模型通过结构化的表示映射而非大规模重新训练进行集成。HDFLIM展示了通过超维计算实现跨模态对齐的可行性，为资源高效的模型集成提供了新思路。

Abstract: Large unimodal foundation models for vision and language encode rich semantic structures, yet aligning them typically requires computationally intensive multimodal fine-tuning. Such approaches depend on large-scale parameter updates, are resource intensive, and can perturb pretrained representations. Emerging evidence suggests, however, that independently trained foundation models may already exhibit latent semantic compatibility, reflecting shared structures in the data they model. This raises a fundamental question: can cross-modal alignment be achieved without modifying the models themselves? Here we introduce HDFLIM (HyperDimensional computing with Frozen Language and Image Models), a framework that establishes cross-modal mappings while keeping pretrained vision and language models fully frozen. HDFLIM projects unimodal embeddings into a shared hyperdimensional space and leverages lightweight symbolic operations -- binding, bundling, and similarity-based retrieval to construct associative cross-modal representations in a single pass over the data. Caption generation emerges from high-dimensional memory retrieval rather than iterative gradient-based optimization. We show that HDFLIM achieves performance comparable to end-to-end vision-language training methods and produces captions that are more semantically grounded than zero-shot baselines. By decoupling alignment from parameter tuning, our results suggest that semantic mapping across foundation models can be realized through symbolic operations on hyperdimensional encodings of the respective embeddings. More broadly, this work points toward an alternative paradigm for foundation model alignment in which frozen models are integrated through structured representational mappings rather than through large-scale retraining. The codebase for our implementation can be found at https://github.com/Abhishek-Dalvi410/HDFLIM.

</details>


### [9] [Pseudo Contrastive Learning for Diagram Comprehension in Multimodal Models](https://arxiv.org/abs/2602.23589)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: 提出了一种新的训练范式，通过生成伪对比样本来增强视觉语言模型对图表结构的理解能力，在流程图理解任务上显著优于标准CLIP和hard-negative CLIP训练。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型（如CLIP）在视觉和语言表示对齐方面表现出色，但在需要精细结构理解的领域（如图表理解）仍面临挑战。图表中微小的视觉差异可能承载重要的语义信息，而现有模型对细粒度结构变化的敏感性有限。

Method: 提出新的训练范式，使用图表渲染器生成伪对比样本。这些样本通过随机选取文本元素创建合成图表，突出图表图像中的结构差异，而不需要修改原始数据。将这些伪对比样本纳入训练目标，使模型学习捕获更精确且语义一致的图表结构。

Result: 在流程图基准数据集上的实证评估显示，该方法在图像-文本匹配和视觉问答任务上都显著优于标准CLIP和hard-negative CLIP训练，取得了实质性改进。

Conclusion: 研究结果强调了领域特定训练策略的价值，为在更广泛的视觉语言学习背景下推进图表理解做出了贡献。该方法通过伪对比样本增强模型对图表结构的敏感性，有效提升了图表理解能力。

Abstract: Recent multimodal models such as Contrastive Language-Image Pre-training (CLIP) have shown remarkable ability to align visual and linguistic representations. However, domains where small visual differences carry large semantic significance, such as diagram understanding, remain challenging due to the models' limited sensitivity to fine-grained structural variations.
  We propose a new training paradigm designed to enhance diagram comprehension in vision-language models. Our approach introduces pseudo contrastive samples generated by a diagram renderer that creates synthetic diagrams using randomly picked text elements. These samples highlight structural differences in diagrammatic imagery without requiring any modification or editing of the original data. By incorporating these pseudo contrastive samples into the training objective, the model learns to capture more precise and semantically consistent diagram structures.
  Empirical evaluations on a benchmark dataset of flowcharts demonstrate substantial improvements over standard CLIP and hard-negative CLIP training in both image-text matching and visual question answering tasks. The results underscore the value of domain-specific training strategies and contribute to advancing diagrammatic understanding within the broader context of vision-language learning.

</details>


### [10] [Annotation-Free Visual Reasoning for High-Resolution Large Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2602.23615)
*Jiacheng Yang,Anqi Chen,Yunkai Dang,Qi Fan,Cong Wang,Wenbin Li,Feng Miao,Yang Gao*

Main category: cs.CV

TL;DR: HART是一个无需标注的高分辨率视觉推理框架，通过自验证关键区域定位来提升大模型处理高分辨率图像的能力。


<details>
  <summary>Details</summary>
Motivation: 当前大模型处理高分辨率视觉输入时面临图像token数量二次增长的问题，导致冗余和无关信息干扰。现有方法需要昂贵的人工标注来识别关键区域，如何在不依赖额外标注的情况下增强模型的定位能力是一个开放性问题。

Method: 提出HART框架，采用后训练范式，设计AP-GRPO（优势偏好组相对策略优化）来鼓励准确的关键区域定位，形成自验证的闭环系统。

Result: 实验表明HART在多种高分辨率视觉任务上表现优异，当应用于Qwen2.5-VL-7B时，甚至超越了更大规模的模型如Qwen2.5-VL-72B和LLaVA-OneVision-72B。

Conclusion: HART提供了一种无需标注的高分辨率视觉推理解决方案，通过自验证关键区域定位机制，显著提升了大模型处理高分辨率视觉输入的能力和效率。

Abstract: Current Large Multimodal Models (LMMs) struggle with high-resolution visual inputs during the reasoning process, as the number of image tokens increases quadratically with resolution, introducing substantial redundancy and irrelevant information. A common practice is to identify key image regions and refer to their high-resolution counterparts during reasoning, typically trained with external visual supervision. However, such visual supervision cues require costly grounding labels from human annotators. Meanwhile, it remains an open question how to enhance a model's grounding abilities to support reasoning without relying on additional annotations. In this paper, we propose High-resolution Annotation-free Reasoning Technique (HART), a closed-loop framework that enables LMMs to focus on and self-verify key regions of high-resolution visual inputs. HART incorporates a post-training paradigm in which we design Advantage Preference Group Relative Policy Optimization (AP-GRPO) to encourage accurate localization of key regions. Notably, HART provides explainable reasoning pathways and enables efficient optimization of localization. Extensive experiments demonstrate that HART improves performance across a wide range of high-resolution visual tasks, consistently outperforming strong baselines. When applied to post-train Qwen2.5-VL-7B, HART even surpasses larger-scale models such as Qwen2.5-VL-72B and LLaVA-OneVision-72B on high-resolution, vision-centric benchmarks.

</details>


### [11] [Egocentric Visibility-Aware Human Pose Estimation](https://arxiv.org/abs/2602.23618)
*Peng Dai,Yu Zhang,Yiqiang Feng,Zhen Fan,Yang Zhang*

Main category: cs.CV

TL;DR: 提出Eva-3M大规模数据集和EvaPose方法，解决第一人称视角姿态估计中的关键点不可见性问题


<details>
  <summary>Details</summary>
Motivation: 现有第一人称视角姿态估计方法忽视关键点不可见性问题，缺乏相关标注数据集，导致可见关键点预测精度受限

Method: 1) 构建Eva-3M数据集（300万帧，43.5万帧带可见性标注）；2) 为EMHI数据集添加可见性标注；3) 提出EvaPose方法，显式整合可见性信息提升姿态估计精度

Result: 实验验证了地面真实可见性标签在第一人称视角姿态估计中的重要性，EvaPose在Eva-3M和EMHI数据集上达到最先进性能

Conclusion: 关键点可见性标注对第一人称视角姿态估计至关重要，提出的数据集和方法有效解决了该问题，提升了姿态估计精度

Abstract: Egocentric human pose estimation (HPE) using a head-mounted device is crucial for various VR and AR applications, but it faces significant challenges due to keypoint invisibility. Nevertheless, none of the existing egocentric HPE datasets provide keypoint visibility annotations, and the existing methods often overlook the invisibility problem, treating visible and invisible keypoints indiscriminately during estimation. As a result, their capacity to accurately predict visible keypoints is compromised. In this paper, we first present Eva-3M, a large-scale egocentric visibility-aware HPE dataset comprising over 3.0M frames, with 435K of them annotated with keypoint visibility labels. Additionally, we augment the existing EMHI dataset with keypoint visibility annotations to further facilitate the research in this direction. Furthermore, we propose EvaPose, a novel egocentric visibility-aware HPE method that explicitly incorporates visibility information to enhance pose estimation accuracy. Extensive experiments validate the significant value of ground-truth visibility labels in egocentric HPE settings, and demonstrate that our EvaPose achieves state-of-the-art performance in both Eva-3M and EMHI datasets.

</details>


### [12] [DLEBench: Evaluating Small-scale Object Editing Ability for Instruction-based Image Editing Model](https://arxiv.org/abs/2602.23622)
*Shibo Hong,Boxian Ai,Jun Kuang,Wei Wang,FengJiao Chen,Zhongyuan Peng,Chenhao Huang,Yixin Cao*

Main category: cs.CV

TL;DR: 本文提出了首个专注于评估指令式图像编辑模型在小尺度物体编辑能力上的基准测试DLEBench，包含1889个样本和7种指令类型，并设计了双模式评估框架来解决LMM评估与人工判断之间的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 尽管指令式图像编辑模型在现有基准测试中表现出良好的指令遵循和推理能力，但它们在小物体编辑方面的能力尚未得到充分探索，而小物体编辑对于精确局部编辑和细节精修在实际应用和生成图像中都非常重要。

Method: 1. 构建DeepLookEditBench基准测试，包含1889个样本，目标物体仅占图像面积的1%-10%，涵盖部分遮挡和多物体编辑等复杂场景；2. 提出改进的评分标准以减少主观性和模糊性；3. 引入双模式评估框架（工具驱动模式和Oracle引导模式）来解决LMM评估与人工判断之间的偏差。

Result: 在10个指令式图像编辑模型上的实证结果显示，这些模型在小尺度物体编辑方面存在显著的性能差距，突显了需要专门基准测试来推进这一能力的发展。

Conclusion: DLEBench是首个专门评估小尺度物体编辑能力的基准测试，揭示了当前指令式图像编辑模型在这一重要任务上的局限性，为未来研究提供了评估框架和方向。

Abstract: Significant progress has been made in the field of Instruction-based Image Editing Models (IIEMs). However, while these models demonstrate plausible adherence to instructions and strong reasoning ability on current benchmarks, their ability to edit small objects remains underexplored, despite its importance for precise local editing and refining details in both real and generated images. In this paper, we introduce DeepLookEditBench (DLEBench), the first benchmark dedicated to assessing the abilities of IIEMs in editing small-scale objects. Specifically, we construct a challenging testbed comprising 1889 samples across seven instruction types. In these samples, target objects occupy only 1%-10% of the image area, covering complex scenarios such as partial occlusion and multi-object editing. To ensure robust evaluation on this benchmark, we propose an evaluation protocol with refined score rubrics to minimize subjectivity and ambiguity in two criteria: Instruction Following and Visual Consistency. This protocol also introduces a dual-mode evaluation framework (Tool-driven and Oracle-guided Modes) addressing the misalignment between LMM-as-a-Judge and human judgements on DLEBench. Empirical results on 10 IIEMs reveal significant performance gaps in small-scale object editing, highlighting the need for specialized benchmarks to advance this ability.

</details>


### [13] [BuildAnyPoint: 3D Building Structured Abstraction from Diverse Point Clouds](https://arxiv.org/abs/2602.23645)
*Tongyan Hua,Haoran Gong,Yuan Liu,Di Wang,Ying-Cong Chen,Wufan Zhao*

Main category: cs.CV

TL;DR: BuildAnyPoint是一个从点云进行结构化3D建筑重建的生成框架，通过松散级联扩散变换器(Loca-DiT)从噪声或稀疏点云恢复底层分布，然后自回归封装成紧凑网格


<details>
  <summary>Details</summary>
Motivation: 从具有不同分布的点云（如机载LiDAR和运动恢复结构）进行结构化3D建筑重建是一个高度欠约束的问题，需要恢复艺术家创建的建筑抽象

Method: 设计松散级联扩散变换器(Loca-DiT)：首先通过条件潜在扩散模型从输入点云恢复底层分布，然后使用仅解码器变换器基于恢复的点云进行条件自回归网格生成

Result: 在建筑抽象方法上取得显著的定性和定量改进，恢复的点云在建筑点云补全基准测试中表现出改进的表面精度和分布均匀性

Conclusion: BuildAnyPoint框架通过结合显式3D生成先验和自回归网格生成，有效解决了从多样化点云分布中进行结构化3D建筑重建的挑战

Abstract: We introduce BuildAnyPoint, a novel generative framework for structured 3D building reconstruction from point clouds with diverse distributions, such as those captured by airborne LiDAR and Structure-from-Motion. To recover artist-created building abstraction in this highly underconstrained setting, we capitalize on the role of explicit 3D generative priors in autoregressive mesh generation. Specifically, we design a Loosely Cascaded Diffusion Transformer (Loca-DiT) that initially recovers the underlying distribution from noisy or sparse points, followed by autoregressively encapsulating them into compact meshes. We first formulate distribution recovery as a conditional generation task by training latent diffusion models conditioned on input point clouds, and then tailor a decoder-only transformer for conditional autoregressive mesh generation based on the recovered point clouds. Our method delivers substantial qualitative and quantitative improvements over prior building abstraction methods. Furthermore, the effectiveness of our approach is evidenced by the strong performance of its recovered point clouds on building point cloud completion benchmarks, which exhibit improved surface accuracy and distribution uniformity.

</details>


### [14] [3D Modality-Aware Pre-training for Vision-Language Model in MRI Multi-organ Abnormality Detection](https://arxiv.org/abs/2602.23652)
*Haowen Zhu,Ning Yin,Xiaogen Zhou*

Main category: cs.CV

TL;DR: MedMAP是一个医学模态感知预训练框架，通过模态感知的视觉-语言对齐和微调阶段，提升3D MRI中多器官异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 将视觉语言模型应用于多器官医学影像面临两个主要挑战：模态特定的视觉-语言对齐和跨模态特征融合。现有方法在3D MRI多器官异常检测方面存在局限性。

Method: 提出MedMAP框架，包括两个阶段：1) 模态感知的视觉-语言对齐预训练阶段，模态感知编码器隐式捕获联合模态分布；2) 微调阶段，使用预训练的视觉编码器（文本编码器冻结）进行下游任务。同时构建了MedMoM-MRI3D数据集，包含7,392个3D MRI-报告对。

Result: 在MedMoM-MRI3D数据集上的广泛实验表明，MedMAP在3D MRI多器官异常检测任务上显著优于现有的视觉语言模型。

Conclusion: MedMAP通过模态感知的预训练框架有效解决了多器官医学影像中的视觉-语言对齐和特征融合问题，在3D MRI异常检测任务上取得了优异性能。

Abstract: Vision-language models (VLMs) show strong potential for complex diagnostic tasks in medical imaging. However, applying VLMs to multi-organ medical imaging introduces two principal challenges: (1) modality-specific vision-language alignment and (2) cross-modal feature fusion. In this work, we propose MedMAP, a Medical Modality-Aware Pretraining framework that enhances vision-language representation learning in 3D MRI. MedMAP comprises a modality-aware vision-language alignment stage and a fine-tuning stage for multi-organ abnormality detection. During the pre-training stage, the modality-aware encoders implicitly capture the joint modality distribution and improve alignment between visual and textual representations. We then fine-tune the pre-trained vision encoders (while keeping the text encoder frozen) for downstream tasks. To this end, we curated MedMoM-MRI3D, comprising 7,392 3D MRI volume-report pairs spanning twelve MRI modalities and nine abnormalities tailored for various 3D medical analysis tasks. Extensive experiments on MedMoM-MRI3D demonstrate that MedMAP significantly outperforms existing VLMs in 3D MRI-based multi-organ abnormality detection. Our code is available at https://github.com/RomantiDr/MedMAP.

</details>


### [15] [ProtoDCS: Towards Robust and Efficient Open-Set Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2602.23653)
*Wei Luo,Yangfan Ou,Jin Deng,Zeshuai Deng,Xiquan Yan,Zhiquan Wen,Mingkui Tan*

Main category: cs.CV

TL;DR: ProtoDCS：一种用于视觉语言模型的开集测试时自适应框架，通过概率双重检查分离机制和证据驱动适应策略，有效处理协变量偏移的分布内和分布外数据。


<details>
  <summary>Details</summary>
Motivation: 现有VLM测试时自适应方法在开集场景下存在局限：依赖硬阈值分离和熵最小化策略，容易错误分类模糊的分布外样本，产生过度自信预测，且参数更新机制计算成本高。

Method: 提出原型双重检查分离框架：1）使用概率高斯混合模型验证代替脆弱的阈值分离；2）采用证据驱动适应策略，利用不确定性感知损失和高效原型级更新。

Result: 在CIFAR-10/100-C和Tiny-ImageNet-C数据集上的实验表明，ProtoDCS在已知类别准确率和OOD检测指标上均达到最先进性能。

Conclusion: ProtoDCS为视觉语言模型提供了一种鲁棒、高效的开集测试时自适应解决方案，显著提升了在协变量偏移场景下的性能表现。

Abstract: Large-scale Vision-Language Models (VLMs) exhibit strong zero-shot recognition, yet their real-world deployment is challenged by distribution shifts. While Test-Time Adaptation (TTA) can mitigate this, existing VLM-based TTA methods operate under a closed-set assumption, failing in open-set scenarios where test streams contain both covariate-shifted in-distribution (csID) and out-of-distribution (csOOD) data. This leads to a critical difficulty: the model must discriminate unknown csOOD samples to avoid interference while simultaneously adapting to known csID classes for accuracy. Current open-set TTA (OSTTA) methods rely on hard thresholds for separation and entropy minimization for adaptation. These strategies are brittle, often misclassifying ambiguous csOOD samples and inducing overconfident predictions, and their parameter-update mechanism is computationally prohibitive for VLMs. To address these limitations, we propose Prototype-based Double-Check Separation (ProtoDCS), a robust framework for OSTTA that effectively separates csID and csOOD samples, enabling safe and efficient adaptation of VLMs to csID data. Our main contributions are: (1) a novel double-check separation mechanism employing probabilistic Gaussian Mixture Model (GMM) verification to replace brittle thresholding; and (2) an evidence-driven adaptation strategy utilizing uncertainty-aware loss and efficient prototype-level updates, mitigating overconfidence and reducing computational overhead. Extensive experiments on CIFAR-10/100-C and Tiny-ImageNet-C demonstrate that ProtoDCS achieves state-of-the-art performance, significantly boosting both known-class accuracy and OOD detection metrics. Code will be available at https://github.com/O-YangF/ProtoDCS.

</details>


### [16] [Suppressing Prior-Comparison Hallucinations in Radiology Report Generation via Semantically Decoupled Latent Steering](https://arxiv.org/abs/2602.23676)
*Ao Li,Rui Liu,Mingjie Li,Sheng Liu,Lei Wang,Xiaodan Liang,Lina Yao,Xiaojun Chang,Lei Xing*

Main category: cs.CV

TL;DR: 提出SDLS框架，通过语义解耦的潜在向量控制，在推理时无需训练即可减少放射学报告生成中的历史比较幻觉，同时保持临床准确性。


<details>
  <summary>Details</summary>
Motivation: 基于视觉语言模型的自动放射学报告生成存在历史比较幻觉风险，即模型生成当前研究不支持的历史发现。现有方法在幻觉抑制和临床准确性之间存在权衡。

Method: 提出语义解耦潜在控制(SDLS)框架：1) 使用LLM进行语义分解；2) 通过QR正交化构建语义无关的干预向量；3) 利用几何约束过滤临床语义，确保只针对"历史比较"轴进行控制。

Result: 在BiomedGPT模型上验证，显著减少历史幻觉(FilBERT分数从0.2373降至0.1889)，提高临床标签保真度(CheXpert macro-F1从0.2242提升至0.3208)，在MIMIC-CXR、CheXpert Plus和IU-Xray数据集上表现稳健。

Conclusion: SDLS框架成功解决了放射学报告生成中历史比较幻觉问题，克服了幻觉抑制与临床准确性之间的权衡，同时保持了临床叙述的结构完整性。

Abstract: Automated radiology report generation using vision-language models (VLMs) is limited by the risk of prior-comparison hallucination, where the model generates historical findings unsupported by the current study. We address this challenge with a training-free, inference-time control framework termed Semantically Decoupled Latent Steering (SDLS). Unlike generic activation steering, which often suffers from semantic entanglement, our approach constructs a semantic-free intervention vector via large language model (LLM)-driven semantic decomposition followed by $QR$-based orthogonalization. This orthogonalization step is critical. It leverages geometric constraints to filter out the clinical semantics often entangled in standard principal component analysis (PCA) directions, ensuring that the steering vector targets only the ``historical comparison" axis. We validate our method on the BiomedGPT foundation model, demonstrating that it overcomes the trade-off between hallucination suppression and clinical accuracy. Extensive experiments on MIMIC-CXR, and zero-shot transfer evaluation on CheXpert Plus and IU-Xray, demonstrate the robustness of our approach. Quantitative evaluations on MIMIC-CXR show that our approach significantly reduces the probability of historical hallucinations (FilBERT score decreases from 0.2373 to 0.1889) and improves clinical label fidelity (CheXpert macro-F1 increases from 0.2242 to 0.3208). Supplementary evaluations confirm that the structural integrity of the clinical narrative is maintained.

</details>


### [17] [Vision-Language Semantic Grounding for Multi-Domain Crop-Weed Segmentation](https://arxiv.org/abs/2602.23677)
*Nazia Hossain,Xintong Jiang,Yu Tian,Philippe Seguin,O. Grant Clark,Shangpeng Sun*

Main category: cs.CV

TL;DR: 提出VL-WS框架，通过视觉-语言对齐实现跨域泛化的细粒度作物-杂草分割，在四个基准数据集上平均Dice分数达91.64%，比CNN基线提升4.98%


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在异构农业环境中泛化能力不足，主要依赖数据集特定的视觉特征，难以适应多样化的作物类型、杂草种类、生长阶段和传感条件

Method: 采用双编码器设计，融合冻结的CLIP嵌入和任务特定的空间特征，通过FiLM层进行特征调制，使用自然语言描述指导通道级特征细化，同时保持细粒度空间定位

Result: 在四个基准数据集上平均Dice分数达91.64%，比CNN基线提升4.98%；最具挑战性的杂草类别Dice分数达80.45%，比最佳基线提升15.42%；在有限目标域监督下保持稳定性能

Conclusion: 视觉-语言对齐能够实现可扩展、标签高效的跨域分割模型，在多样化真实农业场景中具有部署潜力

Abstract: Fine-grained crop-weed segmentation is essential for enabling targeted herbicide application in precision agriculture. However, existing deep learning models struggle to generalize across heterogeneous agricultural environments due to reliance on dataset-specific visual features. We propose Vision-Language Weed Segmentation (VL-WS), a novel framework that addresses this limitation by grounding pixel-level segmentation in semantically aligned, domain-invariant representations. Our architecture employs a dual-encoder design, where frozen Contrastive Language-Image Pretraining (CLIP) embeddings and task-specific spatial features are fused and modulated via Feature-wise Linear Modulation (FiLM) layers conditioned on natural language captions. This design enables image level textual descriptions to guide channel-wise feature refinement while preserving fine-grained spatial localization. Unlike prior works restricted to training and evaluation on single-source datasets, VL-WS is trained on a unified corpus that includes close-range ground imagery (robotic platforms) and high-altitude UAV imagery, covering diverse crop types, weed species, growth stages, and sensing conditions. Experimental results across four benchmark datasets demonstrate the effectiveness of our framework, with VL-WS achieving a mean Dice score of 91.64% and outperforming the CNN baseline by 4.98%. The largest gains occur on the most challenging weed class, where VL-WS attains 80.45% Dice score compared to 65.03% for the best baseline, representing a 15.42% improvement. VL-WS further maintains stable weed segmentation performance under limited target-domain supervision, indicating improved generalization and data efficiency. These findings highlight the potential of vision-language alignment to enable scalable, label-efficient segmentation models deployable across diverse real-world agricultural domains.

</details>


### [18] [Any Model, Any Place, Any Time: Get Remote Sensing Foundation Model Embeddings On Demand](https://arxiv.org/abs/2602.23678)
*Dingqi Ye,Daniel Kiv,Wei Hu,Jimeng Shi,Shaowen Wang*

Main category: cs.CV

TL;DR: rs-embed是一个Python库，为遥感基础模型提供统一的ROI中心接口，简化嵌入获取和比较


<details>
  <summary>Details</summary>
Motivation: 遥感基础模型快速增长，但模型发布格式、平台接口和数据规范存在显著异质性，导致实际采用和公平比较困难，增加了获取、使用和基准测试嵌入的成本

Method: 开发rs-embed Python库，提供统一的感兴趣区域（ROI）中心接口，支持单行代码从任何支持的模型获取任何位置和时间范围的嵌入，并提供高效的批量处理功能

Result: 成功开发了rs-embed库，代码已在GitHub开源，能够简化遥感基础模型的嵌入获取、使用和比较过程

Conclusion: rs-embed通过统一接口解决了遥感基础模型异质性带来的挑战，降低了嵌入获取和比较的成本，促进了模型的实际采用和公平评估

Abstract: The remote sensing community is witnessing a rapid growth of foundation models, which provide powerful embeddings for a wide range of downstream tasks. However, practical adoption and fair comparison remain challenging due to substantial heterogeneity in model release formats, platforms and interfaces, and input data specifications. These inconsistencies significantly increase the cost of obtaining, using, and benchmarking embeddings across models. To address this issue, we propose rs-embed, a Python library that offers a unified, region of interst (ROI) centric interface: with a single line of code, users can retrieve embeddings from any supported model for any location and any time range. The library also provides efficient batch processing to enable large-scale embedding generation and evaluation. The code is available at: https://github.com/cybergis/rs-embed

</details>


### [19] [Towards Source-Aware Object Swapping with Initial Noise Perturbation](https://arxiv.org/abs/2602.23697)
*Jiahui Zhan,Xianbing Sun,Xiangnan Zhu,Yikun Ji,Ruitong Liu,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: SourceSwap提出了一种自监督、源感知的对象交换框架，通过频率分离扰动生成高质量伪配对数据，无需微调即可实现零样本推理，在对象保真度、场景保真度和对象-场景和谐度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有对象交换方法要么需要针对每个对象进行微调和缓慢推理，要么依赖额外的配对数据（通常描绘相同对象在不同上下文中的情况），迫使模型依赖背景线索而非学习跨对象对齐。

Method: 提出SourceSwap框架：1）通过初始噪声空间中的频率分离扰动合成高质量伪配对数据，改变外观同时保持姿态、粗略形状和场景布局；2）训练具有全源条件化和无噪声参考编码器的双U-Net；3）引入SourceBench高质量基准测试集。

Result: SourceSwap在对象保真度、场景保真度和对象-场景和谐度方面表现优异，支持零样本推理无需微调，并能很好地迁移到主题驱动细化和人脸交换等编辑任务。

Conclusion: SourceSwap通过自监督学习和频率分离扰动实现了高质量的跨对象对齐，为对象交换任务提供了高效、高质量的解决方案，无需额外数据或微调即可实现零样本推理。

Abstract: Object swapping aims to replace a source object in a scene with a reference object while preserving object fidelity, scene fidelity, and object-scene harmony. Existing methods either require per-object finetuning and slow inference or rely on extra paired data that mostly depict the same object across contexts, forcing models to rely on background cues rather than learning cross-object alignment. We propose SourceSwap, a self-supervised and source-aware framework that learns cross-object alignment. Our key insight is to synthesize high-quality pseudo pairs from any image via a frequency-separated perturbation in the initial-noise space, which alters appearance while preserving pose, coarse shape, and scene layout, requiring no videos, multi-view data, or additional images. We then train a dual U-Net with full-source conditioning and a noise-free reference encoder, enabling direct inter-object alignment, zero-shot inference without per-object finetuning, and lightweight iterative refinement. We further introduce SourceBench, a high-quality benchmark with higher resolution, more categories, and richer interactions. Experiments demonstrate that SourceSwap achieves superior fidelity, stronger scene preservation, and more natural harmony, and it transfers well to edits such as subject-driven refinement and face swapping.

</details>


### [20] [HiDrop: Hierarchical Vision Token Reduction in MLLMs via Late Injection, Concave Pyramid Pruning, and Early Exit](https://arxiv.org/abs/2602.23699)
*Hao Wu,Yingqi Fan,Jinyang Dai,Junlong Tong,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: HiDrop是一个高效的多模态大语言模型框架，通过层级化视觉token剪枝和延迟注入技术，压缩约90%视觉token，保持性能的同时加速训练1.72倍。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型中视觉token的二次计算成本阻碍了其广泛应用。现有的渐进式视觉token剪枝方法误解了浅层功能并使用刚性调度，未能充分发挥效率潜力。

Method: 提出HiDrop框架，包含两个关键创新：1) 延迟注入技术，绕过被动的浅层，在主动融合开始处引入视觉token；2) 凹形金字塔剪枝配合早期退出机制，通过层间相似性度量和可微分top-k算子动态调整中间层和深层的剪枝率。此外还包含持久位置编码、FlashAttention兼容的token选择和并行解耦视觉计算等技术。

Result: 实验表明HiDrop压缩约90%视觉token的同时匹配原始性能，训练加速1.72倍，为高效MLLM训练和推理设定了新的最先进水平。

Conclusion: HiDrop不仅为高效MLLM训练和推理设定了新的最先进水平，还提供了关于多模态融合层级性质的有价值见解。

Abstract: The quadratic computational cost of processing vision tokens in Multimodal Large Language Models (MLLMs) hinders their widespread adoption. While progressive vision token pruning offers a promising solution, current methods misinterpret shallow layer functions and use rigid schedules, which fail to unlock the full efficiency potential. To address these issues, we propose HiDrop, a framework that aligns token pruning with the true hierarchical function of MLLM layers. HiDrop features two key innovations: (1) Late Injection, which bypasses passive shallow layers to introduce visual tokens exactly where active fusion begins; and (2) Concave Pyramid Pruning with an Early Exit mechanism to dynamically adjust pruning rates across middle and deep layers. This process is optimized via an inter-layer similarity measure and a differentiable top-k operator. To ensure practical efficiency, HiDrop further incorporates persistent positional encoding, FlashAttention-compatible token selection, and parallel decoupling of vision computation to eliminate hidden overhead associated with dynamic token reduction. Extensive experiments show that HiDrop compresses about 90% visual tokens while matching the original performance and accelerating training by 1.72 times. Our work not only sets a new state-of-the-art for efficient MLLM training and inference but also provides valuable insights into the hierarchical nature of multimodal fusion. The code is released at https://github.com/EIT-NLP/HiDrop.

</details>


### [21] [EgoGraph: Temporal Knowledge Graph for Egocentric Video Understanding](https://arxiv.org/abs/2602.23709)
*Shitong Sun,Ke Han,Yukai Huang,Weitong Cai,Jifei Song*

Main category: cs.CV

TL;DR: EgoGraph是一个无需训练的、动态的知识图谱构建框架，用于处理超长第一人称视角视频，通过编码长期跨实体依赖关系来提升视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频理解方法在处理跨越多天的超长第一人称视角视频时存在局限性，主要依赖碎片化的局部处理和有限的时序建模，无法有效推理这种超长序列。

Method: 提出EgoGraph框架，采用统一的第一人称视角模式来提取和抽象核心实体（人物、物体、地点、事件），结构化地推理其属性和交互关系，并开发了时序关系建模策略来捕捉跨实体的时序依赖和积累多天的稳定长期记忆。

Result: 在EgoLifeQA和EgoR1-bench基准测试上的广泛实验表明，EgoGraph在长期视频问答任务上达到了最先进的性能。

Conclusion: EgoGraph为超长第一人称视角视频理解提供了一个新的有效范式，能够显著提升语义表示的丰富性和连贯性。

Abstract: Ultra-long egocentric videos spanning multiple days present significant challenges for video understanding. Existing approaches still rely on fragmented local processing and limited temporal modeling, restricting their ability to reason over such extended sequences. To address these limitations, we introduce EgoGraph, a training-free and dynamic knowledge-graph construction framework that explicitly encodes long-term, cross-entity dependencies in egocentric video streams. EgoGraph employs a novel egocentric schema that unifies the extraction and abstraction of core entities, such as people, objects, locations, and events, and structurally reasons about their attributes and interactions, yielding a significantly richer and more coherent semantic representation than traditional clip-based video models. Crucially, we develop a temporal relational modeling strategy that captures temporal dependencies across entities and accumulates stable long-term memory over multiple days, enabling complex temporal reasoning. Extensive experiments on the EgoLifeQA and EgoR1-bench benchmarks demonstrate that EgoGraph achieves state-of-the-art performance on long-term video question answering, validating its effectiveness as a new paradigm for ultra-long egocentric video understanding.

</details>


### [22] [Can Unified Generation and Understanding Models Maintain Semantic Equivalence Across Different Output Modalities?](https://arxiv.org/abs/2602.23711)
*Hongbo Jiang,Jie Li,Yunhang Shen,Pingyang Dai,Xing Sun,Haoyu Cao,Liujuan Cao*

Main category: cs.CV

TL;DR: 研究发现统一多模态大语言模型在文本推理方面表现良好，但在生成视觉答案时语义一致性崩溃，问题源于跨模态语义对齐失败而非生成保真度不足。


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态大语言模型评估通常将理解和生成能力分开评估，忽略了语义等价性——即无论输出模态如何都能表现一致推理结果的能力。本研究旨在探究当前U-MLLMs是否满足这一前提。

Method: 引入VGUBench框架，通过三个诊断任务解耦推理逻辑与生成保真度：1)文本生成理解（建立文本响应推理准确性基线）；2)视觉生成理解（评估生成正确视觉答案的能力）；3)视觉渲染控制任务（评估直接将显式视觉描述渲染为图像的能力，无需复杂推理）。

Result: 评估显示显著差异：尽管在文本理解和视觉渲染方面表现强劲，但U-MLLMs在需要生成视觉答案时表现出明显的性能崩溃。视觉回答性能与基本渲染质量之间几乎没有相关性。

Conclusion: 失败源于跨模态语义对齐的崩溃，而非生成保真度不足。研究为未来统一生成与理解模型提供了诊断见解，以解决这一挑战。

Abstract: Unified Multimodal Large Language Models (U-MLLMs) integrate understanding and generation within a single architecture. However, existing evaluations typically assess these capabilities separately, overlooking semantic equivalence, i.e., the ability to manifest consistent reasoning results regardless of the output modality. In this work, we investigate whether current U-MLLMs satisfy this premise. We observe that while models demonstrate robust textual reasoning, they fail to maintain semantic equivalence when required to render the same results in the image modality. To rigorously diagnose this discrepancy, we introduce VGUBench, a framework to decouple reasoning logic from generation fidelity. VGUBench comprises three diagnostic tasks: (1)Textual Generative Understanding, establishing a baseline for reasoning accuracy in textual response; (2)Visual Generative Understanding, evaluating the ability to generate visual responses that represent the correct answer; and (3)a Visual Rendering control task, which assesses the ability to directly render explicit visual descriptions into images without complex reasoning. Our evaluation reveals a significant disparity: despite strong performance in textual understanding and visual rendering, U-MLLMs exhibit a marked performance collapse when required to generate visual answers to questions. Furthermore, we find a negligible correlation between visual answering performance and basic rendering quality. These results suggest that the failure stems not from insufficient generation fidelity, but from a breakdown in cross-modal semantic alignment. We provide diagnostic insights to address this challenge in future Unified Generation and Understanding Models.

</details>


### [23] [A Difference-in-Difference Approach to Detecting AI-Generated Images](https://arxiv.org/abs/2602.23732)
*Xinyi Qi,Kai Ye,Chengchun Shi,Ying Yang,Hongyi Zhou,Jin Zhu*

Main category: cs.CV

TL;DR: 提出基于二阶差分（重建误差的差异）的AI生成图像检测方法，相比传统一阶差分方法在生成图像越来越逼真的情况下表现更好


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的AI图像几乎与真实图像无法区分，这带来了滥用风险，而现有基于重建误差的检测器在AI图像越来越逼真的情况下效果下降

Method: 提出差分中的差分方法，不直接使用重建误差（一阶差分），而是计算重建误差的差异（二阶差分），通过方差降低来提高检测准确率

Result: 大量实验表明该方法实现了强大的泛化性能，能够在生成式AI时代可靠地检测AI生成图像

Conclusion: 二阶差分方法相比传统一阶差分方法能更有效地检测越来越逼真的AI生成图像，为解决生成式AI带来的检测挑战提供了新思路

Abstract: Diffusion models are able to produce AI-generated images that are almost indistinguishable from real ones. This raises concerns about their potential misuse and poses substantial challenges for detecting them. Many existing detectors rely on reconstruction error -- the difference between the input image and its reconstructed version -- as the basis for distinguishing real from fake images. However, these detectors become less effective as modern AI-generated images become increasingly similar to real ones. To address this challenge, we propose a novel difference-in-difference method. Instead of directly using the reconstruction error (a first-order difference), we compute the difference in reconstruction error -- a second-order difference -- for variance reduction and improving detection accuracy. Extensive experiments demonstrate that our method achieves strong generalization performance, enabling reliable detection of AI-generated images in the era of generative AI.

</details>


### [24] [UTPTrack: Towards Simple and Unified Token Pruning for Visual Tracking](https://arxiv.org/abs/2602.23734)
*Hao Wu,Xudong Wang,Jialiang Zhang,Junlong Tong,Xinghao Chen,Junyan Lin,Yunpu Ma,Xiaoyu Shen*

Main category: cs.CV

TL;DR: UTPTrack提出统一令牌剪枝框架，首次联合压缩搜索区域、动态模板和静态模板三个组件，在保持性能的同时大幅减少计算开销，在RGB和多模态跟踪中都实现了最优的精度-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的跟踪器虽然性能先进，但计算开销大阻碍实时部署。现有令牌剪枝方法分散地处理不同组件，忽视了组件间的依赖关系，导致次优剪枝和精度下降。

Method: 提出UTPTrack统一令牌剪枝框架，采用注意力引导、令牌类型感知策略来整体建模冗余，支持单模型内统一处理多模态和语言引导的跟踪任务。

Result: 在10个基准测试中，UTPTrack在剪枝类跟踪器中达到最优的精度-效率权衡：RGB跟踪剪除65.4%视觉令牌保持99.7%基线性能，统一跟踪剪除67.5%令牌保持100.5%基线性能。

Conclusion: UTPTrack首次实现三个组件的联合压缩，在RGB和多模态场景中都表现出色，为高效视觉跟踪研究提供了坚实基础。

Abstract: One-stream Transformer-based trackers achieve advanced performance in visual object tracking but suffer from significant computational overhead that hinders real-time deployment. While token pruning offers a path to efficiency, existing methods are fragmented. They typically prune the search region, dynamic template, and static template in isolation, overlooking critical inter-component dependencies, which yields suboptimal pruning and degraded accuracy. To address this, we introduce UTPTrack, a simple and Unified Token Pruning framework that, for the first time, jointly compresses all three components. UTPTrack employs an attention-guided, token type-aware strategy to holistically model redundancy, a design that seamlessly supports unified tracking across multimodal and language-guided tasks within a single model. Extensive evaluations on 10 benchmarks demonstrate that UTPTrack achieves a new state-of-the-art in the accuracy-efficiency trade-off for pruning-based trackers, pruning 65.4% of vision tokens in RGB-based tracking and 67.5% in unified tracking while preserving 99.7% and 100.5% of baseline performance, respectively. This strong performance across both RGB and multimodal scenarios underlines its potential as a robust foundation for future research in efficient visual tracking. Code will be released at https://github.com/EIT-NLP/UTPTrack.

</details>


### [25] [Learning Accurate Segmentation Purely from Self-Supervision](https://arxiv.org/abs/2602.23759)
*Zuyao You,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: Selfment是一个完全自监督的框架，无需人工标注、预训练分割模型或后处理，直接从原始图像分割前景对象。它通过构建补丁级亲和力图、应用NCut获得初始分割，然后通过迭代补丁优化进行特征空间细化，最后训练轻量级分割头实现可迁移的对象表示。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉中，无需人工标注准确分割对象仍然是一个核心挑战。现有方法通常依赖人工标注、预训练模型或复杂的后处理，限制了其可扩展性和泛化能力。

Method: 1. 从自监督特征构建补丁级亲和力图，应用NCut获得初始前景-背景分离；2. 引入迭代补丁优化(IPO)，通过迭代补丁聚类在特征空间中进行细化，增强空间一致性和语义一致性；3. 使用细化后的掩码作为监督信号，训练轻量级分割头，采用对比学习和区域一致性目标。

Result: 在多个基准测试中达到新的最先进水平：在ECSSD上F_max提升4.0%，HKUIS提升4.6%，PASCAL-S提升5.7%。在零样本泛化到伪装对象检测任务中表现优异：CHAMELEON上Sm达到0.910，CAMO上Fβ^ω达到0.792，超越了所有现有无监督方法，甚至可与全监督最先进方法媲美。

Conclusion: Selfment通过完全自监督的方式实现了高质量的对象分割，无需任何人工干预。该方法简单有效，在多个基准测试中表现出色，并展示了强大的零样本泛化能力，为无监督对象分割提供了新的解决方案。

Abstract: Accurately segmenting objects without any manual annotations remains one of the core challenges in computer vision. In this work, we introduce Selfment, a fully self-supervised framework that segments foreground objects directly from raw images without human labels, pretrained segmentation models, or any post-processing. Selfment first constructs patch-level affinity graphs from self-supervised features and applies NCut to obtain an initial coarse foreground--background separation. We then introduce Iterative Patch Optimization (IPO), a feature-space refinement procedure that progressively enforces spatial coherence and semantic consistency through iterative patch clustering. The refined masks are subsequently used as supervisory signals to train a lightweight segmentation head with contrastive and region-consistency objectives, allowing the model to learn stable and transferable object representations. Despite its simplicity and complete absence of manual supervision, Selfment sets new state-of-the-art (SoTA) results across multiple benchmarks. It achieves substantial improvements on $F_{\max}$ over previous unsupervised saliency detection methods on ECSSD ($+4.0\%$), HKUIS ($+4.6\%$), and PASCAL-S ($+5.7\%$). Moreover, without any additional fine-tuning, Selfment demonstrates remarkable zero-shot generalization to camouflaged object detection tasks (e.g., $0.910$ $S_m$ on CHAMELEON and $0.792$ $F_β^ω$ on CAMO), outperforming all existing unsupervised approaches and even rivaling the SoTA fully supervised methods.

</details>


### [26] [Fourier Angle Alignment for Oriented Object Detection in Remote Sensing](https://arxiv.org/abs/2602.23790)
*Changyu Gu,Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 本文提出Fourier Angle Alignment方法解决遥感旋转目标检测中的方向不一致和任务冲突问题，通过傅里叶旋转等变性分析角度信息，并设计了FAAFusion和FAA Head两个即插即用模块，在多个数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 当前遥感旋转目标检测方法存在两个主要瓶颈：1）检测器颈部存在方向不一致问题；2）检测头部存在任务冲突问题。这些问题限制了旋转目标检测的性能。

Method: 利用傅里叶旋转等变性，提出Fourier Angle Alignment方法，通过频谱分析角度信息并将主方向对齐到特定方向。设计了两个即插即用模块：FAAFusion（在检测器颈部工作，将高层特征的主方向与低层特征对齐并融合）和FAA Head（作为新的检测头，将RoI特征预对齐到规范角度后添加到原始特征中，再进行分类和回归）。

Result: 在DOTA-v1.0、DOTA-v1.5和HRSC2016数据集上的实验表明，该方法能显著提升现有工作性能。特别是在单尺度训练和测试下，在DOTA-v1.0上达到78.72% mAP，在DOTA-v1.5上达到72.28% mAP，创造了新的SOTA结果。

Conclusion: 提出的Fourier Angle Alignment方法有效解决了遥感旋转目标检测中的方向不一致和任务冲突问题，通过傅里叶角度对齐和两个创新模块的设计，在多个基准数据集上取得了最先进的性能，验证了方法的有效性。

Abstract: In remote sensing rotated object detection, mainstream methods suffer from two bottlenecks, directional incoherence at detector neck and task conflict at detecting head. Ulitising fourier rotation equivariance, we introduce Fourier Angle Alignment, which analyses angle information through frequency spectrum and aligns the main direction to a certain orientation. Then we propose two plug and play modules : FAAFusion and FAA Head. FAAFusion works at the detector neck, aligning the main direction of higher-level features to the lower-level features and then fusing them. FAA Head serves as a new detection head, which pre-aligns RoI features to a canonical angle and adds them to the original features before classification and regression. Experiments on DOTA-v1.0, DOTA-v1.5 and HRSC2016 show that our method can greatly improve previous work. Particularly, our method achieves new state-of-the-art results of 78.72% mAP on DOTA-v1.0 and 72.28% mAP on DOTA-v1.5 datasets with single scale training and testing, validating the efficacy of our approach in remote sensing object detection. The code is made publicly available at https://github.com/gcy0423/Fourier-Angle-Alignment .

</details>


### [27] [Action-Geometry Prediction with 3D Geometric Prior for Bimanual Manipulation](https://arxiv.org/abs/2602.23814)
*Chongyang Xu,Haipeng Li,Shen Cheng,Jingyu Hu,Haoqiang Fan,Ziliang Feng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于预训练3D几何基础模型的双臂操作框架，通过融合几何感知潜在特征、2D语义特征和本体感知，使用扩散模型联合预测未来动作块和未来3D潜在表示，仅需RGB观测即可实现精确的3D空间理解和预测。


<details>
  <summary>Details</summary>
Motivation: 现有双臂操作方法通常依赖空间感知有限的2D特征，或需要难以在真实场景中可靠获取的显式点云数据。而最近3D几何基础模型的发展表明，可以直接从RGB图像快速稳健地重建准确多样的3D结构。

Method: 构建在预训练3D几何基础模型上的双臂操作框架，将几何感知潜在特征、2D语义特征和本体感知融合为统一状态表示，使用扩散模型联合预测未来动作块和未来3D潜在表示（可解码为密集点云图）。

Result: 在RoboTwin基准测试的仿真环境和真实机器人执行中均进行评估，方法在操作成功率、双臂协调性和3D空间预测准确性方面均优于基于2D和点云的基线方法，达到最先进性能。

Conclusion: 通过将双臂操作直接建立在预训练3D几何基础模型上，并联合预测动作序列和3D场景演化，仅使用RGB观测即可获得强大的空间理解和预测能力，为机器人操作提供了有效的解决方案。

Abstract: Bimanual manipulation requires policies that can reason about 3D geometry, anticipate how it evolves under action, and generate smooth, coordinated motions. However, existing methods typically rely on 2D features with limited spatial awareness, or require explicit point clouds that are difficult to obtain reliably in real-world settings. At the same time, recent 3D geometric foundation models show that accurate and diverse 3D structure can be reconstructed directly from RGB images in a fast and robust manner. We leverage this opportunity and propose a framework that builds bimanual manipulation directly on a pre-trained 3D geometric foundation model. Our policy fuses geometry-aware latents, 2D semantic features, and proprioception into a unified state representation, and uses diffusion model to jointly predict a future action chunk and a future 3D latent that decodes into a dense pointmap. By explicitly predicting how the 3D scene will evolve together with the action sequence, the policy gains strong spatial understanding and predictive capability using only RGB observations. We evaluate our method both in simulation on the RoboTwin benchmark and in real-world robot executions. Our approach consistently outperforms 2D-based and point-cloud-based baselines, achieving state-of-the-art performance in manipulation success, inter-arm coordination, and 3D spatial prediction accuracy. Code is available at https://github.com/Chongyang-99/GAP.git.

</details>


### [28] [Footprint-Guided Exemplar-Free Continual Histopathology Report Generation](https://arxiv.org/abs/2602.23817)
*Pratibha Kumari,Daniel Reisenbüchler,Afshin Bozorgpour,yousef Sadegheih,Priyankar Choudhary,Dorit Merhof*

Main category: cs.CV

TL;DR: 提出了一种无示例的持续学习框架，用于从全切片图像生成病理报告，通过构建紧凑的领域足迹来避免灾难性遗忘，无需存储原始数据。


<details>
  <summary>Details</summary>
Motivation: 在临床部署中，新的器官、机构和报告规范会随时间出现，而顺序微调会导致灾难性遗忘。现有方法假设静态训练并同时访问所有数据，不符合实际临床场景。

Method: 1) 在冻结的patch嵌入空间中构建紧凑的领域足迹：包含代表性形态标记的小型代码本、切片级共现摘要和轻量级patch计数先验；2) 通过生成式重放合成反映领域特定形态混合的伪WSI表示；3) 将领域特定语言特征蒸馏到紧凑的风格描述符中，用于引导生成；4) 推理时直接从切片信号识别最兼容的描述符。

Result: 在多个公开的持续学习基准测试中，该方法优于无示例和有限缓冲重放基线，展示了足迹基生成式重放在不断演变的临床环境中的实用性。

Conclusion: 提出的无示例持续学习框架通过紧凑的领域足迹和生成式重放，有效解决了WSI到报告生成中的灾难性遗忘问题，为临床部署提供了实用解决方案。

Abstract: Rapid progress in vision-language modeling has enabled pathology report generation from gigapixel whole-slide images, but most approaches assume static training with simultaneous access to all data. In clinical deployment, however, new organs, institutions, and reporting conventions emerge over time, and sequential fine-tuning can cause catastrophic forgetting. We introduce an exemplar-free continual learning framework for WSI-to-report generation that avoids storing raw slides or patch exemplars. The core idea is a compact domain footprint built in a frozen patch-embedding space: a small codebook of representative morphology tokens together with slide-level co-occurrence summaries and lightweight patch-count priors. These footprints support generative replay by synthesizing pseudo-WSI representations that reflect domain-specific morphological mixtures, while a teacher snapshot provides pseudo-reports to supervise the updated model without retaining past data. To address shifting reporting conventions, we distill domain-specific linguistic characteristics into a compact style descriptor and use it to steer generation. At inference, the model identifies the most compatible descriptor directly from the slide signal, enabling domain-agnostic setup without requiring explicit domain identifiers. Evaluated across multiple public continual learning benchmarks, our approach outperforms exemplar-free and limited-buffer rehearsal baselines, highlighting footprint-based generative replay as a practical solution for deployment in evolving clinical settings.

</details>


### [29] [Altitude-Aware Visual Place Recognition in Top-Down View](https://arxiv.org/abs/2602.23872)
*Xingyu Shao,Mengfan He,Chunyu Li,Liangzheng Sun,Ziyang Meng*

Main category: cs.CV

TL;DR: 提出了一种自适应高度的视觉地点识别方法，通过分析地面特征密度估计相对高度，然后进行基于高度的图像裁剪，最后使用分类策略进行地点识别，无需额外硬件即可在显著高度变化下实现精准定位。


<details>
  <summary>Details</summary>
Motivation: 解决空中视觉地点识别在显著高度变化下的挑战。传统方法依赖气压高度计或飞行时间传感器等额外硬件，而本文旨在开发一种仅基于视觉的解决方案，适用于中小型空中平台在多样化环境中的定位需求。

Method: 1. 通过分析图像中地面特征的密度来估计空中平台的相对高度；2. 基于相对高度进行图像裁剪，生成规范化的查询图像；3. 采用基于分类的视觉地点识别策略进行定位。该方法无需额外硬件，为下游应用提供即插即用的解决方案。

Result: 1. 在显著高度变化下，将相对高度估计模块集成到VPR检索流程中，使R@1和R@5分别提升29.85%和60.20%；2. 相比传统单目度量深度估计方法，平均误差减少202.1米，R@1和R@5分别额外提升31.4%和44%；3. 在多样化地形和高度条件下均表现出高精度和鲁棒性。

Conclusion: 该方法建立了一个稳健的纯视觉三维视觉地点识别框架，为在显著高度变化和传感器有限条件下实现空中平台的精确定位提供了实用且可扩展的解决方案，特别适合中小型空中平台在城乡等多样化环境中的应用。

Abstract: To address the challenge of aerial visual place recognition (VPR) problem under significant altitude variations, this study proposes an altitude-adaptive VPR approach that integrates ground feature density analysis with image classification techniques. The proposed method estimates airborne platforms' relative altitude by analyzing the density of ground features in images, then applies relative altitude-based cropping to generate canonical query images, which are subsequently used in a classification-based VPR strategy for localization. Extensive experiments across diverse terrains and altitude conditions demonstrate that the proposed approach achieves high accuracy and robustness in both altitude estimation and VPR under significant altitude changes. Compared to conventional methods relying on barometric altimeters or Time-of-Flight (ToF) sensors, this solution requires no additional hardware and offers a plug-and-play solution for downstream applications, {making it suitable for small- and medium-sized airborne platforms operating in diverse environments, including rural and urban areas.} Under significant altitude variations, incorporating our relative altitude estimation module into the VPR retrieval pipeline boosts average R@1 and R@5 by 29.85\% and 60.20\%, respectively, compared with applying VPR retrieval alone. Furthermore, compared to traditional {Monocular Metric Depth Estimation (MMDE) methods}, the proposed method reduces the mean error by 202.1 m, yielding average additional improvements of 31.4\% in R@1 and 44\% in R@5. These results demonstrate that our method establishes a robust, vision-only framework for three-dimensional visual place recognition, offering a practical and scalable solution for accurate airborne platforms localization under large altitude variations and limited sensor availability.

</details>


### [30] [Denoising-Enhanced YOLO for Robust SAR Ship Detection](https://arxiv.org/abs/2602.23820)
*Xiaojing Zhao,Shiyang Li,Zena Chu,Ying Zhang,Peinan Hao,Tianzi Yan,Jiajia Chen,Huicong Ning*

Main category: cs.CV

TL;DR: CPN-YOLO：基于YOLOv8改进的SAR图像船舶检测框架，通过可学习大核去噪模块、PPA注意力机制和NWD高斯相似度损失，在复杂场景下提升检测精度，特别是在SSDD数据集上达到97.0%精度、95.1%召回率和98.9% mAP。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习的发展，合成孔径雷达（SAR）图像已成为船舶检测的关键模态。然而，在复杂场景中，杂波和斑点噪声会导致误报，小目标容易被漏检，稳健性能仍然具有挑战性。

Method: 提出CPN-YOLO框架，基于YOLOv8进行三项针对性改进：1）引入可学习大核去噪模块进行输入预处理；2）基于PPA注意力机制设计特征提取增强策略；3）结合基于归一化Wasserstein距离（NWD）的高斯相似度损失。

Result: 在HRSID和SSDD数据集上的广泛实验证明了该方法的有效性。在SSDD数据集上，CPN-YOLO超越YOLOv8基线，达到97.0%精度、95.1%召回率和98.9% mAP，并在整体性能上持续优于其他代表性深度学习检测器。

Conclusion: CPN-YOLO通过针对性的架构改进，有效解决了SAR图像船舶检测中的噪声干扰、小目标检测和复杂边界框分布问题，在复杂场景下实现了高精度船舶检测。

Abstract: With the rapid advancement of deep learning, synthetic aperture radar (SAR) imagery has become a key modality for ship detection. However, robust performance remains challenging in complex scenes, where clutter and speckle noise can induce false alarms and small targets are easily missed. To address these issues, we propose CPN-YOLO, a high-precision ship detection framework built upon YOLOv8 with three targeted improvements. First, we introduce a learnable large-kernel denoising module for input pre-processing, producing cleaner representations and more discriminative features across diverse ship types. Second, we design a feature extraction enhancement strategy based on the PPA attention mechanism to strengthen multi-scale modeling and improve sensitivity to small ships. Third, we incorporate a Gaussian similarity loss derived from the normalized Wasserstein distance (NWD) to better measure similarity under complex bounding-box distributions and improve generalization. Extensive experiments on HRSID and SSDD demonstrate the effectiveness of our method. On SSDD, CPN-YOLO surpasses the YOLOv8 baseline, achieving 97.0% precision, 95.1% recall, and 98.9% mAP, and consistently outperforms other representative deep-learning detectors in overall performance.

</details>


### [31] [APPO: Attention-guided Perception Policy Optimization for Video Reasoning](https://arxiv.org/abs/2602.23823)
*Henghui Du,Chang Zhou,Xi Chen,Di Hu*

Main category: cs.CV

TL;DR: 该论文发现复杂视频推理中感知能力比专家级推理更重要，提出APPO算法通过注意力引导的感知策略优化来提升细粒度感知能力，无需昂贵标注。


<details>
  <summary>Details</summary>
Motivation: 研究发现复杂视频推理过度依赖细粒度感知而非专家级推理。当感知能力固定时，增强推理带来的性能提升有限（仅0.7%），而感知模型规模的微小变化（从7B到32B）却能带来1.4%的性能提升，表明提升感知能力比增强推理更关键。因此需要探索如何通过推理来增强感知能力，同时避免昂贵的细粒度标注成本。

Method: 提出APPO（Attention-guided Perception Policy Optimization）算法，利用token级密集奖励来改进模型的细粒度感知。核心思想是优化那些来自不同响应但主要关注相同关键视频帧的token（称为组内感知token）。

Result: 在不同视频基准测试和不同规模模型（3B/7B）上的实验结果表明，APPO始终优于GRPO和DAPO算法，性能提升幅度为0.5%~4%。

Conclusion: 该工作提供了一种有前景的低成本方法，通过推理有效增强模型的感知能力，能够服务于多样化的场景和需求。

Abstract: Complex video reasoning, actually, relies excessively on fine-grained perception rather than on expert (e.g., Ph.D, Science)-level reasoning. Through extensive empirical observation, we have recognized the critical impact of perception. In particular, when perception ability is almost fixed, enhancing reasoning from Qwen3-8B to OpenAI-o3 yields only 0.7% performance improvement. Conversely, even minimal change in perception model scale (from 7B to 32B) boosts performance by 1.4%, indicating enhancing perception, rather than reasoning, is more critical to improve performance. Therefore, exploring how to enhance perception ability through reasoning without the need for expensive fine-grained annotation information is worthwhile. To achieve this goal, we specially propose APPO, the Attention-guided Perception Policy Optimization algorithm that leverages token-level dense rewards to improve model's fine-grained perception. The core idea behind APPO is to optimize those tokens from different responses that primarily focus on the same crucial video frame (called intra-group perception tokens). Experimental results on diverse video benchmarks and models with different scales (3/7B) demonstrate APPO consistently outperforms GRPO and DAPO (0.5%~4%). We hope our work provides a promising approach to effectively enhance model's perception abilities through reasoning in a low-cost manner, serving diverse scenarios and demands.

</details>


### [32] [NAU-QMUL: Utilizing BERT and CLIP for Multi-modal AI-Generated Image Detection](https://arxiv.org/abs/2602.23863)
*Xiaoyu Guo,Arkaitz Zubiaga*

Main category: cs.CV

TL;DR: 提出多模态多任务模型，用于检测AI生成图像并识别生成模型，在CT2竞赛中获得第五名


<details>
  <summary>Details</summary>
Motivation: 检测AI生成的图像并识别具体的生成模型，以应对AI生成内容在现实场景中的挑战

Method: 使用预训练的BERT和CLIP Vision编码器提取文本和图像特征，采用跨模态特征融合和定制多任务损失函数，并利用伪标签数据增强策略扩展训练数据集

Result: 在CT2竞赛的任务A和任务B中均获得第五名，F1分数分别为83.16%和48.88%

Conclusion: 提出的架构在AI生成内容检测方面具有有效性，在现实场景中有应用潜力

Abstract: With the aim of detecting AI-generated images and identifying the specific models responsible for their generation, we propose a multi-modal multi-task model. The model leverages pre-trained BERT and CLIP Vision encoders for text and image feature extraction, respectively, and employs cross-modal feature fusion with a tailored multi-task loss function. Additionally, a pseudo-labeling-based data augmentation strategy was utilized to expand the training dataset with high-confidence samples. The model achieved fifth place in both Tasks A and B of the `CT2: AI-Generated Image Detection' competition, with F1 scores of 83.16\% and 48.88\%, respectively. These findings highlight the effectiveness of the proposed architecture and its potential for advancing AI-generated content detection in real-world scenarios. The source code for our method is published on https://github.com/xxxxxxxxy/AIGeneratedImageDetection.

</details>


### [33] [Open-Vocabulary Semantic Segmentation in Remote Sensing via Hierarchical Attention Masking and Model Composition](https://arxiv.org/abs/2602.23869)
*Mohammadreza Heidarianbaei,Mareike Dorozynski,Hubert Kanyamahanga,Max Mehltretter,Franz Rottensteiner*

Main category: cs.CV

TL;DR: ReSeg-CLIP：一种无需训练的开放词汇遥感语义分割方法，通过SAM掩码约束自注意力交互，结合多个RS-CLIP变体参数平均，在三个遥感基准上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP等视觉语言模型在语义分割中因自注意力层不适当交互导致的问题，特别是针对遥感数据的开放词汇语义分割任务。

Method: 1. 使用SAM生成的掩码在多尺度上约束自注意力层的交互；2. 提出模型组合方法，平均多个遥感专用CLIP变体的参数，采用新的加权方案评估不同文本提示的表征质量。

Result: 在三个遥感基准测试中取得了最先进的结果，且无需额外训练。

Conclusion: ReSeg-CLIP通过结合SAM掩码约束和模型组合策略，有效解决了CLIP在遥感语义分割中的局限性，实现了无需训练的开放词汇分割SOTA性能。

Abstract: In this paper, we propose ReSeg-CLIP, a new training-free Open-Vocabulary Semantic Segmentation method for remote sensing data. To compensate for the problems of vision language models, such as CLIP in semantic segmentation caused by inappropriate interactions within the self-attention layers, we introduce a hierarchical scheme utilizing masks generated by SAM to constrain the interactions at multiple scales. We also present a model composition approach that averages the parameters of multiple RS-specific CLIP variants, taking advantage of a new weighting scheme that evaluates representational quality using varying text prompts. Our method achieves state-of-the-art results across three RS benchmarks without additional training.

</details>


### [34] [SelfOccFlow: Towards end-to-end self-supervised 3D Occupancy Flow prediction](https://arxiv.org/abs/2602.23894)
*Xavier Timoneda,Markus Herb,Fabian Duerr,Daniel Goehring*

Main category: cs.CV

TL;DR: 提出了一种无需人工标注或外部光流监督的自监督3D占据流估计方法，将场景解耦为静态和动态符号距离场，通过时间聚合隐式学习运动


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要准确估计车辆周围环境的3D占据和运动信息，但现有方法依赖昂贵的3D占据和流标注、边界框速度标签或预训练光流模型，成本高昂且难以扩展

Method: 1) 将场景解耦为静态和动态符号距离场；2) 通过时间聚合隐式学习运动；3) 引入基于特征余弦相似度的强自监督流线索；4) 完全自监督，无需人工标注或外部流监督

Result: 在SemanticKITTI、KITTI-MOT和nuScenes数据集上验证了方法的有效性，展示了自监督3D占据流估计的可行性

Conclusion: 提出的自监督方法能够有效估计3D占据流，无需昂贵的人工标注或外部监督，为自动驾驶环境感知提供了更经济可扩展的解决方案

Abstract: Estimating 3D occupancy and motion at the vehicle's surroundings is essential for autonomous driving, enabling situational awareness in dynamic environments. Existing approaches jointly learn geometry and motion but rely on expensive 3D occupancy and flow annotations, velocity labels from bounding boxes, or pretrained optical flow models. We propose a self-supervised method for 3D occupancy flow estimation that eliminates the need for human-produced annotations or external flow supervision. Our method disentangles the scene into separate static and dynamic signed distance fields and learns motion implicitly through temporal aggregation. Additionally, we introduce a strong self-supervised flow cue derived from features' cosine similarities. We demonstrate the efficacy of our 3D occupancy flow method on SemanticKITTI, KITTI-MOT, and nuScenes.

</details>


### [35] [Ref-Adv: Exploring MLLM Visual Reasoning in Referring Expression Tasks](https://arxiv.org/abs/2602.23898)
*Qihua Dong,Kuo Yang,Lin Ju,Handong Zhao,Yitian Zhang,Yizhou Wang,Huimin Zeng,Jianglin Lu,Yun Fu*

Main category: cs.CV

TL;DR: 本文介绍了Ref-Adv基准测试，旨在解决现有REC基准的局限性，通过设计具有挑战性的语言表达和视觉干扰物来抑制捷径解决方案，从而更真实地评估多模态大模型的视觉推理和基础能力。


<details>
  <summary>Details</summary>
Motivation: 现有REC基准（如RefCOCO系列）存在三个主要问题：1）许多表达过于简短，推理需求低；2）图像中干扰物少，目标容易识别；3）冗余描述符使模型可以通过捷径解决方案绕过真正的文本理解和视觉推理。这些局限性导致现有基准无法充分测试模型的视觉推理和基础能力。

Method: 作者构建了Ref-Adv基准数据集，包含真实图像上的指代表达，通过以下方式抑制捷径：1）使用语言上非平凡的表达式；2）仅包含唯一识别目标所需的信息；3）精心设计困难干扰物；4）标注推理方面包括否定。通过词序扰动和描述符删除充分性等全面消融实验验证数据集的有效性。

Result: 在RefCOCO、RefCOCO+和RefCOCOg上表现良好的当代多模态大模型在Ref-Adv上表现显著下降，揭示了模型对捷径的依赖以及在视觉推理和基础能力上的差距。作者提供了深入的失败分析，表明解决Ref-Adv需要超越简单线索的推理能力。

Conclusion: Ref-Adv基准通过抑制捷径解决方案，为评估多模态大模型的视觉推理和基础能力提供了更严格的测试环境。该基准揭示了现有模型的局限性，旨在指导未来在视觉推理和基础方面的研究工作。

Abstract: Referring Expression Comprehension (REC) links language to region level visual perception. Standard benchmarks (RefCOCO, RefCOCO+, RefCOCOg) have progressed rapidly with multimodal LLMs but remain weak tests of visual reasoning and grounding: (i) many expressions are very short, leaving little reasoning demand; (ii) images often contain few distractors, making the target easy to find; and (iii) redundant descriptors enable shortcut solutions that bypass genuine text understanding and visual reasoning. We introduce Ref-Adv, a modern REC benchmark that suppresses shortcuts by pairing linguistically nontrivial expressions with only the information necessary to uniquely identify the target. The dataset contains referring expressions on real images, curated with hard distractors and annotated with reasoning facets including negation. We conduct comprehensive ablations (word order perturbations and descriptor deletion sufficiency) to show that solving Ref-Adv requires reasoning beyond simple cues, and we evaluate a broad suite of contemporary multimodal LLMs on Ref-Adv. Despite strong results on RefCOCO, RefCOCO+, and RefCOCOg, models drop markedly on Ref-Adv, revealing reliance on shortcuts and gaps in visual reasoning and grounding. We provide an in depth failure analysis and aim for Ref-Adv to guide future work on visual reasoning and grounding in MLLMs.

</details>


### [36] [Experience-Guided Self-Adaptive Cascaded Agents for Breast Cancer Screening and Diagnosis with Reduced Biopsy Referrals](https://arxiv.org/abs/2602.23899)
*Pramit Saha,Mohammad Alsharid,Joshua Strong,J. Alison Noble*

Main category: cs.CV

TL;DR: BUSD-Agent是一个经验引导的级联多智能体框架，用于乳腺超声筛查和诊断，通过两阶段选择性决策减少诊断升级和不必要的活检转诊。


<details>
  <summary>Details</summary>
Motivation: 当前乳腺超声筛查和诊断中存在过度诊断升级和不必要的活检转诊问题，需要一种能够减少误诊和过度医疗负担的智能决策系统。

Method: 采用两阶段级联多智能体框架：1）筛查诊所智能体使用分类模型筛选出低风险良性/正常病例；2）高风险病例升级到诊断诊所智能体，集成更丰富的感知和放射学描述工具进行活检决策。通过记忆库存储历史决策轨迹，基于图像嵌入、模型预测和置信度检索相似病例进行上下文适应。

Result: 在10个乳腺超声数据集上的评估显示，与无轨迹条件相比，BUSD-Agent将诊断升级率从84.95%降至58.72%，总体活检转诊率从59.50%降至37.08%，同时筛查特异性提高68.48%，诊断特异性提高6.33%。

Conclusion: 经验引导的级联多智能体框架能够有效减少乳腺超声筛查中的诊断升级和不必要的活检转诊，通过检索条件化的上下文适应动态调整模型信任和升级阈值，提高诊断特异性。

Abstract: We propose an experience-guided cascaded multi-agent framework for Breast Ultrasound Screening and Diagnosis, called BUSD-Agent, that aims to reduce diagnostic escalation and unnecessary biopsy referrals. Our framework models screening and diagnosis as a two-stage, selective decision-making process. A lightweight `screening clinic' agent, restricted to classification models as tools, selectively filters out benign and normal cases from further diagnostic escalation when malignancy risk and uncertainty are estimated as low. Cases that have higher risks are escalated to the `diagnostic clinic' agent, which integrates richer perception and radiological description tools to make a secondary decision on biopsy referral. To improve agent performance, past records of pathology-confirmed outcomes along with image embeddings, model predictions, and historical agent actions are stored in a memory bank as structured decision trajectories. For each new case, BUSD-Agent retrieves similar past cases based on image, model response and confidence similarity to condition the agent's current decision policy. This enables retrieval-conditioned in-context adaptation that dynamically adjusts model trust and escalation thresholds from prior experiences without parameter updates. Evaluation across 10 breast ultrasound datasets shows that the proposed experience-guided workflow reduces diagnostic escalation in BUSD-Agent from 84.95% to 58.72% and overall biopsy referrals from 59.50% to 37.08%, compared to the same architecture without trajectory conditioning, while improving average screening specificity by 68.48% and diagnostic specificity by 6.33%.

</details>


### [37] [Half-Truths Break Similarity-Based Retrieval](https://arxiv.org/abs/2602.23906)
*Bora Kargi,Arnas Uselis,Seong Joon Oh*

Main category: cs.CV

TL;DR: CLIP模型在文本描述中添加错误细节时，相似度评分反而可能上升，存在"半真半假"问题。研究者提出CS-CLIP方法，通过分解caption为实体和关系单元进行组件监督训练，显著提高了组合理解能力。


<details>
  <summary>Details</summary>
Motivation: CLIP风格的双编码器存在一个反直觉问题：当在正确的文本描述中添加一个看似合理但错误的细节时，图像-文本相似度评分反而可能增加。这种"半真半假"情况暴露了模型对caption组成部分监督不足的问题，需要改进模型对实体和关系的细粒度理解能力。

Method: 提出CS-CLIP方法：1) 将caption分解为实体和关系单元；2) 为每个单元构建最小编辑的虚假版本；3) 微调模型使正确单元评分高于虚假版本，同时保持标准双编码器推理架构。

Result: 在COCO数据集上，CLIP仅在40.6%的情况下偏好正确的简短描述，当添加细节是关系时性能降至32.9%。CS-CLIP将半真半假准确率提升至69.3%，在已建立的组合基准测试中平均性能提升5.7个百分点。

Conclusion: CS-CLIP通过组件监督训练有效解决了CLIP的半真半假问题，减少这类错误与更广泛的组合理解能力提升相一致，表明细粒度的组件监督对提升多模态模型的组合推理能力至关重要。

Abstract: When a text description is extended with an additional detail, image-text similarity should drop if that detail is wrong. We show that CLIP-style dual encoders often violate this intuition: appending a plausible but incorrect object or relation to an otherwise correct description can increase the similarity score. We call such cases half-truths. On COCO, CLIP prefers the correct shorter description only 40.6% of the time, and performance drops to 32.9% when the added detail is a relation. We trace this vulnerability to weak supervision on caption parts: contrastive training aligns full sentences but does not explicitly enforce that individual entities and relations are grounded. We propose CS-CLIP (Component-Supervised CLIP), which decomposes captions into entity and relation units, constructs a minimally edited foil for each unit, and fine-tunes the model to score the correct unit above its foil while preserving standard dual-encoder inference. CS-CLIP raises half-truth accuracy to 69.3% and improves average performance on established compositional benchmarks by 5.7 points, suggesting that reducing half-truth errors aligns with broader gains in compositional understanding. Code is publicly available at: https://github.com/kargibora/CS-CLIP

</details>


### [38] [PointCoT: A Multi-modal Benchmark for Explicit 3D Geometric Reasoning](https://arxiv.org/abs/2602.23945)
*Dongxu Zhang,Yiding Sun,Pengcheng Li,Yumou Liu,Hongqiang Lin,Haoran Xu,Xiaoxuan Mu,Liang Lin,Wenbiao Yan,Ning Yang,Chaowei Fang,Juanjuan Zhao,Jihua Zhu,Conghui He,Cheng Tan*

Main category: cs.CV

TL;DR: PointCoT：一种通过显式思维链推理增强多模态大语言模型3D点云理解能力的新框架，采用"观察-思考-回答"范式，在几何推理任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在2D场景表现良好，但在3D点云理解方面存在挑战。现有方法主要关注3D特征与预训练模型的对齐，将几何推理视为隐式映射过程，绕过中间逻辑步骤，导致几何幻觉问题——模型会生成看似合理但缺乏精确结构细节依据的响应。

Method: 提出PointCoT框架，采用"观察-思考-回答"范式，监督模型在预测最终答案前生成基于几何的推理依据。构建Point-Reason-Instruct大规模基准数据集（约86k指令调优样本，包含分层思维链标注）。采用双流多模态架构，协同整合语义外观与几何真值。

Result: PointCoT在复杂推理任务上实现了最先进的性能表现，有效解决了几何幻觉问题，提升了3D点云理解的准确性和可靠性。

Conclusion: 通过显式思维链推理范式，PointCoT成功将多模态大语言模型的感知智能扩展到3D点云理解领域，为几何推理任务提供了更可靠、可解释的解决方案。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate proficiency in 2D scenes, extending their perceptual intelligence to 3D point cloud understanding remains a significant challenge. Current approaches focus primarily on aligning 3D features with pre-trained models. However, they typically treat geometric reasoning as an implicit mapping process. These methods bypass intermediate logical steps and consequently suffer from geometric hallucinations. They confidently generate plausible responses that fail to ground in precise structural details. To bridge this gap, we present PointCoT, a novel framework that empowers MLLMs with explicit Chain-of-Thought (CoT) reasoning for 3D data. We advocate for a \textit{Look, Think, then Answer} paradigm. In this approach, the model is supervised to generate geometry-grounded rationales before predicting final answers. To facilitate this, we construct Point-Reason-Instruct, a large-scale benchmark comprising $\sim$86k instruction-tuning samples with hierarchical CoT annotations. By leveraging a dual-stream multi-modal architecture, our method synergizes semantic appearance with geometric truth. Extensive experiments demonstrate that PointCoT achieves state-of-the-art performance on complex reasoning tasks.

</details>


### [39] [CC-VQA: Conflict- and Correlation-Aware Method for Mitigating Knowledge Conflict in Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2602.23952)
*Yuyang Hong,Jiaqi Gu,Yujin Lou,Lubin Fan,Qi Yang,Ying Wang,Kun Ding,Yue Wu,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: CC-VQA提出了一种无需训练、基于冲突和相关性感知的知识型视觉问答方法，通过视觉中心冲突推理和相关性引导编解码，显著提升了KB-VQA性能


<details>
  <summary>Details</summary>
Motivation: 知识型视觉问答中，视觉语言模型的静态参数知识与动态检索信息之间存在冲突，现有方法主要从语言角度处理冲突，忽视了视觉信息的关键作用，且检索到的冗余上下文会影响冲突识别和缓解效果

Method: 提出CC-VQA方法，包含两个核心组件：1）视觉中心上下文冲突推理，在内部和外部知识上下文间进行视觉语义冲突分析；2）相关性引导编码和解码，包括对低相关性语句的位置编码压缩，以及使用相关性加权冲突评分进行自适应解码

Result: 在E-VQA、InfoSeek和OK-VQA基准测试上的广泛评估表明，CC-VQA实现了最先进的性能，相比现有方法绝对准确率提升了3.3%到6.4%

Conclusion: CC-VQA通过视觉中心冲突分析和相关性引导机制，有效解决了知识型视觉问答中的知识冲突问题，无需额外训练即可显著提升性能

Abstract: Knowledge-based visual question answering (KB-VQA) demonstrates significant potential for handling knowledge-intensive tasks. However, conflicts arise between static parametric knowledge in vision language models (VLMs) and dynamically retrieved information due to the static model knowledge from pre-training. The outputs either ignore retrieved contexts or exhibit inconsistent integration with parametric knowledge, posing substantial challenges for KB-VQA. Current knowledge conflict mitigation methods primarily adapted from language-based approaches, focusing on context-level conflicts through engineered prompting strategies or context-aware decoding mechanisms. However, these methods neglect the critical role of visual information in conflicts and suffer from redundant retrieved contexts, which impair accurate conflict identification and effective mitigation. To address these limitations, we propose \textbf{CC-VQA}: a novel training-free, conflict- and correlation-aware method for KB-VQA. Our method comprises two core components: (1) Vision-Centric Contextual Conflict Reasoning, which performs visual-semantic conflict analysis across internal and external knowledge contexts; and (2) Correlation-Guided Encoding and Decoding, featuring positional encoding compression for low-correlation statements and adaptive decoding using correlation-weighted conflict scoring. Extensive evaluations on E-VQA, InfoSeek, and OK-VQA benchmarks demonstrate that CC-VQA achieves state-of-the-art performance, yielding absolute accuracy improvements of 3.3\% to 6.4\% compared to existing methods. Code is available at https://github.com/cqu-student/CC-VQA.

</details>


### [40] [GDA-YOLO11: Amodal Instance Segmentation for Occlusion-Robust Robotic Fruit Harvesting](https://arxiv.org/abs/2602.23953)
*Caner Beldek,Emre Sariyildiz,Son Lam Phung,Gursel Alici*

Main category: cs.CV

TL;DR: 提出GDA-YOLO11模型用于水果采摘中的遮挡处理，通过改进的amodal分割和不对称掩码损失，在遮挡场景下实现更好的水果检测和定位，最终提高机器人采摘成功率。


<details>
  <summary>Details</summary>
Motivation: 遮挡是机器人水果采摘中的关键挑战，未检测或定位不准确的水果会导致大量作物损失。需要解决水果被遮挡时的检测和定位问题。

Method: 提出GDA-YOLO11模型，包含架构改进和更新的不对称掩码损失。模型在修改后的公共柑橘数据集上训练，在基础数据集和不同遮挡程度的子集上评估。使用欧几里得距离变换估计采摘点，并将这些点投影到3D坐标用于机器人采摘执行。

Result: GDA-YOLO11达到精度0.844、召回率0.846、mAP@50为0.914、mAP@50:95为0.636，在精度、mAP@50和mAP@50:95上分别比YOLO11n提高5.1%、1.3%和1.0%。在零到高遮挡水平下，采摘成功率分别为92.59%、85.18%、48.14%和22.22%，在中高遮挡下成功率提高3.5%。

Conclusion: GDA-YOLO11增强了遮挡鲁棒性分割，简化了感知到动作的集成，为农业中更可靠的自主系统铺平了道路。这是机器人水果采摘中amodal实例分割的首次实际演示。

Abstract: Occlusion remains a critical challenge in robotic fruit harvesting, as undetected or inaccurately localised fruits often results in substantial crop losses. To mitigate this issue, we propose a harvesting framework using a new amodal segmentation model, GDA-YOLO11, which incorporates architectural improvements and an updated asymmetric mask loss. The proposed model is trained on a modified version of a public citrus dataset and evaluated on both the base dataset and occlusion-sensitive subsets with varying occlusion levels. Within the framework, full fruit masks, including invisible regions, are inferred by GDA-YOLO11, and picking points are subsequently estimated using the Euclidean distance transform. These points are then projected into 3D coordinates for robotic harvesting execution. Experiments were conducted using real citrus fruits in a controlled environment simulating occlusion scenarios. Notably, to the best of our knowledge, this study provides the first practical demonstration of amodal instance segmentation in robotic fruit harvesting. GDA-YOLO11 achieves a precision of 0.844, recall of 0.846, mAP@50 of 0.914, and mAP@50:95 of 0.636, outperforming YOLO11n by 5.1%, 1.3%, and 1.0% in precision, mAP@50, and mAP@50:95, respectively. The framework attains harvesting success rates of 92.59%, 85.18%, 48.14%, and 22.22% at zero to high occlusion levels, improving success by 3.5% under medium and high occlusion. These findings demonstrate that GDA-YOLO11 enhances occlusion robust segmentation and streamlines perception-to-action integration, paving the way for more reliable autonomous systems in agriculture.

</details>


### [41] [SwitchCraft: Training-Free Multi-Event Video Generation with Attention Controls](https://arxiv.org/abs/2602.23956)
*Qianxun Xu,Chenxi Song,Yujun Cai,Chi Zhang*

Main category: cs.CV

TL;DR: SwitchCraft是一个无需训练的多事件视频生成框架，通过事件对齐查询引导和自适应平衡强度求解器，解决现有文本到视频扩散模型在多事件提示下生成混合或崩溃场景的问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频扩散模型主要针对单事件生成优化，当处理多事件提示时，缺乏明确的时间定位会导致模型生成混合或崩溃的场景，破坏了预期的叙事结构。

Method: 提出SwitchCraft框架，包含两个核心组件：1) 事件对齐查询引导(EAQS)，引导帧级注意力与相关事件提示对齐；2) 自适应平衡强度求解器(ABSS)，自适应平衡引导强度以保持时间一致性和视觉保真度。

Result: 大量实验表明，SwitchCraft在提示对齐、事件清晰度和场景一致性方面显著优于现有基线方法。

Conclusion: SwitchCraft为多事件视频生成提供了一个简单而有效的解决方案，无需额外训练即可显著改善多事件叙事视频的生成质量。

Abstract: Recent advances in text-to-video diffusion models have enabled high-fidelity and temporally coherent videos synthesis. However, current models are predominantly optimized for single-event generation. When handling multi-event prompts, without explicit temporal grounding, such models often produce blended or collapsed scenes that break the intended narrative. To address this limitation, we present SwitchCraft, a training-free framework for multi-event video generation. Our key insight is that uniform prompt injection across time ignores the correspondence between events and frames. To this end, we introduce Event-Aligned Query Steering (EAQS), which steers frame-level attention to align with relevant event prompts. Furthermore, we propose Auto-Balance Strength Solver (ABSS), which adaptively balances steering strength to preserve temporal consistency and visual fidelity. Extensive experiments demonstrate that SwitchCraft substantially improves prompt alignment, event clarity, and scene consistency compared with existing baselines, offering a simple yet effective solution for multi-event video generation.

</details>


### [42] [Thinking with Images as Continuous Actions: Numerical Visual Chain-of-Thought](https://arxiv.org/abs/2602.23959)
*Kesen Zhao,Beier Zhu,Junbao Zhou,Xingyu Zhu,Zhongqi Yue,Hanwang Zhang*

Main category: cs.CV

TL;DR: NV-CoT是一个让多模态大语言模型使用连续数值坐标进行视觉推理的框架，通过将动作空间从离散词汇扩展到连续欧几里得空间，显著提升了定位精度和答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在模态不匹配、语义碎片化或粒度固定的问题，限制了精确区域选择和推理能力，需要一种更自然、更精确的视觉推理方法。

Method: 提出数值视觉思维链框架，将MLLM动作空间扩展到连续坐标空间，使用高斯或拉普拉斯策略生成边界框坐标，支持监督微调和强化学习，与GRPO风格策略优化兼容。

Result: 在三个基准测试中对八个代表性视觉推理基线进行实验，NV-CoT显著提高了定位精度和最终答案准确性，同时加速了训练收敛。

Conclusion: 连续动作视觉推理在多模态大语言模型中具有有效性，为更精确的视觉推理提供了新思路。

Abstract: Recent multimodal large language models (MLLMs) increasingly rely on visual chain-of-thought to perform region-grounded reasoning over images. However, existing approaches ground regions via either textified coordinates-causing modality mismatch and semantic fragmentation or fixed-granularity patches that both limit precise region selection and often require non-trivial architectural changes. In this paper, we propose Numerical Visual Chain-of-Thought (NV-CoT), a framework that enables MLLMs to reason over images using continuous numerical coordinates. NV-CoT expands the MLLM action space from discrete vocabulary tokens to a continuous Euclidean space, allowing models to directly generate bounding-box coordinates as actions with only minimal architectural modification. The framework supports both supervised fine-tuning and reinforcement learning. In particular, we replace categorical token policies with a Gaussian (or Laplace) policy over coordinates and introduce stochasticity via reparameterized sampling, making NV-CoT fully compatible with GRPO-style policy optimization. Extensive experiments on three benchmarks against eight representative visual reasoning baselines demonstrate that NV-CoT significantly improves localization precision and final answer accuracy, while also accelerating training convergence, validating the effectiveness of continuous-action visual reasoning in MLLMs. The code is available in https://github.com/kesenzhao/NV-CoT.

</details>


### [43] [SpikeTrack: A Spike-driven Framework for Efficient Visual Tracking](https://arxiv.org/abs/2602.23963)
*Qiuyang Zhang,Jiujun Cheng,Qichao Mao,Cong Liu,Yu Fang,Yuhong Li,Mengying Ge,Shangce Gao*

Main category: cs.CV

TL;DR: SpikeTrack是一个脉冲驱动的RGB目标跟踪框架，通过非对称设计和神经推理机制实现高能效跟踪，在保持精度的同时大幅降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有SNN跟踪框架要么不完全符合脉冲驱动计算，要么未充分利用神经元的时空动态特性，导致效率与精度之间的权衡。需要开发一个既能充分利用时空动态特性又能降低计算的RGB目标跟踪框架。

Method: 采用非对称设计：非对称时间步扩展和单向信息流，利用时空动态特性同时减少计算。设计受神经推理机制启发的记忆检索模块，通过循环查询模板初始化的紧凑记忆来检索目标线索并随时间增强目标感知。

Result: SpikeTrack在SNN跟踪器中达到最先进水平，与先进ANN跟踪器保持竞争力。在LaSOT数据集上超越TransT，同时能耗仅为TransT的1/26。

Conclusion: SpikeTrack是首个使RGB跟踪既准确又高能效的脉冲驱动框架，为高效视觉跟踪提供了新解决方案。

Abstract: Spiking Neural Networks (SNNs) promise energy-efficient vision, but applying them to RGB visual tracking remains difficult: Existing SNN tracking frameworks either do not fully align with spike-driven computation or do not fully leverage neurons' spatiotemporal dynamics, leading to a trade-off between efficiency and accuracy. To address this, we introduce SpikeTrack, a spike-driven framework for energy-efficient RGB object tracking. SpikeTrack employs a novel asymmetric design that uses asymmetric timestep expansion and unidirectional information flow, harnessing spatiotemporal dynamics while cutting computation. To ensure effective unidirectional information transfer between branches, we design a memory-retrieval module inspired by neural inference mechanisms. This module recurrently queries a compact memory initialized by the template to retrieve target cues and sharpen target perception over time. Extensive experiments demonstrate that SpikeTrack achieves the state-of-the-art among SNN-based trackers and remains competitive with advanced ANN trackers. Notably, it surpasses TransT on LaSOT dataset while consuming only 1/26 of its energy. To our knowledge, SpikeTrack is the first spike-driven framework to make RGB tracking both accurate and energy efficient. The code and models are available at https://github.com/faicaiwawa/SpikeTrack.

</details>


### [44] [Venus: Benchmarking and Empowering Multimodal Large Language Models for Aesthetic Guidance and Cropping](https://arxiv.org/abs/2602.23980)
*Tianxiang Du,Hulingxiao He,Yuxin Peng*

Main category: cs.CV

TL;DR: 论文提出了AesGuide数据集和Venus框架，解决智能手机摄影中普通用户与专业摄影师之间的美学指导差距，通过两阶段方法提升多模态大语言模型的美学指导能力，并在美学裁剪任务上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 智能手机摄影普及，但普通用户与专业摄影师之间存在明显差距，后者能在拍摄过程中识别美学问题并提供可操作的拍摄指导。现有多模态大语言模型主要提供过于积极的反馈，无法识别问题或提供可操作指导，缺乏美学指导能力。

Method: 1. 引入AesGuide数据集：包含10,748张照片，标注了美学评分、分析和指导；2. 提出Venus两阶段框架：第一阶段通过渐进式复杂美学问题赋予MLLMs美学指导能力，第二阶段通过基于CoT的推理激活其美学裁剪能力。

Result: Venus显著提升了美学指导能力，在美学裁剪任务上实现了最先进的性能，能够在照片创作的两个阶段实现可解释和交互式的美学优化。

Conclusion: 该研究填补了计算美学中美学指导领域的空白，通过数据集和框架的提出，使MLLMs能够提供专业的美学分析和指导，为普通用户提供类似专业摄影师的拍摄帮助。

Abstract: The widespread use of smartphones has made photography ubiquitous, yet a clear gap remains between ordinary users and professional photographers, who can identify aesthetic issues and provide actionable shooting guidance during capture. We define this capability as aesthetic guidance (AG) -- an essential but largely underexplored domain in computational aesthetics. Existing multimodal large language models (MLLMs) primarily offer overly positive feedback, failing to identify issues or provide actionable guidance. Without AG capability, they cannot effectively identify distracting regions or optimize compositional balance, thus also struggling in aesthetic cropping, which aims to refine photo composition through reframing after capture. To address this, we introduce AesGuide, the first large-scale AG dataset and benchmark with 10,748 photos annotated with aesthetic scores, analyses, and guidance. Building upon it, we propose Venus, a two-stage framework that first empowers MLLMs with AG capability through progressively complex aesthetic questions and then activates their aesthetic cropping power via CoT-based rationales. Extensive experiments show that Venus substantially improves AG capability and achieves state-of-the-art (SOTA) performance in aesthetic cropping, enabling interpretable and interactive aesthetic refinement across both stages of photo creation. Code is available at https://github.com/PKU-ICST-MIPL/Venus_CVPR2026.

</details>


### [45] [Accelerating Masked Image Generation by Learning Latent Controlled Dynamics](https://arxiv.org/abs/2602.23996)
*Kaiwen Zhu,Quansheng Zeng,Yuandong Pu,Shuo Cao,Xiaohui Li,Yi Xin,Qi Qin,Jiayang Li,Yu Qiao,Jinjin Gu,Yihao Liu*

Main category: cs.CV

TL;DR: 提出MIGM-Shortcut方法，通过学习轻量级模型结合历史特征和采样token来回归特征演化的平均速度场，显著加速掩码图像生成模型，在Lumina-DiMOO上实现4倍加速且保持质量


<details>
  <summary>Details</summary>
Motivation: 掩码图像生成模型(MIGMs)虽然成功，但双向注意力的多步计算导致效率低下。离散token采样时连续特征的丰富语义会丢失，现有缓存特征的方法在激进加速率下近似误差较大，主要原因是表达能力有限且未考虑采样信息

Method: 提出MIGM-Shortcut方法，学习一个轻量级模型，该模型结合先前特征和已采样token，回归特征演化的平均速度场。模型复杂度适中，既能捕捉微妙动态，又比原始基础模型轻量。应用于两种代表性MIGM架构和任务

Result: 在最新的Lumina-DiMOO模型上，实现了文本到图像生成超过4倍的加速，同时保持生成质量，显著推进了掩码图像生成的帕累托前沿

Conclusion: MIGM-Shortcut通过结合历史特征和采样token学习特征演化动态，有效解决了MIGMs的计算冗余问题，实现了高质量加速，代码和模型权重已开源

Abstract: Masked Image Generation Models (MIGMs) have achieved great success, yet their efficiency is hampered by the multiple steps of bi-directional attention. In fact, there exists notable redundancy in their computation: when sampling discrete tokens, the rich semantics contained in the continuous features are lost. Some existing works attempt to cache the features to approximate future features. However, they exhibit considerable approximation error under aggressive acceleration rates. We attribute this to their limited expressivity and the failure to account for sampling information. To fill this gap, we propose to learn a lightweight model that incorporates both previous features and sampled tokens, and regresses the average velocity field of feature evolution. The model has moderate complexity that suffices to capture the subtle dynamics while keeping lightweight compared to the original base model. We apply our method, MIGM-Shortcut, to two representative MIGM architectures and tasks. In particular, on the state-of-the-art Lumina-DiMOO, it achieves over 4x acceleration of text-to-image generation while maintaining quality, significantly pushing the Pareto frontier of masked image generation. The code and model weights are available at https://github.com/Kaiwen-Zhu/MIGM-Shortcut.

</details>


### [46] [Ordinal Diffusion Models for Color Fundus Images](https://arxiv.org/abs/2602.24013)
*Gustav Schmidt,Philipp Berens,Sarah Müller*

Main category: cs.CV

TL;DR: 本文提出了一种序数潜在扩散模型，用于生成糖尿病视网膜病变的眼底图像，该模型将疾病严重程度的顺序结构显式纳入生成过程，实现了相邻阶段间的平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有生成图像模型（如扩散模型）在医学影像任务中通常将疾病阶段视为独立类别，忽略了疾病进展的连续性本质。这种不匹配在医学成像中存在问题，因为连续的病理过程通常只能通过粗粒度、离散但有序的标签来观察，如糖尿病视网膜病变的严重程度分级。

Method: 提出了一种序数潜在扩散模型，使用标量疾病表示代替传统的分类条件，将糖尿病视网膜病变严重程度的顺序结构显式纳入生成过程，实现相邻阶段间的平滑过渡。模型在EyePACS数据集上进行评估。

Result: 与标准条件扩散模型相比，该模型在五个DR阶段中的四个阶段降低了Fréchet起始距离，并将二次加权κ从0.79提高到0.87。插值实验显示模型能够从有序的粗粒度类别标签中学习到疾病进展的连续谱。

Conclusion: 序数潜在扩散模型能够有效捕捉糖尿病视网膜病变进展的连续性，生成更真实且临床一致的眼底图像，为医学影像生成提供了更好的方法。

Abstract: It has been suggested that generative image models such as diffusion models can improve performance on clinically relevant tasks by offering deep learning models supplementary training data. However, most conditional diffusion models treat disease stages as independent classes, ignoring the continuous nature of disease progression. This mismatch is problematic in medical imaging because continuous pathological processes are typically only observed through coarse, discrete but ordered labels as in ophthalmology for diabetic retinopathy (DR). We propose an ordinal latent diffusion model for generating color fundus images that explicitly incorporates the ordered structure of DR severity into the generation process. Instead of categorical conditioning, we used a scalar disease representation, enabling a smooth transition between adjacent stages. We evaluated our approach using visual realism metrics and classification-based clinical consistency analysis on the EyePACS dataset. Compared to a standard conditional diffusion model, our model reduced the Fréchet inception distance for four of the five DR stages and increased the quadratic weighted $κ$ from 0.79 to 0.87. Furthermore, interpolation experiments showed that the model captured a continuous spectrum of disease progression learned from ordered, coarse class labels.

</details>


### [47] [Interpretable Debiasing of Vision-Language Models for Social Fairness](https://arxiv.org/abs/2602.24014)
*Na Min An,Yoonna Jang,Yusuke Hirota,Ryo Hachiuma,Isabelle Augenstein,Hyunjung Shim*

Main category: cs.CV

TL;DR: DeBiasLens：一种通过稀疏自编码器定位视觉语言模型中社会属性神经元，并选择性去激活以减轻社会偏见的可解释、模型无关的偏置缓解框架


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的快速发展引发了对其黑盒推理过程可能导致意外社会偏见的担忧。当前的去偏方法主要通过后处理学习或测试时算法缓解表面偏置信号，而忽略了模型的内部动态机制。

Method: 提出DeBiasLens框架，通过在多模态编码器上应用稀疏自编码器来定位社会属性神经元。利用SAEs的解缠能力，在无社会属性标签的面部图像或字幕数据集上训练，发现对特定人口统计特征（包括少数群体）高度响应的神经元，然后选择性去激活与偏置最相关的神经元。

Result: 该方法能有效缓解视觉语言模型的社会偏置行为，同时不损害其语义知识。为未来审计工具奠定了基础，优先考虑新兴现实世界AI系统的社会公平性。

Conclusion: DeBiasLens为理解和缓解视觉语言模型中的社会偏见提供了一种可解释、模型无关的方法，通过定位和选择性干预内部神经元来实现偏置缓解，同时保持模型的核心语义能力。

Abstract: The rapid advancement of Vision-Language models (VLMs) has raised growing concerns that their black-box reasoning processes could lead to unintended forms of social bias. Current debiasing approaches focus on mitigating surface-level bias signals through post-hoc learning or test-time algorithms, while leaving the internal dynamics of the model largely unexplored. In this work, we introduce an interpretable, model-agnostic bias mitigation framework, DeBiasLens, that localizes social attribute neurons in VLMs through sparse autoencoders (SAEs) applied to multimodal encoders. Building upon the disentanglement ability of SAEs, we train them on facial image or caption datasets without corresponding social attribute labels to uncover neurons highly responsive to specific demographics, including those that are underrepresented. By selectively deactivating the social neurons most strongly tied to bias for each group, we effectively mitigate socially biased behaviors of VLMs without degrading their semantic knowledge. Our research lays the groundwork for future auditing tools, prioritizing social fairness in emerging real-world AI systems.

</details>


### [48] [Steering and Rectifying Latent Representation Manifolds in Frozen Multi-modal LLMs for Video Anomaly Detection](https://arxiv.org/abs/2602.24021)
*Zhaolin Cai,Fan Li,Huiyu Duan,Lijun He,Guangtao Zhai*

Main category: cs.CV

TL;DR: SteerVAD：一种基于多模态大语言模型的视频异常检测新框架，通过主动干预内部表示而非被动读取，在仅需1%训练数据的情况下实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统视频异常检测方法需要大量标注数据和完整训练，成本高昂。现有基于冻结MLLM的无调优方法直接继承预训练偏差，无法适应特定视频上下文，难以处理细微或模糊的异常。

Method: 提出SteerVAD干预框架：1）使用无梯度表示可分性分析识别对异常检测最敏感的注意力头作为潜在异常专家；2）设计分层元控制器，基于全局上下文和LAE输出生成动态校正信号；3）对LAE表示流形执行有针对性的各向异性缩放，放大异常相关维度并抑制固有偏差。

Result: 在主流基准测试中，该方法在仅需1%训练数据的无调优方法中实现了最先进的性能。

Conclusion: SteerVAD通过从被动读取转向主动干预内部表示，为视频异常检测开辟了新的强大方向，显著提升了MLLM在VAD任务中的性能。

Abstract: Video anomaly detection (VAD) aims to identify abnormal events in videos. Traditional VAD methods generally suffer from the high costs of labeled data and full training, thus some recent works have explored leveraging frozen multi-modal large language models (MLLMs) in a tuning-free manner to perform VAD. However, their performance is limited as they directly inherit pre-training biases and cannot adapt internal representations to specific video contexts, leading to difficulties in handling subtle or ambiguous anomalies. To address these limitations, we propose a novel intervention framework, termed SteerVAD, which advances MLLM-based VAD by shifting from passively reading to actively steering and rectifying internal representations. Our approach first leverages the gradient-free representational separability analysis (RSA) to identify top attention heads as latent anomaly experts (LAEs) which are most discriminative for VAD. Then a hierarchical meta-controller (HMC) generates dynamic rectification signals by jointly conditioning on global context and these LAE outputs. The signals execute targeted, anisotropic scaling directly upon the LAE representation manifolds, amplifying anomaly-relevant dimensions while suppressing inherent biases. Extensive experiments on mainstream benchmarks demonstrate our method achieves state-of-the-art performance among tuning-free approaches requiring only 1% of training data, establishing it as a powerful new direction for video anomaly detection. The code will be released upon the publication.

</details>


### [49] [GuardAlign: Test-time Safety Alignment in Multimodal Large Language Models](https://arxiv.org/abs/2602.24027)
*Xingyu Zhu,Beier Zhu,Junfeng Fang,Shuo Wang,Yin Zhang,Xiang Wang,Xiangnan He*

Main category: cs.CV

TL;DR: GuardAlign是一个无需训练的防御框架，通过最优传输增强的安全检测和跨模态注意力校准，有效降低大型视觉语言模型的不安全响应率，同时保持模型实用性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉语言推理任务上取得了显著进展，但确保其安全性仍然是一个关键挑战。现有的输入侧防御方法使用CLIP检测不安全图像并在提示前添加安全前缀，但在复杂场景中存在检测不准确的问题，并且在解码过程中安全信号不稳定。

Method: GuardAlign采用两种策略：1）OT增强的安全检测，利用最优传输测量图像块与不安全语义之间的分布距离，无需额外计算成本即可准确识别恶意区域；2）跨模态注意力校准，通过自适应地重新分配各层注意力来加强安全前缀的影响，确保安全信号在生成过程中持续激活。

Result: 在六个代表性多模态大语言模型上的广泛评估表明，GuardAlign在SPA-VL上将不安全响应率降低了高达39%，同时在保持实用性的情况下，将VQAv2的性能从78.51%提升到79.21%。

Conclusion: GuardAlign是一个有效的无需训练防御框架，能够显著提高大型视觉语言模型的安全性，同时保持甚至提升模型的实用性，为解决现有防御方法在复杂场景检测不准确和安全信号不稳定问题提供了有效方案。

Abstract: Large vision-language models (LVLMs) have achieved remarkable progress in vision-language reasoning tasks, yet ensuring their safety remains a critical challenge. Recent input-side defenses detect unsafe images with CLIP and prepend safety prefixes to prompts, but they still suffer from inaccurate detection in complex scenes and unstable safety signals during decoding. To address these issues, we propose GuardAlign, a training-free defense framework that integrates two strategies. First, OT-enhanced safety detection leverages optimal transport to measure distribution distances between image patches and unsafe semantics, enabling accurate identification of malicious regions without additional computational cost. Second, cross-modal attentive calibration strengthens the influence of safety prefixes by adaptively reallocating attention across layers, ensuring that safety signals remain consistently activated throughout generation. Extensive evaluations on six representative MLLMs demonstrate that GuardAlign reduces unsafe response rates by up to 39% on SPA-VL, while preserving utility, achieving an improvement on VQAv2 from 78.51% to 79.21%.

</details>


### [50] [Look Carefully: Adaptive Visual Reinforcements in Multimodal Large Language Models for Hallucination Mitigation](https://arxiv.org/abs/2602.24041)
*Xingyu Zhu,Kesen Zhao,Liang Yi,Shuo Wang,Zhicai Wang,Beier Zhu,Hanwang Zhang*

Main category: cs.CV

TL;DR: 提出自适应视觉增强(AIR)框架，无需训练即可减少多模态大语言模型的幻觉问题，通过原型令牌压缩和最优传输引导的补丁增强来选择性强化关键视觉信息。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉语言推理方面取得显著进展，但仍存在幻觉问题，即生成内容偏离视觉证据。现有缓解策略要么需要昂贵的训练监督，要么在推理时引入额外延迟。最近的视觉增强方法试图通过强化解码过程中的视觉令牌来解决这个问题，但它们通常不加区分地注入所有令牌，导致背景区域干扰并分散模型对关键线索的注意力。

Method: 提出自适应视觉增强(AIR)框架，包含两个组件：1) 基于原型的令牌压缩：将大量视觉令牌压缩为紧凑子集以抑制冗余；2) OT引导的补丁增强：量化隐藏状态与补丁嵌入之间的对齐，选择性地将最一致的补丁集成到前馈层中。

Result: 在代表性多模态大语言模型上的广泛实验表明，AIR显著减少了幻觉问题，同时保持了一般能力，证明其是构建可靠多模态大语言模型的有效解决方案。

Conclusion: AIR是一种无需训练的多模态大语言模型框架，通过选择性强化关键视觉信息有效缓解幻觉问题，为构建可靠的多模态大语言模型提供了有效解决方案。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language reasoning, yet they remain vulnerable to hallucination, where generated content deviates from visual evidence. Existing mitigation strategies either require costly supervision during training or introduce additional latency at inference time. Recent vision enhancement methods attempt to address this issue by reinforcing visual tokens during decoding, but they typically inject all tokens indiscriminately, which causes interference from background regions and distracts the model from critical cues. To overcome this challenge, we propose Adaptive Visual Reinforcement (AIR), a training-free framework for MLLMs. AIR consists of two components. Prototype-based token reduction condenses the large pool of visual tokens into a compact subset to suppress redundancy. OT-guided patch reinforcement quantifies the alignment between hidden states and patch embeddings to selectively integrate the most consistent patches into feed-forward layers. As a result, AIR enhances the model's reliance on salient visual information and effectively mitigates hallucination. Extensive experiments across representative MLLMs demonstrate that AIR substantially reduces hallucination while preserving general capabilities, establishing it as an effective solution for building reliable MLLMs.

</details>


### [51] [Spatio-Temporal Garment Reconstruction Using Diffusion Mapping via Pattern Coordinates](https://arxiv.org/abs/2602.24043)
*Yingxuan You,Ren Li,Corentin Dumery,Cong Cao,Hao Li,Pascal Fua*

Main category: cs.CV

TL;DR: 提出统一框架，从单张图像和视频序列重建高保真3D服装，结合隐式缝纫模式和生成扩散模型，在2D UV空间学习服装形状先验，实现准确详细的服装重建。


<details>
  <summary>Details</summary>
Motivation: 从单目图像和视频重建3D着装人体是虚拟试穿、虚拟形象创建和混合现实的基础问题。尽管人体重建取得显著进展，但准确重建服装几何，特别是宽松服装，仍然是一个开放挑战。

Method: 结合隐式缝纫模式(ISP)与生成扩散模型，在2D UV空间学习表达性服装形状先验。引入映射模型建立图像像素、UV图案坐标和3D几何之间的对应关系。扩展到动态重建时，引入时空扩散方案和测试时指导以强制长期时间一致性，并开发基于解析投影的约束来保持可见区域的图像对齐几何。

Result: 尽管仅在合成模拟布料数据上训练，但方法能很好地泛化到真实世界图像，在紧身和宽松服装上都持续优于现有方法。重建的服装保留精细几何细节，同时展现逼真的动态运动。

Conclusion: 提出的统一框架实现了从单张图像和视频的高保真3D服装重建，支持纹理编辑、服装重定向和动画等下游应用。

Abstract: Reconstructing 3D clothed humans from monocular images and videos is a fundamental problem with applications in virtual try-on, avatar creation, and mixed reality. Despite significant progress in human body recovery, accurately reconstructing garment geometry, particularly for loose-fitting clothing, remains an open challenge. We propose a unified framework for high-fidelity 3D garment reconstruction from both single images and video sequences. Our approach combines Implicit Sewing Patterns (ISP) with a generative diffusion model to learn expressive garment shape priors in 2D UV space. Leveraging these priors, we introduce a mapping model that establishes correspondences between image pixels, UV pattern coordinates, and 3D geometry, enabling accurate and detailed garment reconstruction from single images. We further extend this formulation to dynamic reconstruction by introducing a spatio-temporal diffusion scheme with test-time guidance to enforce long-range temporal consistency. We also develop analytic projection-based constraints that preserve image-aligned geometry in visible regions while enforcing coherent completion in occluded areas over time. Although trained exclusively on synthetically simulated cloth data, our method generalizes well to real-world imagery and consistently outperforms existing approaches on both tight- and loose-fitting garments. The reconstructed garments preserve fine geometric detail while exhibiting realistic dynamic motion, supporting downstream applications such as texture editing, garment retargeting, and animation.

</details>


### [52] [Quant Experts: Token-aware Adaptive Error Reconstruction with Mixture of Experts for Large Vision-Language Models Quantization](https://arxiv.org/abs/2602.24059)
*Chenwei Jia,Baoting Li,Xuchong Zhang,Mingzhuo Wei,Bochen Lin,Hongbin Sun*

Main category: cs.CV

TL;DR: 本文提出Quant Experts (QE)方法，通过token感知的自适应误差补偿和专家混合机制，改进视觉语言模型的训练后量化效果，解决重要通道分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有训练后量化方法主要依赖静态识别和全局补偿敏感通道，但忽视了这些重要通道在不同输入间的分布差异，导致量化效果不理想。研究发现重要通道的分布和出现频率在不同模态和token间存在显著差异。

Method: 提出Quant Experts (QE)方法：1）将重要通道分为token无关和token相关两组；2）对token无关组使用共享专家（低秩适配器）补偿全局量化误差；3）对token相关组使用路由专家（多个路由低秩适配器）补偿与特定token相关的局部量化误差。

Result: 实验表明QE在各种量化设置和模型规模（2B到70B参数）下都能持续提升任务准确率，同时保持与全精度模型相当的性能。

Conclusion: QE通过token感知的自适应误差补偿机制，有效解决了视觉语言模型量化中重要通道分布差异问题，显著提升了量化效果。

Abstract: Post-Training Quantization (PTQ) has emerged as an effective technique for alleviating the substantial computational and memory overheads of Vision-Language Models (VLMs) by compressing both weights and activations without retraining the full model. Existing PTQ methods primarily rely on static identification and global compensation of sensitive or outlier channels, yet they often overlook the distributional differences of these important channels across inputs, leading to unsatisfactory quantization. In this work, we observe that the distributions and occurrence frequencies of important channels vary significantly both across modalities and among tokens, even within the same modality. Accordingly, we propose \textbf{Quant Experts (QE)}, a token-aware adaptive error compensation with mixture-of-experts for VLMs quantization. QE divides the important channels into token-independent and token-dependent groups. For the former, a shared expert is designed for most tokens to compensate for global quantization error using a low-rank adapter. For the latter, routed experts including multiple routed low-rank adapters are elaborated to compensate for local quantization error related to specific tokens. Extensive experiments demonstrate that QE consistently enhances task accuracy across various quantization settings and model scales, ranging from 2B to 70B parameters, while maintaining performance comparable to full-precision models.

</details>


### [53] [EvalMVX: A Unified Benchmarking for Neural 3D Reconstruction under Diverse Multiview Setups](https://arxiv.org/abs/2602.24065)
*Zaiyan Yang,Jieji Ren,Xiangyi Wang,zonglin li,Xu Cao,Heng Guo,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: EvalMVX是一个包含25个物体、8500张图像的真实世界数据集，用于同时评估多视角立体视觉(MVS)、多视角偏振形状重建(MVSfP)和多视角光度立体视觉(MVPS)三种3D重建技术。


<details>
  <summary>Details</summary>
Motivation: 当前真实世界数据集主要关注基于RGB输入的多视角立体视觉(MVS)基准测试，而多视角光度立体视觉(MVPS)和多视角偏振形状重建(MVSfP)这两种对高保真表面重建和稀疏输入至关重要的技术，尚未与MVS一起进行定量评估。

Method: 提出EvalMVX数据集，包含25个物体，每个物体使用偏振相机在20个不同视角和17种光照条件（包括OLAT和自然光照）下捕获，共8500张图像。每个物体都包含对齐的真实3D网格，支持对MVX方法进行同步定量基准测试。

Result: 基于EvalMVX数据集评估了近年发表的13种MVX方法，记录了最佳性能方法，并识别了在不同几何细节和反射类型下的开放性问题。

Conclusion: EvalMVX数据集和基准测试结果有望启发未来多视角3D重建的研究，为不同MVX技术的工作范围提供定量评估依据。

Abstract: Recent advancements in neural surface reconstruction have significantly enhanced 3D reconstruction. However, current real world datasets mainly focus on benchmarking multiview stereo (MVS) based on RGB inputs. Multiview photometric stereo (MVPS) and multiview shape from polarization (MVSfP), though indispensable on high-fidelity surface reconstruction and sparse inputs, have not been quantitatively assessed together with MVS. To determine the working range of different MVX (MVS, MVSfP, and MVPS) techniques, we propose EvalMVX, a real-world dataset containing $25$ objects, each captured with a polarized camera under $20$ varying views and $17$ light conditions including OLAT and natural illumination, leading to $8,500$ images. Each object includes aligned ground-truth 3D mesh, facilitating quantitative benchmarking of MVX methods simultaneously. Based on our EvalMVX, we evaluate $13$ MVX methods published in recent years, record the best-performing methods, and identify open problems under diverse geometric details and reflectance types. We hope EvalMVX and the benchmarking results can inspire future research on multiview 3D reconstruction.

</details>


### [54] [DiffusionHarmonizer: Bridging Neural Reconstruction and Photorealistic Simulation with Online Diffusion Enhancer](https://arxiv.org/abs/2602.24096)
*Yuxuan Zhang,Katarína Tóthová,Zian Wang,Kangxue Yin,Haithem Turki,Riccardo de Lutio,Yen-Yu Chang,Or Litany,Sanja Fidler,Zan Gojcic*

Main category: cs.CV

TL;DR: DiffusionHarmonizer：一个在线生成增强框架，用于提升神经重建场景的渲染质量，解决视觉伪影和动态物体融合不真实的问题，实现实时一致的仿真输出


<details>
  <summary>Details</summary>
Motivation: 神经重建方法（如NeRF和3D高斯泼溅）虽然能从真实数据自动生成多样化仿真场景，但在渲染新视角时经常出现伪影，且难以真实地融合来自不同场景的动态物体，限制了仿真的真实性和实用性

Method: 提出DiffusionHarmonizer框架，核心是单步时间条件增强器，由预训练的多步图像扩散模型转换而来，能在单GPU上在线运行。关键是通过定制数据整理流程构建合成-真实配对数据，强调外观协调、伪影校正和光照真实性

Result: 开发了一个可扩展系统，显著提升了研究和生产环境中的仿真保真度，能够将不完美场景的渲染转换为时间一致且更真实的输出

Conclusion: DiffusionHarmonizer通过生成增强技术有效解决了神经重建仿真中的视觉质量问题，为自动驾驶等自主机器人的仿真提供了更真实、更实用的解决方案

Abstract: Simulation is essential to the development and evaluation of autonomous robots such as self-driving vehicles. Neural reconstruction is emerging as a promising solution as it enables simulating a wide variety of scenarios from real-world data alone in an automated and scalable way. However, while methods such as NeRF and 3D Gaussian Splatting can produce visually compelling results, they often exhibit artifacts particularly when rendering novel views, and fail to realistically integrate inserted dynamic objects, especially when they were captured from different scenes. To overcome these limitations, we introduce DiffusionHarmonizer, an online generative enhancement framework that transforms renderings from such imperfect scenes into temporally consistent outputs while improving their realism. At its core is a single-step temporally-conditioned enhancer that is converted from a pretrained multi-step image diffusion model, capable of running in online simulators on a single GPU. The key to training it effectively is a custom data curation pipeline that constructs synthetic-real pairs emphasizing appearance harmonization, artifact correction, and lighting realism. The result is a scalable system that significantly elevates simulation fidelity in both research and production environments.

</details>


### [55] [FocusTrack: One-Stage Focus-and-Suppress Framework for 3D Point Cloud Object Tracking](https://arxiv.org/abs/2602.24133)
*Sifan Zhou,Jiahao Nie,Ziyu Zhao,Yichao Cao,Xiaobo Lu*

Main category: cs.CV

TL;DR: FocusTrack是一种新颖的单阶段3D点云目标跟踪框架，通过帧间运动建模和聚焦抑制注意力机制，统一运动-语义协同建模，解决了现有两阶段方法的误差累积和计算瓶颈问题，在多个基准测试中达到SOTA性能且运行速度达105 FPS。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段运动中心方法存在两个根本限制：1）由于在运动估计前进行显式前景分割导致的解耦优化引起的误差累积；2）顺序处理带来的计算瓶颈。需要一种更高效、更准确的3D点云跟踪方法。

Method: 提出FocusTrack单阶段跟踪框架，包含两个核心创新：1）帧间运动建模（IMM）模块，使用时差孪生编码器捕获相邻帧间的全局运动模式；2）聚焦抑制注意力机制，通过运动显著特征门控增强前景语义，并基于IMM提供的时序感知运动上下文抑制背景噪声，无需显式分割。

Result: 在KITTI、nuScenes和Waymo等主要3D跟踪基准测试中，FocusTrack实现了新的SOTA性能，同时以105 FPS的高速运行。

Conclusion: FocusTrack通过统一运动-语义协同建模的单阶段范式，有效解决了现有两阶段方法的局限性，在准确性和效率方面都取得了显著提升，为3D点云目标跟踪提供了新的解决方案。

Abstract: In 3D point cloud object tracking, the motion-centric methods have emerged as a promising avenue due to its superior performance in modeling inter-frame motion. However, existing two-stage motion-based approaches suffer from fundamental limitations: (1) error accumulation due to decoupled optimization caused by explicit foreground segmentation prior to motion estimation, and (2) computational bottlenecks from sequential processing. To address these challenges, we propose FocusTrack, a novel one-stage paradigms tracking framework that unifies motion-semantics co-modeling through two core innovations: Inter-frame Motion Modeling (IMM) and Focus-and-Suppress Attention. The IMM module employs a temp-oral-difference siamese encoder to capture global motion patterns between adjacent frames. The Focus-and-Suppress attention that enhance the foreground semantics via motion-salient feature gating and suppress the background noise based on the temporal-aware motion context from IMM without explicit segmentation. Based on above two designs, FocusTrack enables end-to-end training with compact one-stage pipeline. Extensive experiments on prominent 3D tracking benchmarks, such as KITTI, nuScenes, and Waymo, demonstrate that the FocusTrack achieves new SOTA performance while running at a high speed with 105 FPS.

</details>


### [56] [AgenticOCR: Parsing Only What You Need for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2602.24134)
*Zhengren Wang,Dongsheng Ma,Huaping Zhong,Jiayu Li,Wentao Zhang,Bin Wang,Conghui He*

Main category: cs.CV

TL;DR: AgenticOCR是一种动态OCR解析范式，将传统静态OCR转变为查询驱动的按需提取系统，通过分析文档布局并选择性识别感兴趣区域，解决多模态RAG中页面级分块带来的信息过载问题。


<details>
  <summary>Details</summary>
Motivation: 多模态检索增强生成扩展到视觉文档处理时面临挑战：页面级分块和检索会导致将整个页面传递给生成器，引入过多无关上下文，不仅过载生成器的注意力机制，还稀释了最关键的证据。同时，将这些信息丰富的页面压缩到有限的视觉标记预算中会增加幻觉风险。

Method: 提出AgenticOCR动态解析范式，将光学字符识别从静态的全文本处理转变为查询驱动的按需提取系统。通过"图像思考"方式自主分析文档布局，识别并选择性识别感兴趣区域，实现视觉标记的按需解压缩，从而解耦检索粒度与僵化的页面级分块。

Result: 实验结果表明，AgenticOCR提高了视觉RAG系统的效率和准确性，在长文档理解方面达到了专家级性能。该方法有潜力成为视觉文档RAG堆栈的"第三个构建块"，与标准的嵌入和重排序模块协同工作。

Conclusion: AgenticOCR通过动态、查询驱动的OCR解析方法，有效解决了多模态RAG中页面级分块带来的信息过载和幻觉问题，为视觉文档理解提供了更高效准确的解决方案。

Abstract: The expansion of retrieval-augmented generation (RAG) into multimodal domains has intensified the challenge for processing complex visual documents, such as financial reports. While page-level chunking and retrieval is a natural starting point, it creates a critical bottleneck: delivering entire pages to the generator introduces excessive extraneous context. This not only overloads the generator's attention mechanism but also dilutes the most salient evidence. Moreover, compressing these information-rich pages into a limited visual token budget further increases the risk of hallucinations. To address this, we introduce AgenticOCR, a dynamic parsing paradigm that transforms optical character recognition (OCR) from a static, full-text process into a query-driven, on-demand extraction system. By autonomously analyzing document layout in a "thinking with images" manner, AgenticOCR identifies and selectively recognizes regions of interest. This approach performs on-demand decompression of visual tokens precisely where needed, effectively decoupling retrieval granularity from rigid page-level chunking. AgenticOCR has the potential to serve as the "third building block" of the visual document RAG stack, operating alongside and enhancing standard Embedding and Reranking modules. Experimental results demonstrate that AgenticOCR improves both the efficiency and accuracy of visual RAG systems, achieving expert-level performance in long document understanding. Code and models are available at https://github.com/OpenDataLab/AgenticOCR.

</details>


### [57] [Prune Wisely, Reconstruct Sharply: Compact 3D Gaussian Splatting via Adaptive Pruning and Difference-of-Gaussian Primitives](https://arxiv.org/abs/2602.24136)
*Haoran Wang,Guoxi Huang,Fan Zhang,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 提出了一种针对3D高斯泼溅的高效重建感知剪枝策略和3D差分高斯基元，显著减少高斯数量（高达90%）同时保持或提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅需要大量基元实现高保真度，导致冗余表示和高资源消耗，限制了复杂或大规模场景的可扩展性，需要有效的剪枝策略和更具表现力的基元。

Method: 1. 高效集成重建感知剪枝策略：基于重建质量自适应确定剪枝时机和细化间隔；2. 引入3D差分高斯基元：在单个基元中联合建模正负密度，提高紧凑配置下的高斯表达能力。

Result: 显著提高模型紧凑性，实现高达90%的高斯数量减少，同时提供与最先进方法相似或更好的视觉质量。

Conclusion: 提出的方法通过重建感知剪枝和差分高斯基元，有效解决了3D高斯泼溅的冗余问题，在保持渲染质量的同时大幅减少了模型规模，为实际部署提供了可行方案。

Abstract: Recent significant advances in 3D scene representation have been driven by 3D Gaussian Splatting (3DGS), which has enabled real-time rendering with photorealistic quality. 3DGS often requires a large number of primitives to achieve high fidelity, leading to redundant representations and high resource consumption, thereby limiting its scalability for complex or large-scale scenes. Consequently, effective pruning strategies and more expressive primitives that can reduce redundancy while preserving visual quality are crucial for practical deployment. We propose an efficient, integrated reconstruction-aware pruning strategy that adaptively determines pruning timing and refining intervals based on reconstruction quality, thus reducing model size while enhancing rendering quality. Moreover, we introduce a 3D Difference-of-Gaussians primitive that jointly models both positive and negative densities in a single primitive, improving the expressiveness of Gaussians under compact configurations. Our method significantly improves model compactness, achieving up to 90\% reduction in Gaussian-count while delivering visual quality that is similar to, or in some cases better than, that produced by state-of-the-art methods. Code will be made publicly available.

</details>


### [58] [Fixed Anchors Are Not Enough: Dynamic Retrieval and Persistent Homology for Dataset Distillation](https://arxiv.org/abs/2602.24144)
*Muquan Li,Hang Gou,Yingyi Ma,Rongzheng Wang,Ke Qin,Tao He*

Main category: cs.CV

TL;DR: RETA提出了一种基于检索和拓扑对齐的解耦数据集蒸馏框架，通过动态检索连接和持久拓扑对齐解决现有方法中的拟合复杂度差距和锚点牵引效应问题，在多个数据集上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前解耦数据集蒸馏方法使用静态真实图像块进行残差匹配，导致拟合复杂度差距和锚点牵引效应，降低了类内多样性并损害了泛化能力。

Method: 提出RETA框架：1) 动态检索连接(DRC)：从预建池中选择真实图像块，最小化教师特征空间的拟合复杂度分数，通过残差连接注入以控制复杂度；2) 持久拓扑对齐(PTA)：使用持久同调正则化合成过程，构建互k-NN特征图，计算组件和环的持久图像，惩罚真实和合成集之间的拓扑差异。

Result: 在CIFAR-100、Tiny-ImageNet、ImageNet-1K及多个ImageNet子集上，RETA在可比时间和内存下持续优于各种基线方法，特别是在ImageNet-1K上使用ResNet-18达到每类50张图像时64.3%的top-1准确率，比先前最佳方法提升3.1%。

Conclusion: RETA通过动态检索连接和持久拓扑对齐有效解决了现有解耦数据集蒸馏方法的问题，显著提升了合成数据集的质量和泛化性能，为大规模数据集压缩提供了有效解决方案。

Abstract: Decoupled dataset distillation (DD) compresses large corpora into a few synthetic images by matching a frozen teacher's statistics. However, current residual-matching pipelines rely on static real patches, creating a fit-complexity gap and a pull-to-anchor effect that reduce intra-class diversity and hurt generalization. To address these issues, we introduce RETA -- a Retrieval and Topology Alignment framework for decoupled DD. First, Dynamic Retrieval Connection (DRC) selects a real patch from a prebuilt pool by minimizing a fit-complexity score in teacher feature space; the chosen patch is injected via a residual connection to tighten feature fit while controlling injected complexity. Second, Persistent Topology Alignment (PTA) regularizes synthesis with persistent homology: we build a mutual k-NN feature graph, compute persistence images of components and loops, and penalize topology discrepancies between real and synthetic sets, mitigating pull-to-anchor effect. Across CIFAR-100, Tiny-ImageNet, ImageNet-1K, and multiple ImageNet subsets, RETA consistently outperforms various baselines under comparable time and memory, especially reaching 64.3% top-1 accuracy on ImageNet-1K with ResNet-18 at 50 images per class, +3.1% over the best prior.

</details>


### [59] [A Mixed Diet Makes DINO An Omnivorous Vision Encoder](https://arxiv.org/abs/2602.24181)
*Rishabh Kabra,Maks Ovsjanikov,Drew A. Hudson,Ye Xia,Skanda Koppula,Andre Araujo,Joao Carreira,Niloy J. Mitra*

Main category: cs.CV

TL;DR: 论文提出Omnivorous Vision Encoder框架，解决预训练视觉编码器在不同模态间特征对齐差的问题，通过最大化同一场景不同模态的特征对齐和蒸馏目标，学习模态无关的特征空间。


<details>
  <summary>Details</summary>
Motivation: 现有预训练视觉编码器（如DINOv2）在单模态任务上表现优异，但其特征表示在不同模态间对齐性差。例如，同一场景的RGB图像和深度图的特征嵌入余弦相似度与两个随机不相关图像几乎相同，这限制了跨模态理解能力。

Method: 提出Omnivorous Vision Encoder框架，采用双重训练目标：1）最大化同一场景不同模态（RGB、深度、分割等）之间的特征对齐；2）蒸馏目标将学习到的表示锚定到完全冻结的教师模型（如DINOv2）输出，使学生编码器产生与输入模态无关的一致强大嵌入。

Result: 该方法使编码器变得"全能"，能够为给定场景产生一致的强大嵌入，无论输入模态如何，同时保留了原始基础模型的判别语义，实现了鲁棒的跨模态理解。

Conclusion: Omnivorous Vision Encoder通过学习模态无关的特征空间，解决了预训练视觉编码器跨模态特征对齐差的问题，在保持基础模型判别能力的同时实现了强大的跨模态理解能力。

Abstract: Pre-trained vision encoders like DINOv2 have demonstrated exceptional performance on unimodal tasks. However, we observe that their feature representations are poorly aligned across different modalities. For instance, the feature embedding for an RGB image and its corresponding depth map of the same scene exhibit a cosine similarity that is nearly identical to that of two random, unrelated images. To address this, we propose the Omnivorous Vision Encoder, a novel framework that learns a modality-agnostic feature space. We train the encoder with a dual objective: first, to maximize the feature alignment between different modalities of the same scene; and second, a distillation objective that anchors the learned representations to the output of a fully frozen teacher such as DINOv2. The resulting student encoder becomes "omnivorous" by producing a consistent, powerful embedding for a given scene, regardless of the input modality (RGB, Depth, Segmentation, etc.). This approach enables robust cross-modal understanding while retaining the discriminative semantics of the original foundation model.

</details>


### [60] [HumanOrbit: 3D Human Reconstruction as 360° Orbit Generation](https://arxiv.org/abs/2602.24148)
*Keito Suzuki,Kunyao Chen,Lei Wang,Bang Du,Runfa Blark Li,Peng Liu,Ning Bi,Truong Nguyen*

Main category: cs.CV

TL;DR: HumanOrbit：从单张图像生成360度环绕人物视频的扩散模型方法


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于图像扩散模型进行多视角合成，但存在视角间不一致和身份保持不佳的问题。视频扩散模型在生成逼真结果方面表现出色，因此探索将其用于多视角人物图像生成。

Method: 提出HumanOrbit视频扩散模型，能够合成围绕人物的连续相机旋转，生成几何一致的新视角同时保持人物外观和身份。进一步提出重建流程，从生成的多视角帧中恢复带纹理的人物网格模型。

Result: 实验验证了HumanOrbit在多视角图像生成方面的有效性，重建的3D模型在完整性和保真度方面优于现有最先进基线方法。

Conclusion: HumanOrbit能够从单张输入图像生成360度环绕视频，有效解决多视角一致性和身份保持问题，为3D人物重建提供了高质量的多视角数据。

Abstract: We present a method for generating a full 360° orbit video around a person from a single input image. Existing methods typically adapt image-based diffusion models for multi-view synthesis, but yield inconsistent results across views and with the original identity. In contrast, recent video diffusion models have demonstrated their ability in generating photorealistic results that align well with the given prompts. Inspired by these results, we propose HumanOrbit, a video diffusion model for multi-view human image generation. Our approach enables the model to synthesize continuous camera rotations around the subject, producing geometrically consistent novel views while preserving the appearance and identity of the person. Using the generated multi-view frames, we further propose a reconstruction pipeline that recovers a textured mesh of the subject. Experimental results validate the effectiveness of HumanOrbit for multi-view image generation and that the reconstructed 3D models exhibit superior completeness and fidelity compared to those from state-of-the-art baselines.

</details>


### [61] [Manifold-Preserving Superpixel Hierarchies and Embeddings for the Exploration of High-Dimensional Images](https://arxiv.org/abs/2602.24160)
*Alexander Vieth,Boudewijn Lelieveldt,Elmar Eisemann,Anna Vilanova,Thomas Höllt*

Main category: cs.CV

TL;DR: 提出了一种考虑高维属性流形和空间布局的超像素层次结构，用于高维图像的一致探索


<details>
  <summary>Details</summary>
Motivation: 现有分层降维方法仅基于属性信息构建层次结构，忽略了像素的空间布局，导致图像空间感兴趣区域与属性空间层次结构之间缺乏一致性，阻碍了高维图像的探索

Method: 提出了一种超像素层次结构，在构建过程中同时考虑高维属性流形和像素空间布局，实现图像空间和属性空间的一致探索

Result: 通过两个用例与经典分层嵌入图像探索方法进行比较，展示了新方法在嵌入探索中的有效性

Conclusion: 提出的图像引导层次结构能够实现高维图像在图像空间和属性空间的一致探索，解决了传统方法中空间布局与属性信息分离的问题

Abstract: High-dimensional images, or images with a high-dimensional attribute vector per pixel, are commonly explored with coordinated views of a low-dimensional embedding of the attribute space and a conventional image representation. Nowadays, such images can easily contain several million pixels. For such large datasets, hierarchical embedding techniques are better suited to represent the high-dimensional attribute space than flat dimensionality reduction methods. However, available hierarchical dimensionality reduction methods construct the hierarchy purely based on the attribute information and ignore the spatial layout of pixels in the images. This impedes the exploration of regions of interest in the image space, since there is no congruence between a region of interest in image space and the associated attribute abstractions in the hierarchy. In this paper, we present a superpixel hierarchy for high-dimensional images that takes the high-dimensional attribute manifold into account during construction. Through this, our method enables consistent exploration of high-dimensional images in both image and attribute space. We show the effectiveness of this new image-guided hierarchy in the context of embedding exploration by comparing it with classical hierarchical embedding-based image exploration in two use cases.

</details>


### [62] [GeoDiff4D: Geometry-Aware Diffusion for 4D Head Avatar Reconstruction](https://arxiv.org/abs/2602.24161)
*Chao Xu,Xiaochen Zhao,Xiang Deng,Jingxiang Sun,Zhuo Su,Donglin Di,Yebin Liu*

Main category: cs.CV

TL;DR: 提出基于几何感知扩散模型的新框架，从单张肖像图像重建高保真、可动画的4D头部虚拟形象，通过联合合成图像和表面法线，结合3D高斯表示实现实时渲染。


<details>
  <summary>Details</summary>
Motivation: 从单张肖像图像重建逼真且可动画的4D头部虚拟形象是计算机视觉中的基本挑战。现有方法主要依赖2D先验，难以实现一致的3D几何结构，需要更强的几何先验来提升重建质量。

Method: 提出几何感知扩散框架，联合合成肖像图像和对应的表面法线；使用无姿态表情编码器捕捉隐式表情表示；将合成图像和表情潜在编码整合到基于3D高斯的虚拟形象中，实现高保真渲染。

Result: 实验表明，该方法在视觉质量、表情保真度和跨身份泛化能力方面显著优于现有最先进方法，同时支持实时渲染。

Conclusion: 通过几何感知扩散学习强几何先验，能够从单张肖像图像重建高质量、可动画的4D头部虚拟形象，在多个指标上超越现有方法，具有实际应用价值。

Abstract: Reconstructing photorealistic and animatable 4D head avatars from a single portrait image remains a fundamental challenge in computer vision. While diffusion models have enabled remarkable progress in image and video generation for avatar reconstruction, existing methods primarily rely on 2D priors and struggle to achieve consistent 3D geometry. We propose a novel framework that leverages geometry-aware diffusion to learn strong geometry priors for high-fidelity head avatar reconstruction. Our approach jointly synthesizes portrait images and corresponding surface normals, while a pose-free expression encoder captures implicit expression representations. Both synthesized images and expression latents are incorporated into 3D Gaussian-based avatars, enabling photorealistic rendering with accurate geometry. Extensive experiments demonstrate that our method substantially outperforms state-of-the-art approaches in visual quality, expression fidelity, and cross-identity generalization, while supporting real-time rendering.

</details>


### [63] [A multimodal slice discovery framework for systematic failure detection and explanation in medical image classification](https://arxiv.org/abs/2602.24183)
*Yixuan Liu,Kanwal K. Bhatia,Ahmed E. Fetit*

Main category: cs.CV

TL;DR: 提出了首个针对医学应用的自动化审计框架，将切片发现方法扩展到多模态表示，用于发现和解释分类器失败案例


<details>
  <summary>Details</summary>
Motivation: 尽管基于机器学习的医学图像分类器取得了进展，但其安全性和可靠性在实际应用中仍是主要问题。现有审计方法主要依赖单模态特征或基于元数据的子组分析，这些方法在可解释性方面有限，且往往无法发现隐藏的系统性失败。

Method: 引入了首个自动化审计框架，将切片发现方法扩展到多模态表示，专门针对医学应用。使用MIMIC-CXR-JPG数据集在常见失败场景下进行了全面实验。

Result: 该框架在失败发现和解释生成方面表现出强大能力。结果显示多模态信息通常允许更全面有效的分类器审计，而单模态变体（除仅图像输入外）在资源受限场景下也显示出强大潜力。

Conclusion: 提出的多模态审计框架能够有效发现和解释医学图像分类器的系统性失败，为实际应用中的安全性和可靠性提供了重要工具。

Abstract: Despite advances in machine learning-based medical image classifiers, the safety and reliability of these systems remain major concerns in practical settings. Existing auditing approaches mainly rely on unimodal features or metadata-based subgroup analyses, which are limited in interpretability and often fail to capture hidden systematic failures. To address these limitations, we introduce the first automated auditing framework that extends slice discovery methods to multimodal representations specifically for medical applications. Comprehensive experiments were conducted under common failure scenarios using the MIMIC-CXR-JPG dataset, demonstrating the framework's strong capability in both failure discovery and explanation generation. Our results also show that multimodal information generally allows more comprehensive and effective auditing of classifiers, while unimodal variants beyond image-only inputs exhibit strong potential in scenarios where resources are constrained.

</details>


### [64] [SenCache: Accelerating Diffusion Model Inference via Sensitivity-Aware Caching](https://arxiv.org/abs/2602.24208)
*Yasaman Haghighi,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出SenCache框架，通过分析模型输出对去噪输入的敏感性来动态选择缓存时间步，相比现有启发式缓存方法在相同计算预算下获得更好的视频生成质量


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成方面达到最先进质量，但推理成本高昂，因为需要大量顺序去噪步骤。现有缓存方法依赖启发式标准选择缓存/重用时间步，需要大量调优，缺乏理论依据

Method: 提出敏感性感知缓存框架，通过分析模型输出对噪声潜变量和时间步扰动的敏感性来形式化缓存误差，基于此设计SenCache动态缓存策略，自适应地为每个样本选择缓存时间步

Result: 在Wan 2.1、CogVideoX和LTX-Video上的实验表明，SenCache在相似计算预算下比现有缓存方法获得更好的视觉质量

Conclusion: SenCache为自适应缓存提供了理论基础，解释了先前经验启发式方法为何部分有效，并将其扩展到动态、样本特定的方法，显著提升了扩散模型推理效率

Abstract: Diffusion models achieve state-of-the-art video generation quality, but their inference remains expensive due to the large number of sequential denoising steps. This has motivated a growing line of research on accelerating diffusion inference. Among training-free acceleration methods, caching reduces computation by reusing previously computed model outputs across timesteps. Existing caching methods rely on heuristic criteria to choose cache/reuse timesteps and require extensive tuning. We address this limitation with a principled sensitivity-aware caching framework. Specifically, we formalize the caching error through an analysis of the model output sensitivity to perturbations in the denoising inputs, i.e., the noisy latent and the timestep, and show that this sensitivity is a key predictor of caching error. Based on this analysis, we propose Sensitivity-Aware Caching (SenCache), a dynamic caching policy that adaptively selects caching timesteps on a per-sample basis. Our framework provides a theoretical basis for adaptive caching, explains why prior empirical heuristics can be partially effective, and extends them to a dynamic, sample-specific approach. Experiments on Wan 2.1, CogVideoX, and LTX-Video show that SenCache achieves better visual quality than existing caching methods under similar computational budgets.

</details>


### [65] [MuViT: Multi-Resolution Vision Transformers for Learning Across Scales in Microscopy](https://arxiv.org/abs/2602.24222)
*Albert Dominguez Mantes,Gioele La Manno,Martin Weigert*

Main category: cs.CV

TL;DR: MuViT是一种新型Transformer架构，专门用于融合显微镜图像的多分辨率观测，通过共享世界坐标系嵌入和扩展旋转位置编码，实现跨尺度信息整合。


<details>
  <summary>Details</summary>
Motivation: 现代显微镜产生包含从细胞形态到组织结构的多尺度千兆像素图像，但现有视觉模型通常只在单一分辨率下操作或从单一视图提取多尺度特征，无法充分利用显微镜数据的固有多分辨率特性。

Method: 提出MuViT架构，将所有图像块嵌入到共享的世界坐标系中，扩展旋转位置编码到这些坐标，使注意力机制能够在单个编码器中整合宽视野上下文和高分辨率细节。采用多分辨率MAE预训练方法。

Result: 在合成基准测试、肾脏组织病理学和高分辨率小鼠大脑显微镜数据上，MuViT相比强大的ViT和CNN基线模型均取得一致改进。多分辨率MAE预训练产生尺度一致的表征，增强了下游任务性能。

Conclusion: 显式的世界坐标建模为大规模显微镜分析中利用多分辨率信息提供了一种简单而强大的机制，证明了多分辨率观测融合的有效性。

Abstract: Modern microscopy routinely produces gigapixel images that contain structures across multiple spatial scales, from fine cellular morphology to broader tissue organization. Many analysis tasks require combining these scales, yet most vision models operate at a single resolution or derive multi-scale features from one view, limiting their ability to exploit the inherently multi-resolution nature of microscopy data. We introduce MuViT, a transformer architecture built to fuse true multi-resolution observations from the same underlying image. MuViT embeds all patches into a shared world-coordinate system and extends rotary positional embeddings to these coordinates, enabling attention to integrate wide-field context with high-resolution detail within a single encoder. Across synthetic benchmarks, kidney histopathology, and high-resolution mouse-brain microscopy, MuViT delivers consistent improvements over strong ViT and CNN baselines. Multi-resolution MAE pretraining further produces scale-consistent representations that enhance downstream tasks. These results demonstrate that explicit world-coordinate modelling provides a simple yet powerful mechanism for leveraging multi-resolution information in large-scale microscopy analysis.

</details>


### [66] [Enhancing Spatial Understanding in Image Generation via Reward Modeling](https://arxiv.org/abs/2602.24233)
*Zhenyu Tang,Chaoran Feng,Yufan Deng,Jie Wu,Xiaojie Li,Rui Wang,Yunpeng Chen,Daquan Zhou*

Main category: cs.CV

TL;DR: 提出SpatialScore奖励模型，通过强化学习提升文本到图像生成模型的空间关系理解能力


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成虽然视觉保真度和创造力有所提升，但对复杂空间关系的编码要求更高，通常需要多次采样尝试才能获得满意结果

Method: 1. 构建包含超过80k偏好对的SpatialReward-Dataset；2. 基于此数据集开发SpatialScore奖励模型，用于评估文本到图像生成中的空间关系准确性；3. 使用该奖励模型进行在线强化学习以改善复杂空间生成

Result: SpatialScore奖励模型在空间评估方面表现优异，甚至超越了领先的专有模型；在多个基准测试中，该专门奖励模型为图像生成的空间理解带来了显著且一致的提升

Conclusion: 通过专门的奖励模型和强化学习，可以有效提升文本到图像生成模型对复杂空间关系的理解和生成能力

Abstract: Recent progress in text-to-image generation has greatly advanced visual fidelity and creativity, but it has also imposed higher demands on prompt complexity-particularly in encoding intricate spatial relationships. In such cases, achieving satisfactory results often requires multiple sampling attempts. To address this challenge, we introduce a novel method that strengthens the spatial understanding of current image generation models. We first construct the SpatialReward-Dataset with over 80k preference pairs. Building on this dataset, we build SpatialScore, a reward model designed to evaluate the accuracy of spatial relationships in text-to-image generation, achieving performance that even surpasses leading proprietary models on spatial evaluation. We further demonstrate that this reward model effectively enables online reinforcement learning for the complex spatial generation. Extensive experiments across multiple benchmarks show that our specialized reward model yields significant and consistent gains in spatial understanding for image generation.

</details>


### [67] [Joint Geometric and Trajectory Consistency Learning for One-Step Real-World Super-Resolution](https://arxiv.org/abs/2602.24240)
*Chengyan Deng,Zhangquan Chen,Li Yu,Kai Zhang,Xue Zhou,Wang Zhang*

Main category: cs.CV

TL;DR: GTASR提出了一种用于真实世界图像超分辨率的几何轨迹对齐一致性训练方法，通过轨迹对齐和双参考结构校正机制解决一致性漂移和几何解耦问题，在保持低延迟的同时实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的真实世界图像超分辨率虽然感知质量优秀，但迭代采样计算成本高。现有的一步生成方法要么参数过多，要么受限于教师模型能力。一致性模型虽然推理高效，但存在一致性漂移积累和"几何解耦"问题。

Method: 提出GTASR方法：1) 轨迹对齐策略通过全路径投影修正切向量场；2) 双参考结构校正机制施加严格的结构约束。这是一种简单有效的Real-ISR一致性训练范式。

Result: 大量实验验证GTASR在代表性基线方法上表现出优越性能，同时保持最小延迟。代码和模型将在GitHub上开源。

Conclusion: GTASR通过解决一致性漂移和几何解耦问题，为真实世界图像超分辨率提供了一种高效且性能优越的一致性训练方法。

Abstract: Diffusion-based Real-World Image Super-Resolution (Real-ISR) achieves impressive perceptual quality but suffers from high computational costs due to iterative sampling. While recent distillation approaches leveraging large-scale Text-to-Image (T2I) priors have enabled one-step generation, they are typically hindered by prohibitive parameter counts and the inherent capability bounds imposed by teacher models. As a lightweight alternative, Consistency Models offer efficient inference but struggle with two critical limitations: the accumulation of consistency drift inherent to transitive training, and a phenomenon we term "Geometric Decoupling" - where the generative trajectory achieves pixel-wise alignment yet fails to preserve structural coherence. To address these challenges, we propose GTASR (Geometric Trajectory Alignment Super-Resolution), a simple yet effective consistency training paradigm for Real-ISR. Specifically, we introduce a Trajectory Alignment (TA) strategy to rectify the tangent vector field via full-path projection, and a Dual-Reference Structural Rectification (DRSR) mechanism to enforce strict structural constraints. Extensive experiments verify that GTASR delivers superior performance over representative baselines while maintaining minimal latency. The code and model will be released at https://github.com/Blazedengcy/GTASR.

</details>


### [68] [Compositional Generalization Requires Linear, Orthogonal Representations in Vision Embedding Models](https://arxiv.org/abs/2602.24264)
*Arnas Uselis,Andrea Dittadi,Seong Joon Oh*

Main category: cs.CV

TL;DR: 论文提出组合泛化的几何约束理论：为实现组合泛化，神经表示必须线性分解为各概念的正交分量，这为广泛观察到的线性表示假设提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 尽管现代模型在大量数据上训练，但仅覆盖了可能输入的组合空间的一小部分，需要研究支持未见组合泛化的表示结构。

Method: 形式化组合泛化的三个要求（可分性、可转移性、稳定性），证明这些要求施加了必要的几何约束：表示必须线性分解为每个概念的分量，且这些分量在概念间必须正交。进一步推导维度界限，将可组合概念数量与嵌入几何联系起来。

Result: 在CLIP、SigLIP、DINO等现代视觉模型中评估预测，发现表示确实呈现部分线性分解，具有低秩、近似正交的每概念因子，且这种结构的程度与未见组合上的组合泛化性能相关。

Conclusion: 线性表示假设中观察到的线性结构是组合泛化的必然结果。随着模型规模扩大，这些条件预测了它们可能收敛的表示几何。

Abstract: Compositional generalization, the ability to recognize familiar parts in novel contexts, is a defining property of intelligent systems. Although modern models are trained on massive datasets, they still cover only a tiny fraction of the combinatorial space of possible inputs, raising the question of what structure representations must have to support generalization to unseen combinations. We formalize three desiderata for compositional generalization under standard training (divisibility, transferability, stability) and show they impose necessary geometric constraints: representations must decompose linearly into per-concept components, and these components must be orthogonal across concepts. This provides theoretical grounding for the Linear Representation Hypothesis: the linear structure widely observed in neural representations is a necessary consequence of compositional generalization. We further derive dimension bounds linking the number of composable concepts to the embedding geometry. Empirically, we evaluate these predictions across modern vision models (CLIP, SigLIP, DINO) and find that representations exhibit partial linear factorization with low-rank, near-orthogonal per-concept factors, and that the degree of this structure correlates with compositional generalization on unseen combinations. As models continue to scale, these conditions predict the representational geometry they may converge to. Code is available at https://github.com/oshapio/necessary-compositionality.

</details>


### [69] [Hierarchical Action Learning for Weakly-Supervised Action Segmentation](https://arxiv.org/abs/2602.24275)
*Junxian Huang,Ruichu Cai,Hao Zhu,Juntao Fang,Boyan Xu,Weilin Chen,Zijian Li,Shenghua Gao*

Main category: cs.CV

TL;DR: HAL模型通过分层因果生成过程，利用高低层潜在变量不同时间尺度特性，实现弱监督动作分割，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类通过关键转换点在不同抽象层次上感知动作，而机器依赖视觉特征容易过度分割。高低层潜在变量具有不同演化速率：低层视觉变量变化快，高层动作变量变化慢，这为识别高层动作变量提供了机会。

Method: 提出分层动作学习(HAL)模型，引入分层因果数据生成过程，高层潜在动作控制低层视觉特征动态。使用确定性过程对齐时间尺度，采用分层金字塔transformer捕获视觉特征和潜在变量，并应用稀疏转换约束强制高层动作变量的慢动态。

Result: 在温和假设下证明潜在动作变量严格可识别。在多个基准测试中，HAL模型显著优于现有弱监督动作分割方法，证实了其在实际应用中的有效性。

Conclusion: 通过建模高低层潜在变量的不同时间尺度，HAL模型能够有效识别高层动作变量，在弱监督动作分割任务中表现出色，为视频理解中的分层推理提供了有效解决方案。

Abstract: Humans perceive actions through key transitions that structure actions across multiple abstraction levels, whereas machines, relying on visual features, tend to over-segment. This highlights the difficulty of enabling hierarchical reasoning in video understanding. Interestingly, we observe that lower-level visual and high-level action latent variables evolve at different rates, with low-level visual variables changing rapidly, while high-level action variables evolve more slowly, making them easier to identify. Building on this insight, we propose the Hierarchical Action Learning (\textbf{HAL}) model for weakly-supervised action segmentation. Our approach introduces a hierarchical causal data generation process, where high-level latent action governs the dynamics of low-level visual features. To model these varying timescales effectively, we introduce deterministic processes to align these latent variables over time. The \textbf{HAL} model employs a hierarchical pyramid transformer to capture both visual features and latent variables, and a sparse transition constraint is applied to enforce the slower dynamics of high-level action variables. This mechanism enhances the identification of these latent variables over time. Under mild assumptions, we prove that these latent action variables are strictly identifiable. Experimental results on several benchmarks show that the \textbf{HAL} model significantly outperforms existing methods for weakly-supervised action segmentation, confirming its practical effectiveness in real-world applications.

</details>


### [70] [Mode Seeking meets Mean Seeking for Fast Long Video Generation](https://arxiv.org/abs/2602.24289)
*Shengqu Cai,Weili Nie,Chao Liu,Julius Berner,Lvmin Zhang,Nanye Ma,Hansheng Chen,Maneesh Agrawala,Leonidas Guibas,Gordon Wetzstein,Arash Vahdat*

Main category: cs.CV

TL;DR: 提出一种训练范式，将模式寻求与均值寻求结合，通过解耦扩散变换器分离局部保真度和长期一致性，实现从秒级到分钟级视频生成的扩展。


<details>
  <summary>Details</summary>
Motivation: 解决视频生成从秒级扩展到分钟级的关键瓶颈：短视频数据丰富且高保真，但连贯的长视频数据稀缺且局限于狭窄领域。

Method: 采用解耦扩散变换器，包含全局流匹配头（通过监督学习在长视频上训练以捕捉叙事结构）和局部分布匹配头（通过模式寻求的反向KL散度将滑动窗口与冻结的短视频教师对齐）。

Result: 该方法能够合成分钟级视频，通过监督流匹配从有限的长视频中学习长程一致性和运动，同时通过对齐每个滑动窗口段到冻结的短视频教师来继承局部真实感，实现快速长视频生成。

Conclusion: 评估表明，该方法通过联合改善局部清晰度、运动和长程一致性，有效缩小了保真度与时间范围之间的差距。

Abstract: Scaling video generation from seconds to minutes faces a critical bottleneck: while short-video data is abundant and high-fidelity, coherent long-form data is scarce and limited to narrow domains. To address this, we propose a training paradigm where Mode Seeking meets Mean Seeking, decoupling local fidelity from long-term coherence based on a unified representation via a Decoupled Diffusion Transformer. Our approach utilizes a global Flow Matching head trained via supervised learning on long videos to capture narrative structure, while simultaneously employing a local Distribution Matching head that aligns sliding windows to a frozen short-video teacher via a mode-seeking reverse-KL divergence. This strategy enables the synthesis of minute-scale videos that learns long-range coherence and motions from limited long videos via supervised flow matching, while inheriting local realism by aligning every sliding-window segment of the student to a frozen short-video teacher, resulting in a few-step fast long video generator. Evaluations show that our method effectively closes the fidelity-horizon gap by jointly improving local sharpness, motion and long-range consistency. Project website: https://primecai.github.io/mmm/.

</details>


### [71] [UFO-4D: Unposed Feedforward 4D Reconstruction from Two Images](https://arxiv.org/abs/2602.24290)
*Junhwa Hur,Charles Herrmann,Songyou Peng,Philipp Henzler,Zeyu Ma,Todd Zickler,Deqing Sun*

Main category: cs.CV

TL;DR: UFO-4D提出了一种统一的feedforward框架，仅需一对未标定图像即可重建密集的4D表示，直接估计动态3D高斯溅射，实现3D几何、3D运动和相机姿态的联合一致估计。


<details>
  <summary>Details</summary>
Motivation: 当前密集4D重建方法依赖缓慢的测试时优化或碎片化的任务特定前馈模型，需要一种统一的feedforward框架来解决从未标定图像中重建密集4D表示的挑战。

Method: 核心方法是使用动态3D高斯表示，通过可微分渲染多个信号实现自监督图像合成损失，将外观、深度和运动紧密耦合。所有模态共享相同的几何基元，监督一个模态会自然正则化并改进其他模态。

Result: UFO-4D在联合几何、运动和相机姿态估计方面比先前工作提升高达3倍，能够实现跨新视角和时间的高保真4D插值。

Conclusion: UFO-4D通过统一的feedforward框架成功解决了从未标定图像重建密集4D表示的挑战，其动态3D高斯表示方法在数据稀缺情况下表现出色，实现了高质量的4D重建和插值。

Abstract: Dense 4D reconstruction from unposed images remains a critical challenge, with current methods relying on slow test-time optimization or fragmented, task-specific feedforward models. We introduce UFO-4D, a unified feedforward framework to reconstruct a dense, explicit 4D representation from just a pair of unposed images. UFO-4D directly estimates dynamic 3D Gaussian Splats, enabling the joint and consistent estimation of 3D geometry, 3D motion, and camera pose in a feedforward manner. Our core insight is that differentiably rendering multiple signals from a single Dynamic 3D Gaussian representation offers major training advantages. This approach enables a self-supervised image synthesis loss while tightly coupling appearance, depth, and motion. Since all modalities share the same geometric primitives, supervising one inherently regularizes and improves the others. This synergy overcomes data scarcity, allowing UFO-4D to outperform prior work by up to 3 times in joint geometry, motion, and camera pose estimation. Our representation also enables high-fidelity 4D interpolation across novel views and time. Please visit our project page for visual results: https://ufo-4d.github.io/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [Detoxifying LLMs via Representation Erasure-Based Preference Optimization](https://arxiv.org/abs/2602.23391)
*Nazanin Mohammadi Sepahvand,Eleni Triantafillou,Hugo Larochelle,Doina Precup,Daniel M. Roy,Gintare Karolina Dziugaite*

Main category: cs.LG

TL;DR: REPO是一种基于表示擦除的偏好优化方法，通过token级别的偏好学习强制有毒输出的表示收敛到良性表示，实现深度去毒化，比现有方法更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有基于DPO、NPO等算法的去毒化方法存在局限性：它们只是表面降低了有害输出的概率，但模型表示中仍保留有害"方向"，容易受到对抗性提示和微调攻击的影响。

Method: 提出REPO（基于表示擦除的偏好优化），将去毒化重新定义为token级别的偏好问题。使用新的目标函数和偏好数据，强制有毒输出的表示向良性表示收敛，对编码毒性的神经元进行深度局部编辑。

Result: REPO实现了最先进的鲁棒性，能够阻止包括重新学习攻击和增强的GCG越狱在内的复杂威胁，而现有的基于表示和输出的方法都会失败。机制分析显示REPO能对毒性编码神经元进行深度局部编辑，同时保持模型的一般效用。

Conclusion: REPO通过token级别的表示擦除方法实现了更鲁棒的去毒化，解决了现有方法只能表面降低有害输出概率而无法深度消除毒性表示的根本问题。

Abstract: Large language models (LLMs) trained on webscale data can produce toxic outputs, raising concerns for safe deployment. Prior defenses, based on applications of DPO, NPO, and similar algorithms, reduce the likelihood of harmful continuations, but not robustly so: they are vulnerable to adversarial prompting and easily undone by fine-tuning-based relearning attacks. Indeed, research has shown that these edits to the model are superficial: linear probing reveals that harmful "directions" remain present in representations. To address this, we propose Representation Erasure-based Preference Optimization (REPO), reformulating detoxification as a token-level preference problem. Using a novel objective with preference data, we force the representations of toxic continuations to converge toward their benign counterparts. Our mechanistic analysis reveals that this granular approach is critical: unlike baselines, REPO induces deep, localized edits to toxicity-encoding neurons while preserving general model utility. Exhaustive evaluations show that REPO achieves state-of-the-art robustness, stopping sophisticated threats-including relearning attacks and enhanced GCG jailbreaks-where existing representation- and output-based methods fail.

</details>


### [73] [U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation](https://arxiv.org/abs/2602.23400)
*Zezheng Wu,Rui Wang,Xinghe Cheng,Yang Shao,Qing Yang,Jiapu Wang,Jingwei Zhang*

Main category: cs.LG

TL;DR: U-CAN是一个针对生成式推荐系统的隐私保护框架，通过低秩适配器的软衰减机制选择性遗忘敏感属性，解决传统机器遗忘方法中的多义性困境和效用损失问题。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐系统在微调时会无意中将用户敏感属性编码到模型参数中，引发隐私担忧。现有的机器遗忘技术面临多义性困境——神经元同时编码敏感数据和一般推理模式，导致传统梯度或剪枝方法会造成灾难性的效用损失。

Method: 提出Utility-aware Contrastive AttenuatioN (U-CAN)框架，在低秩适配器上操作：1) 通过对比激活量化风险，识别对遗忘集敏感但对保留集抑制的神经元；2) 引入效用感知校准机制，结合权重大小和保留集激活范数，为对保留性能贡献大的维度分配更高效用分数；3) 采用自适应软衰减和可微衰减函数，选择性降低LoRA适配器上的高风险参数，抑制敏感检索路径同时保持推理电路的拓扑连接性。

Result: 在两个公共数据集上的七个指标实验表明，U-CAN实现了强大的隐私遗忘、效用保留和计算效率。

Conclusion: U-CAN通过精确的软衰减机制有效解决了生成式推荐系统中的隐私遗忘问题，在保护用户敏感信息的同时保持了模型性能，相比传统的二进制剪枝方法具有更好的效果。

Abstract: Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.

</details>


### [74] [Long Range Frequency Tuning for QML](https://arxiv.org/abs/2602.23409)
*Michael Poppel,Jonas Stein,Sebastian Wölckert,Markus Baumann,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 量子机器学习中角度编码的频谱可训练性受限，提出基于三元编码的网格初始化方法解决频率可达性问题


<details>
  <summary>Details</summary>
Motivation: 量子机器学习中使用角度编码的模型虽然理论上可以通过可训练频率方法实现高效频谱匹配，但实际中频率预因子的梯度优化能力有限，导致目标频率超出可达范围时优化失败

Method: 提出基于三元编码的网格初始化方法，生成密集的整数频率谱，确保目标频率位于局部可达范围内，虽然需要O(log_3(ω_max))个编码门，但比固定频率方法指数级减少

Result: 在具有三个偏移高频的合成目标上，三元网格初始化获得中位数R²得分0.9969，而可训练频率基线仅为0.1841；在真实世界Flight Passengers数据集上，三元网格初始化获得中位数R²得分0.9671，比可训练频率初始化（0.7876）提升22.8%

Conclusion: 频率预因子的有限可训练性是量子机器学习中角度编码的实际瓶颈，三元网格初始化方法通过确保目标频率在可达范围内，显著提升了模型性能，为实际应用提供了有效解决方案

Abstract: Quantum machine learning models using angle encoding naturally represent truncated Fourier series, providing universal function approximation capabilities with sufficient circuit depth. For unary fixed-frequency encodings, circuit depth scales as O(omega_max * (omega_max + epsilon^{-2})) with target frequency magnitude omega_max and precision epsilon. Trainable-frequency approaches theoretically reduce this to match the target spectrum size, requiring only as many encoding gates as frequencies in the target spectrum. Despite this compelling efficiency, their practical effectiveness hinges on a key assumption: that gradient-based optimization can drive prefactors to arbitrary target values. We demonstrate through systematic experiments that frequency prefactors exhibit limited trainability: movement is constrained to approximately +/-1 units with typical learning rates. When target frequencies lie outside this reachable range, optimization frequently fails. To overcome this frequency reachability limitation, we propose grid-based initialization using ternary encodings, which generate dense integer frequency spectra. While this approach requires O(log_3(omega_max)) encoding gates -- more than the theoretical optimum but exponentially fewer than fixed-frequency methods -- it ensures target frequencies lie within the locally reachable range. On synthetic targets with three shifted high frequencies, ternary grid initialization achieves a median R^2 score of 0.9969, compared to 0.1841 for the trainable-frequency baseline. For the real-world Flight Passengers dataset, ternary grid initialization achieves a median R^2 score of 0.9671, representing a 22.8% improvement over trainable-frequency initialization (median R^2 = 0.7876).

</details>


### [75] [EvoX: Meta-Evolution for Automated Discovery](https://arxiv.org/abs/2602.23413)
*Shu Liu,Shubham Agarwal,Monishwaran Maheswaran,Mert Cemri,Zhifei Li,Qiuyang Mang,Ashwin Naren,Ethan Boneh,Audrey Cheng,Melissa Z. Pan,Alexander Du,Kurt Keutzer,Alexandros G. Dimakis,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.LG

TL;DR: EvoX是一种自适应进化方法，通过联合进化候选解和搜索策略，动态调整进化过程，在近200个真实世界优化任务中优于现有AI驱动的进化方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法如AlphaEvolve虽然结合了LLM驱动的优化和进化搜索，但依赖固定的搜索策略和预定义参数，这些策略在整个执行过程中保持不变，无法适应不同任务或同一任务中搜索空间随时间变化的情况。

Method: EvoX采用自适应进化方法，联合进化候选解和用于生成这些解的搜索策略。系统持续更新如何选择和变化先前解的方式，基于优化进展动态调整，使系统能够在优化过程中在不同搜索策略之间动态切换。

Result: 在近200个真实世界优化任务中，EvoX在大多数任务上优于现有的AI驱动进化方法，包括AlphaEvolve、OpenEvolve、GEPA和ShinkaEvolve。

Conclusion: EvoX通过自适应地优化自身的进化过程，能够动态调整搜索策略，从而在各种优化任务中实现更好的性能，解决了固定策略方法无法适应任务变化的问题。

Abstract: Recent work such as AlphaEvolve has shown that combining LLM-driven optimization with evolutionary search can effectively improve programs, prompts, and algorithms across domains. In this paradigm, previously evaluated solutions are reused to guide the model toward new candidate solutions. Crucially, the effectiveness of this evolution process depends on the search strategy: how prior solutions are selected and varied to generate new candidates. However, most existing methods rely on fixed search strategies with predefined knobs (e.g., explore-exploit ratios) that remain static throughout execution. While effective in some settings, these approaches often fail to adapt across tasks, or even within the same task as the search space changes over time. We introduce EvoX, an adaptive evolution method that optimizes its own evolution process. EvoX jointly evolves candidate solutions and the search strategies used to generate them, continuously updating how prior solutions are selected and varied based on progress. This enables the system to dynamically shift between different search strategies during the optimization process. Across nearly 200 real-world optimization tasks, EvoX outperforms existing AI-driven evolutionary methods including AlphaEvolve, OpenEvolve, GEPA, and ShinkaEvolve on the majority of tasks.

</details>


### [76] [Human Supervision as an Information Bottleneck: A Unified Theory of Error Floors in Human-Guided Learning](https://arxiv.org/abs/2602.23446)
*Alejandro Rodriguez Dominguez*

Main category: cs.LG

TL;DR: 论文提出"人类有限智能"理论：当人类监督通道不足以捕捉潜在评估目标时，会形成信息减少通道，导致任何学习者都存在严格正的风险下限，无法通过单纯扩展模型规模消除。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型主要基于人类生成的数据和反馈训练，但存在持续错误。这些错误源于标注噪声、主观偏好和自然语言表达限制。作者认为这些限制反映了监督通道的结构特性，而非模型规模或优化问题。

Method: 开发统一理论，形式化"人类有限智能"限制。通过六个互补框架（算子理论、PAC-Bayes、信息论、因果推断、范畴论、基于人类反馈的强化学习的博弈论分析）证明非充分性导致严格正的下界。理论解释了为什么单纯扩展无法消除持续错误，并描述了辅助非人类信号（如检索、程序执行、工具）如何增加有效监督能力。

Result: 实验验证：在真实偏好数据、合成已知目标任务和外部可验证基准测试中，仅人类监督表现出持续的风险下限，而足够信息丰富的辅助通道能严格减少或消除超额误差。

Conclusion: 人类监督通道的结构限制导致无法避免的误差下限，单纯扩展模型规模无法解决。需要引入辅助非人类信号来恢复关于潜在目标的信息，从而突破"人类有限智能"的限制。

Abstract: Large language models are trained primarily on human-generated data and feedback, yet they exhibit persistent errors arising from annotation noise, subjective preferences, and the limited expressive bandwidth of natural language. We argue that these limitations reflect structural properties of the supervision channel rather than model scale or optimization. We develop a unified theory showing that whenever the human supervision channel is not sufficient for a latent evaluation target, it acts as an information-reducing channel that induces a strictly positive excess-risk floor for any learner dominated by it. We formalize this Human-Bounded Intelligence limit and show that across six complementary frameworks (operator theory, PAC-Bayes, information theory, causal inference, category theory, and game-theoretic analyses of reinforcement learning from human feedback), non-sufficiency yields strictly positive lower bounds arising from the same structural decomposition into annotation noise, preference distortion, and semantic compression. The theory explains why scaling alone cannot eliminate persistent human-aligned errors and characterizes conditions under which auxiliary non-human signals (e.g., retrieval, program execution, tools) increase effective supervision capacity and collapse the floor by restoring information about the latent target. Experiments on real preference data, synthetic known-target tasks, and externally verifiable benchmarks confirm the predicted structural signatures: human-only supervision exhibits a persistent floor, while sufficiently informative auxiliary channels strictly reduce or eliminate excess error.

</details>


### [77] [Global Interpretability via Automated Preprocessing: A Framework Inspired by Psychiatric Questionnaires](https://arxiv.org/abs/2602.23459)
*Eric V. Strobl*

Main category: cs.LG

TL;DR: REFINE方法通过将非线性处理限制在基线预处理模块中，提取稳定的项目值，然后学习从这些稳定化基线项目到未来严重程度的线性映射，在保持可解释性的同时提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 精神病学问卷具有高度情境敏感性，对后续症状严重程度的预测能力较弱。虽然非线性模型可以提高预测准确性，但其有限的可解释性会削弱临床信任。需要一种既能提高预测准确性又能保持可解释性的方法。

Method: 采用两阶段方法REFINE：1）将非线性能力限制在基线预处理模块中，用于估计稳定的项目值；2）学习从这些稳定化基线项目到未来严重程度的线性映射。这样将非线性集中在预处理阶段，而预后关系保持透明线性。

Result: 在实验中，REFINE优于其他可解释方法，同时在精神病学和非精神病学纵向预测任务中保持清晰的预后因素全局归因。

Conclusion: REFINE方法通过将非线性处理与预测解耦，在保持线性模型全局可解释性的同时提高了预测准确性，为临床应用中平衡预测性能和可解释性提供了有效解决方案。

Abstract: Psychiatric questionnaires are highly context sensitive and often only weakly predict subsequent symptom severity, which makes the prognostic relationship difficult to learn. Although flexible nonlinear models can improve predictive accuracy, their limited interpretability can erode clinical trust. In fields such as imaging and omics, investigators commonly address visit- and instrument-specific artifacts by extracting stable signal through preprocessing and then fitting an interpretable linear model. We adopt the same strategy for questionnaire data by decoupling preprocessing from prediction: we restrict nonlinear capacity to a baseline preprocessing module that estimates stable item values, and then learn a linear mapping from these stabilized baseline items to future severity. We refer to this two-stage method as REFINE (Redundancy-Exploiting Follow-up-Informed Nonlinear Enhancement), which concentrates nonlinearity in preprocessing while keeping the prognostic relationship transparently linear and therefore globally interpretable through a coefficient matrix, rather than through post hoc local attributions. In experiments, REFINE outperforms other interpretable approaches while preserving clear global attribution of prognostic factors across psychiatric and non-psychiatric longitudinal prediction tasks.

</details>


### [78] [Uncertainty-aware Language Guidance for Concept Bottleneck Models](https://arxiv.org/abs/2602.23495)
*Yangyi Li,Mengdi Huai*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的不确定性感知概念瓶颈模型方法，通过量化LLM标注概念的不确定性并纳入训练过程，解决现有方法忽视LLM标注不确定性和缺乏有效量化机制的问题。


<details>
  <summary>Details</summary>
Motivation: 概念瓶颈模型（CBMs）通过将输入映射到高层语义概念来提供可解释性，但人工标注概念需要大量专家知识和劳动力。虽然已有工作利用大语言模型（LLMs）构建概念瓶颈，但它们忽视了LLM标注概念的不确定性，缺乏有效的量化机制，且未将这种不确定性纳入学习过程，增加了因LLM幻觉导致错误的风险。

Method: 提出了一种不确定性感知CBM方法：1）严格量化LLM标注概念标签的不确定性，提供有效且分布无关的保证；2）将量化的概念不确定性纳入CBM训练过程，以考虑LLM标注概念的不同可靠性水平；3）提供了理论分析支持。

Result: 在真实世界数据集上的大量实验验证了所提出方法的期望特性。

Conclusion: 该方法不仅解决了现有LLM辅助CBM方法忽视不确定性的问题，还通过将不确定性量化纳入训练过程，提高了模型的可靠性和鲁棒性。

Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first mapping input samples to high-level semantic concepts, followed by a combination of these concepts for the final classification. However, the annotation of human-understandable concepts requires extensive expert knowledge and labor, constraining the broad adoption of CBMs. On the other hand, there are a few works that leverage the knowledge of large language models (LLMs) to construct concept bottlenecks. Nevertheless, they face two essential limitations: First, they overlook the uncertainty associated with the concepts annotated by LLMs and lack a valid mechanism to quantify uncertainty about the annotated concepts, increasing the risk of errors due to hallucinations from LLMs. Additionally, they fail to incorporate the uncertainty associated with these annotations into the learning process for concept bottleneck models. To address these limitations, we propose a novel uncertainty-aware CBM method, which not only rigorously quantifies the uncertainty of LLM-annotated concept labels with valid and distribution-free guarantees, but also incorporates quantified concept uncertainty into the CBM training procedure to account for varying levels of reliability across LLM-annotated concepts. We also provide the theoretical analysis for our proposed method. Extensive experiments on the real-world datasets validate the desired properties of our proposed methods.

</details>


### [79] [FedDAG: Clustered Federated Learning via Global Data and Gradient Integration for Heterogeneous Environments](https://arxiv.org/abs/2602.23504)
*Anik Pramanik,Murat Kantarcioglu,Vincent Oria,Shantanu Sharma*

Main category: cs.LG

TL;DR: FedDAG提出了一种新的聚类联邦学习框架，通过整合数据和梯度信息进行更全面的客户端相似性评估，并采用双编码器架构实现跨集群特征迁移，有效解决了数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 传统聚类联邦学习方法存在两个主要问题：1）仅依赖数据相似性或梯度相似性进行聚类，导致对客户端相似性的评估不完整；2）限制知识和表示共享仅限于同一集群内，使得集群模型无法从跨集群的多样化客户端群体中受益。

Method: FedDAG采用加权、类别的相似性度量，整合数据和梯度信息进行更全面的客户端聚类。同时采用双编码器架构：主编码器在自身客户端数据上训练，辅助编码器使用互补集群的梯度进行精炼，实现跨集群特征迁移同时保持集群特定专业化。

Result: 在多样化基准测试和数据异构性设置下的实验表明，FedDAG在准确性方面持续优于最先进的聚类联邦学习基线方法。

Conclusion: FedDAG通过整合数据和梯度信息进行更全面的客户端相似性评估，并采用双编码器架构实现跨集群知识共享，有效提升了在数据异构环境下的联邦学习性能。

Abstract: Federated Learning (FL) enables a group of clients to collaboratively train a model without sharing individual data, but its performance drops when client data are heterogeneous. Clustered FL tackles this by grouping similar clients. However, existing clustered FL approaches rely solely on either data similarity or gradient similarity; however, this results in an incomplete assessment of client similarities. Prior clustered FL approaches also restrict knowledge and representation sharing to clients within the same cluster. This prevents cluster models from benefiting from the diverse client population across clusters. To address these limitations, FedDAG introduces a clustered FL framework, FedDAG, that employs a weighted, class-wise similarity metric that integrates both data and gradient information, providing a more holistic measure of similarity during clustering. In addition, FedDAG adopts a dual-encoder architecture for cluster models, comprising a primary encoder trained on its own clients' data and a secondary encoder refined using gradients from complementary clusters. This enables cross-cluster feature transfer while preserving cluster-specific specialization. Experiments on diverse benchmarks and data heterogeneity settings show that FedDAG consistently outperforms state-of-the-art clustered FL baselines in accuracy.

</details>


### [80] [Sample Size Calculations for Developing Clinical Prediction Models: Overview and pmsims R package](https://arxiv.org/abs/2602.23507)
*Diana Shamsutdinova,Felix Zimmer,Oyebayo Ridwan Olaniran,Sarah Markham,Daniel Stahl,Gordon Forbes,Ewan Carr*

Main category: cs.LG

TL;DR: 该论文提出了一个用于临床预测模型样本量估计的新框架和R包pmsims，通过集成学习曲线、高斯过程优化和保证原则，为复杂模型提供灵活高效的样本量计算方法。


<details>
  <summary>Details</summary>
Motivation: 临床预测模型在医疗决策中应用日益广泛，但确定其开发所需的最小样本量仍是一个关键且未解决的挑战。样本量不足会导致过拟合、泛化能力差和预测偏差。现有方法（启发式规则、闭式公式和基于模拟的方法）在灵活性和准确性方面存在差异，特别是对于复杂数据结构和机器学习模型。

Method: 论文首先回顾了预测建模中样本量估计的现有方法，并提出了一个区分均值标准和保证标准的概念框架。在此基础上，提出了一种新颖的基于模拟的方法，该方法集成学习曲线、高斯过程优化和保证原则，以识别能够以高概率达到目标性能的样本量。该方法在开源、模型无关的R包pmsims中实现。

Result: 通过案例研究表明，样本量估计在不同方法、性能指标和建模策略之间存在显著差异。与现有工具相比，pmsims提供了灵活、高效且可解释的解决方案，能够适应多样化的模型和用户定义的指标，同时明确考虑模型性能的变异性。

Conclusion: 该框架和软件通过将灵活性与计算效率相结合，推进了临床预测模型的样本量方法学。未来工作应将这些方法扩展到分层和多模态数据，纳入公平性和稳定性指标，并解决缺失数据和复杂依赖结构等挑战。

Abstract: Background: Clinical prediction models are increasingly used to inform healthcare decisions, but determining the minimum sample size for their development remains a critical and unresolved challenge. Inadequate sample sizes can lead to overfitting, poor generalisability, and biased predictions. Existing approaches, such as heuristic rules, closed-form formulas, and simulation-based methods, vary in flexibility and accuracy, particularly for complex data structures and machine learning models. Methods: We review current methodologies for sample size estimation in prediction modelling and introduce a conceptual framework that distinguishes between mean-based and assurance-based criteria. Building on this, we propose a novel simulation-based approach that integrates learning curves, Gaussian Process optimisation, and assurance principles to identify sample sizes that achieve target performance with high probability. This approach is implemented in pmsims, an open-source, model-agnostic R package. Results: Through case studies, we demonstrate that sample size estimates vary substantially across methods, performance metrics, and modelling strategies. Compared to existing tools, pmsims provides flexible, efficient, and interpretable solutions that accommodate diverse models and user-defined metrics while explicitly accounting for variability in model performance. Conclusions: Our framework and software advance sample size methodology for clinical prediction modelling by combining flexibility with computational efficiency. Future work should extend these methods to hierarchical and multimodal data, incorporate fairness and stability metrics, and address challenges such as missing data and complex dependency structures.

</details>


### [81] [Neural Operators Can Discover Functional Clusters](https://arxiv.org/abs/2602.23528)
*Yicen Li,Jose Antonio Lara Benitez,Ruiyang Hong,Anastasis Kratsios,Paul David McNicholas,Maarten Valentijn de Hoop*

Main category: cs.LG

TL;DR: 该论文证明了基于样本的神经算子能够学习无限维再生核希尔伯特空间中任意有限类别的聚类，即使这些类别既非凸也非连通，并开发了用于函数数据聚类的神经算子管道。


<details>
  <summary>Details</summary>
Motivation: 神经算子在回归任务中已有深入研究，但在分类及其无监督对应任务——聚类方面的理论理解仍然有限。论文旨在填补这一空白，探索神经算子在无限维空间中进行聚类的理论能力和实际应用。

Method: 1. 理论证明：在温和的核采样假设下，证明了基于样本的神经算子能够学习无限维再生核希尔伯特空间中任意有限类别的聚类，即使这些类别既非凸也非连通。2. 实际应用：开发了神经算子驱动的函数数据聚类管道，将离散化的轨迹通过预训练编码器提升为连续特征映射，然后通过轻量可训练头部映射到软分配。

Result: 1. 提出了通用聚类定理，表明任意K个闭类可以在上Kuratowski拓扑中被神经算子参数化的类任意精度逼近。2. 在合成ODE基准测试中，提出的实用SNO方法在经典方法失败的机制中恢复了潜在的动态结构，为通用聚类理论提供了实证支持。

Conclusion: 该研究为神经算子在聚类任务中的理论能力提供了严格保证，证明了其在无限维空间中处理复杂、非凸、非连通类别的能力，并开发了实用的函数数据聚类框架，为科学计算中的无监督学习开辟了新途径。

Abstract: Operator learning is reshaping scientific computing by amortizing inference across infinite families of problems. While neural operators (NOs) are increasingly well understood for regression, far less is known for classification and its unsupervised analogue: clustering. We prove that sample-based neural operators can learn any finite collection of classes in an infinite-dimensional reproducing kernel Hilbert space, even when the classes are neither convex nor connected, under mild kernel sampling assumptions. Our universal clustering theorem shows that any $K$ closed classes can be approximated to arbitrary precision by NO-parameterized classes in the upper Kuratowski topology on closed sets, a notion that can be interpreted as disallowing false-positive misclassifications.
  Building on this, we develop an NO-powered clustering pipeline for functional data and apply it to unlabeled families of ordinary differential equation (ODE) trajectories. Discretized trajectories are lifted by a fixed pre-trained encoder into a continuous feature map and mapped to soft assignments by a lightweight trainable head. Experiments on diverse synthetic ODE benchmarks show that the resulting practical SNO recovers latent dynamical structure in regimes where classical methods fail, providing evidence consistent with our universal clustering theory.

</details>


### [82] [Active Value Querying to Minimize Additive Error in Subadditive Set Function Learning](https://arxiv.org/abs/2602.23529)
*Martin Černý,David Sychrovský,Filip Úradník,Jakub Černý*

Main category: cs.LG

TL;DR: 研究如何通过添加额外子集的值来近似未知次可加集函数，以减少最小和最大补全之间的距离


<details>
  <summary>Details</summary>
Motivation: 次可加集函数在多个领域有重要应用，但完整指定需要指数级数量的值，实践中资源消耗大。当值缺失时会产生模糊性，特别是在需要进一步优化时问题更严重。基于已知的确定性值查询在乘法误差下不可近似的结论，研究在加法误差下近似未知次可加集函数的问题。

Method: 1) 深入探索不同类别集函数缺失值的最小和最大补全及其距离分析；2) 开发方法在已知先验的集函数类别上最小化该距离，通过离线或在线方式披露额外子集的值；3) 在实际场景中进行算法性能的实证演示。

Result: 论文提出了系统的方法来处理次可加集函数缺失值的近似问题，包括理论分析和实际算法实现。

Conclusion: 该研究为处理次可加集函数缺失值问题提供了理论框架和实用算法，能够在加法误差下有效近似未知集函数，减少最小和最大补全之间的距离。

Abstract: Subadditive set functions play a pivotal role in computational economics (especially in combinatorial auctions), combinatorial optimization or artificial intelligence applications such as interpretable machine learning. However, specifying a set function requires assigning values to an exponentially large number of subsets in general, a task that is often resource-intensive in practice, particularly when the values derive from external sources such as retraining of machine learning models. A~simple omission of certain values introduces ambiguity that becomes even more significant when the incomplete set function has to be further optimized over. Motivated by the well-known result about inapproximability of subadditive functions using deterministic value queries with respect to a multiplicative error, we study a problem of approximating an unknown subadditive (or a subclass of thereof) set function with respect to an additive error -- i. e., we aim to efficiently close the distance between minimal and maximal completions. Our contributions are threefold: (i) a thorough exploration of minimal and maximal completions of different classes of set functions with missing values and an analysis of their resulting distance; (ii) the development of methods to minimize this distance over classes of set functions with a known prior, achieved by disclosing values of additional subsets in both offline and online manner; and (iii) empirical demonstrations of the algorithms' performance in practical scenarios.

</details>


### [83] [Dynamics of Learning under User Choice: Overspecialization and Peer-Model Probing](https://arxiv.org/abs/2602.23565)
*Adhyyan Narang,Sarah Dean,Lillian J Ratliff,Maryam Fazel*

Main category: cs.LG

TL;DR: 论文研究了多平台机器学习中的"过度专业化陷阱"问题，发现现有算法可能导致全局性能极差的模型，并提出基于知识蒸馏的探测算法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 在多平台机器学习部署的经济相关场景中，用户会选择最适合自己的平台，现有研究只关注学习者在观察到的数据分布上的"局部"损失，但存在学习者收敛到全局性能极差模型的风险。

Method: 提出一种基于知识蒸馏的算法，允许学习者"探测"同伴模型的预测，从而了解不选择他们的用户。分析确定了探测成功的关键条件：当探测源足够信息丰富时（如已知的市场领导者或大多数具有良好全局性能的同行）。

Result: 通过MovieLens、Census和Amazon Sentiment数据集的半合成实验验证了发现。当探测源足够信息丰富时，该程序几乎必然收敛到具有有界全人口风险的平稳点。

Conclusion: 在多平台机器学习环境中，过度专业化陷阱是一个真实风险，但通过适当设计的探测算法，学习者可以避免这一陷阱并实现良好的全局性能，前提是探测源提供足够的信息。

Abstract: In many economically relevant contexts where machine learning is deployed, multiple platforms obtain data from the same pool of users, each of whom selects the platform that best serves them. Prior work in this setting focuses exclusively on the "local" losses of learners on the distribution of data that they observe. We find that there exist instances where learners who use existing algorithms almost surely converge to models with arbitrarily poor global performance, even when models with low full-population loss exist. This happens through a feedback-induced mechanism, which we call the overspecialization trap: as learners optimize for users who already prefer them, they become less attractive to users outside this base, which further restricts the data they observe. Inspired by the recent use of knowledge distillation in modern ML, we propose an algorithm that allows learners to "probe" the predictions of peer models, enabling them to learn about users who do not select them. Our analysis characterizes when probing succeeds: this procedure converges almost surely to a stationary point with bounded full-population risk when probing sources are sufficiently informative, e.g., a known market leader or a majority of peers with good global performance. We verify our findings with semi-synthetic experiments on the MovieLens, Census, and Amazon Sentiment datasets.

</details>


### [84] [SDMixer: Sparse Dual-Mixer for Time Series Forecasting](https://arxiv.org/abs/2602.23581)
*Xiang Ao*

Main category: cs.LG

TL;DR: 提出双流稀疏Mixer预测框架，通过频域和时域分别提取序列的全局趋势和局部动态特征，采用稀疏机制过滤无效信息，提升跨变量依赖建模精度


<details>
  <summary>Details</summary>
Motivation: 多元时间序列预测在交通、能源、金融等领域广泛应用，但数据常存在多尺度特性、弱相关性和噪声干扰等问题，限制了现有模型的预测性能

Method: 提出双流稀疏Mixer预测框架，在频域和时域分别提取序列的全局趋势和局部动态特征，采用稀疏机制过滤无效信息，增强跨变量依赖建模能力

Result: 在多个真实场景数据集上实现了领先性能，验证了方法的有效性和泛化能力

Conclusion: 提出的双流稀疏Mixer框架能有效处理多元时间序列的多尺度特性、弱相关性和噪声干扰问题，提升预测性能

Abstract: Multivariate time series forecasting is widely applied in fields such as transportation, energy, and finance. However, the data commonly suffers from issues of multi-scale characteristics, weak correlations, and noise interference, which limit the predictive performance of existing models. This paper proposes a dual-stream sparse Mixer prediction framework that extracts global trends and local dynamic features from sequences in both the frequency and time domains, respectively. It employs a sparsity mechanism to filter out invalid information, thereby enhancing the accuracy of cross-variable dependency modeling. Experimental results demonstrate that this method achieves leading performance on multiple real-world scenario datasets, validating its effectiveness and generality. The code is available at https://github.com/SDMixer/SDMixer

</details>


### [85] [When Does Multimodal Learning Help in Healthcare? A Benchmark on EHR and Chest X-Ray Fusion](https://arxiv.org/abs/2602.23614)
*Kejing Yin,Haizhou Xu,Wenfang Yao,Chen Liu,Zijie Chen,Yui Haang Cheung,William K. Cheung,Jing Qin*

Main category: cs.LG

TL;DR: 该研究系统评估了电子健康记录（EHR）和胸部X光片（CXR）的多模态融合在临床预测中的效果，分析了融合策略、模态缺失鲁棒性、算法公平性等关键问题，并发布了开源基准测试工具包。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习在临床决策支持中具有潜力，但多模态学习在实际应用中的真正价值尚不明确，特别是在面临模态缺失和公平性约束的情况下。研究旨在回答多模态融合何时有效、不同融合策略比较、缺失模态鲁棒性以及算法公平性等四个基本问题。

Method: 使用MIMIC-IV和MIMIC-CXR标准化队列，系统性地对EHR和CXR多模态融合进行基准测试。研究比较了不同的融合策略，评估了现有方法对缺失模态的鲁棒性，并分析了多模态模型的算法公平性。

Result: 研究发现：1）模态完整时多模态融合能提升性能，增益集中在需要EHR和CXR互补信息的疾病上；2）跨模态学习机制能捕捉临床有意义的依赖关系；3）EHR的丰富时间结构导致模态不平衡；4）在现实缺失情况下，多模态优势迅速下降；5）多模态融合不固有改善公平性，子群差异主要源于不同人口群体的敏感性不平等。

Conclusion: 该研究为多模态学习何时有效、何时失败及其原因提供了可操作的指导，为开发既有效又可靠的临床可部署多模态系统奠定了基础。同时发布了开源工具包CareBench支持可重复和可扩展的评估。

Abstract: Machine learning holds promise for advancing clinical decision support, yet it remains unclear when multimodal learning truly helps in practice, particularly under modality missingness and fairness constraints. In this work, we conduct a systematic benchmark of multimodal fusion between Electronic Health Records (EHR) and chest X-rays (CXR) on standardized cohorts from MIMIC-IV and MIMIC-CXR, aiming to answer four fundamental questions: when multimodal fusion improves clinical prediction, how different fusion strategies compare, how robust existing methods are to missing modalities, and whether multimodal models achieve algorithmic fairness. Our study reveals several key insights. Multimodal fusion improves performance when modalities are complete, with gains concentrating in diseases that require complementary information from both EHR and CXR. While cross-modal learning mechanisms capture clinically meaningful dependencies beyond simple concatenation, the rich temporal structure of EHR introduces strong modality imbalance that architectural complexity alone cannot overcome. Under realistic missingness, multimodal benefits rapidly degrade unless models are explicitly designed to handle incomplete inputs. Moreover, multimodal fusion does not inherently improve fairness, with subgroup disparities mainly arising from unequal sensitivity across demographic groups. To support reproducible and extensible evaluation, we further release a flexible benchmarking toolkit that enables plug-and-play integration of new models and datasets. Together, this work provides actionable guidance on when multimodal learning helps, when it fails, and why, laying the foundation for developing clinically deployable multimodal systems that are both effective and reliable. The open-source toolkit can be found at https://github.com/jakeykj/CareBench.

</details>


### [86] [On the Convergence of Single-Loop Stochastic Bilevel Optimization with Approximate Implicit Differentiation](https://arxiv.org/abs/2602.23633)
*Yubo Zhou,Luo Luo,Guang Dai,Haishan Ye*

Main category: cs.LG

TL;DR: 本文对单循环随机近似隐式微分算法进行了理论分析，证明了其达到ε-平稳点的复杂度为O(κ⁷ε⁻²)，匹配了多循环方法的最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 随机双层优化在元学习和超参数优化中应用广泛，但单循环算法（同时更新上下层变量）的理论理解相对多循环方法严重不足。现有分析常得到次优收敛率，且未能清晰揭示对下层条件数κ的依赖关系。

Method: 采用单循环随机近似隐式微分算法，通过精细化的收敛分析，明确刻画了算法对条件数κ的依赖关系。

Result: 证明了SSAID算法达到ε-平稳点的oracle复杂度为O(κ⁷ε⁻²)，匹配了多循环方法的最优O(ε⁻²)收敛率，同时保持了单循环更新的计算效率。

Conclusion: SSAID不仅是一种启发式方法，还具有严格的理论基础，其收敛保证与主流多循环框架具有竞争力，为单循环算法提供了首个明确的κ依赖关系分析。

Abstract: Stochastic Bilevel Optimization has emerged as a fundamental framework for meta-learning and hyperparameter optimization. Despite the practical prevalence of single-loop algorithms--which update lower and upper variables concurrently--their theoretical understanding, particularly in the stochastic regime, remains significantly underdeveloped compared to their multi-loop counterparts. Existing analyses often yield suboptimal convergence rates or obscure the critical dependence on the lower-level condition number $κ$, frequently burying it within generic Lipschitz constants. In this paper, we bridge this gap by providing a refined convergence analysis of the Single-loop Stochastic Approximate Implicit Differentiation (SSAID) algorithm. We prove that SSAID achieves an $ε$-stationary point with an oracle complexity of $\mathcal{O}(κ^7 ε^{-2})$. Our result is noteworthy in two aspects: (i) it matches the optimal $\mathcal{O}(ε^{-2})$ rate of state-of-the-art multi-loop methods (e.g., stocBiO) while maintaining the computational efficiency of a single-loop update; and (ii) it provides the first explicit, fine-grained characterization of the $κ$-dependence for stochastic AID-based single-loop methods. This work demonstrates that SSAID is not merely a heuristic approach, but admits a rigorous theoretical foundation with convergence guarantees competitive with mainstream multi-loop frameworks.

</details>


### [87] [FlexGuard: Continuous Risk Scoring for Strictness-Adaptive LLM Content Moderation](https://arxiv.org/abs/2602.23636)
*Zhihao Ding,Jinming Li,Ze Lu,Jieming Shi*

Main category: cs.LG

TL;DR: 论文提出FlexGuard方法解决LLM内容审核中严格度变化的问题，通过连续风险评分和阈值调整来适应不同平台的审核严格度要求。


<details>
  <summary>Details</summary>
Motivation: 现有LLM内容安全审核模型通常采用固定的二分类方法，假设有害内容的定义是固定的。但实际上，不同平台的审核严格度（如何定义和执行有害内容）各不相同且随时间变化，这使得二分类审核器在需求变化时变得脆弱。

Method: 1. 引入FlexBench基准，支持在多种严格度机制下进行受控评估；2. 提出FlexGuard方法，基于LLM输出校准的连续风险评分，反映风险严重程度；3. 通过风险对齐优化训练FlexGuard以提高评分-严重度一致性；4. 提供实用的阈值选择策略，在部署时适应目标严格度。

Result: 在FlexBench和公共基准测试中，FlexGuard实现了更高的审核准确率，并在不同严格度下显著提高了鲁棒性。现有审核器在不同严格度机制下存在严重的跨严格度不一致性。

Conclusion: FlexGuard通过连续风险评分和灵活阈值调整，有效解决了LLM内容审核中严格度变化带来的挑战，提高了实际部署中的适应性和鲁棒性。

Abstract: Ensuring the safety of LLM-generated content is essential for real-world deployment. Most existing guardrail models formulate moderation as a fixed binary classification task, implicitly assuming a fixed definition of harmfulness. In practice, enforcement strictness - how conservatively harmfulness is defined and enforced - varies across platforms and evolves over time, making binary moderators brittle under shifting requirements. We first introduce FlexBench, a strictness-adaptive LLM moderation benchmark that enables controlled evaluation under multiple strictness regimes. Experiments on FlexBench reveal substantial cross-strictness inconsistency in existing moderators: models that perform well under one regime can degrade substantially under others, limiting their practical usability. To address this, we propose FlexGuard, an LLM-based moderator that outputs a calibrated continuous risk score reflecting risk severity and supports strictness-specific decisions via thresholding. We train FlexGuard via risk-alignment optimization to improve score-severity consistency and provide practical threshold selection strategies to adapt to target strictness at deployment. Experiments on FlexBench and public benchmarks demonstrate that FlexGuard achieves higher moderation accuracy and substantially improved robustness under varying strictness. We release the source code and data to support reproducibility.

</details>


### [88] [FedRot-LoRA: Mitigating Rotational Misalignment in Federated LoRA](https://arxiv.org/abs/2602.23638)
*Haoran Zhang,Dongjun Kim,Seohyeon Cha,Haris Vikalo*

Main category: cs.LG

TL;DR: FedRot-LoRA：一种通过正交变换对齐客户端更新的联邦LoRA框架，解决因子平均导致的旋转不对齐问题，提升训练稳定性和性能


<details>
  <summary>Details</summary>
Motivation: 联邦LoRA在分散数据上微调大语言模型时，因子平均与数学正确聚合之间的差异会导致显著的聚合误差和不稳定训练。主要问题是旋转不对齐——由于低秩分解的旋转不变性，语义相同的更新在不同客户端可能表示在不同的潜在子空间中，直接平均这些不对齐的因子会产生破坏性干扰。

Method: 提出FedRot-LoRA框架，在聚合前通过正交变换对齐客户端更新。这种方法保持语义更新不变，同时减少跨客户端子空间不匹配，不增加通信成本或限制模型表达能力。提供了收敛分析，检查因子平均引起的聚合误差，并展示旋转对齐如何产生更紧的误差上界。

Result: 在自然语言理解和生成任务上的大量实验表明，FedRot-LoRA在各种异构程度和LoRA秩的设置下，始终优于现有的联邦LoRA基线方法。

Conclusion: FedRot-LoRA通过解决联邦LoRA中的旋转不对齐问题，提供了一种通信高效且稳定的微调框架，显著提升了聚合效果和模型性能。

Abstract: Federated LoRA provides a communication-efficient mechanism for fine-tuning large language models on decentralized data. In practice, however, a discrepancy between the factor-wise averaging used to preserve low rank and the mathematically correct aggregation of local updates can cause significant aggregation error and unstable training. We argue that a major source of this problem is rotational misalignment, arising from the rotational invariance of low-rank factorizations -- semantically equivalent updates can be represented in different latent subspaces across clients since $(B_i R_i)(R_i^\top A_i) = B_i A_i$. When such misaligned factors are averaged directly, they interfere destructively and degrade the global update. To address this issue, we propose FedRot-LoRA, a federated LoRA framework that aligns client updates via orthogonal transformations prior to aggregation. This alignment preserves the semantic update while reducing cross-client subspace mismatch, without increasing communication cost or restricting model expressivity. We provide a convergence analysis that examines the aggregation error induced by factor-wise averaging and shows how rotational alignment yields a tighter upper bound on this error. Extensive experiments on natural language understanding and generative tasks demonstrate that FedRot-LoRA consistently outperforms existing federated LoRA baselines across a range of heterogeneity levels and LoRA ranks.

</details>


### [89] [Selective Denoising Diffusion Model for Time Series Anomaly Detection](https://arxiv.org/abs/2602.23662)
*Kohei Obata,Zheng Chen,Yasuko Matsubara,Lingwei Zhu,Yasushi Sakurai*

Main category: cs.LG

TL;DR: 提出AnomalyFilter方法，通过选择性过滤仅去噪异常部分而保留正常部分，改进基于扩散模型的时间序列异常检测性能


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的TSAD方法采用条件策略，从白噪声中重建输入实例，但难以准确重建正常部分，导致检测性能不理想

Method: 提出AnomalyFilter方法：1) 在训练阶段掩码高斯噪声；2) 在不向实例添加噪声的情况下进行去噪过程，构建选择性过滤器仅处理异常部分

Result: 在五个数据集上的实验表明，AnomalyFilter在正常部分实现了显著较低的重建误差，为异常检测有效性提供了实证支持

Conclusion: AnomalyFilter代表了专门为TSAD设计的扩散模型噪声设计的开创性方法，两个简单组件的协同作用显著提升了朴素扩散模型的性能

Abstract: Time series anomaly detection (TSAD) has been an important area of research for decades, with reconstruction-based methods, mostly based on generative models, gaining popularity and demonstrating success. Diffusion models have recently attracted attention due to their advanced generative capabilities. Existing diffusion-based methods for TSAD rely on a conditional strategy, which reconstructs input instances from white noise with the aid of the conditioner. However, this poses challenges in accurately reconstructing the normal parts, resulting in suboptimal detection performance. In response, we propose a novel diffusion-based method, named AnomalyFilter, which acts as a selective filter that only denoises anomaly parts in the instance while retaining normal parts. To build such a filter, we mask Gaussian noise during the training phase and conduct the denoising process without adding noise to the instances. The synergy of the two simple components greatly enhances the performance of naive diffusion models. Extensive experiments on five datasets demonstrate that AnomalyFilter achieves notably low reconstruction error on normal parts, providing empirical support for its effectiveness in anomaly detection. AnomalyFilter represents a pioneering approach that focuses on the noise design of diffusion models specifically tailored for TSAD.

</details>


### [90] [Disentangled Mode-Specific Representations for Tensor Time Series via Contrastive Learning](https://arxiv.org/abs/2602.23663)
*Kohei Obata,Taichi Murayama,Zheng Chen,Yasuko Matsubara,Yasushi Sakurai*

Main category: cs.LG

TL;DR: MoST是一种针对多模态张量时间序列的表示学习方法，通过张量切片降低复杂度，学习可解耦为各非时间模态的表示，结合对比学习框架提升分类和预测性能。


<details>
  <summary>Details</summary>
Motivation: 多模态张量时间序列在搜索引擎、环境监测等领域广泛存在，学习其表示对多种应用有益，但由于张量固有的复杂性，难以实现丰富的表示学习。

Method: MoST使用张量切片方法降低TTS结构复杂度，学习可解耦为各非时间模态的表示。每个表示包含模态特定特征（同一模态内变量间关系）和模态不变特征（不同模态间共有）。采用对比学习框架，损失函数包含模态特定学习和模态不变学习两部分，有效利用解耦表示作为增强。

Result: 在真实世界数据集上的大量实验表明，MoST在分类和预测准确率方面持续优于最先进的方法。

Conclusion: MoST是一种专门为多模态张量时间序列设计的有效表示学习方法，通过解耦表示和对比学习框架，能够学习到丰富的模态特定和模态不变特征，在实际应用中表现优异。

Abstract: Multi-mode tensor time series (TTS) can be found in many domains, such as search engines and environmental monitoring systems. Learning representations of a TTS benefits various applications, but it is also challenging since the complexities inherent in the tensor hinder the realization of rich representations. In this paper, we propose a novel representation learning method designed specifically for TTS, namely MoST. Specifically, MoST uses a tensor slicing approach to reduce the complexity of the TTS structure and learns representations that can be disentangled into individual non-temporal modes. Each representation captures mode-specific features, which are the relationship between variables within the same mode, and mode-invariant features, which are in common in representations of different modes. We employ a contrastive learning framework to learn parameters; the loss function comprises two parts intended to learn representation in a mode-specific way and mode-invariant way, effectively exploiting disentangled representations as augmentations. Extensive experiments on real-world datasets show that MoST consistently outperforms the state-of-the-art methods in terms of classification and forecasting accuracy. Code is available at https://github.com/KoheiObata/MoST.

</details>


### [91] [Optimizer-Induced Low-Dimensional Drift and Transverse Dynamics in Transformer Training](https://arxiv.org/abs/2602.23696)
*Yongzhong Xu*

Main category: cs.LG

TL;DR: 研究发现小Transformer模型的训练轨迹几何特征：参数更新呈现主导漂移方向与横向残余动态，不同优化器（AdamW vs SGD）在轨迹几何上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 研究训练轨迹的几何结构，探索参数更新如何组织成特定模式，以及不同优化器如何影响学习轨迹的有效维度和结构。

Method: 使用未中心化、行归一化的轨迹PCA分析小Transformer模型的训练轨迹，比较AdamW和SGD变体在匹配损失水平下的轨迹几何差异，并通过重新加热实验验证。

Result: 发现单一主导方向捕获了训练早期大部分累积参数移动，剩余分量编码辅助探针性能的振荡行为；AdamW产生多维漂移结构，而SGD产生几乎共线的参数演化；重新加热选择性地扰动横向分量。

Conclusion: 优化器选择塑造了学习轨迹的有效维度和结构，这些特征超出了仅从损失值所能观察到的范围，表明轨迹几何分析提供了理解优化动态的新视角。

Abstract: We study the geometry of training trajectories in small transformer models and find that parameter updates organize into a dominant drift direction with transverse residual dynamics. Using uncentered, row-normalized trajectory PCA, we show that a single direction captures a large fraction of cumulative parameter movement early in training, while remaining components encode oscillatory behavior in auxiliary probe performance. Instantaneous gradients exhibit little alignment with this dominant direction, indicating that it arises from accumulated optimizer updates rather than per-batch gradient structure. Comparing AdamW with SGD variants at matched loss levels reveals substantial differences in trajectory geometry: AdamW develops multi-dimensional drift structure, whereas SGD-family optimizers produce nearly colinear parameter evolution and weaker probe dynamics. Reheating selectively perturbs transverse components with minimal effect on the dominant drift coordinate. These findings suggest that optimizer choice shapes the effective dimensionality and structure of learning trajectories beyond what is apparent from loss values alone.

</details>


### [92] [Bridging Dynamics Gaps via Diffusion Schrödinger Bridge for Cross-Domain Reinforcement Learning](https://arxiv.org/abs/2602.23737)
*Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: 提出BDGxRL框架，利用扩散薛定谔桥对齐源域和目标域动态，通过奖励调制机制估计奖励，实现无需目标域交互的跨域强化学习


<details>
  <summary>Details</summary>
Motivation: 跨域强化学习中，源域和目标域之间存在动态变化，且缺乏目标域环境交互和奖励监督，这阻碍了直接策略学习

Method: 提出BDGxRL框架：1) 使用扩散薛定谔桥将源域转移与目标域离线演示编码的动态对齐；2) 引入基于状态转移估计奖励的奖励调制机制，应用于DSB对齐样本以确保奖励与目标域动态一致

Result: 在MuJoCo跨域基准测试中，BDGxRL优于最先进的基线方法，在转移动态变化下表现出强大的适应性

Conclusion: BDGxRL能够在无需访问目标环境或其奖励的情况下，完全在源域内执行面向目标的策略学习，有效解决了跨域强化学习的挑战

Abstract: Cross-domain reinforcement learning (RL) aims to learn transferable policies under dynamics shifts between source and target domains. A key challenge lies in the lack of target-domain environment interaction and reward supervision, which prevents direct policy learning. To address this challenge, we propose Bridging Dynamics Gaps for Cross-Domain Reinforcement Learning (BDGxRL), a novel framework that leverages Diffusion Schrödinger Bridge (DSB) to align source transitions with target-domain dynamics encoded in offline demonstrations. Moreover, we introduce a reward modulation mechanism that estimates rewards based on state transitions, applying to DSB-aligned samples to ensure consistency between rewards and target-domain dynamics. BDGxRL performs target-oriented policy learning entirely within the source domain, without access to the target environment or its rewards. Experiments on MuJoCo cross-domain benchmarks demonstrate that BDGxRL outperforms state-of-the-art baselines and shows strong adaptability under transition dynamics shifts.

</details>


### [93] [OPTIAGENT: A Physics-Driven Agentic Framework for Automated Optical Design](https://arxiv.org/abs/2602.23761)
*Yuyu Geng,Lei Sun,Yao Gao,Xinxin Hu,Zhonghua Yi,Xiaolong Qian,Weijian Hu,Jian Bai,Kaiwei Wang*

Main category: cs.LG

TL;DR: 首次将大语言模型应用于光学设计领域，通过混合目标训练和物理驱动策略对齐，使非专业用户也能设计功能性透镜系统


<details>
  <summary>Details</summary>
Motivation: 光学设计是高度非凸的优化问题，严重依赖专家经验和领域知识。虽然大语言模型具备丰富的光学知识，但在透镜系统设计方面的能力仍然受限。本研究旨在填补这一空白，让没有正式光学训练的用户也能成功开发功能性透镜系统。

Method: 1. 构建OptiDesignQA数据集，包含经典透镜系统和自动化算法生成的新配置；2. 通过全系统合成和透镜补全的混合目标向LLM注入领域知识；3. 使用DrGRPO算法和光学词典奖励进行物理驱动的策略对齐；4. 集成专门的光学优化例程进行端到端微调和精度优化。

Result: 实验结果表明，该方法在基准测试中优于传统的基于优化的自动化设计算法和其他LLM对比方法，展现了优越的性能。

Conclusion: 本研究首次成功将大语言模型应用于光学设计领域，通过创新的训练方法和物理对齐机制，显著提升了LLM在透镜系统设计方面的能力，为非专业用户参与光学设计提供了可行途径。

Abstract: Optical design is the process of configuring optical elements to precisely manipulate light for high-fidelity imaging. It is inherently a highly non-convex optimization problem that relies heavily on human heuristic expertise and domain-specific knowledge. While Large Language Models (LLMs) possess extensive optical knowledge, their capabilities in leveraging the knowledge in designing lens system remain significantly constrained. This work represents the first attempt to employ LLMs in the field of optical design. We bridge the expertise gap by enabling users without formal optical training to successfully develop functional lens systems. Concretely, we curate a comprehensive dataset, named OptiDesignQA, which encompasses both classical lens systems sourced from standard optical textbooks and novel configurations generated by automated design algorithms for training and evaluation. Furthermore, we inject domain-specific optical expertise into the LLM through a hybrid objective of full-system synthesis and lens completion. To align the model with optical principles, we employ Group Relative Policy Optimization Done Right (DrGRPO) guided by Optical Lexicographic Reward for physics-driven policy alignment. This reward system incorporates structural format rewards, physical feasibility rewards, light-manipulation accuracy, and LLM-based heuristics. Finally, our model integrates with specialized optical optimization routines for end-to-end fine-tuning and precision refinement. We benchmark our proposed method against both traditional optimization-based automated design algorithms and LLM counterparts, and experimental results show the superiority of our method.

</details>


### [94] [MAGE: Multi-scale Autoregressive Generation for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23770)
*Chenxing Lin,Xinhui Gao,Haipeng Zhang,Xinran Li,Haitao Wang,Songzhu Mei,Chenglu Wen,Weiquan Liu,Siqi Shen,Cheng Wang*

Main category: cs.LG

TL;DR: MAGE是一种基于多尺度自回归生成的离线强化学习方法，通过多尺度轨迹建模和条件引导，在长视野稀疏奖励任务中生成连贯可控的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有生成式离线强化学习方法在长视野稀疏奖励任务中表现不佳，虽然一些分层生成方法通过分解问题来缓解，但它们往往忽略了轨迹固有的多尺度时间结构，导致性能次优。

Method: 提出MAGE方法：1）使用条件引导的多尺度自编码器学习分层轨迹表示；2）采用多尺度transformer从粗到细的时间尺度自回归生成轨迹表示；3）使用条件引导解码器精确控制短期行为。

Result: 在五个离线强化学习基准测试中与十五个基线算法对比，MAGE成功将多尺度轨迹建模与条件引导相结合，在长视野稀疏奖励设置中生成连贯可控的轨迹。

Conclusion: MAGE通过多尺度自回归生成框架有效捕捉轨迹的多分辨率时间依赖性，解决了现有生成式离线强化学习方法在长视野稀疏奖励任务中的局限性。

Abstract: Generative models have gained significant traction in offline reinforcement learning (RL) due to their ability to model complex trajectory distributions. However, existing generation-based approaches still struggle with long-horizon tasks characterized by sparse rewards. Some hierarchical generation methods have been developed to mitigate this issue by decomposing the original problem into shorter-horizon subproblems using one policy and generating detailed actions with another. While effective, these methods often overlook the multi-scale temporal structure inherent in trajectories, resulting in suboptimal performance. To overcome these limitations, we propose MAGE, a Multi-scale Autoregressive GEneration-based offline RL method. MAGE incorporates a condition-guided multi-scale autoencoder to learn hierarchical trajectory representations, along with a multi-scale transformer that autoregressively generates trajectory representations from coarse to fine temporal scales. MAGE effectively captures temporal dependencies of trajectories at multiple resolutions. Additionally, a condition-guided decoder is employed to exert precise control over short-term behaviors. Extensive experiments on five offline RL benchmarks against fifteen baseline algorithms show that MAGE successfully integrates multi-scale trajectory modeling with conditional guidance, generating coherent and controllable trajectories in long-horizon sparse-reward settings.

</details>


### [95] [Provable Subspace Identification of Nonlinear Multi-view CCA](https://arxiv.org/abs/2602.23785)
*Zhiwei Han,Stefan Matthes,Hao Shen*

Main category: cs.LG

TL;DR: 本文研究了多视图非线性典型相关分析（CCA）的可识别性问题，证明了在适当条件下，多视图CCA可以恢复共享的潜在信号子空间，并建立了有限样本一致性保证。


<details>
  <summary>Details</summary>
Motivation: 传统非线性CCA试图精确解混，但已被证明是不适定问题。本文重新将多视图CCA框架化为一个基不变子空间识别问题，旨在从非线性观测中恢复共享的潜在结构。

Method: 将多视图CCA重新定义为基不变子空间识别问题，在适当的潜在先验和谱分离条件下，证明多视图CCA可以恢复成对相关的信号子空间。对于N≥3个视图，目标函数能够分离出所有视图共享的联合相关子空间，同时消除视图私有变异。

Result: 理论证明：在适当条件下，多视图CCA可以恢复成对相关的信号子空间（存在视图正交模糊性）。对于N≥3个视图，能够分离出所有视图共享的联合相关子空间。建立了有限样本一致性保证，通过谱扰动理论将经验交叉协方差的集中性转化为明确的子空间误差界。

Conclusion: 多视图非线性CCA可以被重新框架为可识别的子空间恢复问题，在适当条件下能够有效恢复共享的潜在结构。实验验证了理论发现并确认了假设条件的必要性。

Abstract: We investigate the identifiability of nonlinear Canonical Correlation Analysis (CCA) in a multi-view setup, where each view is generated by an unknown nonlinear map applied to a linear mixture of shared latents and view-private noise. Rather than attempting exact unmixing, a problem proven to be ill-posed, we instead reframe multi-view CCA as a basis-invariant subspace identification problem. We prove that, under suitable latent priors and spectral separation conditions, multi-view CCA recovers the pairwise correlated signal subspaces up to view-wise orthogonal ambiguity. For $N \geq 3$ views, the objective provably isolates the jointly correlated subspaces shared across all views while eliminating view-private variations. We further establish finite-sample consistency guarantees by translating the concentration of empirical cross-covariances into explicit subspace error bounds via spectral perturbation theory. Experiments on synthetic and rendered image datasets validate our theoretical findings and confirm the necessity of the assumed conditions.

</details>


### [96] [UPath: Universal Planner Across Topological Heterogeneity For Grid-Based Pathfinding](https://arxiv.org/abs/2602.23789)
*Aleksandr Ananikian,Daniil Drozdov,Konstantin Yakovlev*

Main category: cs.LG

TL;DR: 该论文提出了一种通用启发式预测器，通过深度学习训练一次即可泛化到未见过的网格路径规划任务，显著提升A*算法效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的启发式方法主要依赖训练和测试网格地图来自相同分布（如城市地图、室内地图等），在分布外任务上表现不佳，这限制了实际应用中需要通用求解器的场景。

Method: 设计了一个通用启发式预测器模型，通过深度学习训练一次，但能够泛化到完全未见过的任务谱系。模型考虑了障碍物的位置和形状信息。

Result: 该方法将A*的计算工作量减少了高达2.2倍，同时在完全不同于训练任务的任务上，平均仍能提供与最优成本相差3%以内的解决方案。

Conclusion: 这是可学习求解器首次达到的里程碑：通过一次训练即可在完全不同的任务上实现高效路径规划，为通用路径规划求解器提供了实用解决方案。

Abstract: The performance of search algorithms for grid-based pathfinding, e.g. A*, critically depends on the heuristic function that is used to focus the search. Recent studies have shown that informed heuristics that take the positions/shapes of the obstacles into account can be approximated with the deep neural networks. Unfortunately, the existing learning-based approaches mostly rely on the assumption that training and test grid maps are drawn from the same distribution (e.g., city maps, indoor maps, etc.) and perform poorly on out-of-distribution tasks. This naturally limits their application in practice when often a universal solver is needed that is capable of efficiently handling any problem instance. In this work, we close this gap by designing an universal heuristic predictor: a model trained once, but capable of generalizing across a full spectrum of unseen tasks. Our extensive empirical evaluation shows that the suggested approach halves the computational effort of A* by up to a factor of 2.2, while still providing solutions within 3% of the optimal cost on average altogether on the tasks that are completely different from the ones used for training $\unicode{x2013}$ a milestone reached for the first time by a learnable solver.

</details>


### [97] [GRAIL: Post-hoc Compensation by Linear Reconstruction for Compressed Networks](https://arxiv.org/abs/2602.23795)
*Wenwu Tang,Dong Wang,Lothar Thiele,Olga Saukh*

Main category: cs.LG

TL;DR: GRAIL是一种无需微调的模型压缩后补偿方法，通过Gram矩阵和岭回归线性重建原始隐藏表示，可应用于各种压缩方法，显著提升压缩后模型的精度。


<details>
  <summary>Details</summary>
Motivation: 结构化深度模型压缩方法虽然硬件友好且能大幅降低内存和推理成本，但在激进压缩下会导致精度下降，而后续微调可能因缺乏标注数据或训练成本高而不切实际。

Method: 提出GRAIL方法：压缩后对每个块进行零微调补偿，使用小校准集通过Gram矩阵总结隐藏激活，应用岭回归从压缩表示线性重建原始隐藏表示，将重建映射吸收到下游投影权重中，同时压缩上游层。

Result: 在ResNets、ViTs和仅解码器LLMs上，GRAIL在实用压缩范围内持续优于无数据和有数据感知的剪枝或折叠基线，显著提升精度或降低困惑度，开销可控且无需反向传播。

Conclusion: GRAIL是一种选择器无关、数据感知的压缩后补偿方法，无需梯度或标签，仅需少量前向传播，能有效恢复压缩模型的性能，在弱通道相关性时退化为经典剪枝或折叠方法。

Abstract: Structured deep model compression methods are hardware-friendly and substantially reduce memory and inference costs. However, under aggressive compression, the resulting accuracy degradation often necessitates post-compression finetuning, which can be impractical due to missing labeled data or high training cost. We propose post-hoc blockwise compensation, called GRAIL, a simple zero-finetuning step applied after model compression that restores each block's input-output behavior using a small calibration set. The method summarizes hidden activations via a Gram matrix and applies ridge regression to linearly reconstruct the original hidden representation from the reduced one. The resulting reconstruction map is absorbed into the downstream projection weights, while the upstream layer is compressed. The approach is selector-agnostic (Magnitude, Wanda, Gram-based selection, or folding), data-aware (requiring only a few forward passes without gradients or labels), and recovers classic pruning or folding when the Gram matrix is near identity, indicating weak inter-channel correlations. Across ResNets, ViTs, and decoder-only LLMs, GRAIL consistently improves accuracy or perplexity over data-free and data-aware pruning or folding baselines in practical compression regimes, with manageable overhead and no backpropagation. The code is available at https://github.com/TWWinde/GRAIL.

</details>


### [98] [MPU: Towards Secure and Privacy-Preserving Knowledge Unlearning for Large Language Models](https://arxiv.org/abs/2602.23798)
*Tiantong Wang,Xinyu Yan,Tiantong Wu,Yurong Hao,Yong Jiang,Fei Huang,Wei Yang Bryan Lim*

Main category: cs.LG

TL;DR: MPU是一个算法无关的隐私保护多扰动副本遗忘框架，通过服务器端预处理的随机副本生成和后处理的更新聚合，在双重非披露约束下实现大语言模型的机器遗忘。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型机器遗忘中的隐私困境：严格约束禁止共享服务器参数或客户端的遗忘集，即双重非披露约束。

Method: 提出MPU框架，包含两个服务器端模块：预处理（Pre-Process）生成随机扰动和重参数化的模型副本，客户端在本地私有遗忘集上执行遗忘；后处理（Post-Process）通过反转重参数化和谐波去噪聚合更新来减轻扰动影响。

Result: 在七种遗忘算法上的实验表明，MPU在10%噪声下与无噪声基线性能相当，大多数算法的平均性能下降低于1%；在1%噪声下，某些算法甚至能超越无噪声基线。

Conclusion: MPU框架有效解决了大语言模型机器遗忘中的双重隐私约束问题，通过扰动副本和聚合机制在保护隐私的同时保持了遗忘性能。

Abstract: Machine unlearning for large language models often faces a privacy dilemma in which strict constraints prohibit sharing either the server's parameters or the client's forget set. To address this dual non-disclosure constraint, we propose MPU, an algorithm-agnostic privacy-preserving Multiple Perturbed Copies Unlearning framework that primarily introduces two server-side modules: Pre-Process for randomized copy generation and Post-Process for update aggregation. In Pre-Process, the server distributes multiple perturbed and reparameterized model instances, allowing the client to execute unlearning locally on its private forget set without accessing the server's exact original parameters. After local unlearning, the server performs Post-Process by inverting the reparameterization and aggregating updates with a harmonic denoising procedure to alleviate the impact of perturbation. Experiments with seven unlearning algorithms show that MPU achieves comparable unlearning performance to noise-free baselines, with most algorithms' average degradation well below 1% under 10% noise, and can even outperform the noise-free baseline for some algorithms under 1% noise. Code is available at https://github.com/Tristan-SHU/MPU.

</details>


### [99] [Beyond State-Wise Mirror Descent: Offline Policy Optimization with Parameteric Policies](https://arxiv.org/abs/2602.23811)
*Xiang Li,Nan Jiang,Yuheng Zhang*

Main category: cs.LG

TL;DR: 本文研究了离线强化学习在一般函数逼近下的理论问题，解决了现有算法只能处理有限小动作空间、依赖状态级镜像下降的局限性，将理论保证扩展到参数化策略类和大/连续动作空间。


<details>
  <summary>Details</summary>
Motivation: 现有离线RL算法（如PSPI）虽然计算可行，但仅适用于有限小动作空间，且依赖状态级镜像下降和从价值函数隐式推导策略，无法适应实践中普遍使用的独立策略参数化。需要将这些理论保证扩展到参数化策略类和大/连续动作空间。

Method: 将镜像下降扩展到参数化策略时，识别出上下文耦合是核心难点。通过将镜像下降与自然策略梯度连接起来，提出了新的分析框架、理论保证和算法见解，包括离线RL与模仿学习之间的统一。

Result: 成功将离线RL的理论保证扩展到参数化策略类和大/连续动作空间，提供了新的分析框架和算法设计思路，揭示了离线RL与模仿学习之间的深刻联系。

Conclusion: 本文解决了离线RL在一般函数逼近下的关键理论限制，通过连接镜像下降和自然策略梯度，为参数化策略类和大/连续动作空间的离线学习提供了理论保证和算法设计指导，并揭示了离线RL与模仿学习的统一性。

Abstract: We investigate the theoretical aspects of offline reinforcement learning (RL) under general function approximation. While prior works (e.g., Xie et al., 2021) have established the theoretical foundations of learning a good policy from offline data via pessimism, existing algorithms that are computationally tractable (often in an oracle-efficient sense), such as PSPI, only apply to finite and small action spaces. Moreover, these algorithms rely on state-wise mirror descent and require actors to be implicitly induced from the critic functions, failing to accommodate standalone policy parameterization which is ubiquitous in practice. In this work, we address these limitations and extend the theoretical guarantees to parameterized policy classes over large or continuous action spaces. When extending mirror descent to parameterized policies, we identify contextual coupling as the core difficulty, and show how connecting mirror descent to natural policy gradient leads to novel analyses, guarantees, and algorithmic insights, including a surprising unification between offline RL and imitation learning.

</details>


### [100] [Learning to maintain safety through expert demonstrations in settings with unknown constraints: A Q-learning perspective](https://arxiv.org/abs/2602.23816)
*George Papadopoulos,George A. Vouros*

Main category: cs.LG

TL;DR: SafeQIL算法通过结合任务奖励和安全性评估，在未知约束的约束MDP中学习最大化演示轨迹概率的策略，平衡保守性和高奖励轨迹的可能性。


<details>
  <summary>Details</summary>
Motivation: 在具有可观察奖励但未知约束和不可观察成本的约束MDP中，给定一组安全执行任务的演示轨迹，需要学习一个策略来最大化演示轨迹的可能性，同时平衡保守性和潜在不安全步骤的高奖励轨迹。

Method: 提出SafeQIL算法，将单个状态-动作对的"承诺"用Q值表示，该Q值同时考虑任务特定奖励和状态安全性评估，混合奖励和安全性的期望，形成约束下逆强化学习的安全Q学习视角。

Result: SafeQIL算法在一组具有挑战性的基准任务上与最先进的逆约束强化学习算法进行比较，展示了其优势。

Conclusion: 该研究提出了一种安全Q逆约束强化学习方法，能够有效学习最大化演示轨迹概率的策略，在奖励获取和安全性之间取得良好平衡。

Abstract: Given a set of trajectories demonstrating the execution of a task safely in a constrained MDP with observable rewards but with unknown constraints and non-observable costs, we aim to find a policy that maximizes the likelihood of demonstrated trajectories trading the balance between being conservative and increasing significantly the likelihood of high-rewarding trajectories but with potentially unsafe steps. Having these objectives, we aim towards learning a policy that maximizes the probability of the most $promising$ trajectories with respect to the demonstrations. In so doing, we formulate the ``promise" of individual state-action pairs in terms of $Q$ values, which depend on task-specific rewards as well as on the assessment of states' safety, mixing expectations in terms of rewards and safety. This entails a safe Q-learning perspective of the inverse learning problem under constraints: The devised Safe $Q$ Inverse Constrained Reinforcement Learning (SafeQIL) algorithm is compared to state-of-the art inverse constraint reinforcement learning algorithms to a set of challenging benchmark tasks, showing its merits.

</details>


### [101] [Inferring Chronic Treatment Onset from ePrescription Data: A Renewal Process Approach](https://arxiv.org/abs/2602.23824)
*Pavlin G. Poličar,Dalibor Stanimirović,Blaž Zupan*

Main category: cs.LG

TL;DR: 提出一个概率框架，通过将处方动态建模为更新过程，检测从偶发性治疗到持续性治疗的转变，来推断慢性病治疗开始时间


<details>
  <summary>Details</summary>
Motivation: 纵向电子健康记录数据常存在左截断问题，导致诊断记录不完整且不可靠，而门诊处方形成的更新轨迹能提供疾病管理的连续信号

Method: 将处方动态建模为更新过程，通过变点检测区分偶发性处方（泊松分布）和持续性治疗（威布尔更新模型）两种机制

Result: 基于240万人的全国电子处方数据集，该方法比简单规则触发方法产生更合理的时间起始估计，显著减少左截断下的不合理早期检测；检测性能因疾病而异，与处方密度密切相关

Conclusion: 该框架能更可靠地推断慢性病治疗起始时间，但检测性能受疾病特性和处方密度影响，揭示了基于治疗的起始时间推断的优势和局限性

Abstract: Longitudinal electronic health record (EHR) data are often left-censored, making diagnosis records incomplete and unreliable for determining disease onset. In contrast, outpatient prescriptions form renewal-based trajectories that provide a continuous signal of disease management. We propose a probabilistic framework to infer chronic treatment onset by modeling prescription dynamics as a renewal process and detecting transitions from sporadic to sustained therapy via change-point detection between a baseline Poisson (sporadic prescribing) regime and a regime-specific Weibull (sustained therapy) renewal model. Using a nationwide ePrescription dataset of 2.4 million individuals, we show that the approach yields more temporally plausible onset estimates than naive rule-based triggering, substantially reducing implausible early detections under strong left censoring. Detection performance varies across diseases and is strongly associated with prescription density, highlighting both the strengths and limits of treatment-based onset inference.

</details>


### [102] [FedNSAM:Consistency of Local and Global Flatness for Federated Learning](https://arxiv.org/abs/2602.23827)
*Junkang Liu,Fanhua Shang,Yuxuan Tian,Hongying Liu,Yuanyuan Liu*

Main category: cs.LG

TL;DR: FedNSAM算法通过引入全局Nesterov动量到本地更新中，解决联邦学习中数据异构性导致的全局模型泛化能力下降问题，比现有FedSAM算法收敛更快且性能更优。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中多步本地更新和数据异构性通常导致全局最小值更尖锐，从而降低全局模型的性能。现有方法将SAM集成到本地训练中，但在高数据异构性下，本地训练的平坦性并不代表全局模型的平坦性，因此需要新的解决方案。

Method: 提出FedNSAM算法，通过引入全局Nesterov动量到本地更新中，协调全局和本地平坦性的一致性。使用全局Nesterov动量作为客户端全局扰动的本地估计方向和外推方向。

Result: 理论上证明了比FedSAM更紧的收敛界；实验上在CNN和Transformer模型上进行了全面实验，验证了FedNSAM的优越性能和效率。

Conclusion: FedNSAM算法通过全局Nesterov动量协调全局和本地平坦性，有效解决了联邦学习中数据异构性导致的泛化问题，在理论和实验上都表现出优越性。

Abstract: In federated learning (FL), multi-step local updates and data heterogeneity usually lead to sharper global minima, which degrades the performance of the global model. Popular FL algorithms integrate sharpness-aware minimization (SAM) into local training to address this issue. However, in the high data heterogeneity setting, the flatness in local training does not imply the flatness of the global model. Therefore, minimizing the sharpness of the local loss surfaces on the client data does not enable the effectiveness of SAM in FL to improve the generalization ability of the global model. We define the \textbf{flatness distance} to explain this phenomenon. By rethinking the SAM in FL and theoretically analyzing the \textbf{flatness distance}, we propose a novel \textbf{FedNSAM} algorithm that accelerates the SAM algorithm by introducing global Nesterov momentum into the local update to harmonize the consistency of global and local flatness. \textbf{FedNSAM} uses the global Nesterov momentum as the direction of local estimation of client global perturbations and extrapolation. Theoretically, we prove a tighter convergence bound than FedSAM by Nesterov extrapolation. Empirically, we conduct comprehensive experiments on CNN and Transformer models to verify the superior performance and efficiency of \textbf{FedNSAM}. The code is available at https://github.com/junkangLiu0/FedNSAM.

</details>


### [103] [ULW-SleepNet: An Ultra-Lightweight Network for Multimodal Sleep Stage Scoring](https://arxiv.org/abs/2602.23852)
*Zhaowen Wang,Dongdong Zhou,Qi Xu,Fengyu Cong,Mohammad Al-Sa'd,Jenni Raitoharju*

Main category: cs.LG

TL;DR: ULW-SleepNet：一种超轻量级多模态睡眠分期框架，通过新颖的双流可分离卷积块等技术，在显著减少计算开销的同时保持竞争力准确性，适用于可穿戴和物联网设备的实时睡眠监测。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型通常计算量大且多为单通道EEG设计，限制了其在多模态PSG数据上的实用性。需要开发轻量级、高效的多模态睡眠分期模型，以适应可穿戴和物联网设备的实时监测需求。

Method: 提出ULW-SleepNet框架，采用双流可分离卷积块、深度可分离卷积、通道级参数共享和全局平均池化等技术，有效整合多生理信号信息，大幅降低计算复杂度。

Result: 在Sleep-EDF-20和Sleep-EDF-78数据集上分别达到86.9%和81.4%的准确率，仅需13.3K参数和7.89M FLOPs。相比最先进方法，参数减少高达98.6%，性能损失微小。

Conclusion: ULW-SleepNet在保持竞争力的准确率的同时，显著降低了计算开销，展示了在可穿戴和物联网设备上进行实时睡眠监测的强大潜力，为临床实践提供了实用的解决方案。

Abstract: Automatic sleep stage scoring is crucial for the diagnosis and treatment of sleep disorders. Although deep learning models have advanced the field, many existing models are computationally demanding and designed for single-channel electroencephalography (EEG), limiting their practicality for multimodal polysomnography (PSG) data. To overcome this, we propose ULW-SleepNet, an ultra-lightweight multimodal sleep stage scoring framework that efficiently integrates information from multiple physiological signals. ULW-SleepNet incorporates a novel Dual-Stream Separable Convolution (DSSC) Block, depthwise separable convolutions, channel-wise parameter sharing, and global average pooling to reduce computational overhead while maintaining competitive accuracy. Evaluated on the Sleep-EDF-20 and Sleep-EDF-78 datasets, ULW-SleepNet achieves accuracies of 86.9% and 81.4%, respectively, with only 13.3K parameters and 7.89M FLOPs. Compared to state-of-the-art methods, our model reduces parameters by up to 98.6% with only marginal performance loss, demonstrating its strong potential for real-time sleep monitoring on wearable and IoT devices. The source code for this study is publicly available at https://github.com/wzw999/ULW-SLEEPNET.

</details>


### [104] [A Theory of Random Graph Shift in Truncated-Spectrum vRKHS](https://arxiv.org/abs/2602.23880)
*Zhang Wan,Tingting Mu,Samuel Kaski*

Main category: cs.LG

TL;DR: 该论文提出了一个基于随机图生成模型的图分类领域适应理论，通过向量值再生核希尔伯特空间框架推导出包含领域差异、谱几何和振幅三个因子的泛化误差界。


<details>
  <summary>Details</summary>
Motivation: 现有领域适应理论主要针对传统数据，而图数据作为结构化对象，其非欧几里得特性和专用架构使得对图分布偏移的细粒度分析变得复杂。需要开发专门的理论来处理图分类中的领域偏移问题。

Method: 假设随机图模型作为数据生成过程，利用向量值再生核希尔伯特空间框架，推导出包含三个可分解因子的泛化误差界：领域差异项、谱几何项（由截断谱总结）和振幅项（聚合收敛和构造稳定性效应）。

Result: 理论推导出可分解的泛化误差界，并通过真实数据和模拟实验验证了各项因子的有效性，为图分类领域适应提供了理论支撑。

Conclusion: 该论文提出的理论框架能够对图分类中的领域偏移进行细粒度分析，通过随机图生成视角和vRKHS框架，为图领域适应提供了新的理论工具和见解。

Abstract: This paper develops a theory of graph classification under domain shift through a random-graph generative lens, where we consider intra-class graphs sharing the same random graph model (RGM) and the domain shift induced by changes in RGM components. While classic domain adaptation (DA) theories have well-underpinned existing techniques to handle graph distribution shift, the information of graph samples, which are itself structured objects, is less explored. The non-Euclidean nature of graphs and specialized architectures for graph learning further complicate a fine-grained analysis of graph distribution shifts. In this paper, we propose a theory that assumes RGM as the data generative process, exploiting its connection to hypothesis complexity in function space perspective for such fine-grained analysis. Building on a vector-valued reproducing kernel Hilbert space (vRKHS) formulation, we derive a generalization bound whose shift penalty admits a factorization into (i) a domain discrepancy term, (ii) a spectral-geometry term summarized by the accessible truncated spectrum, and (iii) an amplitude term that aggregates convergence and construction-stability effects. We empirically verify the insights on these terms in both real data and simulations.

</details>


### [105] [MINT: Multimodal Imaging-to-Speech Knowledge Transfer for Early Alzheimer's Screening](https://arxiv.org/abs/2602.23994)
*Vrushank Ahire,Yogesh Kumar,Anouck Girard,M. A. Ganaie*

Main category: cs.LG

TL;DR: MINT框架通过三阶段跨模态知识迁移，将MRI的生物标志物结构转移到语音编码器中，实现无需MRI扫描的阿尔茨海默病早期筛查。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期筛查需要生物标志物，但MRI成本高、部署困难；语音分析虽便捷但缺乏生物学基础。需要将MRI的生物标志物知识迁移到语音分析中，实现既准确又易于部署的筛查方法。

Method: 提出MINT三阶段框架：1）训练MRI教师模型（1228名受试者）定义神经影像嵌入空间；2）通过残差投影头和几何损失将语音表示对齐到冻结的影像流形；3）推理时应用冻结的MRI分类器处理对齐后的语音嵌入，无需MRI扫描。

Result: 在ADNI-4数据集上，对齐后的语音达到与纯语音基线相当的性能（AUC 0.720 vs 0.711），同时无需推理时的影像数据；多模态融合优于单独MRI（0.973 vs 0.958）。消融研究显示dropout正则化和自监督预训练是关键设计。

Conclusion: 首次展示了MRI到语音的知识迁移用于阿尔茨海默病早期筛查，建立了无需神经影像推理的生物学基础通路，为人群级认知分流提供了新途径。

Abstract: Alzheimer's disease is a progressive neurodegenerative disorder in which mild cognitive impairment (MCI) marks a critical transition between aging and dementia. Neuroimaging modalities, such as structural MRI, provide biomarkers of this transition; however, their high costs and infrastructure needs limit their deployment at a population scale. Speech analysis offers a non-invasive alternative, but speech-only classifiers are developed independently of neuroimaging, leaving decision boundaries biologically ungrounded and limiting reliability on the subtle CN-versus-MCI distinction. We propose MINT (Multimodal Imaging-to-Speech Knowledge Transfer), a three-stage cross-modal framework that transfers biomarker structure from MRI into a speech encoder at training time. An MRI teacher, trained on 1,228 subjects, defines a compact neuroimaging embedding space for CN-versus-MCI classification. A residual projection head aligns speech representations to this frozen imaging manifold via a combined geometric loss, adapting speech to the learned biomarker space while preserving imaging encoder fidelity. The frozen MRI classifier, which is never exposed to speech, is applied to aligned embeddings at inference and requires no scanner. Evaluation on ADNI-4 shows aligned speech achieves performance comparable to speech-only baselines (AUC 0.720 vs 0.711) while requiring no imaging at inference, demonstrating that MRI-derived decision boundaries can ground speech representations. Multimodal fusion improves over MRI alone (0.973 vs 0.958). Ablation studies identify dropout regularization and self-supervised pretraining as critical design decisions. To our knowledge, this is the first demonstration of MRI-to-speech knowledge transfer for early Alzheimer's screening, establishing a biologically grounded pathway for population-level cognitive triage without neuroimaging at inference.

</details>


### [106] [Foundation World Models for Agents that Learn, Verify, and Adapt Reliably Beyond Static Environments](https://arxiv.org/abs/2602.23997)
*Florent Delgrange*

Main category: cs.LG

TL;DR: 提出基础世界模型愿景：通过可学习奖励模型、自适应形式验证、在线抽象校准和测试时合成，构建支持强化学习、程序合成和抽象机制的持久组合表示，使智能体能在开放世界中可靠适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设固定任务和环境，缺乏处理新颖性的能力，限制了世界模型支持智能体在条件变化时演化策略的潜力。需要构建能统一强化学习、反应式/程序合成和抽象机制的基础世界模型。

Method: 提出包含四个组件的议程：1) 从规范中学习可学习奖励模型以支持明确目标的优化；2) 在整个学习过程中集成自适应形式验证；3) 在线抽象校准以量化模型预测的可靠性；4) 由验证器指导的测试时合成和世界模型生成。

Result: 该框架使智能体能够合成可验证程序、从少量交互中推导新策略，并在适应新颖性时保持正确性。基础世界模型成为学习、推理和适应的基础。

Conclusion: 基础世界模型为智能体提供了不仅能良好行动，还能解释和证明其行为的基础，为下一代自主智能体在开放世界中高效学习、可靠行动和适应性行为奠定了基础。

Abstract: The next generation of autonomous agents must not only learn efficiently but also act reliably and adapt their behavior in open worlds. Standard approaches typically assume fixed tasks and environments with little or no novelty, which limits world models' ability to support agents that must evolve their policies as conditions change. This paper outlines a vision for foundation world models: persistent, compositional representations that unify reinforcement learning, reactive/program synthesis, and abstraction mechanisms. We propose an agenda built around four components: (i) learnable reward models from specifications to support optimization with clear objectives; (ii) adaptive formal verification integrated throughout learning; (iii) online abstraction calibration to quantify the reliability of the model's predictions; and (iv) test-time synthesis and world-model generation guided by verifiers. Together, these components enable agents to synthesize verifiable programs, derive new policies from a small number of interactions, and maintain correctness while adapting to novelty. The resulting framework positions foundation world models as a substrate for learning, reasoning, and adaptation, laying the groundwork for agents that not only act well but can explain and justify the behavior they adopt.

</details>


### [107] [InfoNCE Induces Gaussian Distribution](https://arxiv.org/abs/2602.24012)
*Roy Betser,Eyal Gofer,Meir Yossef Levi,Guy Gilboa*

Main category: cs.LG

TL;DR: 本文证明对比学习中的InfoNCE损失会诱导表示呈现高斯结构，通过理论分析和实验验证了这一发现。


<details>
  <summary>Details</summary>
Motivation: 对比学习已成为现代表示学习的基石，但对其诱导的表示结构缺乏理论理解。本文旨在揭示InfoNCE损失如何影响表示分布，特别是其诱导的高斯结构特性。

Method: 采用两种互补的理论分析框架：1）在一定对齐和集中性假设下，证明高维表示的投影渐近趋近多元高斯分布；2）在较弱假设下，通过添加渐近消失的正则化项（促进低特征范数和高特征熵）获得类似渐近结果。实验在合成数据和CIFAR-10数据集上进行，涵盖多种编码器架构和规模。

Result: 理论分析和实验结果表明，对比学习训练得到的表示确实呈现高斯分布特性。这一发现为观察到的对比表示高斯性提供了原则性解释，并在合成和真实数据集上得到验证。

Conclusion: InfoNCE目标函数诱导表示呈现高斯结构，这一理论发现为对比学习表示提供了新的理解框架。所得的高斯模型支持对学习表示进行原则性分析处理，有望在对比学习的广泛应用中发挥作用。

Abstract: Contrastive learning has become a cornerstone of modern representation learning, allowing training with massive unlabeled data for both task-specific and general (foundation) models. A prototypical loss in contrastive training is InfoNCE and its variants. In this work, we show that the InfoNCE objective induces Gaussian structure in representations that emerge from contrastive training. We establish this result in two complementary regimes. First, we show that under certain alignment and concentration assumptions, projections of the high-dimensional representation asymptotically approach a multivariate Gaussian distribution. Next, under less strict assumptions, we show that adding a small asymptotically vanishing regularization term that promotes low feature norm and high feature entropy leads to similar asymptotic results. We support our analysis with experiments on synthetic and CIFAR-10 datasets across multiple encoder architectures and sizes, demonstrating consistent Gaussian behavior. This perspective provides a principled explanation for commonly observed Gaussianity in contrastive representations. The resulting Gaussian model enables principled analytical treatment of learned representations and is expected to support a wide range of applications in contrastive learning.

</details>


### [108] [RewardUQ: A Unified Framework for Uncertainty-Aware Reward Models](https://arxiv.org/abs/2602.24040)
*Daniel Yang,Samuel Stante,Florian Redhardt,Lena Libon,Parnian Kassraie,Ido Hakimi,Barna Pásztor,Andreas Krause*

Main category: cs.LG

TL;DR: RewardUQ：一个用于系统评估奖励模型不确定性量化的统一框架，发现模型规模和初始化对性能影响最大，多数先前工作可从替代设计选择中受益。


<details>
  <summary>Details</summary>
Motivation: 奖励模型在将大语言模型与人类偏好对齐中至关重要，但现有方法大多依赖点估计而忽略了有限人类反馈带来的认知不确定性。虽然量化这种不确定性可以通过不确定性引导的主动学习降低人工标注成本，并在LLM后训练中缓解奖励过优化问题，但不确定性感知的奖励模型缺乏系统比较，理解不足。

Method: 提出了RewardUQ统一框架，系统评估奖励模型的不确定性量化。比较了常见方法在准确性和校准性标准指标上的表现，并提出了一种结合这两个维度的新排名策略以简化比较。

Result: 实验结果表明，模型规模和初始化对性能影响最为显著，大多数先前工作本可以从替代设计选择中受益。为促进新方法的开发和评估，并帮助下游应用部署，作者将开源框架发布为Python包。

Conclusion: RewardUQ框架为系统评估奖励模型不确定性量化提供了统一标准，揭示了模型规模和初始化的关键作用，并指出先前研究在方法选择上存在优化空间。开源框架将促进该领域进一步发展。

Abstract: Reward models are central to aligning large language models (LLMs) with human preferences. Yet most approaches rely on pointwise reward estimates that overlook the epistemic uncertainty in reward models arising from limited human feedback. Recent work suggests that quantifying this uncertainty can reduce the costs of human annotation via uncertainty-guided active learning and mitigate reward overoptimization in LLM post-training. However, uncertainty-aware reward models have so far been adopted without thorough comparison, leaving them poorly understood. This work introduces a unified framework, RewardUQ, to systematically evaluate uncertainty quantification for reward models. We compare common methods along standard metrics measuring accuracy and calibration, and we propose a new ranking strategy incorporating both dimensions for a simplified comparison. Our experimental results suggest that model size and initialization have the most meaningful impact on performance, and most prior work could have benefited from alternative design choices. To foster the development and evaluation of new methods and aid the deployment in downstream applications, we release our open-source framework as a Python package. Our code is available at https://github.com/lasgroup/rewarduq.

</details>


### [109] [pathsig: A GPU-Accelerated Library for Truncated and Projected Path Signatures](https://arxiv.org/abs/2602.24066)
*Tobias Nygaard*

Main category: cs.LG

TL;DR: pathsig是一个PyTorch原生库，用于高效计算路径签名，通过CUDA并行计算实现10-30倍加速，支持自定义投影和异向截断以减少维度冗余。


<details>
  <summary>Details</summary>
Motivation: 路径签名在序列数据表示方面具有强大理论保证和良好性能，但现有库缺乏大规模梯度学习所需的可扩展性，需要更高效的实现。

Method: 开发PyTorch原生库pathsig，直接在字基上计算路径签名，使用CUDA内核在前缀封闭字集上并行更新签名系数，实现高GPU吞吐量和近最小峰值内存。

Result: 相比其他库，pathsig在截断签名计算上实现10-30倍加速，在需要签名反向传播的训练中实现4-10倍加速，支持自定义投影和异向截断以减少计算成本。

Conclusion: pathsig提供了高效可扩展的路径签名计算解决方案，通过GPU并行化和灵活的特征选择机制，显著提升机器学习任务中路径签名的计算效率。

Abstract: Path signatures provide a rich representation of sequential data, with strong theoretical guarantees and good performance in a variety of machine-learning tasks. While signatures have progressed from fixed feature extractors to trainable components of machine-learning models, existing libraries often lack the required scalability for large-scale, gradient-based learning. To address this gap, this paper introduces pathsig, a PyTorch-native library that computes path signatures directly in the word basis. By using CUDA kernels to update signature coefficients in parallel over prefix-closed word sets, pathsig achieves high GPU throughput and near-minimal peak memory. Compared with other libraries, pathsig achieves 10-30x speedups for computation of truncated signatures and up to 4-10x speedups in training that require backpropagation through the signature. Beyond regular truncation, pathsig supports projections of the (infinite-dimensional) signature onto user-specified sets of words and anisotropic truncation motivated by inhomogeneous path regularity, enabling more compact representations that can reduce dimensionality, redundancy, and computational cost.

</details>


### [110] [Leveraging Non-linear Dimension Reduction and Random Walk Co-occurrence for Node Embedding](https://arxiv.org/abs/2602.24069)
*Ryan DeWolfe*

Main category: cs.LG

TL;DR: COVE是一种可解释的高维节点嵌入方法，通过非线性降维技术突破低维限制，在聚类和链接预测任务上表现略优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统节点嵌入方法受限于低维约束，作者希望开发一种可解释的高维嵌入方法，同时保持或提升在社区检测和链接预测任务上的性能

Method: 提出COVE高维嵌入方法，基于随机游走中的共现作为相似性指标，与扩散过程密切相关；使用UMAP进行降维，结合HDBSCAN进行聚类分析

Result: COVE嵌入经UMAP降维后，在聚类和链接预测任务上性能略有提升；COVE-UMAP-HDBSCAN流程与流行的Louvain算法性能相当

Conclusion: COVE提供了一种可解释的高维节点嵌入方法，通过非线性降维技术能够获得与传统社区检测算法相当的性能，同时保持可解释性

Abstract: Leveraging non-linear dimension reduction techniques, we remove the low dimension constraint from node embedding and propose COVE, an explainable high dimensional embedding that, when reduced to low dimension with UMAP, slightly increases performance on clustering and link prediction tasks. The embedding is inspired by neural embedding methods that use co-occurrence on a random walk as an indication of similarity, and is closely related to a diffusion process. Extending on recent community detection benchmarks, we find that a COVE UMAP HDBSCAN pipeline performs similarly to the popular Louvain algorithm.

</details>


### [111] [Neural Diffusion Intensity Models for Point Process Data](https://arxiv.org/abs/2602.24083)
*Xinlong Du,Harsha Honnappa,Vinayak Rao*

Main category: cs.LG

TL;DR: 提出Neural Diffusion Intensity Models，一种基于神经SDE的变分框架，用于Cox过程建模，通过滤波扩张理论保证变分族包含真实后验，实现高效推理


<details>
  <summary>Details</summary>
Motivation: 传统Cox过程建模中，强度函数的非参数估计和强度路径的后验推断通常不可行，依赖于昂贵的MCMC方法，需要更高效的推理方法

Method: 基于滤波扩张理论，证明在点过程观测条件下，潜在强度的扩散结构得以保持并具有显式漂移修正；设计摊销编码器架构，将变长事件序列映射到后验强度路径，通过模拟修正后的SDE实现单次前向传播

Result: 在合成和真实世界数据上准确恢复潜在强度动态和后验路径，相比基于MCMC的方法实现数量级的速度提升

Conclusion: Neural Diffusion Intensity Models为Cox过程提供了一种高效、准确的变分推理框架，通过理论保证和摊销编码器设计，显著提升了推理效率

Abstract: Cox processes model overdispersed point process data via a latent stochastic intensity, but both nonparametric estimation of the intensity model and posterior inference over intensity paths are typically intractable, relying on expensive MCMC methods. We introduce Neural Diffusion Intensity Models, a variational framework for Cox processes driven by neural SDEs. Our key theoretical result, based on enlargement of filtrations, shows that conditioning on point process observations preserves the diffusion structure of the latent intensity with an explicit drift correction. This guarantees the variational family contains the true posterior, so that ELBO maximization coincides with maximum likelihood estimation under sufficient model capacity. We design an amortized encoder architecture that maps variable-length event sequences to posterior intensity paths by simulating the drift-corrected SDE, replacing repeated MCMC runs with a single forward pass. Experiments on synthetic and real-world data demonstrate accurate recovery of latent intensity dynamics and posterior paths, with orders-of-magnitude speedups over MCMC-based methods.

</details>


### [112] [Learning with a Budget: Identifying the Best Arm with Resource Constraints](https://arxiv.org/abs/2602.24146)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 论文提出了资源约束下的最佳臂识别问题(BAIwRC)，并开发了SH-RR算法，该算法将资源感知分配整合到经典连续减半框架中，统一了随机和确定性消耗设置的理论分析。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，评估不同替代方案的有效性伴随着不同的成本或资源使用。受这种异质性的启发，研究者研究了资源约束下的最佳臂识别问题，其中智能体需要在存在资源约束的情况下识别最佳替代方案（即臂）。每个臂拉动消耗一种或多种有限资源类型。

Method: 提出了Successive Halving with Resource Rationing (SH-RR)算法，该算法将资源感知分配整合到经典连续减半框架中。该算法统一了随机和确定性消耗设置的理论分析，并引入了新的有效消耗度量。

Result: SH-RR算法在资源约束下的最佳臂识别问题中表现出色，能够有效处理随机和确定性资源消耗设置，通过新的有效消耗度量优化资源分配。

Conclusion: 该研究为资源约束下的最佳臂识别问题提供了统一的算法框架和理论分析，SH-RR算法能够有效处理异质性资源消耗，为实际应用中的资源受限决策问题提供了解决方案。

Abstract: In many applications, evaluating the effectiveness of different alternatives comes with varying costs or resource usage. Motivated by such heterogeneity, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem, where an agent seeks to identify the best alternative (aka arm) in the presence of resource constraints. Each arm pull consumes one or more types of limited resources. We make two key contributions. First, we propose the Successive Halving with Resource Rationing (SH-RR) algorithm, which integrates resource-aware allocation into the classical successive halving framework on best arm identification. The SH-RR algorithm unifies the theoretical analysis for both the stochastic and deterministic consumption settings, with a new \textit{effective consumption measure

</details>


### [113] [Sandwiching Polynomials for Geometric Concepts with Low Intrinsic Dimension](https://arxiv.org/abs/2602.24178)
*Adam R. Klivans,Konstantinos Stavropoulos,Arsen Vasilyan*

Main category: cs.LG

TL;DR: 本文提出了一种构造低阶三明治多项式的新方法，显著改进了多个基本函数类和高斯分布下的阶数界限，特别是将k个半空间的函数从指数级改进到多项式级。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明低阶三明治多项式在分布偏移学习、可测试学习和污染学习等挑战性学习场景中具有强大能力。三明治多项式既能近似目标函数的期望值，又能提供函数值的逐点上界和下界。然而现有方法的阶数界限不够理想，需要改进。

Method: 提出了一种相对简单的新方法，直接利用目标函数边界的平滑性来构造三明治Lipschitz函数，这些函数适合应用高维逼近理论的结果。该方法避免了先前工作中使用的FT-mollification技术。

Result: 获得了多项重大改进：对于高斯分布下的k个半空间函数，将阶数从2^O(k)指数级改进到poly(k)多项式级；对于低维多项式阈值函数(PTFs)，获得了双指数级改进；方法适用于具有平滑边界的低维函数类。

Conclusion: 新方法通过直接利用函数边界的平滑性，以相对简单的证明获得了显著改进的低阶三明治多项式构造，为多个基本函数类提供了更好的逼近界限，特别是在高斯分布下的半空间函数和多项式阈值函数方面取得了突破性进展。

Abstract: Recent work has shown the surprising power of low-degree sandwiching polynomial approximators in the context of challenging learning settings such as learning with distribution shift, testable learning, and learning with contamination. A pair of sandwiching polynomials approximate a target function in expectation while also providing pointwise upper and lower bounds on the function's values. In this paper, we give a new method for constructing low-degree sandwiching polynomials that yield greatly improved degree bounds for several fundamental function classes and marginal distributions. In particular, we obtain degree $\mathrm{poly}(k)$ sandwiching polynomials for functions of $k$ halfspaces under the Gaussian distribution, improving exponentially over the prior $2^{O(k)}$ bound. More broadly, our approach applies to function classes that are low-dimensional and have smooth boundary.
  In contrast to prior work, our proof is relatively simple and directly uses the smoothness of the target function's boundary to construct sandwiching Lipschitz functions, which are amenable to results from high-dimensional approximation theory. For low-dimensional polynomial threshold functions (PTFs) with respect to Gaussians, we obtain doubly exponential improvements without applying the FT-mollification method of Kane used in the best previous result.

</details>


### [114] [Multi-Objective Reinforcement Learning for Large-Scale Tote Allocation in Human-Robot Collaborative Fulfillment Centers](https://arxiv.org/abs/2602.24182)
*Sikata Sengupta,Guangyi Liu,Omer Gottesman,Joseph W Durham,Michael Kearns,Aaron Roth,Michael Caldara*

Main category: cs.LG

TL;DR: 该研究提出了一种基于多目标强化学习的方法来优化集装箱式履约中心的整合流程，通过零和博弈理论解决约束条件下的多目标权衡问题。


<details>
  <summary>Details</summary>
Motivation: 集装箱式履约中心的整合流程需要在处理速度、资源使用和空间利用率等多个竞争目标之间进行权衡，同时满足现实操作约束，这是一个复杂的多目标优化问题。

Method: 将问题建模为大规模多目标强化学习任务，利用零和博弈中的最优响应和无悔动态理论来解决约束RL问题，采用极小极大策略学习方法，并引入处理误差消除问题的理论框架。

Result: 在现实仓库模拟中的策略评估显示，该方法能有效权衡多个目标，学习到的单一策略能同时满足所有约束条件，即使这在理论上并不保证。理论框架能处理误差消除问题，返回接近博弈极小极大值的拉格朗日值。

Conclusion: 研究结果表明多目标强化学习在解决大规模工业系统中复杂、高影响力的决策问题方面具有巨大潜力，为解决现实世界中的多目标优化问题提供了理论和方法基础。

Abstract: Optimizing the consolidation process in container-based fulfillment centers requires trading off competing objectives such as processing speed, resource usage, and space utilization while adhering to a range of real-world operational constraints. This process involves moving items between containers via a combination of human and robotic workstations to free up space for inbound inventory and increase container utilization. We formulate this problem as a large-scale Multi-Objective Reinforcement Learning (MORL) task with high-dimensional state spaces and dynamic system behavior. Our method builds on recent theoretical advances in solving constrained RL problems via best-response and no-regret dynamics in zero-sum games, enabling principled minimax policy learning. Policy evaluation on realistic warehouse simulations shows that our approach effectively trades off objectives, and we empirically observe that it learns a single policy that simultaneously satisfies all constraints, even if this is not theoretically guaranteed. We further introduce a theoretical framework to handle the problem of error cancellation, where time-averaged solutions display oscillatory behavior. This method returns a single iterate whose Lagrangian value is close to the minimax value of the game. These results demonstrate the promise of MORL in solving complex, high-impact decision-making problems in large-scale industrial systems.

</details>


### [115] [Flow-Based Density Ratio Estimation for Intractable Distributions with Applications in Genomics](https://arxiv.org/abs/2602.24201)
*Egor Antipov,Alessandro Palma,Lorenzo Consoli,Stephan Günnemann,Andrea Dittadi,Fabian J. Theis*

Main category: cs.LG

TL;DR: 提出一种基于条件感知流匹配的密度比估计方法，避免分别计算两个分布的似然积分，在单细胞基因组学数据分析中表现优异。


<details>
  <summary>Details</summary>
Motivation: 密度比估计是概率建模的核心问题，但传统方法如归一化流需要分别计算两个分布的似然积分，计算成本高昂。

Method: 利用条件感知流匹配技术，推导出单一动力学公式来跟踪生成轨迹上的密度比，避免分别计算两个分布的似然积分。

Result: 在闭式比估计的模拟基准测试中表现出竞争力，在单细胞基因组学数据分析中支持多种任务，包括治疗效果估计和批次校正评估。

Conclusion: 该方法提供了一种高效准确的密度比估计方法，特别适用于需要比较不同实验条件下细胞状态的单细胞基因组学数据分析。

Abstract: Estimating density ratios between pairs of intractable data distributions is a core problem in probabilistic modeling, enabling principled comparisons of sample likelihoods under different data-generating processes across conditions and covariates. While exact-likelihood models such as normalizing flows offer a promising approach to density ratio estimation, naive flow-based evaluations are computationally expensive, as they require simulating costly likelihood integrals for each distribution separately. In this work, we leverage condition-aware flow matching to derive a single dynamical formulation for tracking density ratios along generative trajectories. We demonstrate competitive performance on simulated benchmarks for closed-form ratio estimation, and show that our method supports versatile tasks in single-cell genomics data analysis, where likelihood-based comparisons of cellular states across experimental conditions enable treatment effect estimation and batch correction evaluation.

</details>


### [116] [The Stability of Online Algorithms in Performative Prediction](https://arxiv.org/abs/2602.24207)
*Gabriele Farina,Juan Carlos Perdomo*

Main category: cs.LG

TL;DR: 论文证明：在预测性决策环境中，任何无遗憾算法都会收敛到（混合）预测稳定均衡，无需对模型影响数据分布的方式做限制性假设。


<details>
  <summary>Details</summary>
Motivation: 算法预测在决策中的使用会导致反馈循环：部署的模型会影响数据分布，进而影响后续的重新训练。Perdomo等人2020年将这种动态形式化为预测性预测。现有研究对模型如何影响分布有严格限制，需要更一般的理论框架。

Method: 使用鞅论证和允许随机化的方法，避免对模型影响数据分布方式的任何假设。通过无条件约简，将预测性设置中的无遗憾算法与稳定均衡联系起来。

Result: 证明任何在预测性设置中部署的无遗憾算法都会收敛到（混合）预测稳定均衡，即模型主动塑造数据分布，使其预测在后验中看起来最优。这绕过了最近关于寻找稳定模型的硬度结果。

Conclusion: 该连接揭示了为什么常见算法（如梯度下降）自然具有稳定性并防止失控的反馈循环。这项工作为在线优化和预测性之间的思想技术转移提供了基础。

Abstract: The use of algorithmic predictions in decision-making leads to a feedback loop where the models we deploy actively influence the data distributions we see, and later use to retrain on. This dynamic was formalized by Perdomo et al. 2020 in their work on performative prediction. Our main result is an unconditional reduction showing that any no-regret algorithm deployed in performative settings converges to a (mixed) performatively stable equilibrium: a solution in which models actively shape data distributions in ways that their own predictions look optimal in hindsight. Prior to our work, all positive results in this area made strong restrictions on how models influenced distributions. By using a martingale argument and allowing randomization, we avoid any such assumption and sidestep recent hardness results for finding stable models. Lastly, on a more conceptual note, our connection sheds light on why common algorithms, like gradient descent, are naturally stabilizing and prevent runaway feedback loops. We hope our work enables future technical transfer of ideas between online optimization and performativity.

</details>


### [117] [An Efficient Unsupervised Federated Learning Approach for Anomaly Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2602.24209)
*Mohsen Tajgardan,Atena Shiranzaei,Mahdi Rabbani,Reza Khoshkangini,Mahtab Jamali*

Main category: cs.LG

TL;DR: 提出一种高效的无人监督联邦学习框架，利用两个不同物联网数据集的共享特征来增强异常检测，同时保持数据集特定特征，并通过可解释AI技术提高透明度。


<details>
  <summary>Details</summary>
Motivation: 物联网环境中的联邦学习面临数据异构性挑战，设备能力、数据格式和通信约束的差异影响了全局模型性能和隐私保护。在物联网异常检测场景中，特征异构性使模型训练和优化变得复杂，阻碍了有效实施。

Method: 提出一种高效的无人监督联邦学习框架，利用两个不同物联网数据集（一个专注于异常检测，另一个专注于设备识别）的共享特征来增强异常检测，同时保持数据集特定特征。采用可解释AI技术（如SHAP）来识别影响本地模型决策的关键特征，提高透明度和可解释性。

Result: 在真实世界物联网数据集上的实验表明，所提出的方法在异常检测准确率方面显著优于传统的联邦学习方法。

Conclusion: 这项工作强调了利用互补数据集的共享特征来优化无人监督联邦学习，在去中心化物联网环境中实现卓越异常检测结果的潜力。

Abstract: Federated learning (FL) is an effective paradigm for distributed environments such as the Internet of Things (IoT), where data from diverse devices with varying functionalities remains localized while contributing to a shared global model. By eliminating the need to transmit raw data, FL inherently preserves privacy. However, the heterogeneous nature of IoT data, stemming from differences in device capabilities, data formats, and communication constraints, poses significant challenges to maintaining both global model performance and privacy. In the context of IoT-based anomaly detection, unsupervised FL offers a promising means to identify abnormal behavior without centralized data aggregation. Nevertheless, feature heterogeneity across devices complicates model training and optimization, hindering effective implementation. In this study we propose an efficient unsupervised FL framework that enhances anomaly detection by leveraging shared features from two distinct IoT datasets: one focused on anomaly detection and the other on device identification, while preserving dataset-specific features. To improve transparency and interpretability, we employ explainable AI techniques, such as SHAP, to identify key features influencing local model decisions. Experiments conducted on real-world IoT datasets demonstrate that the proposed method significantly outperforms conventional FL approaches in anomaly detection accuracy. This work underscores the potential of using shared features from complementary datasets to optimize unsupervised federated learning and achieve superior anomaly detection results in decentralized IoT environments.

</details>


### [118] [Adaptive Combinatorial Experimental Design: Pareto Optimality for Decision-Making and Inference](https://arxiv.org/abs/2602.24231)
*Hongrui Xie,Junyu Cao,Kan Xu*

Main category: cs.LG

TL;DR: 该论文首次研究自适应组合实验设计，关注组合多臂老虎机中遗憾最小化与统计功效之间的权衡，提出了帕累托最优学习的概念，并针对两种反馈机制设计了相应算法。


<details>
  <summary>Details</summary>
Motivation: 在组合多臂老虎机中，最小化遗憾需要重复利用高奖励臂，而准确推断奖励差距需要充分探索次优动作。这种权衡在自适应组合实验设计中尚未得到系统研究。

Method: 通过帕累托最优性形式化权衡问题，针对全老虎机反馈和半老虎机反馈两种信息结构，分别提出MixCombKL和MixCombUCB算法。

Result: 理论证明两种算法都是帕累托最优的，在遗憾和臂差距估计误差方面都获得有限时间保证。更丰富的反馈显著收紧可达帕累托前沿，主要增益来自估计精度的提升。

Conclusion: 这些发现为多目标决策中的自适应组合实验建立了原则性框架，揭示了反馈机制对权衡关系的重要影响。

Abstract: In this paper, we provide the first investigation into adaptive combinatorial experimental design, focusing on the trade-off between regret minimization and statistical power in combinatorial multi-armed bandits (CMAB). While minimizing regret requires repeated exploitation of high-reward arms, accurate inference on reward gaps requires sufficient exploration of suboptimal actions. We formalize this trade-off through the concept of Pareto optimality and establish equivalent conditions for Pareto-efficient learning in CMAB. We consider two relevant cases under different information structures, i.e., full-bandit feedback and semi-bandit feedback, and propose two algorithms MixCombKL and MixCombUCB respectively for these two cases. We provide theoretical guarantees showing that both algorithms are Pareto optimal, achieving finite-time guarantees on both regret and estimation error of arm gaps. Our results further reveal that richer feedback significantly tightens the attainable Pareto frontier, with the primary gains arising from improved estimation accuracy under our proposed methods. Taken together, these findings establish a principled framework for adaptive combinatorial experimentation in multi-objective decision-making.

</details>


### [119] [Time Series Foundation Models as Strong Baselines in Transportation Forecasting: A Large-Scale Benchmark Analysis](https://arxiv.org/abs/2602.24238)
*Javier Pulido,Filipe Rodrigues*

Main category: cs.LG

TL;DR: Chronos-2时间序列基础模型在交通预测任务中表现出色，无需特定数据集训练即可达到或超越专门深度学习模型的效果，特别是在长期预测方面。


<details>
  <summary>Details</summary>
Motivation: 当前交通预测方法通常需要针对特定数据集进行训练、架构设计和超参数调优，过程复杂且耗时。研究旨在评估通用时间序列基础模型是否能够作为交通预测任务的可行替代方案。

Method: 使用最先进的Chronos-2模型，在10个真实世界交通数据集上进行零样本性能基准测试，涵盖高速公路交通量和流量、城市交通速度、共享单车需求和电动汽车充电站数据，采用一致的评估协议。

Result: 即使没有任何任务特定的微调，Chronos-2在大多数数据集上都能提供最先进或具有竞争力的准确性，经常超越经典统计基线和专门的深度学习架构，特别是在较长预测时间范围内。其原生概率输出也提供了有用的不确定性量化。

Conclusion: 时间序列基础模型可以作为交通预测研究的关键基线，支持其在交通预测任务中的采用，减少对特定数据集训练的依赖。

Abstract: Accurate forecasting of transportation dynamics is essential for urban mobility and infrastructure planning. Although recent work has achieved strong performance with deep learning models, these methods typically require dataset-specific training, architecture design and hyper-parameter tuning. This paper evaluates whether general-purpose time-series foundation models can serve as forecasters for transportation tasks by benchmarking the zero-shot performance of the state-of-the-art model, Chronos-2, across ten real-world datasets covering highway traffic volume and flow, urban traffic speed, bike-sharing demand, and electric vehicle charging station data. Under a consistent evaluation protocol, we find that, even without any task-specific fine-tuning, Chronos-2 delivers state-of-the-art or competitive accuracy across most datasets, frequently outperforming classical statistical baselines and specialized deep learning architectures, particularly at longer horizons. Beyond point forecasting, we evaluate its native probabilistic outputs using prediction-interval coverage and sharpness, demonstrating that Chronos-2 also provides useful uncertainty quantification without dataset-specific training. In general, this study supports the adoption of time-series foundation models as a key baseline for transportation forecasting research.

</details>


### [120] [Chunk-wise Attention Transducers for Fast and Accurate Streaming Speech-to-Text](https://arxiv.org/abs/2602.24245)
*Hainan Xu,Vladimir Bataev,Travis M. Bartley,Jagadeesh Balam*

Main category: cs.LG

TL;DR: CHAT是一种基于RNN-T的改进模型，通过分块处理和跨注意力机制，在保持流式处理能力的同时提升效率和准确率


<details>
  <summary>Details</summary>
Motivation: RNN-T模型虽然支持流式处理，但其严格的单调对齐机制在某些任务（特别是语音翻译）中限制了性能，同时处理长序列时效率较低

Method: 提出分块注意力转换器（CHAT），将音频分割为固定大小的块，在每个块内使用跨注意力机制进行局部对齐建模，保持RNN-T的流式特性

Result: 显著提升效率：训练内存峰值降低46.2%，训练速度提升1.36倍，推理速度提升1.69倍；准确率提升：语音识别相对WER降低6.3%，语音翻译BLEU提升18.0%

Conclusion: CHAT模型为部署更强大的流式语音模型提供了实用解决方案，在不牺牲实时性约束的情况下实现了效率和准确率的双重提升

Abstract: We propose Chunk-wise Attention Transducer (CHAT), a novel extension to RNN-T models that processes audio in fixed-size chunks while employing cross-attention within each chunk. This hybrid approach maintains RNN-T's streaming capability while introducing controlled flexibility for local alignment modeling. CHAT significantly reduces the temporal dimension that RNN-T must handle, yielding substantial efficiency improvements: up to 46.2% reduction in peak training memory, up to 1.36X faster training, and up to 1.69X faster inference. Alongside these efficiency gains, CHAT achieves consistent accuracy improvements over RNN-T across multiple languages and tasks -- up to 6.3% relative WER reduction for speech recognition and up to 18.0% BLEU improvement for speech translation. The method proves particularly effective for speech translation, where RNN-T's strict monotonic alignment hurts performance. Our results demonstrate that the CHAT model offers a practical solution for deploying more capable streaming speech models without sacrificing real-time constraints.

</details>


### [121] [Who Guards the Guardians? The Challenges of Evaluating Identifiability of Learned Representations](https://arxiv.org/abs/2602.24278)
*Shruti Joshi,Théo Saulus,Wieland Brendel,Philippe Brouillard,Dhanya Sridhar,Patrik Reizinger*

Main category: cs.LG

TL;DR: 现有表示学习可识别性评估方法存在局限性：标准指标仅在特定结构条件下有效反映理论保证的等价类恢复，当数据生成过程或编码器几何假设被违反时会产生误判。


<details>
  <summary>Details</summary>
Motivation: 当前表示学习可识别性评估依赖于标准指标（如MCC、DCI、R²）在已知真实因子的合成基准上进行，这些指标被假设能反映理论保证的等价类恢复。但研究发现这种假设仅在特定条件下成立，需要揭示指标的有效性边界。

Method: 提出一个分类法，将数据生成过程假设与编码器几何假设分离，用于刻画现有指标的有效域；发布一个评估套件用于可重复的压力测试和比较。

Result: 当数据生成过程或编码器几何假设被违反时，指标会变得错误指定，产生系统性假阳性和假阴性；这种失败既发生在经典可识别性机制内，也发生在最需要可识别性的后处理设置中。

Conclusion: 表示学习可识别性评估需要更谨慎的方法，标准指标仅在特定结构条件下有效；提出的分类法和评估套件有助于更可靠地评估表示学习方法的可识别性。

Abstract: Identifiability in representation learning is commonly evaluated using standard metrics (e.g., MCC, DCI, R^2) on synthetic benchmarks with known ground-truth factors. These metrics are assumed to reflect recovery up to the equivalence class guaranteed by identifiability theory. We show that this assumption holds only under specific structural conditions: each metric implicitly encodes assumptions about both the data-generating process (DGP) and the encoder. When these assumptions are violated, metrics become misspecified and can produce systematic false positives and false negatives. Such failures occur both within classical identifiability regimes and in post-hoc settings where identifiability is most needed. We introduce a taxonomy separating DGP assumptions from encoder geometry, use it to characterise the validity domains of existing metrics, and release an evaluation suite for reproducible stress testing and comparison.

</details>


### [122] [Taming Momentum: Rethinking Optimizer States Through Low-Rank Approximation](https://arxiv.org/abs/2602.24283)
*Zhengbo Wang,Jian Liang,Ran He,Zilei Wang,Tieniu Tan*

Main category: cs.LG

TL;DR: LoRA-Pre是一种新颖的低秩优化器，通过将动量矩阵分解为紧凑的低秩子空间，显著减少内存占用，在预训练和微调任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代优化器如Adam和Muon在训练大语言模型时依赖一阶和二阶动量，这带来了显著的内存开销，限制了模型的可扩展性和计算效率。

Method: 将指数移动平均重新定义为通过在线梯度流训练线性回归器，并基于此等价性引入LoRA-Pre。该方法将完整的动量矩阵分解为在线线性学习器中的紧凑低秩子空间。

Result: 在Llama架构家族的60M到1B参数模型上进行预训练，LoRA-Pre在所有模型规模上都取得了最高性能。在秩效率方面，仅使用基线方法1/8的秩就能达到相当或更优的结果。在微调场景中，LoRA-Pre始终优于所有高效微调基线，在Llama-3.1-8B上比标准LoRA提升3.14分，在Llama-2-7B上提升6.17分。

Conclusion: LoRA-Pre通过低秩分解有效减少了优化器的内存占用，同时保持了优化性能，在预训练和微调任务中都表现出色，为大规模语言模型训练提供了高效的内存优化解决方案。

Abstract: Modern optimizers like Adam and Muon are central to training large language models, but their reliance on first- and second-order momenta introduces significant memory overhead, which constrains scalability and computational efficiency. In this work, we reframe the exponential moving average (EMA) used in these momenta as the training of a linear regressor via online gradient flow. Building on this equivalence, we introduce LoRA-Pre, a novel low-rank optimizer designed for efficient pre-training. Specifically, LoRA-Pre reduces the optimizer's memory footprint by decomposing the full momentum matrix into a compact low-rank subspace within the online linear learner, thereby maintaining optimization performance while improving memory efficiency. We empirically validate LoRA-Pre's efficacy by pre-training models from the Llama architecture family, scaling from 60M to 1B parameters. LoRA-Pre achieves the highest performance across all model sizes. Notably, LoRA-Pre demonstrates remarkable rank efficiency, achieving comparable or superior results using only 1/8 the rank of baseline methods. Beyond pre-training, we evaluate LoRA-Pre's effectiveness in fine-tuning scenarios. With the same rank, LoRA-Pre consistently outperforms all efficient fine-tuning baselines. Specifically, compared to standard LoRA, LoRA-Pre achieves substantial improvements of 3.14 points on Llama-3.1-8B and 6.17 points on Llama-2-7B, validating our approach's effectiveness across both pre-training and fine-tuning paradigms. Our code is publicly available at https://github.com/mrflogs/LoRA-Pre.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [123] [HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance](https://arxiv.org/abs/2602.23367)
*Shubh Laddha,Lucas Changbencharoen,Win Kuptivej,Surya Shringla,Archana Vaidheeswaran,Yash Bhaskar*

Main category: cs.AI

TL;DR: 本文提出了首个大规模MCP数据集，包含针对2800个工具和308个MCP服务器的多样化高质量用户查询，解决了现有数据集缺乏真实用户查询模式的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MCP服务器数据集缺乏真实、人性化的用户查询，无法反映不同用户如何表达请求，导致评估工具使用和生态系统时存在关键差距，泛化能力差且基准测试可靠性被夸大。

Method: 基于MCP Zero数据集开发，为2800个工具和308个MCP服务器生成多样化高质量用户查询，每个工具配对多个独特用户角色，涵盖从精确任务请求到模糊探索性命令的不同用户意图层次。

Result: 创建了首个大规模MCP数据集，包含针对2800个工具和308个MCP服务器的多样化用户查询，能够捕捉真实世界交互模式的复杂性。

Conclusion: 该数据集填补了MCP服务器评估的关键空白，通过引入真实用户查询模式提高了工具使用和生态系统评估的准确性和泛化能力。

Abstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.

</details>


### [124] [Causal Identification from Counterfactual Data: Completeness and Bounding Results](https://arxiv.org/abs/2602.23541)
*Arvind Raghavan,Elias Bareinboim*

Main category: cs.AI

TL;DR: 论文提出了CTFIDU+算法，用于从任意Layer 3分布中识别反事实查询，证明了其完备性，并建立了从物理可实现分布中识别反事实的理论极限。


<details>
  <summary>Details</summary>
Motivation: 先前关于反事实识别完备性的研究局限于观测或干预分布（Pearl因果层次结构的Layer 1和2），因为一般认为无法获得Layer 3的反事实分布数据。然而，最近的研究表明某些反事实分布可以通过实验方法直接估计（反事实可实现性），这引发了新的问题：在能够访问部分Layer 3数据的情况下，哪些额外的反事实量变得可识别？

Method: 开发了CTFIDU+算法，用于从任意Layer 3分布集合中识别反事实查询。该算法建立在反事实可实现性的基础上，能够处理物理可实现的分布数据。

Result: 证明了CTFIDU+算法对于从Layer 3分布识别反事实查询是完备的。建立了从物理可实现分布中识别反事实的理论极限，这暗示了非参数设置中精确因果推断的基本极限。对于某些不可识别的关键反事实类型，推导了使用可实现反事实数据的新分析界限。

Conclusion: 该研究填补了反事实识别理论的重要空白，明确了在能够访问部分Layer 3数据的情况下反事实识别的可能性边界。通过模拟验证，反事实数据在实践中确实有助于收紧不可识别量的界限，为因果推断提供了新的理论工具和实践指导。

Abstract: Previous work establishing completeness results for $\textit{counterfactual identification}$ has been circumscribed to the setting where the input data belongs to observational or interventional distributions (Layers 1 and 2 of Pearl's Causal Hierarchy), since it was generally presumed impossible to obtain data from counterfactual distributions, which belong to Layer 3. However, recent work (Raghavan & Bareinboim, 2025) has formally characterized a family of counterfactual distributions which can be directly estimated via experimental methods - a notion they call $\textit{counterfactual realizabilty}$. This leaves open the question of what $\textit{additional}$ counterfactual quantities now become identifiable, given this new access to (some) Layer 3 data. To answer this question, we develop the CTFIDU+ algorithm for identifying counterfactual queries from an arbitrary set of Layer 3 distributions, and prove that it is complete for this task. Building on this, we establish the theoretical limit of which counterfactuals can be identified from physically realizable distributions, thus implying the $\textit{fundamental limit to exact causal inference in the non-parametric setting}$. Finally, given the impossibility of identifying certain critical types of counterfactuals, we derive novel analytic bounds for such quantities using realizable counterfactual data, and corroborate using simulations that counterfactual data helps tighten the bounds for non-identifiable quantities in practice.

</details>


### [125] [Planning under Distribution Shifts with Causal POMDPs](https://arxiv.org/abs/2602.23545)
*Matteo Ceriscioli,Karthika Mohan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于因果知识的POMDP理论框架，用于处理分布偏移下的规划问题，通过将环境变化表示为对因果POMDP的干预，能够评估假设变化下的规划策略并识别环境变化组件。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的规划常常面临分布偏移的挑战，在一种条件下获得的环境模型在状态分布或环境动态变化时可能失效，导致先前学习的策略失败。需要一种能够处理分布变化的理论框架。

Method: 使用基于因果知识的部分可观测马尔可夫决策过程（POMDP）框架，将环境变化表示为对因果POMDP的干预，维护和更新关于潜在状态和底层领域的信念，并证明价值函数在增强信念空间中保持分段线性凸性。

Result: 证明了价值函数在增强信念空间中保持分段线性凸性（PWLC），这使得基于α向量的POMDP方法在分布偏移下仍然保持可处理性，为规划提供了理论保证。

Conclusion: 提出的因果POMDP框架为处理分布偏移下的规划问题提供了理论基础，通过将环境变化建模为干预，能够评估规划策略在不同分布下的表现，并保持规划的可处理性。

Abstract: In the real world, planning is often challenged by distribution shifts. As such, a model of the environment obtained under one set of conditions may no longer remain valid as the distribution of states or the environment dynamics change, which in turn causes previously learned strategies to fail. In this work, we propose a theoretical framework for planning under partial observability using Partially Observable Markov Decision Processes (POMDPs) formulated using causal knowledge. By representing shifts in the environment as interventions on this causal POMDP, the framework enables evaluating plans under hypothesized changes and actively identifying which components of the environment have been altered. We show how to maintain and update a belief over both the latent state and the underlying domain, and we prove that the value function remains piecewise linear and convex (PWLC) in this augmented belief space. Preservation of PWLC under distribution shifts has the advantage of maintaining the tractability of planning via $α$-vector-based POMDP methods.

</details>


### [126] [Construct, Merge, Solve & Adapt with Reinforcement Learning for the min-max Multiple Traveling Salesman Problem](https://arxiv.org/abs/2602.23579)
*Guillem Rodríguez-Corominas,Maria J. Blesa,Christian Blum*

Main category: cs.AI

TL;DR: 提出RL-CMSA方法解决对称单仓库最小最大mTSP问题，结合强化学习引导的聚类构造、精确优化和局部搜索，在平衡工作负载方面优于现有混合遗传算法。


<details>
  <summary>Details</summary>
Motivation: 解决最小最大mTSP问题，目标是平衡多个销售员的工作负载，最小化最长路径。传统方法在探索和利用之间难以平衡，需要结合精确优化和启发式方法。

Method: 提出RL-CMSA方法：1) 使用强化学习学习的q值指导概率聚类构造多样化解；2) 合并路径形成紧凑池；3) 求解受限集合覆盖MILP；4) 通过移除、移位和交换等局部搜索改进解；5) 根据高质量解更新q值，并通过老化修剪机制调整池。

Result: 在随机和TSPLIB实例上的计算结果表明，RL-CMSA能持续找到（接近）最优解，在可比时间限制下优于最先进的混合遗传算法，尤其在实例规模和销售员数量增加时表现更优。

Conclusion: RL-CMSA通过结合精确优化和强化学习引导的构造，有效平衡了探索和利用，为对称单仓库最小最大mTSP问题提供了高效解决方案，在平衡工作负载方面具有优越性能。

Abstract: The Multiple Traveling Salesman Problem (mTSP) extends the Traveling Salesman Problem to m tours that start and end at a common depot and jointly visit all customers exactly once. In the min-max variant, the objective is to minimize the longest tour, reflecting workload balance. We propose a hybrid approach, Construct, Merge, Solve & Adapt with Reinforcement Learning (RL-CMSA), for the symmetric single-depot min-max mTSP. The method iteratively constructs diverse solutions using probabilistic clustering guided by learned pairwise q-values, merges routes into a compact pool, solves a restricted set-covering MILP, and refines solutions via inter-route remove, shift, and swap moves. The q-values are updated by reinforcing city-pair co-occurrences in high-quality solutions, while the pool is adapted through ageing and pruning. This combination of exact optimization and reinforcement-guided construction balances exploration and exploitation. Computational results on random and TSPLIB instances show that RL-CMSA consistently finds (near-)best solutions and outperforms a state-of-the-art hybrid genetic algorithm under comparable time limits, especially as instance size and the number of salesmen increase.

</details>


### [127] [SleepLM: Natural-Language Intelligence for Human Sleep](https://arxiv.org/abs/2602.23605)
*Zongzhe Xu,Zitao Shuai,Eideen Mozaffari,Ravi S. Aysola,Rajesh Kumar,Yuzhe Yang*

Main category: cs.AI

TL;DR: SleepLM是一个睡眠-语言基础模型，通过自然语言与多模态睡眠生理数据对齐，实现睡眠分析、解释和交互，在零样本和少样本学习等任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于学习的睡眠分析系统存在局限性：它们工作在封闭的标签空间（如预定义的睡眠阶段或事件），无法描述、查询或泛化到新的睡眠现象。这限制了睡眠分析的灵活性和实用性。

Method: 1. 提出多级睡眠描述生成流程，创建首个大规模睡眠-文本数据集（超过10万小时数据，来自1万多名个体）；2. 设计统一的预训练目标，结合对比对齐、描述生成和信号重建，以更好地捕捉生理保真度和跨模态交互。

Result: 在真实世界的睡眠理解任务中，SleepLM在零样本学习、少样本学习、跨模态检索和睡眠描述生成方面优于现有最先进方法。模型还展现出语言引导的事件定位、针对性洞察生成和零样本泛化到未见任务的能力。

Conclusion: SleepLM成功建立了自然语言与多模态睡眠生理数据之间的桥梁，为睡眠分析提供了更灵活、可解释和交互式的方法。所有代码和数据将开源，促进睡眠研究领域的发展。

Abstract: We present SleepLM, a family of sleep-language foundation models that enable human sleep alignment, interpretation, and interaction with natural language. Despite the critical role of sleep, learning-based sleep analysis systems operate in closed label spaces (e.g., predefined stages or events) and fail to describe, query, or generalize to novel sleep phenomena. SleepLM bridges natural language and multimodal polysomnography, enabling language-grounded representations of sleep physiology. To support this alignment, we introduce a multilevel sleep caption generation pipeline that enables the curation of the first large-scale sleep-text dataset, comprising over 100K hours of data from more than 10,000 individuals. Furthermore, we present a unified pretraining objective that combines contrastive alignment, caption generation, and signal reconstruction to better capture physiological fidelity and cross-modal interactions. Extensive experiments on real-world sleep understanding tasks verify that SleepLM outperforms state-of-the-art in zero-shot and few-shot learning, cross-modal retrieval, and sleep captioning. Importantly, SleepLM also exhibits intriguing capabilities including language-guided event localization, targeted insight generation, and zero-shot generalization to unseen tasks. All code and data will be open-sourced.

</details>


### [128] [MMKG-RDS: Reasoning Data Synthesis via Deep Mining of Multimodal Knowledge Graphs](https://arxiv.org/abs/2602.23632)
*Lun Zhan,Feng Xiong,Huanyong Liu,Feng Zhang,Yuhui Yin*

Main category: cs.AI

TL;DR: MMKG-RDS是一个基于多模态知识图谱的推理数据合成框架，通过细粒度知识提取、可定制路径采样和多维数据质量评分，生成高质量训练数据提升领域模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长尾知识覆盖、有效性验证和可解释性方面存在局限，知识图谱方法在功能性、粒度、可定制性和评估方面仍有不足，需要更灵活的推理数据合成框架。

Method: 提出MMKG-RDS框架，利用多模态知识图谱支持细粒度知识提取、可定制路径采样和多维数据质量评分，并构建MMKG-RDS-Bench数据集进行验证。

Result: 在MMKG-RDS-Bench数据集（5个领域、17种任务类型、14,950个样本）上验证，使用少量合成样本微调Qwen3模型（0.6B/8B/32B）可将推理准确率提升9.2%。

Conclusion: MMKG-RDS能有效合成高质量推理训练数据，提升模型推理能力，生成具有挑战性的表格和公式任务数据，可用于复杂基准构建，框架和数据集已开源。

Abstract: Synthesizing high-quality training data is crucial for enhancing domain models' reasoning abilities. Existing methods face limitations in long-tail knowledge coverage, effectiveness verification, and interpretability. Knowledge-graph-based approaches still fall short in functionality, granularity, customizability, and evaluation. To address these issues, we propose MMKG-RDS, a flexible framework for reasoning data synthesis that leverages multimodal knowledge graphs. It supports fine-grained knowledge extraction, customizable path sampling, and multidimensional data quality scoring. We validate MMKG-RDS with the MMKG-RDS-Bench dataset, covering five domains, 17 task types, and 14,950 samples. Experimental results show fine-tuning Qwen3 models (0.6B/8B/32B) on a small number of synthesized samples improves reasoning accuracy by 9.2%. The framework also generates distinct data, challenging existing models on tasks involving tables and formulas, useful for complex benchmark construction. The dataset and code are available at https://github.com/360AILAB-NLP/MMKG-RDS

</details>


### [129] [AI Must Embrace Specialization via Superhuman Adaptable Intelligence](https://arxiv.org/abs/2602.23643)
*Judah Goldfeder,Philippe Wyder,Yann LeCun,Ravid Shwartz Ziv*

Main category: cs.AI

TL;DR: 该论文批判了当前对通用人工智能（AGI）的定义，认为人类本身并非"通用"，提出应放弃追求通用性，转而专注于发展"超人适应智能（SAI）"——能够在重要任务上超越人类并填补人类能力空白的专业化智能。


<details>
  <summary>Details</summary>
Motivation: 当前AI领域对AGI的定义存在混乱和矛盾，不同群体对AGI的理解不一致。作者认为人类本身并非"通用"智能体，因此以"像人类一样能做所有事情"作为AGI定义存在根本缺陷。需要重新思考AI发展的方向和目标。

Method: 通过分析当前AGI定义的问题，论证人类智能的局限性，提出SAI概念作为替代框架。SAI强调专业化而非通用性，追求在特定重要任务上超越人类能力，并填补人类能力空白。

Result: 提出了SAI作为更清晰、更实用的AI发展框架，能够帮助澄清被AGI模糊定义所混淆的讨论，为AI未来发展提供更有指导意义的路径。

Conclusion: AI发展不应追求通用性，而应专注于专业化，发展能够在重要领域超越人类并填补人类能力空白的超人适应智能。SAI概念为AI讨论提供了更清晰的框架，对指导未来AI发展具有重要意义。

Abstract: Everyone from AI executives and researchers to doomsayers, politicians, and activists is talking about Artificial General Intelligence (AGI). Yet, they often don't seem to agree on its exact definition. One common definition of AGI is an AI that can do everything a human can do, but are humans truly general? In this paper, we address what's wrong with our conception of AGI, and why, even in its most coherent formulation, it is a flawed concept to describe the future of AI. We explore whether the most widely accepted definitions are plausible, useful, and truly general. We argue that AI must embrace specialization, rather than strive for generality, and in its specialization strive for superhuman performance, and introduce Superhuman Adaptable Intelligence (SAI). SAI is defined as intelligence that can learn to exceed humans at anything important that we can do, and that can fill in the skill gaps where humans are incapable. We then lay out how SAI can help hone a discussion around AI that was blurred by an overloaded definition of AGI, and extrapolate the implications of using it as a guide for the future.

</details>


### [130] [PseudoAct: Leveraging Pseudocode Synthesis for Flexible Planning and Action Control in Large Language Model Agents](https://arxiv.org/abs/2602.23668)
*Yihan,Wen,Xin Chen*

Main category: cs.AI

TL;DR: PseudoAct是一个通过伪代码合成实现灵活规划和行动控制的LLM智能体框架，相比传统反应式决策方法，在复杂长时任务中显著提升效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 传统LLM智能体（如ReAct）依赖反应式决策，在复杂长时任务中面临工具使用冗余、推理不稳定、token消耗高等问题，需要更结构化的规划和控制方法。

Method: 提出PseudoAct框架，利用LLM将任务解决策略表达为代码的能力，合成结构化伪代码计划，将任务分解为子任务并显式编码控制流（序列、条件、循环、并行组合等），然后按全局计划执行行动。

Result: 在基准数据集上显著优于现有反应式智能体方法，在FEVER上实现20.93%的绝对成功率提升，在HotpotQA上达到新的最先进水平。

Conclusion: PseudoAct通过伪代码合成实现显式、时间一致的决策逻辑，减少冗余行动、防止无限循环、避免无信息替代探索，为LLM智能体提供一致高效的长时决策能力。

Abstract: Large language model (LLM) agents typically rely on reactive decision-making paradigms such as ReAct, selecting actions conditioned on growing execution histories. While effective for short tasks, these approaches often lead to redundant tool usage, unstable reasoning, and high token consumption in complex long-horizon tasks involving branching, iteration, or multi-tool coordination. To address these limitations, this paper introduces PseudoAct, a novel framework for flexible planning and action control in LLM agents through pseudocode synthesis. Leveraging the ability of LLMs to express task-solving strategies as code, PseudoAct synthesizes a structured pseudocode plan that decomposes a task into subtasks and explicitly encodes control flow, including sequencing, conditionals, loops, parallel composition, and combinations of these logic primitives. Actions are then executed by following this global plan, making the decision logic explicit and temporally coherent. This design reduces redundant actions, prevents infinite loops, and avoids uninformative alternative exploration, enabling consistent and efficient long-horizon decision-making. Experiments on benchmark datasets show that our method significantly outperforms existing reactive agent approaches, achieving a 20.93% absolute gain in success rate on FEVER and setting a new state-of-the-art on HotpotQA.

</details>


### [131] [From Flat Logs to Causal Graphs: Hierarchical Failure Attribution for LLM-based Multi-Agent Systems](https://arxiv.org/abs/2602.23701)
*Yawen Wang,Wenjie Wu,Junjie Wang,Qing Wang*

Main category: cs.AI

TL;DR: CHIEF框架通过层次因果图将多智能体系统轨迹结构化，使用层次化回溯和虚拟预言机剪枝搜索空间，通过渐进因果筛选实现反事实归因，显著提升故障定位准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的多智能体系统存在脆弱性和故障机制不透明问题，传统方法将执行日志视为扁平序列，无法解耦复杂的因果联系，导致弱可观测性和责任边界模糊。

Method: 1) 将混沌轨迹转换为结构化层次因果图；2) 使用层次化预言机引导回溯，通过合成虚拟预言机高效剪枝搜索空间；3) 采用渐进因果筛选策略实现反事实归因，区分真正根因与传播症状。

Result: 在Who&When基准测试中，CHIEF在智能体级和步骤级准确性上均优于八个强基线方法。消融研究进一步证实了每个提出模块的关键作用。

Conclusion: CHIEF通过结构化层次因果分析和反事实归因方法，显著提升了多智能体系统的故障定位能力，为解决MAS的脆弱性和不透明性提供了有效框架。

Abstract: LLM-powered Multi-Agent Systems (MAS) have demonstrated remarkable capabilities in complex domains but suffer from inherent fragility and opaque failure mechanisms. Existing failure attribution methods, whether relying on direct prompting, costly replays, or supervised fine-tuning, typically treat execution logs as flat sequences. This linear perspective fails to disentangle the intricate causal links inherent to MAS, leading to weak observability and ambiguous responsibility boundaries. To address these challenges, we propose CHIEF, a novel framework that transforms chaotic trajectories into a structured hierarchical causal graph. It then employs hierarchical oracle-guided backtracking to efficiently prune the search space via sybthesized virtual oracles. Finally, it implements counterfactual attribution via a progressive causal screening strategy to rigorously distinguish true root causes from propagated symptoms. Experiments on Who&When benchmark show that CHIEF outperforms eight strong and state-of-the-art baselines on both agent- and step-level accuracy. Ablation studies further confirm the critical role of each proposed module.

</details>


### [132] [ProductResearch: Training E-Commerce Deep Research Agents via Multi-Agent Synthetic Trajectory Distillation](https://arxiv.org/abs/2602.23716)
*Jiangyuan Wang,Kejun Xiao,Huaipeng Zhao,Tao Luo,Xiaoyi Zeng*

Main category: cs.AI

TL;DR: 提出ProductResearch多智能体框架，通过合成高质量工具使用轨迹来训练电商购物智能体，显著提升响应全面性、研究深度和用户感知效用


<details>
  <summary>Details</summary>
Motivation: 现有LLM智能体在电商对话购物中缺乏交互深度和上下文广度，而深度研究范式在迁移到电商领域时存在领域差距，需要更好的训练方法

Method: 采用多智能体框架：用户智能体从行为历史推断购物意图，监督智能体协调研究智能体迭代协作生成合成轨迹，通过反思内化过程将多智能体交互整合为单角色训练样本

Result: 在合成数据上微调的紧凑MoE模型在响应全面性、研究深度和用户感知效用方面显著优于基础模型，接近前沿专有深度研究系统性能

Conclusion: 多智能体合成轨迹训练是增强基于LLM的购物辅助的有效且可扩展范式，能够训练出处理复杂购物查询的鲁棒电商智能体

Abstract: Large Language Model (LLM)-based agents show promise for e-commerce conversational shopping, yet existing implementations lack the interaction depth and contextual breadth required for complex product research. Meanwhile, the Deep Research paradigm, despite advancing information synthesis in web search, suffers from domain gaps when transferred to e-commerce. We propose ProductResearch, a multi-agent framework that synthesizes high-fidelity, long-horizon tool-use trajectories for training robust e-commerce shopping agents. The framework employs a User Agent to infer nuanced shopping intents from behavioral histories, and a Supervisor Agent that orchestrates iterative collaboration with a Research Agent to generate synthetic trajectories culminating in comprehensive, insightful product research reports. These trajectories are rigorously filtered and distilled through a reflective internalization process that consolidates multi-agent supervisory interactions into coherent single-role training examples, enabling effective fine-tuning of LLM agents for complex shopping inquiries. Extensive experiments show that a compact MoE model fine-tuned on our synthetic data achieves substantial improvements over its base model in response comprehensiveness, research depth, and user-perceived utility, approaching the performance of frontier proprietary deep research systems and establishing multi-agent synthetic trajectory training as an effective and scalable paradigm for enhancing LLM-based shopping assistance.

</details>


### [133] [Unlocking Cognitive Capabilities and Analyzing the Perception-Logic Trade-off](https://arxiv.org/abs/2602.23730)
*Longyin Zhang,Shuo Sun,Yingxu He,Won Cheng Yi Lewis,Muhammad Huzaifah Bin Md Shahrin,Hardik Bhupendra Sailor,Heng Meng Jeremy Wong,Tarun Kumar Vangani,Yi Ma,Qiongqiong Wang,Minh Duc Pham,Ridong Jiang,Jingtao Li,Jingyi Liao,Zhuohan Liu,Yanfeng Lu,Manas Gupta,Ai Ti Aw*

Main category: cs.AI

TL;DR: MERaLiON2-Omni (Alpha) 是一个针对东南亚地区的10B参数多语言全感知MLLM，通过分离和整合"系统1"(感知)与"系统2"(推理)能力，在区域特定多模态任务上取得进展，但发现推理能力会引入感知不稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型追求全感知能力，但将稳健的感官基础与复杂推理相结合仍然具有挑战性，特别是在代表性不足的地区如东南亚。需要开发能够理解当地语言、文化和环境的区域定制化模型。

Method: 采用渐进式训练流程：1) 建立稳健的感知骨干，通过正交模态适应将区域特定的视听线索与多语言LLM对齐；2) 提出成本效益高的生成-判断-精炼流程，利用超级LLM过滤幻觉并通过共识机制解决冲突，合成高质量银数据，将文本链式思维推理转移到多模态场景。

Result: 在SEA-Omni基准测试套件上评估发现效率-稳定性悖论：推理能力对抽象任务（如数学和指令遵循）有显著提升作用，但在低级感官处理中引入不稳定性，具体表现为长上下文音频中的时间漂移和视觉过度解释问题。

Conclusion: 该研究展示了区域定制化MLLM的架构设计和数据高效训练方法，同时诊断分析了稳健感知与结构化推理之间的权衡关系，为未来多模态AI系统设计提供了重要见解。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) pursue omni-perception capabilities, yet integrating robust sensory grounding with complex reasoning remains a challenge, particularly for underrepresented regions. In this report, we introduce the research preview of MERaLiON2-Omni (Alpha), a 10B-parameter multilingual omni-perception tailored for Southeast Asia (SEA). We present a progressive training pipeline that explicitly decouples and then integrates "System 1" (Perception) and "System 2" (Reasoning) capabilities. First, we establish a robust Perception Backbone by aligning region-specific audio-visual cues (e.g., Singlish code-switching, local cultural landmarks) with a multilingual LLM through orthogonal modality adaptation. Second, to inject cognitive capabilities without large-scale supervision, we propose a cost-effective Generate-Judge-Refine pipeline. By utilizing a Super-LLM to filter hallucinations and resolve conflicts via a consensus mechanism, we synthesize high-quality silver data that transfers textual Chain-of-Thought reasoning to multimodal scenarios.
  Comprehensive evaluation on our newly introduced SEA-Omni Benchmark Suite reveals an Efficiency-Stability Paradox: while reasoning acts as a non-linear amplifier for abstract tasks (boosting mathematical and instruction-following performance significantly), it introduces instability in low-level sensory processing. Specifically, we identify Temporal Drift in long-context audio, where extended reasoning desynchronizes the model from acoustic timestamps, and Visual Over-interpretation, where logic overrides pixel-level reality. This report details the architecture, the data-efficient training recipe, and a diagnostic analysis of the trade-offs between robust perception and structured reasoning.

</details>


### [134] [Reasoning-Driven Multimodal LLM for Domain Generalization](https://arxiv.org/abs/2602.23777)
*Zhipeng Xu,Zilong Wang,Xinyang Jiang,Dongsheng Li,De Cheng,Nannan Wang*

Main category: cs.AI

TL;DR: 该论文提出RD-MLDG框架，利用多模态大语言模型的推理能力解决领域泛化问题，通过推理链构建和自对齐正则化提升模型在未见领域的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化方法主要关注视觉特征不变性，但忽略了多模态大语言模型的推理能力。论文探索通过构建推理链来推导图像类别，以实现领域偏移下更鲁棒的预测。

Method: 提出RD-MLDG框架，包含两个核心组件：1) MTCT（多任务交叉训练），引入直接分类路径来指导推理监督；2) SARR（自对齐推理正则化），通过迭代自标注保持推理链的语义丰富性，同时缓解推理模式不匹配问题。

Result: 在标准DomainBed数据集（PACS、VLCS、OfficeHome、TerraInc）上的实验表明，RD-MLDG达到了最先进的性能，验证了推理作为鲁棒领域外泛化的有前景的补充信号。

Conclusion: 推理是提升领域泛化性能的有效补充信号，RD-MLDG框架通过解决推理链优化挑战和推理模式不匹配问题，实现了在未见领域上的鲁棒泛化。

Abstract: This paper addresses the domain generalization (DG) problem in deep learning. While most DG methods focus on enforcing visual feature invariance, we leverage the reasoning capability of multimodal large language models (MLLMs) and explore the potential of constructing reasoning chains that derives image categories to achieve more robust predictions under domain shift. To this end, we systematically study the role of reasoning in DG using DomainBed-Reasoning, a newly constructed extension of DomainBed dataset, in which each sample is paired with class-relevant reasoning chains. Our analysis reveals two key challenges: (i) fine-tuning MLLMs with reasoning chains for classification is more challenging than direct label supervision, since the model must optimize complex reasoning sequences before label prediction; and (ii) mismatches in reasoning patterns between supervision signals and fine-tuned MLLMs lead to a trade-off between semantic richness (informative but harder to optimize) and optimization efficiency (easier to optimize but less informative). To address these issues, we propose RD-MLDG (Reasoning-Driven Multimodal LLM for Domain Generalization), a framework with two components: (i) MTCT (Multi-Task Cross-Training), which introduces an additional direct classification pathway to guide reasoning supervision; and (ii) SARR (Self-Aligned Reasoning Regularization), which preserves the semantic richness of reasoning chains while mitigating reasoning-pattern mismatches via iterative self-labeling. Experiments on standard DomainBed datasets (PACS, VLCS, OfficeHome, TerraInc) demonstrate that RD-MLDG achieves state-of-the-art performances, highlighting reasoning as a promising complementary signal for robust out-of-domain generalization.

</details>


### [135] [EMO-R3: Reflective Reinforcement Learning for Emotional Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2602.23802)
*Yiyang Fang,Wenke Huang,Pei Fu,Yihao Yang,Kehua Su,Zhenbo Luo,Jian Luan,Mang Ye*

Main category: cs.AI

TL;DR: 提出EMO-R3框架，通过结构化情感思维和反思情感奖励机制，增强多模态大语言模型的情感推理能力


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉推理方面有显著进展，但在捕捉人类情感的复杂性和主观性方面仍有困难。现有监督微调方法泛化能力有限且可解释性差，而强化学习方法如GRPO未能与情感认知的内在特性对齐。

Method: 提出EMO-R3框架，包含两个核心组件：1) 结构化情感思维，引导模型以结构化、可解释的方式进行逐步情感推理；2) 反思情感奖励，使模型能够基于视觉-文本一致性和情感连贯性重新评估其推理过程。

Result: 大量实验表明，EMO-R3显著提升了多模态大语言模型的可解释性和情感智能，在多个视觉情感理解基准测试中取得了优越性能。

Conclusion: EMO-R3框架有效解决了多模态大语言模型在情感推理方面的局限性，通过结构化推理和反思机制提升了模型的情感理解能力和可解释性。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable progress in visual reasoning and understanding tasks but still struggle to capture the complexity and subjectivity of human emotions. Existing approaches based on supervised fine-tuning often suffer from limited generalization and poor interpretability, while reinforcement learning methods such as Group Relative Policy Optimization fail to align with the intrinsic characteristics of emotional cognition. To address these challenges, we propose Reflective Reinforcement Learning for Emotional Reasoning (EMO-R3), a framework designed to enhance the emotional reasoning ability of MLLMs. Specifically, we introduce Structured Emotional Thinking to guide the model to perform step-by-step emotional reasoning in a structured and interpretable manner, and design a Reflective Emotional Reward that enables the model to re-evaluate its reasoning based on visual-text consistency and emotional coherence. Extensive experiments demonstrate that EMO-R3 significantly improves both the interpretability and emotional intelligence of MLLMs, achieving superior performance across multiple visual emotional understanding benchmarks.

</details>


### [136] [RF-Agent: Automated Reward Function Design via Language Agent Tree Search](https://arxiv.org/abs/2602.23876)
*Ning Gao,Xiuhui Zhang,Xingyu Jiang,Mukang You,Mohan Zhang,Yue Deng*

Main category: cs.AI

TL;DR: RF-Agent：一个将LLM作为语言智能体、将奖励函数设计建模为序列决策过程的框架，通过蒙特卡洛树搜索提升复杂控制任务中的奖励函数优化效率


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的奖励函数生成方法存在历史反馈利用不足和搜索效率低的问题，在复杂控制任务中改进有限，需要更有效的优化框架

Method: 将LLM视为语言智能体，将奖励函数设计建模为序列决策过程，集成蒙特卡洛树搜索来管理奖励设计和优化过程，利用LLM的多阶段上下文推理能力

Result: 在17个多样化的低层控制任务中取得了出色的实验结果，证明了方法的有效性

Conclusion: RF-Agent框架通过更好的上下文推理和历史信息利用，显著提升了复杂控制任务中奖励函数设计的效率和效果

Abstract: Designing efficient reward functions for low-level control tasks is a challenging problem. Recent research aims to reduce reliance on expert experience by using Large Language Models (LLMs) with task information to generate dense reward functions. These methods typically rely on training results as feedback, iteratively generating new reward functions with greedy or evolutionary algorithms. However, they suffer from poor utilization of historical feedback and inefficient search, resulting in limited improvements in complex control tasks. To address this challenge, we propose RF-Agent, a framework that treats LLMs as language agents and frames reward function design as a sequential decision-making process, enhancing optimization through better contextual reasoning. RF-Agent integrates Monte Carlo Tree Search (MCTS) to manage the reward design and optimization process, leveraging the multi-stage contextual reasoning ability of LLMs. This approach better utilizes historical information and improves search efficiency to identify promising reward functions. Outstanding experimental results in 17 diverse low-level control tasks demonstrate the effectiveness of our method. The source code is available at https://github.com/deng-ai-lab/RF-Agent.

</details>


### [137] [Pessimistic Auxiliary Policy for Offline Reinforcement Learning](https://arxiv.org/abs/2602.23974)
*Fan Zhang,Baoru Huang,Xin Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一种悲观辅助策略，通过最大化Q函数的下置信界来采样可靠动作，以缓解离线强化学习中分布外动作带来的近似误差累积问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习从预收集的数据集中学习智能体，避免了实时交互的不安全和低效。然而，在学习过程中不可避免地访问分布外动作会引入近似误差，导致误差累积和严重的高估问题。

Method: 构建了一个新的悲观辅助策略来采样可靠动作。具体来说，通过最大化Q函数的下置信界来开发悲观辅助策略。该策略在学习策略附近表现出相对较高的价值和较低的不确定性，避免了学习过程采样具有潜在高误差的高价值动作。

Result: 悲观辅助策略引入的近似误差较少，从而缓解了误差累积问题。在离线强化学习基准测试上的大量实验表明，利用悲观辅助策略可以有效提高其他离线RL方法的效能。

Conclusion: 提出的悲观辅助策略通过采样可靠动作来减少近似误差，有效改善了离线强化学习中的误差累积问题，提升了现有方法的性能。

Abstract: Offline reinforcement learning aims to learn an agent from pre-collected datasets, avoiding unsafe and inefficient real-time interaction. However, inevitable access to out-ofdistribution actions during the learning process introduces approximation errors, causing the error accumulation and considerable overestimation. In this paper, we construct a new pessimistic auxiliary policy for sampling reliable actions. Specifically, we develop a pessimistic auxiliary strategy by maximizing the lower confidence bound of the Q-function. The pessimistic auxiliary strategy exhibits a relatively high value and low uncertainty in the vicinity of the learned policy, avoiding the learned policy sampling high-value actions with potentially high errors during the learning process. Less approximation error introduced by sampled action from pessimistic auxiliary strategy leads to the alleviation of error accumulation. Extensive experiments on offline reinforcement learning benchmarks reveal that utilizing the pessimistic auxiliary strategy can effectively improve the efficacy of other offline RL approaches.

</details>


### [138] [Portfolio Reinforcement Learning with Scenario-Context Rollout](https://arxiv.org/abs/2602.24037)
*Vanya Priscillia Bendatu,Yao Lu*

Main category: cs.AI

TL;DR: 该论文提出了一种针对市场制度转换的宏观条件场景上下文展开方法，通过生成压力事件下的多变量回报场景来改进投资组合再平衡策略，解决了传统强化学习中的奖励-转移不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 市场制度转换会导致分布偏移，从而降低投资组合再平衡策略的性能。历史数据无法告诉我们如果发生不同情况会怎样，这给强化学习带来了奖励-转移不匹配的挑战。

Method: 提出宏观条件场景上下文展开方法，生成压力事件下的多变量回报场景。通过分析奖励-转移不匹配问题，构建反事实的下一状态，并使用展开隐含的连续性来增强评论家智能体的引导目标。

Result: 在31个不同的美国股票和ETF投资组合宇宙中进行样本外评估，相比经典和基于强化学习的投资组合再平衡基准，夏普比率提高了76%，最大回撤降低了53%。

Conclusion: 该方法通过解决强化学习中的奖励-转移不匹配问题，稳定了学习过程，提供了可行的偏差-方差权衡，显著提高了投资组合再平衡策略的性能。

Abstract: Market regime shifts induce distribution shifts that can degrade the performance of portfolio rebalancing policies. We propose macro-conditioned scenario-context rollout (SCR) that generates plausible next-day multivariate return scenarios under stress events. However, doing so faces new challenges, as history will never tell what would have happened differently. As a result, incorporating scenario-based rewards from rollouts introduces a reward--transition mismatch in temporal-difference learning, destabilizing RL critic training.
  We analyze this inconsistency and show it leads to a mixed evaluation target. Guided by this analysis, we construct a counterfactual next state using the rollout-implied continuations and augment the critic agent's bootstrap target. Doing so stabilizes the learning and provides a viable bias-variance tradeoff.
  In out-of-sample evaluations across 31 distinct universes of U.S. equity and ETF portfolios, our method improves Sharpe ratio by up to 76% and reduces maximum drawdown by up to 53% compared with classic and RL-based portfolio rebalancing baselines.

</details>


### [139] [CIRCLE: A Framework for Evaluating AI from a Real-World Lens](https://arxiv.org/abs/2602.24055)
*Reva Schwartz,Carina Westling,Morgan Briggs,Marzieh Fadaee,Isar Nejadgholi,Matthew Holmes,Fariza Rashid,Maya Carlyle,Afaf Taïk,Kyra Wilson,Peter Douglas,Theodora Skeadas,Gabriella Waters,Rumman Chowdhury,Thiago Lacerda*

Main category: cs.AI

TL;DR: CIRCLE是一个六阶段、基于生命周期的框架，旨在弥合模型中心性能指标与AI在部署中实际成果之间的现实差距，通过将利益相关者关注转化为可测量信号来操作TEVV中的验证阶段。


<details>
  <summary>Details</summary>
Motivation: 现有框架如MLOps关注系统稳定性，基准测试衡量抽象能力，但AI技术栈外的决策者缺乏关于AI在真实世界用户变异性和约束下行为的系统性证据。

Method: CIRCLE框架包含六个阶段，将上下文敏感的定性洞察与可扩展的定量指标联系起来，整合现场测试、红队测试和纵向研究等方法，形成协调的管道。

Result: CIRCLE产生系统性知识：可在不同站点间比较但对本地上下文敏感的证据，使治理能够基于实际下游效应而非理论能力。

Conclusion: CIRCLE提供了一个结构化、前瞻性的协议，用于连接定性洞察和定量指标，弥合AI性能指标与实际部署成果之间的现实差距，支持基于实际效果的治理。

Abstract: This paper proposes CIRCLE, a six-stage, lifecycle-based framework to bridge the reality gap between model-centric performance metrics and AI's materialized outcomes in deployment. While existing frameworks like MLOps focus on system stability and benchmarks measure abstract capabilities, decision-makers outside the AI stack lack systematic evidence about the behavior of AI technologies under real-world user variability and constraints. CIRCLE operationalizes the Validation phase of TEVV (Test, Evaluation, Verification, and Validation) by formalizing the translation of stakeholder concerns outside the stack into measurable signals. Unlike participatory design, which often remains localized, or algorithmic audits, which are often retrospective, CIRCLE provides a structured, prospective protocol for linking context-sensitive qualitative insights to scalable quantitative metrics. By integrating methods such as field testing, red teaming, and longitudinal studies into a coordinated pipeline, CIRCLE produces systematic knowledge: evidence that is comparable across sites yet sensitive to local context. This can enable governance based on materialized downstream effects rather than theoretical capabilities.

</details>


### [140] [Human or Machine? A Preliminary Turing Test for Speech-to-Speech Interaction](https://arxiv.org/abs/2602.24080)
*Xiang Li,Jiabao Gao,Sipei Lin,Xuan Zhou,Chi Zhang,Bo Cheng,Jiale Han,Benyou Wang*

Main category: cs.AI

TL;DR: 首个语音对话系统图灵测试显示，现有S2S系统均未通过测试，与人类对话存在显著差距。瓶颈在于副语言特征、情感表达和对话个性，而非语义理解。研究还发现现成AI模型作为图灵测试评判者不可靠，提出了基于细粒度人类相似度评分的可解释模型。


<details>
  <summary>Details</summary>
Motivation: 现代语音对话系统能否像人类一样对话仍是一个未解问题。研究旨在通过首个语音对话系统图灵测试，评估现有S2S系统的人类相似度，并诊断其不足之处。

Method: 收集了2,968个人类评判，对9个最先进的S2S系统与28名人类参与者之间的对话进行评估。开发了包含18个人类相似度维度的细粒度分类体系，并对收集的对话进行众包标注。提出了一个利用细粒度人类相似度评分的可解释模型。

Result: 所有评估的S2S系统均未通过图灵测试，与人类对话存在显著差距。瓶颈主要在于副语言特征、情感表达和对话个性，而非语义理解。现成的AI模型作为图灵测试评判者表现不可靠。

Conclusion: 研究建立了首个S2S系统人类相似度评估框架，超越了简单的二元结果，提供了详细的诊断洞察。提出的可解释模型为自动人类相似度评估提供了强大工具，为对话AI系统的人类化改进铺平了道路。

Abstract: The pursuit of human-like conversational agents has long been guided by the Turing test. For modern speech-to-speech (S2S) systems, a critical yet unanswered question is whether they can converse like humans. To tackle this, we conduct the first Turing test for S2S systems, collecting 2,968 human judgments on dialogues between 9 state-of-the-art S2S systems and 28 human participants. Our results deliver a clear finding: no existing evaluated S2S system passes the test, revealing a significant gap in human-likeness. To diagnose this failure, we develop a fine-grained taxonomy of 18 human-likeness dimensions and crowd-annotate our collected dialogues accordingly. Our analysis shows that the bottleneck is not semantic understanding but stems from paralinguistic features, emotional expressivity, and conversational persona. Furthermore, we find that off-the-shelf AI models perform unreliably as Turing test judges. In response, we propose an interpretable model that leverages the fine-grained human-likeness ratings and delivers accurate and transparent human-vs-machine discrimination, offering a powerful tool for automatic human-likeness evaluation. Our work establishes the first human-likeness evaluation for S2S systems and moves beyond binary outcomes to enable detailed diagnostic insights, paving the way for human-like improvements in conversational AI systems.

</details>


### [141] [Recycling Failures: Salvaging Exploration in RLVR via Fine-Grained Off-Policy Guidance](https://arxiv.org/abs/2602.24110)
*Yanwei Ren,Haotian Zhang,Likang Xiao,Xikai Zhang,Jiaxing Huang,Jiayan Qiu,Baosheng Yu,Quan Chen,Liu Liu*

Main category: cs.AI

TL;DR: SCOPE框架通过过程奖励模型精确定位推理轨迹中的首个错误步骤，进行细粒度修正，有效利用部分正确的推理轨迹，提升探索多样性13.5%，在数学推理任务上达到46.6%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 传统基于结果的强化学习监督存在关键局限：对大部分正确但有几个错误步骤的轨迹与完全错误的轨迹给予同样惩罚，导致模型丢弃有价值的部分正确推理轨迹，降低探索多样性，过早缩小探索空间。

Method: 提出SCOPE框架，利用过程奖励模型精确定位次优推理轨迹中的第一个错误步骤，应用细粒度的、步骤级别的离策略修正，对部分正确的推理轨迹进行精确精炼。

Result: SCOPE有效拯救了部分正确的推理轨迹，将多样性分数提升了13.5%，维持了广阔的探索空间。在数学推理任务上达到46.6%的平均准确率，在分布外推理任务上达到53.4%的准确率，建立了新的最先进结果。

Conclusion: SCOPE框架通过步骤级别的修正机制，有效解决了传统基于结果的强化学习监督中的粗粒度反馈问题，能够充分利用部分正确的推理轨迹，维持探索多样性，在复杂推理任务上取得了显著的性能提升。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for enhancing the complex reasoning capabilities of Large Reasoning Models. However, standard outcome-based supervision suffers from a critical limitation that penalizes trajectories that are largely correct but fail due to several missteps as heavily as completely erroneous ones. This coarse feedback signal causes the model to discard valuable largely correct rollouts, leading to a degradation in rollout diversity that prematurely narrows the exploration space. Process Reward Models have demonstrated efficacy in providing reliable step-wise verification for test-time scaling, naively integrating these signals into RLVR as dense rewards proves ineffective.Prior methods attempt to introduce off-policy guided whole-trajectory replacement that often outside the policy model's distribution, but still fail to utilize the largely correct rollouts generated by the model itself and thus do not effectively mitigate the narrowing of the exploration space. To address these issues, we propose SCOPE (Step-wise Correction for On-Policy Exploration), a novel framework that utilizes Process Reward Models to pinpoint the first erroneous step in suboptimal rollouts and applies fine-grained, step-wise off-policy rectification. By applying precise refinement on partially correct rollout, our method effectively salvages partially correct trajectories and increases diversity score by 13.5%, thereby sustaining a broad exploration space. Extensive experiments demonstrate that our approach establishes new state-of-the-art results, achieving an average accuracy of 46.6% on math reasoning and exhibiting robust generalization with 53.4% accuracy on out-of-distribution reasoning tasks.

</details>


### [142] [LemmaBench: A Live, Research-Level Benchmark to Evaluate LLM Capabilities in Mathematics](https://arxiv.org/abs/2602.24173)
*Antoine Peyronnet,Fabian Gloeckle,Amaury Hayat*

Main category: cs.AI

TL;DR: 提出一个基于arXiv最新数学研究论文的LLM能力基准测试框架，可定期更新，避免训练数据污染问题


<details>
  <summary>Details</summary>
Motivation: 现有数学基准测试主要依赖静态的手工整理竞赛题或教科书问题，不能真正反映LLM在数学研究层面的能力，需要建立与最新数学研究直接相关的动态评估框架

Method: 开发自动化流水线：从arXiv提取引理，通过明确所有假设和定义将其重写为自包含的陈述，创建可定期更新的基准测试集

Result: 当前最先进的LLM在定理证明任务上准确率约为10-15%（pass@1），表明LLM要达到人类研究水平的证明能力还有很大提升空间

Conclusion: 建立了基于最新数学研究的动态基准测试框架，揭示了LLM在数学研究层面的能力差距，为未来模型发展提供了有意义的评估标准

Abstract: We present a new approach for benchmarking Large Language Model (LLM) capabilities on research-level mathematics. Existing benchmarks largely rely on static, hand-curated sets of contest or textbook-style problems as proxies for mathematical research. Instead, we establish an updatable benchmark evaluating models directly on the latest research results in mathematics. This consists of an automatic pipeline that extracts lemmas from arXiv and rewrites them into self-contained statements by making all assumptions and required definitions explicit. It results in a benchmark that can be updated regularly with new problems taken directly from human mathematical research, while previous instances can be used for training without compromising future evaluations. We benchmark current state-of-the-art LLMs, which obtain around 10-15$\%$ accuracy in theorem proving (pass@1) depending on the model, showing that there is currently a large margin of progression for LLMs to reach human-level proving capabilities in a research context.

</details>


### [143] [Uncertainty Quantification for Multimodal Large Language Models with Incoherence-adjusted Semantic Volume](https://arxiv.org/abs/2602.24195)
*Gregory Kang Ruey Lau,Hieu Dao,Nicole Kan Hui Lin,Bryan Kian Hsiang Low*

Main category: cs.AI

TL;DR: UMPIRE：一种无需训练的多模态大语言模型不确定性量化框架，通过计算采样响应的语义体积来评估不确定性，支持多种输入输出模态且无需外部工具


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型可能产生看似合理但错误的输出，现有不确定性度量方法存在局限性：仅适用于特定模态、依赖外部工具或计算成本高，需要一种通用高效的不确定性量化框架

Method: 提出UMPIRE框架，基于模型内部模态特征，计算采样响应的不连贯调整语义体积，捕捉样本的全局语义多样性和基于内部模型置信度的局部不连贯性

Result: 在图像、音频和视频-文本基准测试（包括对抗性和分布外设置）中，UMPIRE在错误检测和不确定性校准方面始终优于基线方法，并能泛化到非文本输出任务（如图像和音频生成）

Conclusion: UMPIRE为多模态大语言模型提供了一种高效、无需训练的不确定性量化解决方案，支持多种模态且不依赖外部工具，有助于提高模型部署的可靠性

Abstract: Despite their capabilities, Multimodal Large Language Models (MLLMs) may produce plausible but erroneous outputs, hindering reliable deployment. Accurate uncertainty metrics could enable escalation of unreliable queries to human experts or larger models for improved performance. However, existing uncertainty metrics have practical constraints, such as being designed only for specific modalities, reliant on external tools, or computationally expensive. We introduce UMPIRE, a training-free uncertainty quantification framework for MLLMs that works efficiently across various input and output modalities without external tools, relying only on the models' own internal modality features. UMPIRE computes the incoherence-adjusted semantic volume of sampled MLLM responses for a given task instance, effectively capturing both the global semantic diversity of samples and the local incoherence of responses based on internal model confidence. We propose uncertainty desiderata for MLLMs and provide theoretical analysis motivating UMPIRE's design. Extensive experiments show that UMPIRE consistently outperforms baseline metrics in error detection and uncertainty calibration across image, audio, and video-text benchmarks, including adversarial and out-of-distribution settings. We also demonstrate UMPIRE's generalization to non-text output tasks, including image and audio generation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [144] [Demystifying Action Space Design for Robotic Manipulation Policies](https://arxiv.org/abs/2602.23408)
*Yuchun Feng,Jinliang Zheng,Zhihao Wang,Dongxiu Liu,Jianxiong Li,Jiangmiao Pang,Tai Wang,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 本文通过大规模实证研究发现，在基于模仿学习的机器人操作策略中，动作空间的设计对策略学习有显著影响，增量动作表示能持续提升性能，关节空间和任务空间表示各有优势。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略学习中，动作空间设计主要依赖经验法则或传统设计，缺乏系统理解。作者旨在通过大规模实证研究，明确动作空间设计对机器人策略学习的影响，为策略设计提供理论指导。

Method: 作者从时间和空间两个维度解构动作设计空间，通过13,000+次真实世界机器人部署和500+个训练模型，在四个场景中系统比较了绝对vs增量表示、关节空间vs任务空间参数化的性能差异。

Result: 大规模实验表明：1）设计策略预测增量动作能持续提升性能；2）关节空间表示有利于控制稳定性，任务空间表示有利于泛化能力，两者具有互补优势。

Conclusion: 动作空间设计对机器人策略学习有重要且复杂的影响，增量动作表示是更优选择，而关节空间和任务空间表示应根据具体需求（稳定性或泛化）进行权衡选择。

Abstract: The specification of the action space plays a pivotal role in imitation-based robotic manipulation policy learning, fundamentally shaping the optimization landscape of policy learning. While recent advances have focused heavily on scaling training data and model capacity, the choice of action space remains guided by ad-hoc heuristics or legacy designs, leading to an ambiguous understanding of robotic policy design philosophies. To address this ambiguity, we conducted a large-scale and systematic empirical study, confirming that the action space does have significant and complex impacts on robotic policy learning. We dissect the action design space along temporal and spatial axes, facilitating a structured analysis of how these choices govern both policy learnability and control stability. Based on 13,000+ real-world rollouts on a bimanual robot and evaluation on 500+ trained models over four scenarios, we examine the trade-offs between absolute vs. delta representations, and joint-space vs. task-space parameterizations. Our large-scale results suggest that properly designing the policy to predict delta actions consistently improves performance, while joint-space and task-space representations offer complementary strengths, favoring control stability and generalization, respectively.

</details>


### [145] [Printed helicoids with embedded air channels make sensorized segments for soft continuum robots](https://arxiv.org/abs/2602.23457)
*Annan Zhang,Hanna Matusik,Miguel Flores-Acton,Emily R. Sologuren,Joshua Jacob,Daniela Rus*

Main category: cs.RO

TL;DR: 提出一种在螺旋结构软体机器人中嵌入气道的制造方法，实现分布式变形感知，并构建了米级14自由度软体臂进行验证


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有安全、适应性强的优点，但由于高度可变形的结构，传感和控制仍然困难。螺旋结构软材料虽然具有可调刚度和强度，但因其稀疏几何结构而难以集成传感器

Method: 引入一种制造方法，将空气通道嵌入基于螺旋结构的软体连续机器人中。通过视觉控制喷射在单个打印中制造多材料段，并与包含微型压力传感器和IMU的PCB板接口，实现分布式变形传感

Result: 表征了四种螺旋设计的机械性能，验证了传感器对基本变形模式的响应。构建并机械评估了米级14自由度电缆驱动软体臂，能够进行开环轨迹跟踪和物体抓取，并使用夹持器传感器演示了基于触觉的刚度检测

Conclusion: 该方法为大规模软体机器人系统中的传感器化结构材料建立了可扩展的制造策略

Abstract: Soft robots enable safe, adaptive interaction with complex environments but remain difficult to sense and control due to their highly deformable structures. Architected soft materials such as helicoid lattices offer tunable stiffness and strength but are challenging to instrument because of their sparse geometry. We introduce a fabrication method for embedding air channels into helicoid-based soft continuum robots. Multi-material segments fabricated via vision-controlled jetting in a single print interface with PCBs housing miniature pressure sensors and IMUs for distributed deformation sensing. We characterize the mechanical properties of four helicoid designs and validate the sensor response to fundamental deformation modes. To demonstrate the platform's scalability, we construct and mechanically evaluate a meter-scale, 14-DoF cable-driven soft arm capable of open-loop trajectory tracking and object grasping, with tactile-based stiffness detection demonstrated using the gripper sensors. This approach establishes a scalable fabrication strategy for sensorized architected materials in large-scale soft robotic systems.

</details>


### [146] [Refining Almost-Safe Value Functions on the Fly](https://arxiv.org/abs/2602.23478)
*Sander Tonkens,Sosuke Kojima,Chenhao Liu,Judy Masri,Sylvia Herbert*

Main category: cs.RO

TL;DR: 本文提出refineCBF和HJ-Patch两种方法，通过热启动的Hamilton-Jacobi可达性分析在线精化近似控制屏障函数，实现实时安全适应动态环境。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数（CBFs）是确保机器人安全的有力工具，但为复杂系统设计或学习有效的CBFs具有挑战性。Hamilton-Jacobi可达性分析虽然能形式化合成安全值函数，但计算复杂度高且通常离线进行，限制了其在动态环境中的应用。

Method: 提出refineCBF方法，通过热启动的HJ可达性分析精化近似CBF（无论是解析推导、学习获得，甚至是不安全的）。然后提出其计算高效的继任者HJ-Patch，通过局部化更新加速这一过程。两种方法都能保证恢复安全值函数，并确保适应过程中的单调安全改进。

Result: 实验验证了框架的主要贡献：在回路中的实时适应能力，在仿真（包含详细值函数分析）和物理硬件上均得到验证。地面车辆和四旋翼飞行器的实验表明，该框架能成功适应突然的环境变化，如新障碍物和未建模的风扰动。

Conclusion: 该框架为在现实世界环境中部署形式化保证的安全提供了一条实用路径，通过在线适应机制弥补了离线合成与动态环境需求之间的差距。

Abstract: Control Barrier Functions (CBFs) are a powerful tool for ensuring robotic safety, but designing or learning valid CBFs for complex systems is a significant challenge. While Hamilton-Jacobi Reachability provides a formal method for synthesizing safe value functions, it scales poorly and is typically performed offline, limiting its applicability in dynamic environments. This paper bridges the gap between offline synthesis and online adaptation. We introduce refineCBF for refining an approximate CBF - whether analytically derived, learned, or even unsafe - via warm-started HJ reachability. We then present its computationally efficient successor, HJ-Patch, which accelerates this process through localized updates. Both methods guarantee the recovery of a safe value function and can ensure monotonic safety improvements during adaptation. Our experiments validate our framework's primary contribution: in-the-loop, real-time adaptation, in simulation (with detailed value function analysis) and on physical hardware. Our experiments on ground vehicles and quadcopters show that our framework can successfully adapt to sudden environmental changes, such as new obstacles and unmodeled wind disturbances, providing a practical path toward deploying formally guaranteed safety in real-world settings.

</details>


### [147] [TaCarla: A comprehensive benchmarking dataset for end-to-end autonomous driving](https://arxiv.org/abs/2602.23499)
*Tugrul Gorgulu,Atakan Dag,M. Esat Kalfaoglu,Halil Ibrahim Kuru,Baris Can Cam,Ozsel Kilinc*

Main category: cs.RO

TL;DR: 本文介绍了在CARLA仿真环境中收集的新数据集，包含超过285万帧数据，专门针对自动驾驶的感知和规划任务，支持多种任务评估并提供了场景稀有度评分。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶数据集存在局限性：感知数据集缺乏规划数据，规划数据集行为多样性不足，且缺乏闭环评估设置。CARLA Leaderboard 2.0提供了多样场景但现有数据集传感器配置有限，需要更全面的数据集支持端到端自动驾驶研究。

Method: 使用CARLA仿真环境为Leaderboard 2.0挑战的多样场景收集了超过285万帧数据。数据集不仅支持规划任务，还支持动态物体检测、车道线检测、中心线检测、交通灯识别、预测任务和视觉语言动作模型。同时提供了数值化的稀有度评分来衡量当前状态在数据集中的罕见程度。

Result: 创建了一个包含超过285万帧的全面数据集，覆盖CARLA Leaderboard 2.0的多样场景。数据集支持多种自动驾驶任务，并通过训练不同模型展示了其多功能性。还提供了稀有度评分系统来帮助理解数据分布。

Conclusion: 该数据集填补了现有自动驾驶数据集的空白，为端到端自动驾驶研究提供了全面的数据支持，特别是在感知和规划任务的结合以及闭环评估方面，同时通过稀有度评分帮助理解长尾问题。

Abstract: Collecting a high-quality dataset is a critical task that demands meticulous attention to detail, as overlooking certain aspects can render the entire dataset unusable. Autonomous driving challenges remain a prominent area of research, requiring further exploration to enhance the perception and planning performance of vehicles. However, existing datasets are often incomplete. For instance, datasets that include perception information generally lack planning data, while planning datasets typically consist of extensive driving sequences where the ego vehicle predominantly drives forward, offering limited behavioral diversity. In addition, many real datasets struggle to evaluate their models, especially for planning tasks, since they lack a proper closed-loop evaluation setup. The CARLA Leaderboard 2.0 challenge, which provides a diverse set of scenarios to address the long-tail problem in autonomous driving, has emerged as a valuable alternative platform for developing perception and planning models in both open-loop and closed-loop evaluation setups. Nevertheless, existing datasets collected on this platform present certain limitations. Some datasets appear to be tailored primarily for limited sensor configuration, with particular sensor configurations. To support end-to-end autonomous driving research, we have collected a new dataset comprising over 2.85 million frames using the CARLA simulation environment for the diverse Leaderboard 2.0 challenge scenarios. Our dataset is designed not only for planning tasks but also supports dynamic object detection, lane divider detection, centerline detection, traffic light recognition, prediction tasks and visual language action models . Furthermore, we demonstrate its versatility by training various models using our dataset. Moreover, we also provide numerical rarity scores to understand how rarely the current state occurs in the dataset.

</details>


### [148] [V-MORALS: Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space](https://arxiv.org/abs/2602.23524)
*Faiz Aladin,Ashwin Balasubramanian,Lars Lindemann,Daniel Seita*

Main category: cs.RO

TL;DR: V-MORALS是一种基于视觉的吸引域估计方法，通过在学习的潜在空间中构建Morse图来分析机器人系统的可达性和安全性，仅使用图像轨迹数据而不依赖系统动力学或完整状态信息。


<details>
  <summary>Details</summary>
Motivation: 现有可达性和安全性分析方法通常需要已知系统动力学或大量数据集来估计准确模型，计算成本高，且假设完整状态信息。MORALS方法虽然使用拓扑工具在低维潜在空间中估计吸引域，但仍依赖完整状态知识，未研究仅使用传感器测量的情况。

Method: V-MORALS接收给定控制器下系统的图像轨迹数据集，学习用于可达性分析的潜在空间。在该学习到的潜在空间中，方法能够生成定义良好的Morse图，从中可以计算各种系统和控制器的吸引域。

Result: V-MORALS提供了与原始MORALS架构类似的能力，但不依赖状态知识，仅使用高级传感器数据。该方法能够在仅使用图像轨迹数据的情况下进行可达性分析。

Conclusion: V-MORALS成功扩展了MORALS方法，使其能够在仅使用传感器测量（图像数据）的情况下进行吸引域估计，解决了现有方法对完整状态信息的依赖问题，为机器人系统的可达性和安全性分析提供了更实用的解决方案。

Abstract: Reachability analysis has become increasingly important in robotics to distinguish safe from unsafe states. Unfortunately, existing reachability and safety analysis methods often fall short, as they typically require known system dynamics or large datasets to estimate accurate system models, are computationally expensive, and assume full state information. A recent method, called MORALS, aims to address these shortcomings by using topological tools to estimate3DR-eEgnciodnesr of Attraction (ROA) in a low-dimensional latent space. However, MORALS still relies on full state knowledge and has not been studied when only sensor measurements are available. This paper presents Visual Morse Graph-Aided Estimation of Regions of Attraction in a Learned Latent Space (V- MORALS). V-MORALS takes in a dataset of image-based trajectories of a system under a given controller, and learns a latent space for reachability analysis. Using this learned latent space, our method is able to generate well-defined Morse Graphs, from which we can compute ROAs for various systems and controllers. V-MORALS provides capabilities similar to the original MORALS architecture without relying on state knowledge, and using only high-level sensor data. Our project website is at: https://v-morals.onrender.com.

</details>


### [149] [Tilt-X: Enabling Compliant Aerial Manipulation through a Tiltable-Extensible Continuum Manipulator](https://arxiv.org/abs/2602.23576)
*Anuraj Uthayasooriyan,Krishna Manaswi Digumarti,Jack Breward,Fernando Vanegas,Julian Galvez-Serna,Felipe Gonzalez*

Main category: cs.RO

TL;DR: Tilt-X是一种新型连续臂空中机械手，通过集成倾斜机构、伸缩平台和缆线驱动连续臂，解决了现有设计只能在无人机下方操作和对螺旋桨下洗流敏感的问题，实现了多方向操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有连续臂空中机械手系统存在两个主要限制：1）只能在无人机下方进行操作，限制了多方向部署和通过杂乱环境的能力；2）对螺旋桨下洗流敏感，影响操作精度。

Method: 提出Tilt-X系统，集成三个关键组件：1）倾斜机构；2）伸缩平台；3）缆线驱动连续臂部分。建立了系统的运动学模型，并通过飞行演示进行验证。

Result: Tilt-X实现了体积工作空间，最大延伸75毫米，平面方向在0°到90°之间。实验比较了有无下洗流情况下的末端执行器姿态，结果显示当机械臂延伸出螺旋桨影响区域时，末端执行器姿态得到稳定。

Conclusion: Tilt-X系统通过创新的机械设计解决了现有空中机械手的局限性，为可靠空中机械手的设计和控制提供了关键证据，特别是在减少螺旋桨下洗流影响方面取得了显著进展。

Abstract: Aerial manipulators extend the reach and manipulation capabilities of uncrewed multirotor aerial vehicles for inspection, agriculture, sampling, and delivery. Continuum arm aerial manipulation systems offer lightweight, dexterous, and compliant interaction opportunities. Existing designs allow manipulation only below the UAV which restricts their deployability in multiple directions and through clutter. They are also sensitive to propeller downwash. Addressing these limitations, we present Tilt-X, a continuum arm aerial manipulator that integrates a tilting mechanism, a telescopic stage, and a cable-driven continuum section. We present its design and kinematic model and validate it through flight demonstrations. Tilt-X enables a volumetric workspace with up to 75 mm extension and planar orientations between 0$^\circ$ to 90$^\circ$. Experiments comparing end effector pose with and without downwash quantitatively measure its accuracy, providing critical evidence to guide the design and control of reliable aerial manipulators. Results show stabilisation of end effector pose as the manipulator extends out of the propeller influence zone.

</details>


### [150] [VCA: Vision-Click-Action Framework for Precise Manipulation of Segmented Objects in Target Ambiguous Environments](https://arxiv.org/abs/2602.23583)
*Donggeon Kim,Seungwon Jan,Hyeonjun Park,Daegyu Lim*

Main category: cs.RO

TL;DR: 提出Vision-Click-Action框架，用点击式视觉交互替代语言指令，解决VLA模型中语言依赖带来的模糊性、认知负担和精确物体识别问题


<details>
  <summary>Details</summary>
Motivation: 传统视觉-语言-动作模型依赖语言指令会引入模糊性、增加认知负担，在多相似物体环境中难以精确识别对象和执行序列任务

Method: 提出Vision-Click-Action框架，使用预训练分割模型，允许操作者通过点击机器人2D相机视图中的目标物体进行直接视觉选择，替代冗长的文本命令

Result: 实验验证VCA框架能有效实现指定目标物体的实例级操作，减少解释错误，降低认知负荷

Conclusion: VCA为真实世界机器人操作提供了一种实用且可扩展的替代方案，优于语言驱动接口

Abstract: The reliance on language in Vision-Language-Action (VLA) models introduces ambiguity, cognitive overhead, and difficulties in precise object identification and sequential task execution, particularly in environments with multiple visually similar objects. To address these limitations, we propose Vision-Click-Action (VCA), a framework that replaces verbose textual commands with direct, click-based visual interaction using pretrained segmentation models. By allowing operators to specify target objects clearly through visual selection in the robot's 2D camera view, VCA reduces interpretation errors, lowers cognitive load, and provides a practical and scalable alternative to language-driven interfaces for real-world robotic manipulation. Experimental results validate that the proposed VCA framework achieves effective instance-level manipulation of specified target objects. Experiment videos are available at https://robrosinc.github.io/vca/.

</details>


### [151] [KEEP: A KV-Cache-Centric Memory Management System for Efficient Embodied Planning](https://arxiv.org/abs/2602.23592)
*Zebin Yang,Tong Xie,Baotong Lu,Shaoshan Liu,Bo Yu,Meng Li*

Main category: cs.RO

TL;DR: KEEP是一个面向具身规划的KV缓存中心内存管理系统，通过静态-动态内存构建、多跳内存重计算和层平衡内存加载三大创新，显著提升效率，在ALFRED数据集上实现2.68倍加速，相比CacheBlend提升4.13%成功率并减少1.90倍首token时间。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆增强的大语言模型在具身规划中通常将记忆存储为原始文本，导致提示过长和预填充延迟高。虽然可以存储和重用KV缓存，但由于频繁的KV缓存更新，效率提升有限。需要一种更高效的KV缓存中心内存管理系统来解决这些问题。

Method: KEEP系统包含三大关键技术：1) 静态-动态内存构建算法，通过混合粒度内存组减少KV缓存重计算；2) 多跳内存重计算算法，动态识别不同内存组间的重要交叉注意力并迭代重建内存交互；3) 层平衡内存加载，消除不同层间不平衡的KV缓存加载和交叉注意力计算。

Result: 在ALFRED数据集上的实验表明，KEEP相比基于文本的记忆方法实现了2.68倍加速且准确率损失可忽略。相比KV重计算方法CacheBlend，KEEP展示了4.13%的成功率提升和1.90倍的首token时间减少。

Conclusion: KEEP是一个高效的KV缓存中心内存管理系统，通过创新的内存管理技术显著提升了具身规划任务的效率和性能，为记忆增强LLMs的实际部署提供了有效的解决方案。

Abstract: Memory-augmented Large Language Models (LLMs) have demonstrated remarkable capability for complex and long-horizon embodied planning. By keeping track of past experiences and environmental states, memory enables LLMs to maintain a global view, thereby avoiding repetitive exploration. However, existing approaches often store the memory as raw text, leading to excessively long prompts and high prefill latency. While it is possible to store and reuse the KV caches, the efficiency benefits are greatly undermined due to frequent KV cache updates. In this paper, we propose KEEP, a KV-cache-centric memory management system for efficient embodied planning. KEEP features 3 key innovations: (1) a Static-Dynamic Memory Construction algorithm that reduces KV cache recomputation by mixed-granularity memory group; (2) a Multi-hop Memory Re-computation algorithm that dynamically identifies important cross-attention among different memory groups and reconstructs memory interactions iteratively; (3) a Layer-balanced Memory Loading that eliminates unbalanced KV cache loading and cross-attention computation across different layers. Extensive experimental results have demonstrated that KEEP achieves 2.68x speedup with negligible accuracy loss compared with text-based memory methods on ALFRED dataset. Compared with the KV re-computation method CacheBlend (EuroSys'25), KEEP shows 4.13% success rate improvement and 1.90x time-to-first-token (TTFT) reduction. Our code is available on https://github.com/PKU-SEC-Lab/KEEP_Embodied_Memory.

</details>


### [152] [MicroPush: A Simulator and Benchmark for Contact-Rich Cell Pushing and Assembly with a Magnetic Rolling Microrobot](https://arxiv.org/abs/2602.23607)
*Yanda Yang,Sambeeta Das*

Main category: cs.RO

TL;DR: MicroPush是一个用于磁性滚动微机器人的开源模拟器和基准测试套件，专注于接触密集的微操作任务，如细胞推动和多目标组装。


<details>
  <summary>Details</summary>
Motivation: 磁性滚动微机器人在受限微流体环境中能够实现温和操作，但接触密集行为（如细胞推动和多目标组装）的自主性难以开发和可重复评估。

Method: 结合过阻尼交互模型与接触感知的粘滑效应、轻量级近场阻尼、可选泊肃叶背景流，以及从驱动频率到自由空间滚动速度的校准映射。提供模块化规划-控制堆栈，采用两阶段策略进行接触建立和目标导向推动。

Result: 结果显示控制器稳定性在流动干扰下主导性能，而规划器选择可以通过路径点进展影响长时程序列的命令平滑度。提供了成功、时间、跟踪指标和驱动变化度量E_Δω。

Conclusion: MicroPush实现了微尺度接触密集微操作的规划、控制和学习方法的可重复比较和消融研究。

Abstract: Magnetic rolling microrobots enable gentle manipulation in confined microfluidic environments, yet autonomy for contact-rich behaviors such as cell pushing and multi-target assembly remains difficult to develop and evaluate reproducibly. We present MicroPush, an open-source simulator and benchmark suite for magnetic rolling microrobots in cluttered 2D scenes. MicroPush combines an overdamped interaction model with contact-aware stick--slip effects, lightweight near-field damping, optional Poiseuille background flow, and a calibrated mapping from actuation frequency to free-space rolling speed. On top of the simulator core, we provide a modular planning--control stack with a two-phase strategy for contact establishment and goal-directed pushing, together with a deterministic benchmark protocol with fixed tasks, staged execution, and unified CSV logging for single-object transport and hexagonal assembly. We report success, time, and tracking metrics, and an actuation-variation measure $E_{Δω}$. Results show that controller stability dominates performance under flow disturbances, while planner choice can influence command smoothness over long-horizon sequences via waypoint progression. MicroPush enables reproducible comparison and ablation of planning, control, and learning methods for microscale contact-rich micromanipulation.

</details>


### [153] [FAVLA: A Force-Adaptive Fast-Slow VLA model for Contact-Rich Robotic Manipulation](https://arxiv.org/abs/2602.23648)
*Yao Li,Peiyuan Tang,Wuyang Zhang,Chengyang Zhu,Yifan Duan,Weikai Shi,Xiaodong Zhang,Zijiang Yang,Jianmin Ji,Yanyong Zhang*

Main category: cs.RO

TL;DR: FAVLA提出了一种力自适应快慢视觉语言动作模型，通过解耦慢速感知规划和快速接触感知控制，解决了传统VLA模型在接触丰富操作中响应延迟的问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将所有模态以单一频率融合，忽略了机器人传感器采样率不匹配的问题，导致高频接触信号被下采样，加上VLM-动作专家管道在昂贵VLM更新之间以开环方式执行动作块，使得对冲击、粘滑和力峰值的响应延迟。

Method: FAVLA采用力自适应快慢架构：慢速VLM以固定低频编码模态生成潜在表示并预测近未来力变化；快速AE以可变高频执行，基于最新力序列数据生成反应性动作；引入力适配器将高频力特征注入多个AE层，并根据VLM预测的力变化自适应调度AE执行频率。

Result: 在接触丰富的任务上进行广泛实验表明，FAVLA显著优于基线方法，实现了更好的反应性和成功率，特别是在操作过程中使用更小的接触力时表现更优。

Conclusion: 通过解耦慢速感知规划和快速接触感知控制，FAVLA能够有效处理接触丰富操作任务，提供更及时的反应性控制，减少操作过程中的接触力，提高任务成功率。

Abstract: Force/torque feedback can substantially improve Vision-Language-Action (VLA) models on contact-rich manipulation, but most existing approaches fuse all modalities at a single operating frequency. This design ignores the mismatched sampling rates of real robot sensors, forcing downsampling of the high-frequency contact cues needed for reactive correction. Combined with common VLM-action-expert (AE) pipelines that execute action chunks largely open loop between expensive VLM updates, unified-frequency fusion often yields delayed responses to impacts, stick-slip, and force spikes. We propose FAVLA, a force-adaptive fast-slow VLA that decouples slow perception planning from fast contact-aware control. FAVLA runs a slow VLM at a fixed low frequency to encode modalities to produce latent representations and to predict near-future force variation. A fast AE then executes at a variable high frequency, conditioning on the latest force sequence data to generate reactive actions. We further introduce a force adapter that injects high-frequency force features into multiple AE layers, and adaptively schedules the AE's execution frequency based on the VLM's predicted force variation. Extensive experiments on contact-rich tasks demonstrate that FAVLA significantly outperforms baselines, achieving superior reactivity and success rates, especially with a smaller contact force during manipulation.

</details>


### [154] [Interpretable Multimodal Gesture Recognition for Drone and Mobile Robot Teleoperation via Log-Likelihood Ratio Fusion](https://arxiv.org/abs/2602.23694)
*Seungyeol Baek,Jaspreet Singh,Lala Shakti Swarup Ray,Hymalai Bello,Paul Lukowicz,Sungho Suh*

Main category: cs.RO

TL;DR: 提出一个用于无人机和移动机器人遥操作的多模态手势识别框架，结合苹果手表惯性数据和定制手套电容传感，通过LLR后期融合策略提升识别性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在灾害区域和工业设施等危险环境中，人类操作员需要直观可靠的手势遥操作系统。基于视觉的手势识别在遮挡、光照变化和复杂背景下的性能会下降，限制了其在实际操作中的应用。

Method: 提出多模态手势识别框架，整合双手苹果手表的惯性数据（加速度计、陀螺仪、方向）和定制手套的电容传感信号。采用基于对数似然比（LLR）的后期融合策略，增强识别性能并提供可解释性。

Result: 实验结果表明，该框架在保持与最先进视觉基线相当性能的同时，显著降低了计算成本、模型大小和训练时间，适合实时机器人控制。

Conclusion: 基于传感器的多模态融合为手势驱动的移动机器人和无人机遥操作提供了鲁棒且可解释的解决方案，具有实际应用潜力。

Abstract: Human operators are still frequently exposed to hazardous environments such as disaster zones and industrial facilities, where intuitive and reliable teleoperation of mobile robots and Unmanned Aerial Vehicles (UAVs) is essential. In this context, hands-free teleoperation enhances operator mobility and situational awareness, thereby improving safety in hazardous environments. While vision-based gesture recognition has been explored as one method for hands-free teleoperation, its performance often deteriorates under occlusions, lighting variations, and cluttered backgrounds, limiting its applicability in real-world operations. To overcome these limitations, we propose a multimodal gesture recognition framework that integrates inertial data (accelerometer, gyroscope, and orientation) from Apple Watches on both wrists with capacitive sensing signals from custom gloves. We design a late fusion strategy based on the log-likelihood ratio (LLR), which not only enhances recognition performance but also provides interpretability by quantifying modality-specific contributions. To support this research, we introduce a new dataset of 20 distinct gestures inspired by aircraft marshalling signals, comprising synchronized RGB video, IMU, and capacitive sensor data. Experimental results demonstrate that our framework achieves performance comparable to a state-of-the-art vision-based baseline while significantly reducing computational cost, model size, and training time, making it well suited for real-time robot control. We therefore underscore the potential of sensor-based multimodal fusion as a robust and interpretable solution for gesture-driven mobile robot and drone teleoperation.

</details>


### [155] [A Reliable Indoor Navigation System for Humans Using AR-based Technique](https://arxiv.org/abs/2602.23706)
*Vijay U. Rathod,Manav S. Sharma,Shambhavi Verma,Aadi Joshi,Sachin Aage,Sujal Shahane*

Main category: cs.RO

TL;DR: 该论文提出了一种基于AR的室内导航系统，使用Vuforia Area Target进行环境建模，结合NavMesh组件和A*算法进行路径规划，相比传统方法显著提升了导航准确性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 室内环境（如校园和小型区域）缺乏可靠的导航系统，用户只能依赖混乱、耗时的静态标识或楼层地图，需要更直观、实时的导航解决方案。

Method: 采用AR技术进行室内导航，使用Vuforia Area Target进行环境建模，利用AI导航的NavMesh组件进行导航，并在该组件内使用A*算法进行最短路径计算。

Result: 相比Dijkstra算法，A*算法在较小搜索空间中的求解速度提高2-3倍；相比传统GPS方法，AR叠加和实时处理能提供更直观的导航指引；实验结果显示导航准确性、用户体验和效率均有显著提升。

Conclusion: AR技术与现有路径规划算法结合是可行且可扩展的室内导航解决方案，在有限定义的室内空间中效果显著，但对于大型或高度动态环境，需要进一步优化NavMesh。

Abstract: Reliable navigation systems are not available indoors, such as in campuses and small areas. Users must depend on confusing, time-consuming static signage or floor maps. In this paper, an AR-based technique has been applied to campus and small-site navigation, where Vuforia Area Target is used for environment modeling. AI navigation's NavMesh component is used for navigation purposes, and the A* algorithm is used within this component for shortest path calculation. Compared to Dijkstra's algorithm, it can reach a solution about two to three times faster for smaller search spaces. In many cases, Dijkstra's algorithm has difficulty performing well in high-complexity environments where memory usage grows and processing times increase. Compared to older approaches such as GPS, real-time processing and AR overlays can be combined to provide intuitive directions for users while dynamically updating the path in response to environmental changes. Experimental results indicate significantly improved navigation accuracy, better user experience, and greater efficiency compared to traditional methods. These results show that AR technology integrated with existing pathfinding algorithms is feasible and scalable, making it a user-friendly solution for indoor navigation. Although highly effective in limited and defined indoor spaces, further optimization of NavMesh is required for large or highly dynamic environments.

</details>


### [156] [SAGE-LLM: Towards Safe and Generalizable LLM Controller with Fuzzy-CBF Verification and Graph-Structured Knowledge Retrieval for UAV Decision](https://arxiv.org/abs/2602.23719)
*Wenzhe Zhao,Yang Zhao,Ganchao Liu,Zhiyu Jiang,Dandan Ma,Zihao Li,Xuelong Li*

Main category: cs.RO

TL;DR: 本文提出了一种基于大语言模型的无训练双层决策架构，通过模糊控制屏障函数验证和星型层次图检索增强生成系统，为无人机动态决策提供可证明的安全保障和场景泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无人机动态决策中复杂多变的危险因素对算法泛化能力构成严峻挑战。尽管大语言模型提供语义理解和场景泛化能力，但缺乏特定领域无人机控制知识和形式化安全保障，限制了其直接应用。

Method: 提出无训练双层决策架构：1）高层安全规划与底层精确控制结合；2）模糊控制屏障函数验证机制为语义增强动作提供可证明安全认证；3）星型层次图检索增强生成系统实现高效、弹性、可解释的场景适应。

Result: 在具有未知障碍和突发威胁的追逃场景中进行系统实验验证，SAGE-LLM在保持性能的同时显著提升了安全性和泛化能力，无需在线训练。

Conclusion: 该框架展示了强大的可扩展性，表明其有潜力泛化到更广泛的具身智能系统和安全关键控制领域。

Abstract: In UAV dynamic decision, complex and variable hazardous factors pose severe challenges to the generalization capability of algorithms. Despite offering semantic understanding and scene generalization, Large Language Models (LLM) lack domain-specific UAV control knowledge and formal safety assurances, restricting their direct applicability. To bridge this gap, this paper proposes a train-free two-layer decision architecture based on LLMs, integrating high-level safety planning with low-level precise control. The framework introduces three key contributions: 1) A fuzzy Control Barrier Function verification mechanism for semantically-augmented actions, providing provable safety certification for LLM outputs. 2) A star-hierarchical graph-based retrieval-augmented generation system, enabling efficient, elastic, and interpretable scene adaptation. 3) Systematic experimental validation in pursuit-evasion scenarios with unknown obstacles and emergent threats, demonstrating that our SAGE-LLM maintains performance while significantly enhancing safety and generalization without online training. The proposed framework demonstrates strong extensibility, suggesting its potential for generalization to broader embodied intelligence systems and safety-critical control domains.

</details>


### [157] [StemVLA:An Open-Source Vision-Language-Action Model with Future 3D Spatial Geometry Knowledge and 4D Historical Representation](https://arxiv.org/abs/2602.23721)
*Jiasong Xiao,Yutao She,Kai Li,Yuyang Sha,Ziang Cheng,Ziang Tong*

Main category: cs.RO

TL;DR: StemVLA是一个新颖的视觉-语言-动作框架，通过显式整合未来导向的3D空间知识和历史4D时空表示来提升机器人操作任务中的空间推理和长期决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要依赖从2D视觉输入到动作序列的直接映射，缺乏对底层3D空间结构和时间世界动态的显式建模，这限制了在动态环境中的空间推理和长期决策能力。

Method: StemVLA采用双路径方法：1) 预测结构化3D未来空间几何世界知识，以预见场景几何和物体配置；2) 通过预训练的视频几何transformer提取历史帧的隐式3D世界表示，并使用时间注意力模块(VideoFormer)跨时间聚合，形成统一的4D历史时空表示。

Result: 在仿真实验中，StemVLA显著提高了长期任务的成功率，并在CALVIN ABC-D基准测试中达到了最先进的性能，平均序列长度为XXX。

Conclusion: 通过联合建模2D观测、预测的3D未来结构和聚合的4D时间动态，StemVLA实现了更全面的世界理解，为机器人操作提供了更强大的空间推理和长期决策能力。

Abstract: Vision-language-action (VLA) models integrate visual observations and language instructions to predict robot actions, demonstrating promising generalization in manipulation tasks. However, most existing approaches primarily rely on direct mappings from 2D visual inputs to action sequences, without explicitly modeling the underlying 3D spatial structure or temporal world dynamics. Such representations may limit spatial reasoning and long-horizon decision-making in dynamic environments. To address this limitation, we propose StemVLA, a novel framework that explicitly incorporates both future-oriented 3D spatial knowledge and historical 4D spatiotemporal representations into action prediction. First, instead of relying solely on observed images, StemVLA forecasts structured 3D future spatial-geometric world knowledge, enabling the model to anticipate upcoming scene geometry and object configurations. Second, to capture temporal consistency and motion dynamics, we feed historical image frames into a pretrained video-geometry transformer backbone to extract implicit 3D world representations, and further aggregate them across time using a temporal attention module, termed VideoFormer [20], forming a unified 4D historical spatiotemporal representation. By jointly modeling 2D observations, predicted 3D future structure, and aggregated 4D temporal dynamics, StemVLA enables more comprehensive world understanding for robot manipulation. Extensive experiments in simulation demonstrate that StemVLA significantly improves long-horizon task success and achieves state-of-the-art performance on the CALVIN ABC-D benchmark [46], achieving an average sequence length of XXX.

</details>


### [158] [Acceleration-Based Control of Fixed-Wing UAVs for Guidance Applications](https://arxiv.org/abs/2602.23821)
*Jixiang Wang,Siyuan Yang,Ziyi Wu,Siqi Wei,Ashay Wakode,Agata Barcis,Hung Nguyen,Shaoming He*

Main category: cs.RO

TL;DR: 该论文提出了一种加速度指令外环控制框架，将指令切向和法向加速度转换为可执行的体角速率和归一化推力指令，使比例导航等加速度指令制导律能够在固定翼无人机上实际部署。


<details>
  <summary>Details</summary>
Motivation: 加速度指令制导律（如比例导航）在高层决策中很有吸引力，但直接部署在固定翼无人机上具有挑战性，因为加速度不能直接驱动，必须在飞行包线约束下通过姿态和推力实现。

Method: 1. 法向通道：在假设小角度条件下，推导从期望法向加速度到滚转和俯仰速率指令的工程映射，调节升力矢量的方向和大小。2. 切向通道：基于总能量控制思想引入能量公式，直接从飞行数据中识别经验推力-能量加速度关系，避免显式推进建模或推力台校准。3. 讨论饱和和非水平机动条件下法向和切向加速度的优先级处理。

Result: 在VTOL固定翼平台上进行的广泛实飞实验证明了精确的加速度跟踪能力，并实现了仅使用体角速率和归一化推力接口的比例导航实际部署。

Conclusion: 该加速度级外环控制框架成功解决了加速度指令制导律在固定翼无人机上的实际部署问题，通过工程映射和能量公式实现了加速度到可执行指令的有效转换，为比例导航等高级制导算法提供了实用的实现途径。

Abstract: Acceleration-commanded guidance laws (e.g., proportional navigation) are attractive for high-level decision making, but their direct deployment on fixed-wing UAVs is challenging because accelerations are not directly actuated and must be realized through attitude and thrust under flight-envelope constraints. This paper presents an acceleration-level outer-loop control framework that converts commanded tangential and normal accelerations into executable body-rate and normalized thrust commands compatible with mainstream autopilots (e.g., PX4/APM). For the normal channel, we derive an engineering mapping from the desired normal acceleration to roll- and pitch-rate commands that regulate the direction and magnitude of the lift vector under small-angle assumptions. For the tangential channel, we introduce an energy-based formulation inspired by total energy control and identify an empirical thrust-energy acceleration relationship directly from flight data, avoiding explicit propulsion modeling or thrust bench calibration. We further discuss priority handling between normal and tangential accelerations under saturation and non-level maneuvers. Extensive real-flight experiments on a VTOL fixed-wing platform demonstrate accurate acceleration tracking and enable practical implementation of proportional navigation using only body-rate and normalized thrust interfaces.

</details>


### [159] [OmniTrack: General Motion Tracking via Physics-Consistent Reference](https://arxiv.org/abs/2602.23832)
*Yuhan Li,Peiyuan Zhi,Yunshen Wang,Tengyu Liu,Sixu Yan,Wenyu Liu,Xinggang Wang,Baoxiong Jia,Siyuan Huang*

Main category: cs.RO

TL;DR: OmniTrack是一个两阶段框架，通过解耦物理可行性和运动跟踪，解决人形机器人运动跟踪中因形态差异和数据噪声导致的物理不可行问题，实现稳定、通用的运动控制。


<details>
  <summary>Details</summary>
Motivation: 人类运动数据与机器人形态和动力学存在差异，加上数据噪声，会产生物理不可行的运动伪影（如漂浮和穿透），这些伪影在训练和执行时造成跟踪不准确参考运动与维持机器人稳定性之间的冲突，阻碍通用运动跟踪策略的发展。

Method: OmniTrack采用两阶段框架：第一阶段，特权通用策略通过仿真轨迹生成严格遵循机器人动力学的物理可行运动；第二阶段，通用控制策略训练跟踪这些物理可行运动，确保稳定控制迁移到真实机器人。

Result: 实验表明OmniTrack提高了跟踪精度，对未见运动表现出强泛化能力。真实世界测试中实现小时级一致稳定跟踪，包括复杂杂技动作如翻跟头和侧手翻。同时支持人类风格的稳定动态在线遥操作。

Conclusion: OmniTrack通过解耦物理可行性和运动跟踪，解决了人形机器人运动跟踪中的关键挑战，实现了稳定、通用且可迁移到真实机器人的运动控制，为通用人形机器人控制提供了有效框架。

Abstract: Learning motion tracking from rich human motion data is a foundational task for achieving general control in humanoid robots, enabling them to perform diverse behaviors. However, discrepancies in morphology and dynamics between humans and robots, combined with data noise, introduce physically infeasible artifacts in reference motions, such as floating and penetration. During both training and execution, these artifacts create a conflict between following inaccurate reference motions and maintaining the robot's stability, hindering the development of a generalizable motion tracking policy. To address these challenges, we introduce OmniTrack, a general tracking framework that explicitly decouples physical feasibility from general motion tracking. In the first stage, a privileged generalist policy generates physically plausible motions that strictly adhere to the robot's dynamics via trajectory rollout in simulation. In the second stage, the general control policy is trained to track these physically feasible motions, ensuring stable and coherent control transfer to the real robot. Experiments show that OmniTrack improves tracking accuracy and demonstrates strong generalization to unseen motions. In real-world tests, OmniTrack achieves hour-long, consistent, and stable tracking, including complex acrobatic motions such as flips and cartwheels. Additionally, we show that OmniTrack supports human-style stable and dynamic online teleoperation, highlighting its robustness and adaptability to varying user inputs.

</details>


### [160] [OmniXtreme: Breaking the Generality Barrier in High-Dynamic Humanoid Control](https://arxiv.org/abs/2602.23843)
*Yunshen Wang,Shaohang Zhu,Peiyuan Zhi,Yuhan Li,Jiaxin Li,Yong-Lu Li,Yuchen Xiao,Xingxing Wang,Baoxiong Jia,Siyuan Huang*

Main category: cs.RO

TL;DR: OmniXtreme框架通过解耦通用运动技能学习与仿真到现实的物理技能精炼，解决了高动态人形控制中保真度与可扩展性的长期权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前策略在运动库多样性扩展时面临"通用性障碍"：随着运动库规模增加，跟踪保真度不可避免地下降，特别是在高动态运动的现实部署中。这源于两个因素：多运动优化的学习瓶颈和现实驱动中的物理可执行性约束。

Method: 引入OmniXtreme框架，将通用运动技能学习与仿真到现实的物理技能精炼解耦。使用高容量架构的流匹配策略扩展表示能力，避免干扰密集的多运动RL优化，然后进行驱动感知的精炼阶段以确保在物理硬件上的鲁棒性能。

Result: 广泛实验表明，OmniXtreme在多样、高难度数据集上保持高保真度跟踪。在真实机器人上，统一策略成功执行多个极端运动，有效打破了高动态人形控制中长期存在的保真度-可扩展性权衡。

Conclusion: OmniXtreme通过解耦学习框架成功解决了运动跟踪中的通用性障碍，实现了在高动态人形控制中保真度与可扩展性的统一，为现实世界部署提供了有效解决方案。

Abstract: High-fidelity motion tracking serves as the ultimate litmus test for generalizable, human-level motor skills. However, current policies often hit a "generality barrier": as motion libraries scale in diversity, tracking fidelity inevitably collapses - especially for real-world deployment of high-dynamic motions. We identify this failure as the result of two compounding factors: the learning bottleneck in scaling multi-motion optimization and the physical executability constraints that arise in real-world actuation. To overcome these challenges, we introduce OmniXtreme, a scalable framework that decouples general motor skill learning from sim-to-real physical skill refinement. Our approach uses a flow-matching policy with high-capacity architectures to scale representation capacity without interference-intensive multi-motion RL optimization, followed by an actuation-aware refinement phase that ensures robust performance on physical hardware. Extensive experiments demonstrate that OmniXtreme maintains high-fidelity tracking across diverse, high-difficulty datasets. On real robots, the unified policy successfully executes multiple extreme motions, effectively breaking the long-standing fidelity-scalability trade-off in high-dynamic humanoid control.

</details>


### [161] [Hybrid Offline-Online Reinforcement Learning for Sensorless, High-Precision Force Regulation in Surgical Robotic Grasping](https://arxiv.org/abs/2602.23870)
*Edoardo Fazzari,Omar Mohamed,Khalfan Hableel,Hamdan Alhadhrami,Cesare Stefanini*

Main category: cs.RO

TL;DR: 提出一种结合物理一致性建模和混合强化学习的无传感器控制框架，用于手术器械的精确远端力调节，无需远端力传感即可实现高精度控制。


<details>
  <summary>Details</summary>
Motivation: 肌腱驱动手术器械的精确抓握力调节受到电机动力学、传动柔度、摩擦和远端机械非线性耦合的根本限制。现有解决方案通常依赖远端力传感或分析补偿，增加了硬件复杂性或在动态运动下性能下降。

Method: 开发了da Vinci Xi抓握机构的第一性原理数字孪生，采用统一微分代数公式捕捉耦合的电气、传动和颚部动力学。提出三阶段混合强化学习管道：1) 使用滚动时域CMA-ES生成动态可行的专家轨迹；2) 通过隐式Q学习进行完全离线策略学习；3) 使用TD3进行在线精调以适应在线动态。

Result: 在仿真中，控制器在多谐波颚部运动期间将抓握力保持在期望参考值的1%以内。硬件实验显示，在不同轨迹上平均力误差低于4%，验证了仿真到现实的迁移。学习策略包含约71k参数，可在kHz速率下执行。

Conclusion: 高保真建模结合结构化离线-在线强化学习可以恢复精确的远端力行为，无需额外传感，为手术机器人操作提供了可扩展且机械兼容的解决方案。

Abstract: Precise grasp force regulation in tendon-driven surgical instruments is fundamentally limited by nonlinear coupling between motor dynamics, transmission compliance, friction, and distal mechanics. Existing solutions typically rely on distal force sensing or analytical compensation, increasing hardware complexity or degrading performance under dynamic motion. We present a sensorless control framework that combines physics-consistent modeling and hybrid reinforcement learning to achieve high-precision distal force regulation in a proximally actuated surgical end-effector. We develop a first-principles digital twin of the da Vinci Xi grasping mechanism that captures coupled electrical, transmission, and jaw dynamics within a unified differential-algebraic formulation. To safely learn control policies in this stiff and highly nonlinear system, we introduce a three-stage pipeline:(i)a receding-horizon CMA-ES oracle that generates dynamically feasible expert trajectories,(ii)fully offline policy learning via Implicit Q-Learning to ensure stable initialization without unsafe exploration, and (iii)online refinement using TD3 for adaptation to on-policy dynamics. The resulting policy directly maps proximal measurements to motor voltages and requires no distal sensing. In simulation, the controller maintains grasp force within 1% of the desired reference during multi-harmonic jaw motion. Hardware experiments demonstrate average force errors below 4% across diverse trajectories, validating sim-to-real transfer. The learned policy contains approximately 71k param and executes at kH rates, enabling real-time deployment. These results demonstrate that high-fidelity modeling combined with structured offline-online RL can recover precise distal force behavior without additional sensing, offering a scalable and mechanically compatible solution for surgical robotic manipulation.

</details>


### [162] [TSC: Topology-Conditioned Stackelberg Coordination for Multi-Agent Reinforcement Learning in Interactive Driving](https://arxiv.org/abs/2602.23896)
*Xiaotong Zhang,Gang Xiong,Yuanjing Wang,Siyu Teng,Alois Knoll,Long Chen*

Main category: cs.RO

TL;DR: TSC是一种去中心化交互驾驶学习框架，通过提取时变有向优先级图来分解密集交通交互，使用Stackelberg博弈方法在CTDE框架下学习顺序协调策略，显著减少碰撞并保持交通效率。


<details>
  <summary>Details</summary>
Motivation: 密集交通中的自动驾驶本质上是去中心化多智能体协调问题，现有MARL方法存在同步决策加剧非平稳性、集中式排序机制扩展性差的问题，需要解决在部分可观测下快速变化的交互模式导致的振荡让行或不安全承诺等不稳定行为。

Method: 提出拓扑条件Stackelberg协调(TSC)框架：1)从编织轨迹关系中提取时变有向优先级图，定义局部领导者-跟随者依赖关系；2)基于该图将密集交互分解为图局部Stackelberg子博弈；3)在CTDE框架下，通过学习顺序协调策略：领导者通过动作预测进行预判，跟随者通过动作条件价值学习近似局部最优响应。

Result: 在四个密集交通场景中的实验表明，TSC在关键指标上优于代表性MARL基线方法，最显著的是减少碰撞，同时保持竞争力的交通效率和控制平滑性。

Conclusion: TSC框架通过提取优先级图来分解密集交互，结合Stackelberg博弈和CTDE训练，有效解决了去中心化交互驾驶中的协调问题，提高了训练稳定性和安全性，为密集交通中的自动驾驶提供了可行的解决方案。

Abstract: Safe and efficient autonomous driving in dense traffic is fundamentally a decentralized multi-agent coordination problem, where interactions at conflict points such as merging and weaving must be resolved reliably under partial observability. With only local and incomplete cues, interaction patterns can change rapidly, often causing unstable behaviors such as oscillatory yielding or unsafe commitments. Existing multi-agent reinforcement learning (MARL) approaches either adopt synchronous decision-making, which exacerbate non-stationarity, or depend on centralized sequencing mechanisms that scale poorly as traffic density increases. To address these limitations, we propose Topology-conditioned Stackelberg Coordination (TSC), a learning framework for decentralized interactive driving under communication-free execution, which extracts a time-varying directed priority graph from braid-inspired weaving relations between trajectories, thereby defining local leader-follower dependencies without constructing a global order of play. Conditioned on this graph, TSC endogenously factorizes dense interactions into graph-local Stackelberg subgames and, under centralized training and decentralized execution (CTDE), learns a sequential coordination policy that anticipates leaders via action prediction and trains followers through action-conditioned value learning to approximate local best responses, improving training stability and safety in dense traffic. Experiments across four dense traffic scenarios show that TSC achieves superior performance over representative MARL baselines across key metrics, most notably reducing collisions while maintaining competitive traffic efficiency and control smoothness.

</details>


### [163] [ABPolicy: Asynchronous B-Spline Flow Policy for Real-Time and Smooth Robotic Manipulation](https://arxiv.org/abs/2602.23901)
*Fan Yang,Peiguang Jing,Kaihua Qu,Ningyuan Zhao,Yuting Su*

Main category: cs.RO

TL;DR: ABPolicy是一种异步流匹配策略，在B样条控制点动作空间中运行，解决了机器人操作中同步推理导致的抖动、不连续和启停问题，实现了平滑的实时连续动作更新。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要平滑且能响应环境变化的策略，但原始动作空间中的同步推理会导致块内抖动、块间不连续和启停执行等问题，影响策略的平滑性和响应能力。

Method: 提出ABPolicy异步流匹配策略：1）使用B样条表示确保块内平滑性；2）引入双向动作预测结合重拟合优化强制块间连续性；3）通过异步推理实现实时连续更新。

Result: 在7个任务（包括静态和动态移动物体场景）的评估表明，ABPolicy减少了轨迹抖动，实现了更平滑的运动和更好的性能表现。

Conclusion: ABPolicy通过B样条动作空间、双向预测和异步推理的组合，有效解决了机器人操作策略的平滑性和响应性问题，为实时连续控制提供了有效解决方案。

Abstract: Robotic manipulation requires policies that are smooth and responsive to evolving observations. However, synchronous inference in the raw action space introduces several challenges, including intra-chunk jitter, inter-chunk discontinuities, and stop-and-go execution. These issues undermine a policy's smoothness and its responsiveness to environmental changes. We propose ABPolicy, an asynchronous flow-matching policy that operates in a B-spline control-point action space. First, the B-spline representation ensures intra-chunk smoothness. Second, we introduce bidirectional action prediction coupled with refitting optimization to enforce inter-chunk continuity. Finally, by leveraging asynchronous inference, ABPolicy delivers real-time, continuous updates. We evaluate ABPolicy across seven tasks encompassing both static settings and dynamic settings with moving objects. Empirical results indicate that ABPolicy reduces trajectory jerk, leading to smoother motion and improved performance. Project website: https://teee000.github.io/ABPolicy/.

</details>


### [164] [Teleoperated Omni-directional Dual Arm Mobile Manipulation Robotic System with Shared Control for Retail Store](https://arxiv.org/abs/2602.23923)
*Rolif Lima,Somdeb Saha,Nijil George,Vismay Vakharia,Shubham Parab,Sahil Gaonkar,Vighnesh Vatsal,Kaushik Das*

Main category: cs.RO

TL;DR: 本文提出了一种面向零售环境的全向双臂移动机器人系统，采用VR运动捕捉实现人机共享控制的遥操作，配备异构夹持器以处理多样化商品。


<details>
  <summary>Details</summary>
Motivation: 零售行业正快速采用AI驱动的自主移动机器人，但这些机器人在面对动态变化的零售商品时适应性不足，难以在陌生场景中自主操作。需要开发能够处理多样化商品且具备灵活操作能力的机器人系统。

Method: 1) 设计全向双移动机器人平台；2) 提出人机共享控制的遥操作方法，使用VR运动捕捉系统采集操作者指令并远程传输给机器人；3) 在双臂上配备异构夹持器以处理不同类型物品；4) 在模拟零售环境中测试单臂和双臂协调操作能力。

Result: 在模拟零售环境中验证了系统的有效性，展示了机器人能够使用单臂和双臂协调操作技术处理各种常见零售物品，证明了异构夹持器和遥操作系统的实用性。

Conclusion: 提出的全向双臂移动机器人系统结合VR遥操作和异构夹持器设计，能够有效应对零售环境中商品多样性和动态变化的挑战，为人机协作在零售场景的应用提供了可行方案。

Abstract: The swiftly expanding retail sector is increasingly adopting autonomous mobile robots empowered by artificial intelligence and machine learning algorithms to gain an edge in the competitive market. However, these autonomous robots encounter challenges in adapting to the dynamic nature of retail products, often struggling to operate autonomously in novel situations. In this study, we introduce an omni-directional dual-arm mobile robot specifically tailored for use in retail environments. Additionally, we propose a tele-operation method that enables shared control between the robot and a human operator. This approach utilizes a Virtual Reality (VR) motion capture system to capture the operator's commands, which are then transmitted to the robot located remotely in a retail setting. Furthermore, the robot is equipped with heterogeneous grippers on both manipulators, facilitating the handling of a wide range of items. We validate the efficacy of the proposed system through testing in a mockup of retail environment, demonstrating its ability to manipulate various commonly encountered retail items using both single and dual-arm coordinated manipulation techniques.

</details>


### [165] [Learning to Build: Autonomous Robotic Assembly of Stable Structures Without Predefined Plans](https://arxiv.org/abs/2602.23934)
*Jingwen Wang,Johannes Kirschner,Paul Rolland,Luis Salamanca,Stefana Parascho*

Main category: cs.RO

TL;DR: 提出基于强化学习的自主机器人装配框架，无需预定义蓝图，通过目标和障碍定义任务，在15个2D离散积木装配任务中验证可行性


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配依赖预定义建筑蓝图，缺乏对施工过程中环境不确定性和变化的适应能力。需要更灵活、适应性强的自主装配方法

Method: 采用基于深度Q学习和后继特征的强化学习策略作为决策组件，通过目标和障碍定义装配任务，而非固定计划，允许系统灵活适应环境变化

Result: 在15个2D机器人装配基准任务中验证了方法的可行性，真实世界闭环机器人实验表明能够处理施工噪声，框架展现出良好的适应性

Conclusion: 该框架为现实环境中更适应性强、鲁棒的机器人施工提供了有前景的方向，展示了强化学习在自主装配任务中的应用潜力

Abstract: This paper presents a novel autonomous robotic assembly framework for constructing stable structures without relying on predefined architectural blueprints. Instead of following fixed plans, construction tasks are defined through targets and obstacles, allowing the system to adapt more flexibly to environmental uncertainty and variations during the building process. A reinforcement learning (RL) policy, trained using deep Q-learning with successor features, serves as the decision-making component. As a proof of concept, we evaluate the approach on a benchmark of 15 2D robotic assembly tasks of discrete block construction. Experiments using a real-world closed-loop robotic setup demonstrate the feasibility of the method and its ability to handle construction noise. The results suggest that our framework offers a promising direction for more adaptable and robust robotic construction in real-world environments.

</details>


### [166] [Enhancing Vision-Language Navigation with Multimodal Event Knowledge from Real-World Indoor Tour Videos](https://arxiv.org/abs/2602.23937)
*Haoxuan Xu,Tianfu Li,Wenbo Chen,Yi Liu,Xingxing Zuo,Yaoxian Song,Haoang Li*

Main category: cs.RO

TL;DR: 该论文提出了一种基于事件中心知识增强的视觉语言导航方法，通过构建大规模多模态时空知识图谱YE-KG，并设计粗到细层次检索机制STE-VLN，解决了VLN任务中粗粒度指令和长时程推理的挑战。


<details>
  <summary>Details</summary>
Motivation: 视觉语言导航（VLN）智能体在未见环境中处理长时程推理时面临困难，特别是在面对模糊、粗粒度指令时。虽然最近的研究使用知识图谱来增强推理能力，但受人类情景记忆启发的多模态事件知识潜力尚未得到充分探索。

Method: 1. 构建YE-KG：首个大规模多模态时空知识图谱，包含超过86k节点和83k边，从真实室内视频中提取。利用多模态大语言模型（如LLaVa、GPT4）将非结构化视频流转化为结构化的语义-动作-效果事件，作为显式情景记忆。
2. 提出STE-VLN：通过粗到细层次检索机制将知识图谱集成到VLN模型中，使智能体能够检索因果事件序列，并将其与自我中心视觉观察动态融合。

Result: 在REVERIE、R2R和R2R-CE基准测试上的实验证明了该事件中心策略的有效性，在多样化动作空间中超越了最先进的方法。

Conclusion: 该研究提出的基于事件中心知识增强的视觉语言导航方法，通过构建多模态时空知识图谱和设计层次检索机制，显著提升了VLN智能体在粗粒度指令和长时程推理任务上的性能。

Abstract: Vision-Language Navigation (VLN) agents often struggle with long-horizon reasoning in unseen environments, particularly when facing ambiguous, coarse-grained instructions. While recent advances use knowledge graph to enhance reasoning, the potential of multimodal event knowledge inspired by human episodic memory remains underexplored. In this work, we propose an event-centric knowledge enhancement strategy for automated process knowledge mining and feature fusion to solve coarse-grained instruction and long-horizon reasoning in VLN task. First, we construct YE-KG, the first large-scale multimodal spatiotemporal knowledge graph, with over 86k nodes and 83k edges, derived from real-world indoor videos. By leveraging multimodal large language models (i.e., LLaVa, GPT4), we extract unstructured video streams into structured semantic-action-effect events to serve as explicit episodic memory. Second, we introduce STE-VLN, which integrates the above graph into VLN models via a Coarse-to-Fine Hierarchical Retrieval mechanism. This allows agents to retrieve causal event sequences and dynamically fuse them with egocentric visual observations. Experiments on REVERIE, R2R, and R2R-CE benchmarks demonstrate the efficiency of our event-centric strategy, outperforming state-of-the-art approaches across diverse action spaces. Our data and code are available on the project website https://sites.google.com/view/y-event-kg/.

</details>


### [167] [Learning Robust Control Policies for Inverted Pose on Miniature Blimp Robots](https://arxiv.org/abs/2602.23972)
*Yuanlin Yang,Lin Hong,Fumin Zhang*

Main category: cs.RO

TL;DR: 提出一个用于微型飞艇机器人倒立姿态控制的三阶段框架：构建高保真仿真环境、训练鲁棒控制策略、设计仿真到现实的映射层，实现倒立姿态的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 微型飞艇机器人（MBRs）实现倒立姿态对其充分发挥敏捷性至关重要，但由于其复杂且欠驱动的动力学特性，开发可靠的控制方法具有挑战性。

Method: 三阶段框架：1）构建基于真实运动数据校准的高保真3D仿真环境；2）通过域随机化策略和改进的TD3算法在仿真中训练鲁棒控制策略；3）设计映射层以弥合仿真到现实的差距。

Result: 仿真评估显示学习策略比能量整形控制器具有更高的成功率；实验结果表明，带有映射层的学习策略能使MBR在真实环境中实现并保持完全倒立姿态。

Conclusion: 提出的框架成功实现了微型飞艇机器人的倒立姿态控制，通过仿真训练和映射层设计有效解决了复杂动力学和仿真到现实的转换问题。

Abstract: The ability to achieve and maintain inverted poses is essential for unlocking the full agility of miniature blimp robots (MBRs). However, developing reliable control methods for MBRs remains challenging due to their complex and underactuated dynamics. To address this challenge, we propose a novel framework that enables robust control policy learning for inverted pose on MBRs. The proposed framework operates through three core stages: First, a high-fidelity three-dimensional (3D) simulation environment was constructed, which was calibrated against real-world MBR motion data to ensure accurate replication of inverted-state dynamics. Second, a robust policy for MBR inverted control was trained within the simulation environment via a domain randomization strategy and a modified Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm. Third, a mapping layer was designed to bridge the sim-to-real gap for the learned policy deployment. Comprehensive evaluations in the simulation environment demonstrate that the learned policy achieves a higher success rate compared to the energy-shaping controller. Furthermore, experimental results confirm that the learned policy with a mapping layer enables an MBR to achieve and maintain a fully upside-down pose in real-world settings.

</details>


### [168] [Geometry-based pneumatic actuators for soft robotics](https://arxiv.org/abs/2602.24104)
*Rui Chen,Daniele Leonardis,Domenico Chiaradia,Antonio Frisoli*

Main category: cs.RO

TL;DR: 提出基于几何的气动执行器（GPA），通过可配置的CNC热封腔室约束层，实现可预测变形、近零弯曲半径、多状态驱动和可定制复杂几何形状，应用于腕部外骨骼、触觉接口和双足机器人。


<details>
  <summary>Details</summary>
Motivation: 软气动执行器虽然能实现安全的人机交互，但在复杂驱动模式方面存在设计限制，包括最小弯曲半径、多状态能力和结构稳定性不足等问题。

Method: 采用基于几何的气动执行器设计方法，引入具有可配置CNC热封腔室的约束层，通过数学建模预测线性角度变换并验证非线性扭矩-角度关系。

Result: 开发了三个应用：49克腕部外骨骼减少肌肉活动达51%；30.8克触觉接口提供8N力反馈且响应快速；208克双足机器人实现多步态运动。

Conclusion: GPA为下一代可穿戴机器人、触觉系统和软体运动设备建立了可配置平台，解决了传统软气动执行器的设计限制。

Abstract: Soft pneumatic actuators enable safe human-machine interaction with lightweight and powerful applied parts. On the other side, they suffer design limitations as regards complex actuation patterns, including minimum bending radii, multi-states capabilities and structural stability. We present geometry-based pneumatic actuators (GPAs), a design and implementation approach that introduces constraint layers with configurable CNC heat-sealed chambers. The approach achieves predictable deformation, near-zero bending radii, multi-states actuation, and enables customizable and repeatable complex actuated geometries. Mathematical modeling reveals predictable linear angle transformations and validates nonlinear torque-angle relationships across diverse configurations. We demonstrate versatility of the GPAs approach through three applications: a 49 g wrist exoskeleton reducing muscle activity by up to 51%, a 30.8 g haptic interface delivering 8 N force feedback with fast response, and a 208 g bipedal robot achieving multi-gait locomotion. GPAs establish a configurable platform for next-generation wearable robotics, haptic systems, and soft locomotion devices.

</details>


### [169] [Planning from Observation and Interaction](https://arxiv.org/abs/2602.24121)
*Tyler Han,Siyang Shen,Rohan Baijal,Harine Ravichandiran,Bat Nemekhbold,Kevin Huang,Sanghun Jung,Byron Boots*

Main category: cs.RO

TL;DR: 本文提出了一种基于规划的逆强化学习算法，仅通过观察和交互就能进行世界建模，在真实世界中从零开始学习图像操作任务，无需奖励函数设计或演示者动作数据。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习中，通常需要手工设计的奖励函数或演示者动作数据，这限制了学习的可扩展性。本文旨在解决仅通过观察任务执行过程就能学习的场景，无需奖励函数、演示者动作、先验知识或预训练数据。

Method: 提出了一种基于规划的逆强化学习算法，仅通过观察和交互进行世界建模。该方法从任务观察中学习世界模型表示，并利用该表示进行规划，实现从零开始的在线学习。

Result: 实验完全在真实世界中进行，证明该方法能在1小时内从零开始学习基于图像的操作任务，且学习到的世界模型表示能够在真实世界中实现在线迁移学习。相比现有的IRL、RL和BC方法，该方法具有显著更高的样本效率和成功率。

Conclusion: 该方法为仅通过观察和交互进行在线世界建模和规划提供了一条实用路径，在数据受限的场景下表现出优越的性能，为机器人学习提供了更灵活和可扩展的解决方案。

Abstract: Observational learning requires an agent to learn to perform a task by referencing only observations of the performed task. This work investigates the equivalent setting in real-world robot learning where access to hand-designed rewards and demonstrator actions are not assumed. To address this data-constrained setting, this work presents a planning-based Inverse Reinforcement Learning (IRL) algorithm for world modeling from observation and interaction alone. Experiments conducted entirely in the real-world demonstrate that this paradigm is effective for learning image-based manipulation tasks from scratch in under an hour, without assuming prior knowledge, pre-training, or data of any kind beyond task observations. Moreover, this work demonstrates that the learned world model representation is capable of online transfer learning in the real-world from scratch. In comparison to existing approaches, including IRL, RL, and Behavior Cloning (BC), which have more restrictive assumptions, the proposed approach demonstrates significantly greater sample efficiency and success rates, enabling a practical path forward for online world modeling and planning from observation and interaction. Videos and more at: https://uwrobotlearning.github.io/mpail2/.

</details>


### [170] [Robust Skills, Brittle Grounding: Diagnosing Restricted Generalization in Vision-Language Action Policies via Multi-Object Picking](https://arxiv.org/abs/2602.24143)
*David Emukpere,Romain Deffayet,Jean-Michel Renders*

Main category: cs.RO

TL;DR: 研究发现视觉语言动作策略在基准测试中表现良好，但可能依赖对象-位置相关性而非真正的语言-对象关联，建议使用任务阶梯和分解指标来更好评估指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言动作策略在操纵基准测试中表现出色，但不确定这是否反映了真正的语言-对象关联能力，还是仅仅依赖训练数据中的对象-位置相关性。需要验证这些策略在超出训练分布情况下的泛化能力。

Method: 设计了一个受控的多对象拾取研究，逐步增加对象放置的变异性直至完全工作空间随机化，并评估了打破熟悉关联的保留对象-位置配对，同时保持空间难度不变。

Result: 在压力测试和数据扩展中，代表性VLA策略（包括SmolVLA和π0.5）的操纵原语执行可靠性显著高于指令条件任务成功率，表明操纵技能获取与指令跟随能力是解耦的。

Conclusion: 建议增强操纵基准测试，加入任务阶梯和分解指标，分别测量原语执行能力和指令条件成功率，以更好地诊断基于指令的泛化能力。

Abstract: Vision-language action (VLA) policies often report strong manipulation benchmark performance with relatively few demonstrations, but it remains unclear whether this reflects robust language-to-object grounding or reliance on object--location correlations that do not transfer beyond the training distribution. We present a controlled multi-object picking study that progressively increases object placement variability up to full workspace randomization and evaluates held-out object--location pairings that break familiar associations without increasing spatial difficulty. Across these stress tests and data scaling, we find that for representative VLA policies, including SmolVLA and $π_{0.5}$, execution of the manipulation primitive remains substantially more reliable than instruction-conditioned task success in harder regimes, suggesting that manipulation skill acquisition is decoupled from instruction following. We recommend augmenting manipulation benchmarks with task ladders and decomposed metrics that separately measure primitive execution and instruction-conditioned success to better diagnose instruction-grounded generalization.

</details>


### [171] [Humanoid Robots as First Assistants in Endoscopic Surgery](https://arxiv.org/abs/2602.24156)
*Sue Min Cho,Jan Emily Mangulabnan,Han Zhang,Zhekai Mao,Yufan He,Pengfei Guo,Daguang Xu,Gregory Hager,Masaru Ishii,Mathias Unberath*

Main category: cs.RO

TL;DR: 首例人形机器人辅助外科手术的概念验证：远程操作的Unitree G1在尸体蝶窦切除术中提供内窥镜可视化支持，成功完成手术并保持稳定视野。


<details>
  <summary>Details</summary>
Motivation: 当前关于人形机器人外科能力的预测缺乏实证基础，尚无任何人形机器人实际辅助外科手术。本研究旨在填补这一空白，验证人形机器人形态因素在外科辅助中的可行性。

Method: 采用远程操作的Unitree G1人形机器人，在耳鼻喉科医生进行尸体蝶窦切除术时提供内窥镜可视化支持。通过远程操作评估人形机器人形态因素在持久性和精度方面能否满足外科辅助的物理需求。

Result: 手术成功完成，整个过程中保持了稳定的可视化。研究证实了人形机器人形态因素在外科辅助中的可行性，同时识别了临床转化所需的工程目标，以及近期机会如自主诊断性内窥镜检查。

Conclusion: 本研究首次实证了人形机器人辅助外科手术的可行性，为人形机器人外科应用奠定了基础，同时指出了持续发展面临的挑战和未来研究方向。

Abstract: Humanoid robots have become a focal point of technological ambition, with claims of surgical capability within years in mainstream discourse. These projections are aspirational yet lack empirical grounding. To date, no humanoid has assisted a surgeon through an actual procedure, let alone performed one. The work described here breaks this new ground. Here we report a proof of concept in which a teleoperated Unitree G1 provided endoscopic visualization while an attending otolaryngologist performed a cadaveric sphenoidectomy. The procedure was completed successfully, with stable visualization maintained throughout. Teleoperation allowed assessment of whether the humanoid form factor could meet the physical demands of surgical assistance in terms of sustenance and precision; the cognitive demands were satisfied -- for now -- by the operator. Post-procedure analysis identified engineering targets for clinical translation, alongside near-term opportunities such as autonomous diagnostic scoping. This work establishes form-factor feasibility for humanoid surgical assistance while identifying challenges for continued development.

</details>


### [172] [How IMU Drift Influences Multi-Radar Inertial Odometry for Ground Robots in Subterranean Terrains](https://arxiv.org/abs/2602.24192)
*Moumita Mukherjee,Magnus Norén,Anton Koval,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种两阶段MRIO框架，用于在GPS拒止的地下环境中实现可靠的雷达惯性里程计，通过IMU偏置估计器和EKF在线校正来解决低成本IMU漂移问题，在烟雾、灰尘等恶劣条件下优于LiDAR方案。


<details>
  <summary>Details</summary>
Motivation: 在地下环境中，低成本IMU（如Pixhawk）存在偏置漂移问题，而FMCW雷达虽然能在烟雾、灰尘等恶劣条件下工作，但其稀疏、噪声大、闪烁的返回信号使得与IMU融合不稳定。现有LiDAR方案在烟雾等条件下失效，因此需要一种能在恶劣环境下稳定工作的雷达惯性里程计方案。

Method: 提出两阶段MRIO框架：1）使用最小二乘法进行基于雷达的自我速度估计，并集成到EKF中进行在线IMU偏置校正；2）将校正后的IMU加速度与多个雷达和IMU的异构测量值融合以优化里程计。该框架还支持仅使用雷达进行建图，利用估计的平移和旋转位移。

Result: 在地下实地测试中，MRIO实现了鲁棒的定位和建图，性能优于EKF-RIO。该框架在低成本FMCW雷达设置和不同IMU（包括Pixhawk和更高端的VectorNav）上均保持准确性，表现出良好的适应性。

Conclusion: MRIO框架通过有效的IMU偏置校正和异构传感器融合，解决了地下环境中低成本IMU漂移和雷达信号质量差的问题，在烟雾等恶劣条件下提供了可靠的定位和建图能力，优于传统雷达惯性里程计方案，并将开源供社区使用。

Abstract: Reliable radar inertial odometry (RIO) requires mitigating IMU bias drift, a challenge that intensifies in subterranean environments due to extreme temperatures and gravity-induced accelerations. Cost-effective IMUs such as the Pixhawk, when paired with FMCW TI IWR6843AOP EVM radars, suffer from drift-induced degradation compounded by sparse, noisy, and flickering radar returns, making fusion less stable than LiDAR-based odometry. Yet, LiDAR fails under smoke, dust, and aerosols, whereas FMCW radars remain compact, lightweight, cost-effective, and robust in these situations. To address these challenges, we propose a two-stage MRIO framework that combines an IMU bias estimator for resilient localization and mapping in GPS-denied subterranean environments affected by smoke. Radar-based ego-velocity estimation is formulated through a least-squares approach and incorporated into an EKF for online IMU bias correction; the corrected IMU accelerations are fused with heterogeneous measurements from multiple radars and an IMU to refine odometry. The proposed framework further supports radar-only mapping by exploiting the robot's estimated translational and rotational displacements. In subterranean field trials, MRIO delivers robust localization and mapping, outperforming EKF-RIO. It maintains accuracy across cost-efficient FMCW radar setups and different IMUs, showing resilience with Pixhawk and higher-grade units such as VectorNav. The implementation will be provided as an open-source resource to the community (code available at https://github.com/LTU-RAI/MRIO

</details>


### [173] [Evaluating Accuracy of Vine Robot Shape Sensing with Distributed Inertial Measurement Units](https://arxiv.org/abs/2602.24202)
*Alexis E. Laudenslager,Antonio Alvarez Valdivia,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 该研究系统评估了基于分布式IMU的藤蔓机器人形状感知精度，量化了在不同条件下的误差表现


<details>
  <summary>Details</summary>
Motivation: 藤蔓机器人在城市搜救等应用中需要精确的形状感知来定位传感器信息和确定机器人配置，但现有分布式IMU形状感知方法在主动转向、不同长度和传感器间距下的准确性尚未系统量化

Method: 通过实验评估使用分布式IMU进行藤蔓机器人形状感知的准确性，测量IMU漂移率，并在被动转向、主动转向、不同长度（30-175厘米）以及不同传感器间距条件下进行测试

Result: IMU平均方向漂移率为1.33度/分钟；被动转向时尖端位置误差平均为机器人长度的11%；主动转向时误差增加到16%；在30-175厘米长度范围内，平均尖端误差为8%，且随长度增加呈正相关趋势；中等传感器间距对单曲率形状的误差最小

Conclusion: 分布式IMU形状感知对藤蔓机器人具有可行性，但需要改进建模和算法集成以应对实际部署中的关键限制

Abstract: Soft, tip-extending vine robots are well suited for navigating tight, debris-filled environments, making them ideal for urban search and rescue. Sensing the full shape of a vine robot's body is helpful both for localizing information from other sensors placed along the robot body and for determining the robot's configuration within the space being explored. Prior approaches have localized vine robot tips using a single inertial measurement unit (IMU) combined with force sensing or length estimation, while one method demonstrated full-body shape sensing using distributed IMUs on a passively steered robot in controlled maze environments. However, the accuracy of distributed IMU-based shape sensing under active steering, varying robot lengths, and different sensor spacings has not been systematically quantified. In this work, we experimentally evaluate the accuracy of vine robot shape sensing using distributed IMUs along the robot body. We quantify IMU drift, measuring an average orientation drift rate of 1.33 degrees/min across 15 sensors. For passive steering, mean tip position error was 11% of robot length. For active steering, mean tip position error increased to 16%. During growth experiments across lengths from 30-175 cm, mean tip error was 8%, with a positive trend with increasing length. We also analyze the influence of sensor spacing and observe that intermediate spacings can minimize error for single-curvature shapes. These results demonstrate the feasibility of distributed IMU-based shape sensing for vine robots while highlighting key limitations and opportunities for improved modeling and algorithmic integration for field deployment.

</details>


### [174] [SafeGen-LLM: Enhancing Safety Generalization in Task Planning for Robotic Systems](https://arxiv.org/abs/2602.24235)
*Jialiang Fan,Weizhe Xu,Mengyu Liu,Oleg Sokolsky,Insup Lee,Fangxin Kong*

Main category: cs.RO

TL;DR: SafeGen-LLM：一种安全可泛化的大型语言模型，用于机器人安全关键任务规划，通过两阶段后训练框架提升安全性并泛化到新安全约束


<details>
  <summary>Details</summary>
Motivation: 当前机器人安全关键任务规划面临挑战：经典规划器扩展性差，基于强化学习的方法泛化能力弱，基础大语言模型无法保证安全性。需要一种既能保证安全性又能良好泛化的解决方案。

Method: 1) 构建多领域PDDL3基准测试集；2) 两阶段后训练框架：监督微调学习规划语法语义，基于细粒度奖励机的组相对策略优化确保安全对齐，结合课程学习处理复杂任务

Result: SafeGen-LLM在跨领域规划任务和多种输入格式（PDDL和自然语言）上表现出强大的安全泛化能力，优于前沿专有基线模型

Conclusion: SafeGen-LLM能够有效提升任务规划的安全性满足度，并能良好泛化到各种领域的新安全属性，为解决机器人安全关键规划问题提供了有效方案

Abstract: Safety-critical task planning in robotic systems remains challenging: classical planners suffer from poor scalability, Reinforcement Learning (RL)-based methods generalize poorly, and base Large Language Models (LLMs) cannot guarantee safety. To address this gap, we propose safety-generalizable large language models, named SafeGen-LLM. SafeGen-LLM can not only enhance the safety satisfaction of task plans but also generalize well to novel safety properties in various domains. We first construct a multi-domain Planning Domain Definition Language 3 (PDDL3) benchmark with explicit safety constraints. Then, we introduce a two-stage post-training framework: Supervised Fine-Tuning (SFT) on a constraint-compliant planning dataset to learn planning syntax and semantics, and Group Relative Policy Optimization (GRPO) guided by fine-grained reward machines derived from formal verification to enforce safety alignment and by curriculum learning to better handle complex tasks. Extensive experiments show that SafeGen-LLM achieves strong safety generalization and outperforms frontier proprietary baselines across multi-domain planning tasks and multiple input formats (e.g., PDDLs and natural language).

</details>
