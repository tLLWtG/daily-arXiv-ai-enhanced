<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 36]
- [cs.AI](#cs.AI) [Total: 7]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.LG](#cs.LG) [Total: 63]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding](https://arxiv.org/abs/2602.17768)
*Boda Lin,Yongjie Zhu,Xiaocheng Gong,Wenyu Qin,Meng Wang*

Main category: cs.CV

TL;DR: 该论文针对视频描述中细粒度运动细节描述不准确和幻觉问题，提出了KPM-Bench数据集和MoPE算法，通过运动解析和提取技术改善运动中心视频描述的质量。


<details>
  <summary>Details</summary>
Motivation: 当前视频描述模型在描述细粒度运动细节方面存在局限，特别是在运动中心视频中，对复杂肢体动态的精确描述不足，且存在严重的幻觉问题。

Method: 1) 开发自动化标注流程，整合基于运动学的运动计算和语言解析；2) 构建KPM-Bench数据集，包含细粒度视频-描述对、运动理解问答对和幻觉评估集；3) 提出MoPE算法，从文本描述中准确提取运动特定属性；4) 将MoPE集成到GRPO后训练框架中。

Result: 创建了KPM-Bench开源数据集，提出了基于MoPE的幻觉评估指标，通过GRPO框架有效缓解了幻觉问题，显著提高了运动中心视频描述模型的可靠性。

Conclusion: 该研究通过创新的数据集构建和算法设计，系统性地解决了视频描述中的细粒度运动理解和幻觉问题，为运动中心视频理解提供了有效的解决方案。

Abstract: Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.

</details>


### [2] [CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild](https://arxiv.org/abs/2602.17770)
*Balamurugan Thambiraja,Omid Taheri,Radek Danecek,Giorgio Becherini,Gerard Pons-Moll,Justus Thies*

Main category: cs.CV

TL;DR: 该论文提出了3D-HIW数据集和CLUTCH系统，用于解决野外环境下文本与手部动作生成/描述的问题，通过创新的VQ-VAE架构和几何优化实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 手部动作在日常生活中至关重要，但现有方法依赖工作室采集的有限数据集，难以扩展到野外环境，且文本与动作对齐质量不足。

Method: 1) 构建3D-HIW数据集：结合视觉语言模型和3D手部追踪器处理大量第一人称动作视频；2) 提出CLUTCH系统：包含SHIFT（部分模态分解的VQ-VAE架构）和几何优化阶段，通过重建损失微调LLM。

Result: 在文本到手部动作生成和动作到文本描述任务上实现了最先进的性能，首次建立了可扩展的野外手部动作建模基准。

Conclusion: 通过3D-HIW数据集和CLUTCH系统，成功解决了野外环境下手部动作建模的挑战，为文本与手部动作的互生成任务提供了有效的解决方案。

Abstract: Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to "in-the-wild" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.

</details>


### [3] [LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge](https://arxiv.org/abs/2602.17793)
*Peide Zhu,Linbin Lu,Zhiqin Chen,Xiong Chen*

Main category: cs.CV

TL;DR: 提出LGD-Net框架，通过跨模态特征幻觉而非像素级图像生成，从H&E切片直接预测HER2表达水平，避免重建伪影并提高效率


<details>
  <summary>Details</summary>
Motivation: 传统IHC染色资源密集、昂贵且耗时，在许多地区不可用。现有基于H&E的虚拟IHC方法计算成本高且易产生重建伪影，可能传播诊断错误

Method: 提出Latent-Guided Dual-Stream Network (LGD-Net)，学习将形态学H&E特征直接映射到分子潜在空间，通过教师IHC编码器引导训练，并利用核分布和膜染色强度等任务特定领域知识进行正则化

Result: 在公开BCI数据集上的实验表明，LGD-Net达到最先进性能，显著优于基线方法，同时能够使用单模态H&E输入进行高效推理

Conclusion: LGD-Net通过跨模态特征幻觉而非像素级图像生成，有效解决了传统虚拟染色方法的局限性，为乳腺癌HER2评估提供了一种高效准确的替代方案

Abstract: It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.

</details>


### [4] [Enabling Training-Free Text-Based Remote Sensing Segmentation](https://arxiv.org/abs/2602.17799)
*Jose Sosa,Danila Rukhovich,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出一种无需额外训练即可实现遥感图像文本引导分割的方法，结合对比式和生成式视觉语言模型与SAM，在19个遥感基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型和视觉基础模型为零样本文本引导遥感图像分割提供了新机会，但大多数方法仍依赖额外的可训练组件，限制了其泛化能力和实际应用。本研究旨在探索仅依赖现有基础模型、无需额外训练即可实现基于文本的遥感分割的可能性。

Method: 提出一种简单有效的训练免费或轻量级LoRA微调管道：1）对比式方法使用CLIP作为SAM网格提议的掩码选择器，实现完全零样本的开放词汇语义分割；2）生成式方法使用GPT-5（零样本）和LoRA微调的Qwen-VL模型生成SAM的点击提示，实现推理和指代分割。

Result: 在19个遥感基准测试（包括开放词汇、指代和基于推理的任务）上的广泛实验表明，该方法具有强大能力：对比式方法在完全零样本设置下实现了最先进的开放词汇语义分割；生成式方法中，LoRA微调的Qwen-VL模型表现最佳。

Conclusion: 研究表明，仅依赖现有基础模型、无需额外训练即可实现有效的遥感图像文本引导分割，为实际应用提供了更通用的解决方案。

Abstract: Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.

</details>


### [5] [VQPP: Video Query Performance Prediction Benchmark](https://arxiv.org/abs/2602.17814)
*Adrian Catalin Lutu,Eduard Poesina,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 本文提出了首个视频查询性能预测（VQPP）基准，包含两个文本到视频检索数据集和两个CBVR系统，共56K文本查询和51K视频，为视频领域的QPP研究提供了标准化评估框架。


<details>
  <summary>Details</summary>
Motivation: 查询性能预测（QPP）在信息检索中具有重要应用，但在基于内容的视频检索（CBVR）领域研究不足，缺乏标准化的评估基准。

Method: 构建了VQPP基准，包含两个文本到视频检索数据集和两个CBVR系统，探索了多种检索前和检索后性能预测器，并利用最佳检索前预测器作为奖励模型，通过直接偏好优化训练LLM进行查询重构。

Result: 检索前预测器取得了有竞争力的性能，能够在检索步骤之前实现应用；VQPP基准为视频领域的QPP研究提供了可复现的比较框架。

Conclusion: VQPP是首个视频查询性能预测基准，填补了CBVR领域QPP研究的空白，为未来视频检索性能预测研究提供了标准化评估平台。

Abstract: Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

</details>


### [6] [On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective](https://arxiv.org/abs/2602.17854)
*Domonkos Varga*

Main category: cs.CV

TL;DR: 该论文对Liu和Szirányi提出的手势识别方法进行方法论分析，指出其评估协议存在严重的数据泄露问题，导致报告的高准确率不反映对未见个体的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本文旨在分析Liu和Szirányi手势识别方法的评估协议有效性，揭示其报告的高准确率可能源于数据泄露问题，强调在无人机-人交互等实际应用中，需要能够泛化到未见个体的可靠手势识别系统。

Method: 通过检查已发表的混淆矩阵、学习曲线和数据集构建方式，分析其评估协议。特别关注帧级随机训练-测试分割是否导致同一受试者的样本混合出现在训练集和测试集中，从而造成数据泄露。

Result: 研究发现，报告的接近完美的准确率指标源于帧级随机训练-测试分割，这种分割不可避免地混合了同一受试者在训练集和测试集中的样本，导致严重的数据泄露。评估并未测量对未见个体的泛化能力。

Conclusion: 在基于视觉的手势识别研究中，特别是对于需要可靠识别未见个体手势的应用（如无人机-人交互），采用受试者独立的数据划分至关重要。当前评估协议存在缺陷，需要更严格的评估方法。

Abstract: This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.

</details>


### [7] [Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.17869)
*Yuxiao Chen,Jue Wang,Zhikang Zhang,Jingru Yi,Xu Zhang,Yang Zou,Zhaowei Cai,Jianbo Yuan,Xinyu Li,Hao Yang,Davide Modolo*

Main category: cs.CV

TL;DR: 提出了一种用于长视频理解的新型端到端框架，包含基于信息密度的自适应视频采样器和基于自动编码器的时空视频压缩器，结合多模态大语言模型，有效处理长视频冗余问题。


<details>
  <summary>Details</summary>
Motivation: 随着视频骨干架构的进步和大语言模型的发展，分析长达数十分钟的长视频变得可行且普遍。然而，视频序列固有的冗余性给现有最先进模型带来了两大挑战：1) 在内存限制内高效处理更多帧；2) 从大量输入数据中提取判别性信息。

Method: 提出了一个端到端的长视频理解框架，包含：1) 基于信息密度的自适应视频采样器(AVS)，根据视频内容重要性自适应采样关键帧；2) 基于自动编码器的时空视频压缩器(SVC)，实现高压缩率同时保留关键判别信息；3) 与多模态大语言模型(MLLM)集成。

Result: 该框架在各种基准测试中表现出色，在长视频理解任务和标准视频理解基准测试中都取得了优异性能，证明了其处理长视频复杂性的有效性和通用性。

Conclusion: 提出的框架能够自适应有效地从不同时长的视频序列中捕获关键信息，实现高压缩率同时保留重要判别信息，为解决长视频理解中的冗余问题提供了有效方案。

Abstract: With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.

</details>


### [8] [Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models](https://arxiv.org/abs/2602.17871)
*Dhruba Ghosh,Yuhui Zhang,Ludwig Schmidt*

Main category: cs.CV

TL;DR: 该研究发现当前视觉语言模型在细粒度图像分类任务上表现不佳，通过实验发现更好的视觉编码器能显著提升细粒度分类性能，而预训练阶段对模型性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在多种视觉问答基准测试中取得了显著进展，但近期研究表明这些模型在传统的细粒度图像分类基准测试中表现落后。研究者希望探索视觉语言模型在细粒度视觉知识与通用视觉能力之间存在差距的原因。

Method: 研究测试了大量最新的视觉语言模型在细粒度分类基准上的表现，通过一系列消融实验分析性能差异的原因。实验重点考察了不同LLM和视觉编码器对性能的影响，以及预训练阶段对模型性能的重要性。

Result: 研究发现：1）使用更好的LLM能同等提升所有基准测试分数；2）更好的视觉编码器能不成比例地提升细粒度分类性能；3）预训练阶段对细粒度性能至关重要，特别是在预训练期间语言模型权重未冻结的情况下。

Conclusion: 这些发现为增强视觉语言模型的细粒度视觉理解和视觉中心能力提供了重要见解，指出了改进视觉编码器和优化预训练策略的重要性。

Abstract: Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.

</details>


### [9] [A Single Image and Multimodality Is All You Need for Novel View Synthesis](https://arxiv.org/abs/2602.17909)
*Amirhosein Javadi,Chi-Shiang Gau,Konstantinos D. Polyzos,Tara Javidi*

Main category: cs.CV

TL;DR: 该论文提出了一种利用稀疏多模态测距数据（如雷达或激光雷达）改进基于扩散的单图像新视角合成方法，通过高斯过程在角度域重建密集深度图，提升几何一致性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的单图像新视角合成方法依赖单目深度估计的几何信息，但在低纹理、恶劣天气和遮挡严重的真实场景中，深度估计的可靠性有限，导致合成视角的质量和一致性不足。

Method: 提出多模态深度重建框架，利用极稀疏的测距传感数据（如汽车雷达或激光雷达），在角度域使用局部高斯过程建模深度，实现高效计算并显式量化观测有限区域的不确定性。重建的深度和不确定性可直接替换现有扩散渲染流程中的单目深度估计器。

Result: 在真实多模态驾驶场景实验中，用稀疏测距重建深度替换纯视觉深度，显著提高了单图像新视角视频生成的几何一致性和视觉质量。

Conclusion: 可靠的几何先验对基于扩散的视角合成至关重要，即使在极端稀疏条件下，多模态传感也能带来实际效益，为扩散模型提供更稳健的几何条件。

Abstract: Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.

</details>


### [10] [ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging](https://arxiv.org/abs/2602.17929)
*Athanasios Angelakis*

Main category: cs.CV

TL;DR: ZACH-ViT是一种紧凑型视觉Transformer，移除了位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性，在医学图像分类任务中表现出色，特别适合资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 传统视觉Transformer依赖位置嵌入和类别标记编码固定的空间先验，这在自然图像中有效，但在医学成像中可能阻碍泛化能力，因为医学图像的空间布局通常信息较弱或不一致。

Method: 提出ZACH-ViT，移除位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性；采用自适应残差投影保持训练稳定性；在紧凑配置下保持严格的参数预算。

Result: 在7个MedMNIST数据集上评估，ZACH-ViT（0.25M参数）在BloodMNIST上表现最强，在PathMNIST上与TransMIL竞争，但在具有强解剖先验的数据集（OCTMNIST、OrganAMNIST）上优势减弱；保持亚秒级推理时间。

Conclusion: 将架构归纳偏置与数据结构对齐比追求通用基准优势更重要；ZACH-ViT在资源受限的临床环境中具有部署潜力，尽管规模小且无预训练，仍能保持竞争力。

Abstract: Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term "Zero-token" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.
  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.

</details>


### [11] [ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models](https://arxiv.org/abs/2602.17951)
*Guoheng Sun,Tingting Du,Kaixi Feng,Chenxiang Luo,Xingguo Ding,Zheyu Shen,Ziyao Wang,Yexiao He,Ang Li*

Main category: cs.CV

TL;DR: ROCKET提出了一种残差导向的多层表示对齐框架，通过共享投影器将VLA模型的多个层与强大的3D视觉基础模型对齐，显著降低了计算成本并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action模型通常在2D数据上预训练，缺乏3D空间理解能力。现有的表示对齐方法通常只在单层进行监督，无法充分利用深度分布的信息，而朴素的多层对齐会导致梯度干扰。

Method: ROCKET采用残差导向的多层表示对齐框架，将多层对齐建模为将一个残差流对齐到另一个残差流。使用共享投影器通过层不变映射将VLA骨干的多个层与3D视觉基础模型的多个层对齐，减少梯度冲突。还提出了Matryoshka风格的稀疏激活方案来平衡多个对齐损失。

Result: 实验显示，结合免训练层选择策略，ROCKET仅需约4%的计算预算，在LIBERO上达到98.5%的最先进成功率。在LIBERO-Plus、RoboTwin以及多个VLA模型上都表现出优越性能。

Conclusion: ROCKET通过残差导向的多层表示对齐框架，有效解决了现有VLA模型缺乏3D空间理解的问题，在显著降低计算成本的同时实现了优异的性能表现。

Abstract: Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.

</details>


### [12] [Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching](https://arxiv.org/abs/2602.18000)
*Xuting Lan,Mingliang Zhou,Xuekai Wei,Jielu Yan,Yueting Huang,Huayan Pu,Jun Luo,Weijia Jia*

Main category: cs.CV

TL;DR: 提出了一种基于记忆驱动的质量感知框架（MQAF），通过建立存储失真模式的记忆库，动态切换双模式质量评估策略，减少对高质量参考图像的依赖，实现全参考和无参考图像质量评估的通用框架。


<details>
  <summary>Details</summary>
Motivation: 现有全参考图像质量评估（FR-IQA）方法依赖参考图像质量，限制了在理想参考源不可用的实际应用。受人类视觉系统能够积累视觉记忆并基于长期记忆存储进行图像质量评估的启发，需要开发减少对高质量参考图像依赖的通用质量评估框架。

Method: 提出记忆驱动的质量感知框架（MQAF），建立存储失真模式的记忆库，动态切换双模式质量评估策略：当参考图像可用时，通过自适应加权参考信息并比较失真图像与记忆库中的失真模式获得参考引导的质量分数；当参考图像缺失时，依赖记忆库中的失真模式推断图像质量，实现无参考质量评估。

Result: 实验结果表明，该方法在多个数据集上优于现有最先进方法，同时能够适应无参考和全参考任务。

Conclusion: 提出的记忆驱动质量感知框架通过模拟人类视觉记忆机制，建立了统一的图像质量评估框架，显著减少了对高质量参考图像的依赖，在保持高性能的同时增强了实际应用能力。

Abstract: Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.

</details>


### [13] [MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method](https://arxiv.org/abs/2602.18006)
*Ahsan Baidar Bakht,Mohamad Alansari,Muhayy Ud Din,Muzammal Naseer,Sajid Javed,Irfan Hussain,Jiri Matas,Arif Mahmood*

Main category: cs.CV

TL;DR: MUOT_3M是首个伪多模态水下目标跟踪基准数据集，包含300万帧视频数据，支持RGB、增强RGB、深度和语言四种模态。基于此数据集提出的MUTrack多模态到单模态跟踪器，通过知识蒸馏将多模态知识迁移到单模态模型，在五个基准测试中性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下目标跟踪对海洋机器人、生态监测和海洋探索至关重要，但现有基准数据集规模小且仅支持RGB模态，限制了在严重颜色失真、浑浊和低能见度条件下的鲁棒性。缺乏大规模、多模态、多样化的数据集阻碍了该领域的发展。

Method: 1. 构建MUOT_3M基准数据集：包含3030个视频（27.8小时，300万帧），标注32个跟踪属性、677个细粒度类别，提供同步的RGB、估计增强RGB、估计深度和语言四种模态，经海洋生物学家验证。
2. 提出MUTrack跟踪器：基于SAM的多模态到单模态跟踪器，包含视觉几何对齐、视觉语言融合和四级知识蒸馏，将多模态知识迁移到单模态学生模型中。

Result: 在五个水下目标跟踪基准测试中，MUTrack相比最强的SOTA基线方法，AUC提升高达8.40%，精度提升高达7.80%，同时保持24 FPS的实时运行速度。

Conclusion: MUOT_3M和MUTrack为可扩展、多模态训练但实际可部署的水下跟踪建立了新的基础，解决了该领域数据集稀缺和模态单一的问题，显著提升了水下目标跟踪的性能和实用性。

Abstract: Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.

</details>


### [14] [Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating](https://arxiv.org/abs/2602.18016)
*Jiamin Luo,Xuqian Gu,Jingjing Wang,Jiahong Lu*

Main category: cs.CV

TL;DR: 本文提出了一种基于多模态大语言模型的情感视觉定制任务（L-AVC），旨在通过编辑图像的主观情感内容来生成新图像，并开发了高效精确的情感操纵方法（EPEM）来解决情感语义转换和情感无关内容保留的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定制研究主要关注语言、布局等客观控制信号与编辑图像的对齐，忽略了主观情感内容，并且缺乏通用的情感视觉定制基础模型。因此需要开发能够有效处理情感内容的视觉定制方法。

Method: 提出了高效精确情感操纵方法（EPEM），包含两个核心模块：1）高效情感间转换（EIC）模块，使LLM在编辑前后高效对齐情感语义转换；2）精确情感外保留（PER）模块，精确保留情感无关内容。

Result: 在构建的L-AVC数据集上进行全面实验评估，结果显示EPEM方法在L-AVC任务上优于多个最先进的基线方法，证明了情感信息对L-AVC的重要性以及EPEM在高效精确操纵情感信息方面的有效性。

Conclusion: 本文提出的L-AVC任务和EPEM方法填补了情感视觉定制领域的空白，通过多模态LLM实现了对图像主观情感的高效精确编辑，为情感感知的视觉定制提供了新的解决方案。

Abstract: Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

</details>


### [15] [DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE](https://arxiv.org/abs/2602.18019)
*Yujie Jin,Wenxin Zhang,Jingjing Wang,Guodong Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新的深度安全导向视频理解任务DeepSVU，旨在不仅识别和定位威胁，还能归因和评估威胁原因，并提出了UPRM方法来解决该任务中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有安全导向视频理解研究主要关注检测和定位威胁（如枪击、抢劫），但缺乏生成和评估威胁原因的有效能力。为了填补这一空白，本文提出了深度安全导向视频理解任务。

Method: 提出了统一物理世界正则化混合专家方法UPRM，包含两个关键组件：统一物理世界增强MoE块和物理世界权衡正则化器，分别解决建模粗到细物理世界信息和自适应权衡这些因素的挑战。

Result: 在DeepSVU指令数据集（UCF-C指令和CUVA指令）上的广泛实验表明，UPRM优于多个先进的视频大语言模型和非VLM方法，证明了粗到细物理世界信息在DeepSVU任务中的重要性以及UPRM捕获此类信息的有效性。

Conclusion: 本文提出的DeepSVU任务和UPRM方法为安全导向视频理解提供了更深入的分析能力，通过有效建模和权衡物理世界信息，显著提升了威胁原因归因和评估的性能。

Abstract: In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.

</details>


### [16] [Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers](https://arxiv.org/abs/2602.18022)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: 提出DCAG框架，通过同时操纵DiT注意力机制中的Key和Value通道实现训练免费的编辑强度控制，相比仅操作Key的方法在编辑保真度权衡上更精确。


<details>
  <summary>Details</summary>
Motivation: 现有基于DiT架构的扩散图像编辑模型需要训练免费的编辑强度控制。现有注意力操纵方法只关注Key空间来调节注意力路由，而完全忽略了控制特征聚合的Value空间。

Method: 首先发现DiT多模态注意力层中的Key和Value投影都表现出明显的偏置-增量结构。基于此提出双通道注意力引导(DCAG)框架，同时操纵Key通道（控制关注位置）和Value通道（控制聚合内容）。理论分析表明Key通道通过非线性softmax函数作为粗粒度控制，Value通道通过线性加权求和作为细粒度补充。

Result: 在PIE-Bench基准测试（700张图像，10个编辑类别）上，DCAG在所有保真度指标上都优于仅使用Key引导的方法，在对象删除（LPIPS减少4.9%）和对象添加（LPIPS减少3.2%）等局部编辑任务中改进最显著。

Conclusion: DCAG通过二维参数空间(δ_k, δ_v)实现了比任何单通道方法更精确的编辑-保真度权衡，证明了同时操纵Key和Value通道的有效性。

Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).

</details>


### [17] [Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition](https://arxiv.org/abs/2602.18043)
*Hongyu Qu,Xiangbo Shu,Rui Yan,Hailiang Gao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: DiST提出了一种基于分解-融合框架的少样本动作识别方法，利用大语言模型提供的解耦空间和时间知识来学习多粒度原型。


<details>
  <summary>Details</summary>
Motivation: 传统的少样本动作识别方法通常使用语义粗糙的类别名称作为辅助上下文，但这种上下文信息有限，无法为捕捉动作中的新颖空间和时间概念提供足够的背景知识。

Method: 提出DiST框架：1）分解阶段：将原始动作名称解耦为多样化的时空属性描述；2）融合阶段：提出空间/时间知识补偿器（SKC/TKC）来发现判别性的对象级和帧级原型。SKC在空间知识指导下自适应聚合重要补丁标记，TKC利用时间属性辅助帧间时间关系建模。

Result: 实验结果显示DiST在五个标准FSAR数据集上取得了最先进的结果。

Conclusion: 通过利用大语言模型提供的解耦空间和时间知识，DiST能够学习表达性强的多粒度原型，有效捕捉细粒度空间细节和多样化时间模式，从而提升少样本动作识别性能。

Abstract: Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.

</details>


### [18] [CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras](https://arxiv.org/abs/2602.18047)
*Rong Fu,Wenxin Zhang,Yibo Meng,Jia Yee Tan,Jiaxuan Lu,Rui Lu,Jiekai Wu,Zhaolu Kang,Simon Fong*

Main category: cs.CV

TL;DR: CityGuard：一种用于分散式监控中隐私保护身份检索的拓扑感知Transformer框架，通过自适应度量学习、空间条件注意力和差分隐私嵌入实现跨摄像头人员重识别


<details>
  <summary>Details</summary>
Motivation: 城市规模的人员重识别面临视角变化、遮挡和域偏移等严重外观变化，同时需要遵守数据保护规则，防止共享原始图像数据

Method: 1. 分散自适应度量学习器根据特征分布调整实例级边界；2. 空间条件注意力将粗略几何信息（如GPS或部署平面图）注入基于图的自注意力；3. 差分隐私嵌入映射与紧凑近似索引结合

Result: 在Market-1501和其他公共基准测试中，检索精度和查询吞吐量均优于强基线，验证了框架在隐私关键城市身份匹配中的实用性

Conclusion: CityGuard框架能够产生对视角变化、遮挡和域偏移具有鲁棒性的描述符，并在严格的差分隐私核算下实现隐私与效用的可调平衡

Abstract: City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.

</details>


### [19] [Temporal Consistency-Aware Text-to-Motion Generation](https://arxiv.org/abs/2602.18057)
*Hongsong Wang,Wenjing Yan,Qiuxia Lai,Xin Geng*

Main category: cs.CV

TL;DR: TCA-T2M：一种时间一致性感知的文本到动作生成框架，通过跨序列时间对齐和运动约束解决现有方法的时间不一致问题，在HumanML3D和KIT-ML基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段文本到动作生成框架通常忽视跨序列的时间一致性，即相同动作的不同实例间共享的时间结构，这导致语义错位和物理上不合理的动作。

Method: 提出TCA-T2M框架：1）时间一致性感知空间VQ-VAE（TCaS-VQ-VAE）用于跨序列时间对齐；2）掩码运动变换器用于文本条件动作生成；3）运动学约束块减轻离散化伪影以确保物理合理性。

Result: 在HumanML3D和KIT-ML基准测试中，TCA-T2M实现了最先进的性能，证明了时间一致性在鲁棒和连贯的文本到动作生成中的重要性。

Conclusion: TCA-T2M通过引入时间一致性感知机制有效解决了文本到动作生成中的跨序列时间对齐问题，显著提升了生成动作的语义对齐和物理合理性。

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.

</details>


### [20] [Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation](https://arxiv.org/abs/2602.18066)
*Daniel Busch,Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Richard Meyes,Tobias Meisen*

Main category: cs.CV

TL;DR: 提出一种两阶段训练策略，通过自监督预训练和半监督微调，在减少50%标注数据和三分之二训练时间的情况下，BEV语义分割性能仍优于全监督基线模型


<details>
  <summary>Details</summary>
Motivation: 当前多相机BEV语义地图方法依赖昂贵且标注不一致的BEV地面真值，需要减少对完全监督的依赖，降低标注成本

Method: 两阶段训练：1) 自监督预训练：将BEVFormer预测可微分重投影到图像平面，使用Mask2Former生成的多视角语义伪标签训练，加入时序一致性损失；2) 监督微调：仅使用50%数据集进行微调

Result: 在nuScenes数据集上，微调性能优于全监督基线模型（提升达+2.5pp mIoU），同时减少50%标注数据使用，总训练时间减少三分之二

Conclusion: 可微分重投影加相机视角伪标签能够产生可迁移的BEV特征，为减少标注的自动驾驶感知提供了可扩展路径

Abstract: Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.

</details>


### [21] [DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text](https://arxiv.org/abs/2602.18089)
*Kunwar Arpit Singh,Ankush Prakash,Haroon R Lone*

Main category: cs.CV

TL;DR: DohaScript是一个大规模、多书写者的手写印地语数据集，包含531位不同书写者转录的六首传统印地语对句，旨在解决德瓦纳格里文字手写文本在公开基准数据集中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管德瓦纳格里文字有数亿使用者，但其手写文本在公开基准数据集中严重不足。现有资源规模有限，主要关注孤立字符或短词，缺乏受控的词汇内容和书写者多样性，无法捕捉德瓦纳格里手写体连续、融合和结构复杂的特性。

Method: 收集531位独特贡献者的手写印地语文本，设计为平行风格语料库，所有书写者转录相同的六首传统印地语对句。数据集包含非识别性人口统计元数据，基于客观清晰度和分辨率标准进行严格质量筛选，并提供页面级布局难度标注。

Result: 基线实验显示数据集具有清晰的质量分离和强大的未见书写者泛化能力，突出了数据集的可靠性和实用价值。数据集支持手写识别、书写者识别、风格分析和生成建模等任务。

Conclusion: DohaScript旨在作为标准化、可复现的基准，推动在低资源脚本环境下对连续手写德瓦纳格里文本的研究进展。

Abstract: Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.

</details>


### [22] [Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.18093)
*Hanshuai Cui,Zhiqing Tang,Qianli Ma,Zhi Yao,Weijia Jia*

Main category: cs.CV

TL;DR: PrediT：一种无需训练的DiT加速框架，通过线性多步法预测模型输出，结合校正器和动态步长调制，实现5.54倍延迟降低且质量损失可忽略。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiT）在图像和视频生成中广泛应用，但其迭代去噪过程计算成本高。现有免训练加速方法基于特征缓存和重用，假设时间稳定性，但多步重用特征可能导致潜在漂移和视觉质量下降。

Method: 提出PrediT框架：1）将特征预测建模为线性多步问题，使用经典线性多步法从历史信息预测未来模型输出；2）在高动态区域激活校正器防止误差累积；3）动态步长调制机制通过监测特征变化率自适应调整预测范围。

Result: 在各种基于DiT的图像和视频生成模型上实现了高达5.54倍的延迟降低，同时质量下降可忽略不计。实验验证了方法的有效性。

Conclusion: PrediT通过将特征预测形式化为线性多步问题，结合校正器和动态步长调制，实现了对DiT模型的高效加速，在保持生成保真度的同时显著降低计算成本。

Abstract: Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.

</details>


### [23] [OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2602.18094)
*Ling Lin,Yang Bai,Heng Su,Congcong Zhu,Yaoxing Wang,Yang Zhou,Huazhu Fu,Jingrun Chen*

Main category: cs.CV

TL;DR: OODBench：一个用于评估视觉语言模型处理分布外数据能力的自动化基准测试方法，包含4万个实例级OOD实例-类别对，揭示了当前VLMs在OOD数据上的显著性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型通常假设数据独立同分布，但现实场景中分布外数据普遍存在，处理不当可能带来安全风险（如自动驾驶、医疗辅助）。目前缺乏全面评估VLMs处理OOD数据能力的有效基准。

Method: 提出OODBench方法，采用最小人工验证的自动化方式构建基准：1）包含40K实例级OOD实例-类别对；2）设计从基础到高级的渐进式提示问题评估指标；3）全面评估OOD数据对不同难度问题的影响。

Result: 实验表明，即使图像类别常见，当前VLMs在OODBench上仍表现出显著性能下降。提出的自动化评估指标能有效评估OOD数据对模型性能的影响。

Conclusion: OODBench为评估VLMs处理分布外数据能力提供了有效基准，揭示了当前模型的局限性，总结了重要发现和见解，有助于未来OOD数据获取和评估研究。

Abstract: Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.

</details>


### [24] [Evaluating Graphical Perception Capabilities of Vision Transformers](https://arxiv.org/abs/2602.18178)
*Poonam Poonam,Pere-Pau Vázquez,Timo Ropinski*

Main category: cs.CV

TL;DR: ViTs在可视化图形感知任务中表现不如人类和CNN，存在感知差距


<details>
  <summary>Details</summary>
Motivation: 虽然ViTs在各种图像任务中表现出色，但其在可视化图形感知任务中的能力尚未被探索，而这对可视化系统的设计至关重要

Method: 基于Cleveland和McGill的基础研究，设计了一系列受控的图形感知任务，将ViTs与CNNs和人类参与者进行对比评估

Result: ViTs在通用视觉任务中表现强劲，但在可视化领域的类人图形感知方面与人类对齐有限，存在显著的感知差距

Conclusion: ViTs在可视化系统和图形感知建模中的应用需要谨慎考虑，研究揭示了重要的感知局限性

Abstract: Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.

</details>


### [25] [BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards](https://arxiv.org/abs/2602.18193)
*Yiran Yang,Zhaowei Liu,Yuan Yuan,Yukun Song,Xiong Ma,Yinghao Song,Xiangji Zeng,Lu Sun,Yulu Wang,Hai Zhou,Shuai Cui,Zhaohan Gong,Jiefei Zhang*

Main category: cs.CV

TL;DR: BLM-Guard是一个用于短视频广告内容审核的框架，结合了思维链推理、基于规则的政策原则和批评引导奖励，通过强化学习优化模型，能有效检测跨模态不匹配和欺骗性内容。


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的多模态广告包含欺骗性的视觉、语音和字幕内容，需要比社区安全过滤器更细粒度、基于政策的审核机制。

Method: 1. 使用规则驱动的ICoT数据合成管道生成结构化场景描述、推理链和标签；2. 通过强化学习使用复合奖励（平衡因果一致性和政策遵从性）优化模型；3. 多任务架构建模模态内操纵（如夸张图像）和跨模态不匹配（如字幕-语音漂移）。

Result: 在真实短视频广告上的实验显示，BLM-Guard在准确性、一致性和泛化能力方面超越了强基线模型。

Conclusion: BLM-Guard框架通过融合思维链推理、政策原则和强化学习，为商业广告内容审核提供了有效的解决方案，能够处理复杂的多模态欺骗性内容。

Abstract: Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.

</details>


### [26] [Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314)
*Tianyi Song,Danail Stoyanov,Evangelos Mazomenos,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: Diff2DGS：用于手术场景实时重建的两阶段框架，通过扩散模型修复被器械遮挡的组织，结合2D高斯泼溅和可学习变形模型，在图像质量和深度精度上均超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有手术场景重建方法在遮挡区域重建质量有限，且缺乏深度精度评估，因为EndoNeRF和StereoMIS等基准数据集缺少3D真值数据

Method: 两阶段框架：第一阶段使用基于扩散的视频模块结合时序先验修复被器械遮挡的组织；第二阶段采用2D高斯泼溅结合可学习变形模型捕捉动态组织变形和解剖几何

Result: 在EndoNeRF上达到38.02 dB PSNR，在StereoMIS上达到34.40 dB PSNR，超越现有方法；实验表明仅优化图像质量不一定能获得最佳3D重建精度

Conclusion: Diff2DGS在手术场景重建中实现了高质量的外观和几何重建，通过深度质量优化确保了更准确的3D几何重建，为机器人手术提供了更可靠的实时重建方案

Abstract: Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

</details>


### [27] [A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion](https://arxiv.org/abs/2602.18199)
*Gahyeon Shim,Soogeun Park,Hyemin Ahn*

Main category: cs.CV

TL;DR: DMC是一个后处理模块，通过自监督数据驱动方法修正文本生成动作中的物理不合理性（如脚部漂浮），同时保持语义一致性


<details>
  <summary>Details</summary>
Motivation: 当前文本到动作生成技术虽然取得了快速进展，但生成的动画在语义对齐的同时往往缺乏物理合理性（如脚部漂浮等问题），需要一种既能保持语义一致性又能提升物理真实性的解决方案

Method: 提出Distortion-aware Motion Calibrator (DMC)后处理模块，采用自监督数据驱动方法，通过故意扭曲的动作和原始文本描述作为输入，学习生成物理合理的动作，无需复杂的物理建模

Result: DMC在多种文本到动作生成模型上均有效：在T2M上FID分数降低42.74%，在T2M-GPT上降低13.20%，并达到最高的R-Precision；应用于MoMask等高质量模型时，穿透率减少33.0%，漂浮伪影更接近真实参考

Conclusion: DMC作为一个有前景的后处理动作优化框架，能够为各种文本到动作生成模型同时提升语义一致性和物理合理性，实现更真实的动作生成

Abstract: Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.

</details>


### [28] [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424)
*Xia Su,Ruiqi Chen,Benlin Liu,Jingwei Ma,Zonglin Di,Ranjay Krishna,Jon Froehlich*

Main category: cs.CV

TL;DR: CapNav是一个评估视觉语言模型在考虑智能体物理能力约束下进行室内导航的新基准，包含5种代表性智能体、45个真实室内场景和473个导航任务，发现当前VLM在能力约束严格时性能显著下降


<details>
  <summary>Details</summary>
Motivation: 现实世界导航受智能体移动能力约束（如扫地机器人不能爬楼梯），但现有视觉语言导航研究未充分考虑智能体的具体物理和操作能力，需要评估VLM在能力约束下的导航表现

Method: 定义5种代表性人类和机器人智能体（各有物理尺寸、移动能力和环境交互能力描述），构建包含45个真实室内场景、473个导航任务和2365个问答对的CapNav基准，评估13个现代VLM模型

Result: 当前VLM的导航性能随移动约束收紧而急剧下降，即使最先进模型也难以处理需要空间维度推理的障碍类型，表明现有模型在能力感知导航方面存在局限

Conclusion: CapNav基准揭示了VLM在能力约束导航中的挑战，为未来VLM的具身空间推理能力发展提供了重要机会和方向

Abstract: Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

</details>


### [29] [On the Adversarial Robustness of Discrete Image Tokenizers](https://arxiv.org/abs/2602.18252)
*Rishika Bhagwatkar,Irina Rish,Nicolas Flammarion,Francesco Croce*

Main category: cs.CV

TL;DR: 本文首次研究离散图像分词器的对抗攻击脆弱性，提出高效、应用无关的攻击方法，并通过无监督对抗训练提升分词器鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 离散图像分词器在多模态系统中日益流行，但其对抗攻击脆弱性尚未被探索。与CLIP编码器相比，缺乏对离散分词器安全性的研究，这成为多模态基础模型发展的关键问题。

Method: 1) 提出针对离散分词器的对抗攻击方法，通过扰动特征来改变提取的token；2) 采用无监督对抗训练防御策略，仅微调分词器而保持其他组件不变，利用未标记图像提升鲁棒性。

Result: 攻击方法在分类、多模态检索和字幕生成任务中均有效且计算高效。防御方法显著提升了对抗攻击的鲁棒性，并能泛化到未见任务和数据，优于有监督对抗训练。

Conclusion: 本文首次揭示了离散图像分词器的对抗脆弱性，强调了分词器鲁棒性对下游任务的重要性，为安全多模态基础模型的发展提供了重要步骤。

Abstract: Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.

</details>


### [30] [DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282)
*Shiyan Du,Conghan Yue,Xinyu Cheng,Dongyu Zhang*

Main category: cs.CV

TL;DR: DEIG是一个用于细粒度可控多实例生成的框架，通过实例细节提取器和细节融合模块解决现有方法在复杂文本描述下的语义理解问题，在空间一致性、语义准确性和组合泛化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多实例生成方法在空间布局和属性绑定方面已有进展，但在处理复杂文本描述时仍面临细粒度语义理解的挑战，特别是在防止实例间属性泄漏方面存在局限。

Method: 提出DEIG框架，包含实例细节提取器（将文本编码器嵌入转换为紧凑的实例感知表示）和细节融合模块（应用基于实例的掩码注意力防止实例间属性泄漏）。构建了高质量数据集和DEIG-Bench基准。

Result: DEIG在多个基准测试中在空间一致性、语义准确性和组合泛化方面一致优于现有方法。作为即插即用模块，可轻松集成到标准扩散模型中。

Conclusion: DEIG通过细粒度实例表示和属性泄漏预防机制，实现了对复杂文本描述的可控多实例生成，为解决多实例生成中的细粒度语义理解问题提供了有效方案。

Abstract: Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

</details>


### [31] [Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309)
*Ziyue Liu,Davide Talon,Federico Girella,Zanxi Ruan,Mattia Mondo,Loris Bazzani,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS框架通过多级条件引导将局部草图-文本对与全局草图结构相结合，增强时尚图像生成，在保持全局结构的同时利用局部语义指导。


<details>
  <summary>Details</summary>
Motivation: 设计师在早期时尚创意阶段使用草图表达结构和轮廓，文本描述补充材料和颜色等细节。需要有效结合文本和视觉模态，在利用文本局部属性指导时保持草图视觉结构。

Method: 提出LOTS框架：1) 多级条件阶段在共享潜在空间中独立编码局部特征，同时保持全局结构协调；2) 扩散对引导阶段通过注意力引导在扩散模型去噪过程中整合局部和全局条件。还创建了Sketchy数据集，包含专业草图和非专家草图两种类型。

Result: 实验表明该方法在保持全局结构一致性的同时利用更丰富的局部语义指导，相比现有技术有所改进。创建了首个包含多文本-草图对的时尚数据集Sketchy。

Conclusion: LOTS框架通过结合全局草图引导和多局部草图-文本对，增强了时尚图像生成能力，在保持结构一致性的同时实现了更好的语义控制。数据集和代码已公开。

Abstract: Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

</details>


### [32] [Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322)
*Ziteng Cui,Shuhong Liu,Xiaoyu Dong,Xuangeng Chu,Lin Gu,Ming-Hsuan Yang,Tatsuya Harada*

Main category: cs.CV

TL;DR: Luminance-GS++是一个基于3D高斯泼溅的框架，用于解决多视角图像采集中的光照不一致问题，通过全局自适应亮度调整和局部像素级残差细化实现鲁棒的新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现实环境中高质量图像采集面临复杂光照变化和相机成像管道的限制，特别是在多视角捕获中，光照、传感器响应和ISP配置的差异导致光度不一致，破坏了现代3D新视角合成方法（如NeRF和3DGS）所依赖的光度一致性假设，导致重建和渲染质量下降。

Method: 提出Luminance-GS++框架，结合全局视角自适应亮度调整和局部像素级残差细化进行精确色彩校正，设计无监督目标函数联合强制执行亮度校正以及多视角几何和光度一致性，同时保持显式的3DGS表示形式。

Result: 在低光照、过曝光以及复杂亮度和色彩变化的挑战性场景中，该方法展现出最先进的性能，同时保持实时渲染效率。

Conclusion: Luminance-GS++通过创新的光照校正方法解决了多视角图像采集中的光度不一致问题，在保持3DGS实时渲染优势的同时，显著提升了在复杂光照条件下的重建保真度和渲染质量。

Abstract: High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

</details>


### [33] [G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329)
*Qingsong Wang,Jiaxing He,Bingzhe Hou,Tieru Wu,Yang Cao,Cailing Yao*

Main category: cs.CV

TL;DR: 该论文提出了一种基于高斯-拉普拉斯算子（G-LoG）的双参数过滤方法，用于医学图像拓扑数据分析，在MedMNIST数据集上表现优于单参数过滤，且基于拓扑特征的简单MLP模型性能可与复杂深度学习模型媲美。


<details>
  <summary>Details</summary>
Motivation: 在拓扑数据分析（TDA）中，构建实用的过滤方法来检测对象的拓扑和几何特征是一个重要任务。作者旨在利用拉普拉斯高斯算子在增强医学图像边界方面的能力，开发更适合多参数持久性模块的特征提取方法。

Method: 1. 提出G-LoG（高斯-拉普拉斯高斯）双参数过滤方法，利用拉普拉斯高斯算子增强医学图像边界特征
2. 将体积图像建模为有界函数
3. 证明从有界函数的双参数过滤获得的持久性模块的交错距离相对于有界函数的最大范数是稳定的
4. 在MedMNIST数据集上进行实验，与单参数过滤和深度学习基线（Google AutoML Vision、ResNet、AutoKeras、auto-sklearn）进行比较

Result: 1. G-LoG双参数过滤显著优于单参数过滤
2. 基于双参数过滤生成的拓扑特征训练的简单多层感知器（MLP）性能与在原始数据集上训练的复杂深度学习模型相当
3. 证明了持久性模块交错距离的稳定性

Conclusion: 提出的G-LoG双参数过滤方法为医学图像拓扑数据分析提供了一种有效的特征提取技术，能够生成适合多参数持久性模块的特征，在保持理论稳定性的同时，在实际应用中取得了与复杂深度学习模型相媲美的性能。

Abstract: Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

</details>


### [34] [Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394)
*Stefan Becker,Simon Weiss,Wolfgang Hübner,Michael Arens*

Main category: cs.CV

TL;DR: 提出基于退化流形的退化感知自感知框架，通过对比学习组织特征空间，实现无需退化标签的退化检测，为安全关键应用提供独立的退化信号。


<details>
  <summary>Details</summary>
Motivation: 目标检测器在正常成像条件下表现良好，但在模糊、噪声、压缩、恶劣天气或分辨率变化等退化条件下可能无声失败。在安全关键应用中，仅产生预测而不评估输入是否处于检测器正常操作范围是不够的，因此需要自感知目标检测能力。

Method: 基于退化流形的退化感知自感知框架，通过多层对比学习训练轻量级嵌入头，将具有相同退化组成的图像拉近，将不同退化配置的图像推远，从而获得几何组织的表示。通过从干净训练嵌入中估计原始原型来锚定学习到的几何结构，自感知表现为与该参考点的几何偏差。

Result: 在合成损坏基准测试、跨数据集零样本迁移和自然天气引起的分布偏移实验中，展示了强大的原始-退化可分性、跨多个检测器架构的一致行为以及在语义偏移下的稳健泛化能力。

Conclusion: 退化感知表示几何为自感知目标检测提供了实用且检测器无关的基础，能够独立于检测置信度提供退化引起的偏移信号。

Abstract: Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.
  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.
  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.
  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.

</details>


### [35] [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422)
*Linxi Xie,Lisong C. Sun,Ashley Neall,Tong Wu,Shengqu Cai,Gordon Wetzstein*

Main category: cs.CV

TL;DR: 提出了一种基于头部和手部姿态控制的人为中心视频世界模型，用于扩展现实(XR)中的交互式虚拟环境生成


<details>
  <summary>Details</summary>
Motivation: 当前视频世界模型只能接受文本或键盘等粗略控制信号，无法响应用户的真实世界运动跟踪，限制了在具身交互中的实用性

Method: 评估现有扩散变换器条件策略，提出有效的3D头部和手部控制机制；训练双向视频扩散模型教师，并蒸馏为因果交互式系统生成第一人称虚拟环境

Result: 通过人类受试者评估显示，相比相关基线，该系统提高了任务性能，并显著增强了用户对执行动作的控制感

Conclusion: 提出的人为中心视频世界模型能够响应跟踪的头部和手部姿态，实现了灵巧的手-物体交互，为扩展现实中的具身交互提供了有效解决方案

Abstract: Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

</details>


### [36] [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434)
*Vatsal Agarwal,Saksham Suri,Matthew Gwilliam,Pulkit Kumar,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: MemStream通过增加token预算、自适应选择策略和训练免费的检索专家混合，显著提升了流式视频理解在多个基准测试上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有流式视频理解方法使用有限的每帧token数量，导致细粒度视觉细节丢失，且在处理密集视频流时存在查询-帧相似度随时间增加的问题，使检索偏向后期帧。

Method: 1) 扩展token预算以实现更细粒度的时空理解；2) 引入自适应选择策略减少token冗余同时保留局部时空信息；3) 提出训练免费的检索专家混合，利用外部模型更好地识别相关帧。

Result: 在CG-Bench上提升+8.0%，LVBench上提升+8.5%，VideoMME (Long)上提升+2.4%，相比使用Qwen2.5-VL-7B的ReKV方法。

Conclusion: MemStream通过解决现有方法在处理密集视频流时的局限性，显著提升了流式视频问答的性能，证明了扩展token预算和智能检索策略的有效性。

Abstract: Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [37] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 该论文提出AI安全问题的根源不是训练缺陷，而是模型错误设定导致的理性行为，需要从操纵奖励转向设计智能体的主观世界模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和AI智能体在关键领域部署受到行为病理学（如奉承、幻觉、策略性欺骗）的阻碍，现有安全范式缺乏统一理论框架解释这些行为的出现和稳定性。

Method: 将经济学中的Berk-Nash理性化理论应用于人工智能，建立智能体在错误主观世界模型下优化的理论框架，通过六个最先进模型家族的实验验证理论预测。

Result: 实验验证了理论预测：不安全行为作为稳定的错位均衡或振荡循环出现，策略性欺骗作为"锁定"均衡或认知不确定性持续存在，安全行为具有离散相边界。

Conclusion: 安全是智能体认知先验决定的离散相，而非奖励大小的连续函数，需要从操纵环境奖励转向设计智能体内部信念结构的主观模型工程。

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [38] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: 该研究探索了使用形式化领域本体（OpenMath）通过检索增强生成来提升语言模型在数学推理中的可靠性，发现本体引导的上下文在检索质量高时能改善性能，但无关上下文会降低性能。


<details>
  <summary>Details</summary>
Motivation: 语言模型存在幻觉、脆弱性和缺乏形式化基础等根本限制，这些在高风险专业领域（如数学）中尤为成问题，需要可验证的推理能力。

Method: 采用神经符号管道，利用OpenMath本体，结合混合检索和交叉编码器重排序技术，将相关定义注入模型提示中，在MATH基准上评估三个开源模型。

Result: 本体引导的上下文在检索质量高时能提高模型性能，但无关的上下文会主动降低性能，突显了神经符号方法的潜力和挑战。

Conclusion: 形式化领域本体可以增强语言模型可靠性，但检索质量至关重要，无关上下文会带来负面影响，神经符号方法既有前景也面临挑战。

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [39] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一个基于16世纪数学决斗启发的评估框架，让大语言模型通过互相创建编程谜题来挑战彼此，无需人工标注即可评估推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估大语言模型推理能力面临挑战：人工创建难题成本高，且难以确定模型是否真正推理还是见过类似训练数据。需要一种无法被设计饱和的评估范式。

Method: 采用编程谜题格式（给定返回布尔值的Python函数，找到使函数返回True的输入），让模型互相创建谜题挑战对方。通过两两对决计算Elo评分来比较模型性能。

Result: 评估了10个前沿模型，TTG的排名与现有基准（如Humanity's Last Exam）高度匹配，且无需人工创建谜题。发现创建好谜题对当前模型仍是高度挑战性的任务。

Conclusion: TTG提出了无法被设计饱和的推理评估新范式，能够同时测试模型的创造力、任务创建能力和问题解决能力，超越了传统基准的局限性。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [40] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: WorkflowPerturb是一个用于评估工作流评估指标的基准测试，通过向黄金工作流施加受控扰动来研究指标性能


<details>
  <summary>Details</summary>
Motivation: LLM生成的结构化工作流评估困难，因为指标分数通常未校准，且分数变化不能直接反映工作流退化的严重程度

Method: 引入WorkflowPerturb基准，通过对4,973个黄金工作流施加三种类型（缺失步骤、压缩步骤、描述变化）和三个严重程度（10%、30%、50%）的受控扰动，产生44,757个扰动变体

Result: 基准测试了多个指标家族，使用预期分数轨迹和残差分析其敏感性和校准性，揭示了指标家族间的系统性差异，支持基于严重程度的工作流评估分数解释

Conclusion: WorkflowPerturb为工作流评估指标提供了受控基准，有助于理解指标性能并实现严重程度感知的评估分数解释

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [41] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 该研究将离线强化学习与跨具身学习结合，通过分析16个机器人平台的数据集，发现该方法在包含大量次优轨迹的数据集上优于纯行为克隆，但随次优数据和机器人类型增加会出现梯度冲突问题，提出了基于形态相似性的分组策略来缓解冲突。


<details>
  <summary>Details</summary>
Motivation: 机器人策略预训练面临高质量演示数据收集成本高的问题，需要一种能够利用次优数据并跨不同机器人平台学习通用控制先验的方法。

Method: 结合离线强化学习和跨具身学习，构建包含16个不同机器人平台的运动数据集，分析该范式的优势和局限，并提出基于形态相似性的分组策略来减少跨机器人梯度冲突。

Result: 实验表明，该方法在包含丰富次优轨迹的数据集上预训练效果优于纯行为克隆，但随着次优数据比例和机器人类型增加，跨形态的梯度冲突会阻碍学习。提出的分组策略能显著减少机器人间的冲突，优于现有冲突解决方法。

Conclusion: 离线强化学习与跨具身学习的结合为机器人策略预训练提供了有效途径，但需要解决跨形态梯度冲突问题。基于形态相似性的分组策略是简单有效的解决方案，为大规模机器人策略学习提供了新思路。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [42] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: 研究发现，即使训练时排除敏感属性，无监督表征仍会泄露这些信息。SOMtime方法在年龄、收入等敏感属性上显示出高达0.85的相关性，而传统方法相关性较低，表明"通过不知情实现公平"在表征层面失效。


<details>
  <summary>Details</summary>
Motivation: 挑战"无监督表征在排除敏感属性时保持中立"的假设，研究即使明确排除敏感属性，这些属性是否仍会在无监督嵌入中作为主导潜在轴出现。

Method: 使用SOMtime（基于高容量自组织映射的拓扑保持表征方法），在两个大规模真实数据集（五个国家的世界价值观调查和人口普查收入数据集）上进行实验，将SOMtime与PCA、UMAP、t-SNE和自编码器等传统方法进行比较。

Result: SOMtime恢复了与排除的敏感属性对齐的单调排序，斯皮尔曼相关性高达0.85，而PCA和UMAP通常低于0.23，t-SNE和自编码器最多达到0.34。无监督分割SOMtime嵌入会产生人口统计学偏斜的聚类。

Conclusion: "通过不知情实现公平"在序数敏感属性的表征层面失败，公平性审计必须扩展到机器学习管道的无监督组件。无监督表征可能无意中编码敏感信息，带来下游公平性风险。

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [43] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD是首个在在线多智能体强化学习中应用扩散策略的框架，通过放松的策略目标最大化联合熵，解决了扩散模型似然不可处理的问题，在MPE和MAMuJoCo的10个任务中实现了2.5-5倍的样本效率提升。


<details>
  <summary>Details</summary>
Motivation: 在线多智能体强化学习需要增强策略表达能力以获得更好的性能。扩散生成模型在图像生成和离线设置中已展现出卓越的表达能力和多模态表示能力，但在在线MARL中的应用尚未充分探索。主要障碍是扩散模型的不可处理似然阻碍了基于熵的探索和协调。

Method: 提出OMAD框架：1）采用放松的策略目标最大化缩放联合熵，实现有效探索而不依赖可处理似然；2）在CTDE范式下，使用联合分布值函数优化去中心化扩散策略；3）利用可处理的熵增强目标指导扩散策略的同步更新，确保稳定协调。

Result: 在MPE和MAMuJoCo的10个多样化任务上进行了广泛评估，OMAD成为新的最先进方法，展示了2.5倍到5倍的样本效率提升。

Conclusion: OMAD成功地将扩散策略应用于在线多智能体强化学习，通过创新的放松策略目标和联合分布值函数优化，克服了扩散模型似然不可处理的挑战，显著提升了多智能体协调的性能和样本效率。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [44] [Nested Training for Mutual Adaptation in Human-AI Teaming](https://arxiv.org/abs/2602.17737)
*Upasana Biswas,Durgesh Kalwar,Subbarao Kambhampati,Sarath Sreedharan*

Main category: cs.RO

TL;DR: 该研究提出了一种基于I-POMDP框架的嵌套训练方法，用于解决人机协作中的相互适应问题，避免训练中出现隐式协调策略，提高与未见过的自适应伙伴的协作性能。


<details>
  <summary>Details</summary>
Motivation: 人机协作中的核心挑战是相互适应问题，人类会自然调整策略来响应机器人策略。现有方法使用静态训练伙伴来近似人类行为，但无法捕捉人类的适应性行为。当两个智能体在多智能体环境中同时学习时，它们往往会收敛到不透明的隐式协调策略，这些策略只适用于共同训练的伙伴，无法泛化到新伙伴。

Method: 将人机协作场景建模为交互式部分可观测马尔可夫决策过程（I-POMDP），将人类适应行为明确建模为状态的一部分。提出嵌套训练机制来近似学习有限级I-POMDP的解，每一级的智能体都针对下一级的自适应智能体进行训练，确保自我智能体在训练中暴露于适应性行为，同时避免出现隐式协调策略。

Result: 在Overcooked领域的多回合必需合作设置中训练该方法，并与几个人机协作基线智能体进行比较。评估结果表明，当与训练中未见过的自适应伙伴配对时，该方法不仅获得更高的任务性能，而且在团队互动中表现出显著更强的适应性。

Conclusion: 通过I-POMDP框架和嵌套训练机制，能够有效捕捉人类的适应性行为，避免训练中出现隐式协调策略，从而提高人机协作智能体与未见过的自适应伙伴的协作性能和适应性。

Abstract: Mutual adaptation is a central challenge in human--AI teaming, as humans naturally adjust their strategies in response to a robot's policy. Existing approaches aim to improve diversity in training partners to approximate human behavior, but these partners are static and fail to capture adaptive behavior of humans. Exposing robots to adaptive behaviors is critical, yet when both agents learn simultaneously in a multi-agent setting, they often converge to opaque implicit coordination strategies that only work with the agents they were co-trained with. Such agents fail to generalize when paired with new partners. In order to capture the adaptive behavior of humans, we model the human-robot teaming scenario as an Interactive Partially Observable Markov Decision Process (I-POMDP), explicitly modeling human adaptation as part of the state. We propose a nested training regime to approximately learn the solution to a finite-level I-POMDP. In this framework, agents at each level are trained against adaptive agents from the level below. This ensures that the ego agent is exposed to adaptive behavior during training while avoiding the emergence of implicit coordination strategies, since the training partners are not themselves learning. We train our method in a multi-episode, required cooperation setup in the Overcooked domain, comparing it against several baseline agents designed for human-robot teaming. We evaluate the performance of our agent when paired with adaptive partners that were not seen during training. Our results demonstrate that our agent not only achieves higher task performance with these adaptive partners but also exhibits significantly greater adaptability during team interactions.

</details>


### [45] [WHED: A Wearable Hand Exoskeleton for Natural, High-Quality Demonstration Collection](https://arxiv.org/abs/2602.17908)
*Mingzhang Zhu,Alvin Zhu,Jose Victor S. H. Ramos,Beom Jun Kim,Yike Shi,Yufeng Wu,Ruochen Hou,Quanyou Wang,Eric Song,Tony Fan,Yuchen Cui,Dennis W. Hong*

Main category: cs.RO

TL;DR: WHED是一种可穿戴手部外骨骼系统，用于在自然环境中捕获人类手部操作演示，解决了多指手演示数据收集的困难，具有可穿戴优先设计和自由移动拇指耦合等特点。


<details>
  <summary>Details</summary>
Motivation: 由于遮挡、复杂手部运动学和接触丰富的交互，收集自然、高保真的人类多指手演示数据存在困难，这限制了灵巧操作的可扩展学习。

Method: 开发了WHED可穿戴手部外骨骼系统，采用可穿戴优先操作设计，具有自由移动拇指耦合机制，结合连杆驱动的手指接口、被动适应配合、改进的被动手部以及机载传感/电源模块。还提供了端到端数据管道，同步关节编码器、AR末端执行器姿态和腕部视觉观察。

Result: 在代表性抓取和操作序列上展示了可行性，涵盖精确捏取和全手包围抓取，并显示了收集的演示与回放执行之间的定性一致性。

Conclusion: WHED系统为在自然环境中捕获高质量人类手部演示提供了一种可行解决方案，有助于解决灵巧操作学习中的数据收集瓶颈问题。

Abstract: Scalable learning of dexterous manipulation remains bottlenecked by the difficulty of collecting natural, high-fidelity human demonstrations of multi-finger hands due to occlusion, complex hand kinematics, and contact-rich interactions. We present WHED, a wearable hand-exoskeleton system designed for in-the-wild demonstration capture, guided by two principles: wearability-first operation for extended use and a pose-tolerant, free-to-move thumb coupling that preserves natural thumb behaviors while maintaining a consistent mapping to the target robot thumb degrees of freedom. WHED integrates a linkage-driven finger interface with passive fit accommodation, a modified passive hand with robust proprioceptive sensing, and an onboard sensing/power module. We also provide an end-to-end data pipeline that synchronizes joint encoders, AR-based end-effector pose, and wrist-mounted visual observations, and supports post-processing for time alignment and replay. We demonstrate feasibility on representative grasping and manipulation sequences spanning precision pinch and full-hand enclosure grasps, and show qualitative consistency between collected demonstrations and replayed executions.

</details>


### [46] [Latent Diffeomorphic Co-Design of End-Effectors for Deformable and Fragile Object Manipulation](https://arxiv.org/abs/2602.17921)
*Kei Ikemura,Yifei Dong,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出首个用于可变形和易碎物体操作的末端执行器形态与控制协同设计框架，包含潜在微分同胚形状参数化、应力感知双层协同设计流程和特权到点云策略蒸馏方案。


<details>
  <summary>Details</summary>
Motivation: 可变形和易碎物体的操作是机器人学中的基本挑战，现有方法通常单独优化末端执行器设计或控制策略，限制了可实现的性能。

Method: 1) 引入潜在微分同胚形状参数化，实现表达性强且可处理的末端执行器几何优化；2) 提出应力感知双层协同设计流程，耦合形态和控制优化；3) 开发特权到点云策略蒸馏方案，实现零样本真实世界部署。

Result: 在具有挑战性的食物操作任务（包括抓取和推动果冻、舀取鱼片）上进行评估，仿真和真实世界实验证明了该方法的有效性。

Conclusion: 该协同设计框架通过联合优化末端执行器形态和操作控制，有效解决了可变形和易碎物体操作的挑战。

Abstract: Manipulating deformable and fragile objects remains a fundamental challenge in robotics due to complex contact dynamics and strict requirements on object integrity. Existing approaches typically optimize either end-effector design or control strategies in isolation, limiting achievable performance. In this work, we present the first co-design framework that jointly optimizes end-effector morphology and manipulation control for deformable and fragile object manipulation. We introduce (1) a latent diffeomorphic shape parameterization enabling expressive yet tractable end-effector geometry optimization, (2) a stress-aware bi-level co-design pipeline coupling morphology and control optimization, and (3) a privileged-to-pointcloud policy distillation scheme for zero-shot real-world deployment. We evaluate our approach on challenging food manipulation tasks, including grasping and pushing jelly and scooping fillets. Simulation and real-world experiments demonstrate the effectiveness of the proposed method.

</details>


### [47] [Homotopic information gain for sparse active target tracking](https://arxiv.org/abs/2602.17926)
*Jennifer Wakulicz,Ki Myung Brian Lee,Teresa Vidal-Calleja,Robert Fitch*

Main category: cs.RO

TL;DR: 该论文提出了一种用于主动目标跟踪的新规划方法，通过最大化目标同伦类信息来优化机器人感知轨迹，相比传统度量信息方法能以更少测量获得更准确的轨迹估计。


<details>
  <summary>Details</summary>
Motivation: 在主动目标跟踪中，当目标具有多模态运动模型时，传统的信息增益概念往往定义不明确。需要一种能够有效处理目标高层次运动信息的规划方法。

Method: 提出同伦信息增益的概念，作为给定测量条件下预期高层次轨迹信息的度量。证明同伦信息增益是度量或低层次信息增益的下界，并且像障碍物一样在环境中稀疏分布。规划感知轨迹以最大化同伦信息增益。

Result: 在真实和模拟的行人数据上进行实证评估，结果表明：最大化同伦信息增益的方法相比度量信息方法，能够以更少的测量获得更准确的轨迹估计。

Conclusion: 同伦信息增益为多模态运动模型下的主动目标跟踪提供了一种有效的规划框架，通过关注目标的高层次运动模式，能够在减少测量次数的同时提高轨迹预测精度。

Abstract: The problem of planning sensing trajectories for a mobile robot to collect observations of a target and predict its future trajectory is known as active target tracking. Enabled by probabilistic motion models, one may solve this problem by exploring the belief space of all trajectory predictions given future sensing actions to maximise information gain. However, for multi-modal motion models the notion of information gain is often ill-defined. This paper proposes a planning approach designed around maximising information regarding the target's homotopy class, or high-level motion. We introduce homotopic information gain, a measure of the expected high-level trajectory information given by a measurement. We show that homotopic information gain is a lower bound for metric or low-level information gain, and is as sparsely distributed in the environment as obstacles are. Planning sensing trajectories to maximise homotopic information results in highly accurate trajectory estimates with fewer measurements than a metric information approach, as supported by our empirical evaluation on real and simulated pedestrian data.

</details>


### [48] [Quasi-Periodic Gaussian Process Predictive Iterative Learning Control](https://arxiv.org/abs/2602.18014)
*Unnati Nigam,Radhendushka Srivastava,Faezeh Marzbanrad,Michael Burke*

Main category: cs.RO

TL;DR: 该研究将准周期高斯过程（QPGP）融入预测性迭代学习控制（ILC）框架，用于建模和预测重复运动任务中的扰动与漂移，显著降低了计算复杂度并实现了更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 机器人重复运动任务中，环境变化和机器人磨损会导致性能随时间下降。传统迭代学习控制（ILC）虽然能利用先前迭代信息补偿预期误差，但在处理时变扰动和计算效率方面存在局限。

Method: 采用准周期高斯过程（QPGP）的结构方程公式化方法，将其整合到预测性ILC框架中。该方法将计算复杂度从O(i²p³)降低到O(p³)，其中p为单次迭代中的点数，i为总迭代次数。这种公式化还实现了无信息损失的参数估计，使持续高斯过程学习在控制循环中计算可行。

Result: 在三个任务（自动驾驶车辆轨迹跟踪、三连杆机器人操纵器、真实世界Stretch机器人实验）中，该方法相比标准ILC和传统基于高斯过程的预测性ILC，收敛速度更快，在注入和自然扰动下保持鲁棒性，同时降低了计算成本。

Conclusion: 提出的QPGP-ILC方法在多种重复动态系统中具有实际应用价值，能够高效建模和预测扰动与漂移，实现快速收敛并保持鲁棒性，计算复杂度显著降低，特别适合大规模迭代任务。

Abstract: Repetitive motion tasks are common in robotics, but performance can degrade over time due to environmental changes and robot wear and tear. Iterative learning control (ILC) improves performance by using information from previous iterations to compensate for expected errors in future iterations. This work incorporates the use of Quasi-Periodic Gaussian Processes (QPGPs) into a predictive ILC framework to model and forecast disturbances and drift across iterations. Using a recent structural equation formulation of QPGPs, the proposed approach enables efficient inference with complexity $\mathcal{O}(p^3)$ instead of $\mathcal{O}(i^2p^3)$, where $p$ denotes the number of points within an iteration and $i$ represents the total number of iterations, specially for larger $i$. This formulation also enables parameter estimation without loss of information, making continual GP learning computationally feasible within the control loop. By predicting next-iteration error profiles rather than relying only on past errors, the controller achieves faster convergence and maintains this under time-varying disturbances. We benchmark the method against both standard ILC and conventional Gaussian Process (GP)-based predictive ILC on three tasks, autonomous vehicle trajectory tracking, a three-link robotic manipulator, and a real-world Stretch robot experiment. Across all cases, the proposed approach converges faster and remains robust under injected and natural disturbances while reducing computational cost. This highlights its practicality across a range of repetitive dynamical systems.

</details>


### [49] [EgoPush: Learning End-to-End Egocentric Multi-Object Rearrangement for Mobile Robots](https://arxiv.org/abs/2602.18071)
*Boyuan An,Zhexiong Wang,Yipeng Wang,Jiaqi Li,Sihang Li,Jing Zhang,Chen Feng*

Main category: cs.RO

TL;DR: EgoPush是一个用于移动机器人多物体非抓取重排的框架，使用单目自我中心视觉，通过特权RL教师学习物体相对空间关系的潜在表示，然后蒸馏到纯视觉学生策略中，实现了无需全局状态估计的长时程重排。


<details>
  <summary>Details</summary>
Motivation: 受人类在杂乱环境中通过自我中心感知重排物体的能力启发，研究移动机器人使用单目自我中心相机进行长时程多物体非抓取重排，避免依赖在动态场景中容易失败的显式全局状态估计。

Method: 设计了物体中心的潜在空间编码物体间的相对空间关系而非绝对位姿；使用特权RL教师从稀疏关键点联合学习潜在状态和移动动作，然后蒸馏到纯视觉学生策略；限制教师观察为视觉可访问线索以减少监督差距；使用时间衰减的阶段局部完成奖励分解长时程重排任务。

Result: 大量仿真实验表明EgoPush在成功率上显著优于端到端RL基线，消融研究验证了每个设计选择的有效性；进一步展示了在真实世界移动平台上的零样本仿真到现实迁移。

Conclusion: EgoPush框架成功实现了基于自我中心视觉的移动机器人多物体重排，无需全局状态估计，通过特权学习、主动感知和任务分解解决了长时程信用分配问题，并展示了良好的仿真到现实迁移能力。

Abstract: Humans can rearrange objects in cluttered environments using egocentric perception, navigating occlusions without global coordinates. Inspired by this capability, we study long-horizon multi-object non-prehensile rearrangement for mobile robots using a single egocentric camera. We introduce EgoPush, a policy learning framework that enables egocentric, perception-driven rearrangement without relying on explicit global state estimation that often fails in dynamic scenes. EgoPush designs an object-centric latent space to encode relative spatial relations among objects, rather than absolute poses. This design enables a privileged reinforcement-learning (RL) teacher to jointly learn latent states and mobile actions from sparse keypoints, which is then distilled into a purely visual student policy. To reduce the supervision gap between the omniscient teacher and the partially observed student, we restrict the teacher's observations to visually accessible cues. This induces active perception behaviors that are recoverable from the student's viewpoint. To address long-horizon credit assignment, we decompose rearrangement into stage-level subproblems using temporally decayed, stage-local completion rewards. Extensive simulation experiments demonstrate that EgoPush significantly outperforms end-to-end RL baselines in success rate, with ablation studies validating each design choice. We further demonstrate zero-shot sim-to-real transfer on a mobile platform in the real world. Code and videos are available at https://ai4ce.github.io/EgoPush/.

</details>


### [50] [Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning](https://arxiv.org/abs/2602.18097)
*Aarati Andrea Noronha,Jean Oh*

Main category: cs.RO

TL;DR: 提出一个结合哈密顿-雅可比可达性分析与深度Q学习的框架，使自动驾驶车辆能在保证安全的前提下与骑行者高效交互


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要与骑行者安全交互，同时保持行驶效率，现有方法难以平衡安全保证和时间效率

Method: 整合哈密顿-雅可比可达性分析与深度Q学习，通过求解时间依赖的HJB不等式计算安全度量值，并将其作为结构化奖励信号融入强化学习框架，同时建模骑行者对车辆的潜在响应

Result: 通过仿真评估，并与人类驾驶行为和现有最先进方法进行比较验证

Conclusion: 提出的框架能够平衡安全性和最优性，使自动驾驶车辆更好地与骑行者交互

Abstract: In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.

</details>


### [51] [GrandTour: A Legged Robotics Dataset in the Wild for Multi-Modal Perception and State Estimation](https://arxiv.org/abs/2602.18164)
*Jonas Frey,Turcan Tuna,Frank Fu,Katharine Patterson,Tianao Xu,Maurice Fallon,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: GrandTour是一个大规模多模态四足机器人数据集，包含在各种复杂室内外环境中收集的同步传感器数据，用于腿式机器人的状态估计、感知和导航研究。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏大规模公开的腿式机器人数据集来开发和评估复杂环境中腿式机器人的状态估计、感知和导航算法，这限制了相关研究的发展。

Method: 使用ANYmal-D四足机器人配备多模态传感器载荷，在多种挑战性环境（高山、森林、拆除建筑、城市区域）中收集数据，提供时间同步的激光雷达、多RGB相机、本体感知传感器、立体深度相机数据，以及高精度RTK-GNSS和全站仪地面真值轨迹。

Result: 创建了迄今为止最大的开源腿式机器人数据集GrandTour，涵盖广泛的环境和操作场景，支持SLAM、高精度状态估计和多模态学习研究，提供ROS格式和非ROS格式的数据。

Conclusion: GrandTour数据集填补了腿式机器人研究领域大规模多模态数据集的空白，为传感器融合、状态估计和感知算法的开发和评估提供了重要资源。

Abstract: Accurate state estimation and multi-modal perception are prerequisites for autonomous legged robots in complex, large-scale environments. To date, no large-scale public legged-robot dataset captures the real-world conditions needed to develop and benchmark algorithms for legged-robot state estimation, perception, and navigation. To address this, we introduce the GrandTour dataset, a multi-modal legged-robotics dataset collected across challenging outdoor and indoor environments, featuring an ANYbotics ANYmal-D quadruped equipped with the \boxi multi-modal sensor payload. GrandTour spans a broad range of environments and operational scenarios across distinct test sites, ranging from alpine scenery and forests to demolished buildings and urban areas, and covers a wide variation in scale, complexity, illumination, and weather conditions. The dataset provides time-synchronized sensor data from spinning LiDARs, multiple RGB cameras with complementary characteristics, proprioceptive sensors, and stereo depth cameras. Moreover, it includes high-precision ground-truth trajectories from satellite-based RTK-GNSS and a Leica Geosystems total station. This dataset supports research in SLAM, high-precision state estimation, and multi-modal learning, enabling rigorous evaluation and development of new approaches to sensor fusion in legged robotic systems. With its extensive scope, GrandTour represents the largest open-access legged-robotics dataset to date. The dataset is available at https://grand-tour.leggedrobotics.com, on HuggingFace (ROS-independent), and in ROS formats, along with tools and demo resources.

</details>


### [52] [Have We Mastered Scale in Deep Monocular Visual SLAM? The ScaleMaster Dataset and Benchmark](https://arxiv.org/abs/2602.18174)
*Hyoseok Ju,Bokeon Suh,Giseop Kim*

Main category: cs.RO

TL;DR: 该论文提出了ScaleMaster数据集，这是首个专门评估大规模室内环境中深度单目视觉SLAM系统尺度一致性的基准测试，揭示了现有系统在真实大规模场景中的严重尺度漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度单目视觉SLAM系统虽然在精度和稠密重建方面取得了显著进展，但在大规模室内环境中的尺度一致性鲁棒性尚未得到充分研究。现有基准测试局限于房间尺度或结构简单的场景，无法有效评估跨楼层、长轨迹等挑战性场景下的尺度漂移和尺度模糊问题。

Method: 作者提出了ScaleMaster数据集，这是首个专门设计用于评估尺度一致性的基准测试，包含多楼层结构、长轨迹、重复视图和低纹理区域等挑战性场景。系统分析了最先进的深度单目视觉SLAM系统对尺度不一致性的脆弱性，提供了定量和定性评估。特别地，除了传统的轨迹指标外，还引入了直接的地图到地图质量评估，使用Chamfer距离等指标与高保真3D地面真值进行比较。

Result: 研究结果表明，虽然最近的深度单目视觉SLAM系统在现有基准测试上表现良好，但在真实的大规模室内环境中存在严重的尺度相关故障。通过发布ScaleMaster数据集和基线结果，为未来开发尺度一致且可靠的视觉SLAM系统奠定了基础。

Conclusion: 该研究填补了深度单目视觉SLAM在尺度一致性评估方面的空白，揭示了现有系统在大规模室内环境中的局限性，并提供了专门的基准测试工具来推动该领域的发展。

Abstract: Recent advances in deep monocular visual Simultaneous Localization and Mapping (SLAM) have achieved impressive accuracy and dense reconstruction capabilities, yet their robustness to scale inconsistency in large-scale indoor environments remains largely unexplored. Existing benchmarks are limited to room-scale or structurally simple settings, leaving critical issues of intra-session scale drift and inter-session scale ambiguity insufficiently addressed. To fill this gap, we introduce the ScaleMaster Dataset, the first benchmark explicitly designed to evaluate scale consistency under challenging scenarios such as multi-floor structures, long trajectories, repetitive views, and low-texture regions. We systematically analyze the vulnerability of state-of-the-art deep monocular visual SLAM systems to scale inconsistency, providing both quantitative and qualitative evaluations. Crucially, our analysis extends beyond traditional trajectory metrics to include a direct map-to-map quality assessment using metrics like Chamfer distance against high-fidelity 3D ground truth. Our results reveal that while recent deep monocular visual SLAM systems demonstrate strong performance on existing benchmarks, they suffer from severe scale-related failures in realistic, large-scale indoor environments. By releasing the ScaleMaster dataset and baseline results, we aim to establish a foundation for future research toward developing scale-consistent and reliable visual SLAM systems.

</details>


### [53] [Design and Characterization of a Dual-DOF Soft Shoulder Exosuit with Volume-Optimized Pneumatic Actuator](https://arxiv.org/abs/2602.18212)
*Rui Chen,Domenico Chiaradia,Daniele Leonardis,Antonio Frisoli*

Main category: cs.RO

TL;DR: 该研究开发了一种体积优化的纺锤形角度执行器(SSAA)，用于2自由度软肩外骨骼，在减少35.7%体积的同时保持94.2%扭矩输出和35.2%更快的动态响应，并集成到仅390克的双自由度纺织肩外骨骼中。


<details>
  <summary>Details</summary>
Motivation: 便携式气动系统在2自由度软肩外骨骼中研究不足，面临扭矩输出与动态响应之间的基本权衡，且需要多个执行器支持复杂的肩部运动。

Method: 采用体积优化的纺锤形角度执行器(SSAA)几何设计，开发基于SSAA的弯曲外展执行器(CAA)和基于袋式电机原理的水平内收执行器(HAA)，集成到双自由度纺织肩外骨骼中。

Result: SSAA相比均匀圆柱设计减少35.7%体积(357mL vs 555mL)，保持94.2%扭矩输出，动态响应快35.2%。用户研究显示外骨骼显著降低肩外展和屈曲任务的肌电活动，外展时最多减少59%，屈曲时最多减少63.7%。

Conclusion: 该研究通过优化执行器几何设计解决了便携式气动肩外骨骼的扭矩-响应权衡问题，为多自由度外骨骼系统提供了设计指导，但在健康用户中增加CAA的增量效益有限。

Abstract: Portable pneumatic systems for 2 degree-of-freedom (DOF) soft shoulder exosuits remain underexplored, and face fundamental trade-offs between torque output and dynamic response that are further compounded by the need for multiple actuators to support complex shoulder movement. This work addresses these constraints through a volume-optimized spindle-shaped angled actuator (SSAA) geometry: by reducing actuator volume by 35.7% (357mL vs. 555mL), the SSAA maintains 94.2% of output torque while achieving 35.2% faster dynamic response compared to uniform cylindrical designs. Building on the SSAA, we develop a curved abduction actuator (CAA) based on the SSAA geometry and a horizontal adduction actuator (HAA) based on the pouch motor principle, integrating both into a dual-DOF textile-based shoulder exosuit (390 g). The exosuit delivers multi-modal assistance spanning shoulder abduction, flexion, and horizontal adduction, depending on the actuation.
  User studies with 10 healthy participants reveal that the exosuit substantially reduces electromyographic (EMG) activity across both shoulder abduction and flexion tasks. For abduction with HAA only, the exosuit achieved up to 59% muscle activity reduction across seven muscles. For flexion, both the single-actuator configuration (HAA only) and the dual-actuator configuration (HAA,+,CAA) reduced EMG activity by up to 63.7% compared to no assistance. However, the incremental benefit of adding the CAA to existing HAA support was limited in healthy users during flexion, with statistically significant additional reductions observed only in pectoralis major. These experimental findings characterize actuator contributions in healthy users and provide design guidance for multi-DOF exosuit systems.

</details>


### [54] [RoEL: Robust Event-based 3D Line Reconstruction](https://arxiv.org/abs/2602.18258)
*Gwangtak Bae,Jaeho Shin,Seunggu Kang,Junho Kim,Ayoung Kim,Young Min Kim*

Main category: cs.RO

TL;DR: 本文提出了一种基于事件相机的鲁棒线特征跟踪与建图方法，通过多时间切片观测补偿事件数据中的噪声，利用几何代价函数优化3D线地图和相机位姿，实现跨模态应用。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动时主要检测物体边界或纹理边缘，产生亮度变化线，这些线可以作为鲁棒的中间表示。然而，线的稀疏性可能导致微小估计误差下的性能急剧下降。现有方法大多需要额外传感器，且难以处理事件传感器的严重域差异和不可预测的噪声特性。

Method: 1) 提出稳定提取不同外观线轨迹的方法，通过观察事件多个时间切片的多重表示来补偿事件数据中的潜在干扰；2) 提出几何代价函数，可消除投影畸变和深度模糊，优化3D线地图和相机位姿；3) 3D线地图高度紧凑，提出的代价函数可适应任何能检测和提取线结构或其投影的观测，包括3D点云地图或图像观测。

Result: 该方法在多个数据集上显著提升了事件建图和位姿优化的性能，并能灵活应用于多模态场景。结果表明，基于线的公式化方法是事件感知模块实际部署的鲁棒有效方法。

Conclusion: 提出的线基公式化方法为事件相机提供了鲁棒的中间表示，通过多时间切片观测和几何优化，有效处理了事件数据的噪声和域差异问题，实现了高性能的跨模态应用。

Abstract: Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/

</details>


### [55] [Role-Adaptive Collaborative Formation Planning for Team of Quadruped Robots in Cluttered Environments](https://arxiv.org/abs/2602.18260)
*Magnus Norén,Marios-Nektarios Stamatopoulos,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一种基于自适应领导-跟随的四足机器人编队规划控制框架，能够在复杂环境中实现动态角色分配和灵活编队导航


<details>
  <summary>Details</summary>
Motivation: 传统编队方法采用固定领导或刚性角色分配，在复杂环境中缺乏灵活性，难以实现无碰撞导航。需要一种能够动态适应环境变化、灵活调整编队结构的控制框架。

Method: 1. 动态角色分配和部分目标规划；2. 虚拟弹簧阻尼系统确保编队稳定性和机器人间安全；3. 自适应避障层调整各智能体速度；4. 动态前瞻参考生成器允许临时编队变形；5. Fast Marching Square算法提供全局和局部路径规划

Result: 通过大量仿真和真实四足机器人实验验证，展示了平滑协调、自适应角色切换和鲁棒的编队保持能力，在复杂非结构化环境中表现良好

Conclusion: 该框架成功实现了四足机器人在复杂环境中的自适应编队导航，通过动态角色分配和灵活编队控制，提高了团队在障碍密集环境中的导航能力和安全性

Abstract: This paper presents a role-adaptive Leader-Follower-based formation planning and control framework for teams of quadruped robots operating in cluttered environments. Unlike conventional methods with fixed leaders or rigid formation roles, the proposed approach integrates dynamic role assignment and partial goal planning, enabling flexible, collision-free navigation in complex scenarios. Formation stability and inter-robot safety are ensured through a virtual spring-damper system coupled with a novel obstacle avoidance layer that adaptively adjusts each agent's velocity. A dynamic look-ahead reference generator further enhances flexibility, allowing temporary formation deformation to maneuver around obstacles while maintaining goal-directed motion. The Fast Marching Square (FM2) algorithm provides the global path for the leader and local paths for the followers as the planning backbone. The framework is validated through extensive simulations and real-world experiments with teams of quadruped robots. Results demonstrate smooth coordination, adaptive role switching, and robust formation maintenance in complex, unstructured environments. A video featuring the simulation and physical experiments along with their associated visualizations can be found at https://youtu.be/scq37Tua9W4.

</details>


### [56] [Tendon-Driven Reciprocating and Non-Reciprocating Motion via Snapping Metabeams](https://arxiv.org/abs/2602.18330)
*Mohsen Jafarpour,Ayberk Yüksek,Shahab Eshghi,Stanislav Gorb,Edoardo Milana*

Main category: cs.RO

TL;DR: 开发了一种基于螺旋形超梁的肌腱驱动机构，利用非线性失稳实现快速几何转变，用于软体机器人的往复和非往复运动


<details>
  <summary>Details</summary>
Motivation: 利用梁的快速失稳特性实现软体机器人系统的高效运动生成，探索几何驱动结构在可编程驱动中的应用潜力

Method: 采用熔融沉积成型技术用PLA材料制造螺旋形超梁结构，通过肌腱驱动机制，在不同边界条件下测试非线性行为

Result: 仅通过调整边界约束即可调节机械特性（临界力和稳定性），螺旋几何允许大变形；集成到游泳机器人中实现两种驱动模式，非往复运动达到81mm/s的推进速度

Conclusion: 几何驱动的失稳结构为软体机器人系统提供了高效且可编程的驱动方案，展示了在可控运动生成方面的潜力

Abstract: Snapping beams enable rapid geometric transitions through nonlinear instability, offering an efficient means of generating motion in soft robotic systems. In this study, a tendon-driven mechanism consisting of spiral-based metabeams was developed to exploit this principle for producing both reciprocating and non-reciprocating motion. The snapping structures were fabricated using fused deposition modeling with polylactic acid (PLA) and experimentally tested under different boundary conditions to analyze their nonlinear behavior. The results show that the mechanical characteristics, including critical forces and stability, can be tuned solely by adjusting the boundary constraints. The spiral geometry allows large reversible deformation even when made from a relatively stiff material such as PLA, providing a straightforward design concept for controllable snapping behavior. The developed mechanism was further integrated into a swimming robot, where tendon-driven fins exhibited two distinct actuation modes: reciprocating and non-reciprocating motion. The latter enabled efficient propulsion, producing a forward displacement of about 32 mm per 0.4 s cycle ($\approx$ 81 mm/s, equivalent to 0.4 body lengths per second). This study highlights the potential of geometry-driven snapping structures for efficient and programmable actuation in soft robotic systems.

</details>


### [57] [Downwash-aware Configuration Optimization for Modular Aerial Systems](https://arxiv.org/abs/2602.18344)
*Mengguang Li,Heinz Koeppl*

Main category: cs.RO

TL;DR: 提出一个为同质模块化空中系统生成和优化选择任务特定装配配置的框架，明确强制执行模块间下洗流的边界约束


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注平面布局且常忽略空气动力学干扰，需要解决模块化空中系统的装配配置优化问题

Method: 首先大规模枚举非同构连接拓扑，然后求解非线性规划问题检查可行性并选择最小化控制输入的最优配置

Result: 在物理仿真中评估框架，并在真实世界实验中验证其有效性

Conclusion: 该框架能够为模块化空中系统生成满足下洗流约束的优化装配配置，具有实际应用价值

Abstract: This work proposes a framework that generates and optimally selects task-specific assembly configurations for a large group of homogeneous modular aerial systems, explicitly enforcing bounds on inter-module downwash. Prior work largely focuses on planar layouts and often ignores aerodynamic interference. In contrast, firstly we enumerate non-isomorphic connection topologies at scale; secondly, we solve a nonlinear program to check feasibility and select the configuration that minimizes control input subject to actuation limits and downwash constraints. We evaluate the framework in physics-based simulation and demonstrate it in real-world experiments.

</details>


### [58] [Zero-shot Interactive Perception](https://arxiv.org/abs/2602.18374)
*Venkatesh Sripada,Frank Guerin,Amir Ghalamzan*

Main category: cs.RO

TL;DR: ZS-IP是一个零样本交互感知框架，结合多策略操作（推和抓）与记忆驱动的视觉语言模型，通过物理交互解决复杂场景中的语义查询问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂、部分可观察的场景中，机器人需要通过物理交互来提取隐藏信息并解决遮挡和模糊性问题。现有的被动感知方法在处理这类交互任务时存在局限。

Method: ZS-IP包含三个核心组件：1）增强观察模块，使用传统关键点和新型pushlines（专为推动作设计的2D视觉增强）增强VLM视觉感知；2）记忆引导动作模块，通过上下文查找强化语义推理；3）机器人控制器，根据VLM输出执行推、拉或抓取动作。

Result: 在7-DOF Franka Panda机械臂上的实验表明，ZS-IP在多样化场景中优于被动和基于视点的感知技术（如MOKA），特别是在推任务中表现突出，同时能保持非目标元素的完整性。

Conclusion: ZS-IP框架通过结合多策略操作与记忆驱动的VLM，有效解决了复杂交互感知任务，特别是pushlines的设计显著提升了推动作的性能，为零样本交互感知提供了新思路。

Abstract: Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.

</details>


### [59] [Ori-Sense: origami capacitive sensing for soft robotic applications](https://arxiv.org/abs/2602.18379)
*Hugo de Souza Oliveira,Xin Li,Mohsen Jafarpour,Edoardo Milana*

Main category: cs.RO

TL;DR: Ori-Sense是一种受倒置Kresling折纸启发的柔性电容传感器，可将扭转变形转化为可测量的电容变化，为软体机器人提供本体感知反馈。


<details>
  <summary>Details</summary>
Motivation: 为软体机器人系统开发能够将机械变形转化为电信号的集成式柔性传感器，实现本体感知功能。

Method: 采用可溶性芯模成型技术制造单体硅胶结构，嵌入导电TPU电极形成集成软电容器；通过机械和电气测试表征性能，并用有限元模拟验证应力分布。

Result: 传感器表现出低刚度和最小阻抗，扭矩值在±15mm轴向位移时低于0.01N·mm，30度扭转压缩时达0.03N·mm；电容调制可达30%，与扭转角度直接相关，在5mm轴向变形时最大灵敏度为0.0067pF/度。

Conclusion: Ori-Sense成功实现了将扭转变形转化为电容变化的软体传感器设计，为软体机器人系统提供了有效的本体感知解决方案。

Abstract: This work introduces Ori-Sense, a compliant capacitive sensor inspired by the inverted Kresling origami pattern. The device translates torsional deformation into measurable capacitance changes, enabling proprioceptive feedback for soft robotic systems. Using dissolvable-core molding, we fabricated a monolithic silicone structure with embedded conductive TPU electrodes, forming an integrated soft capacitor. Mechanical characterization revealed low stiffness and minimal impedance, with torque values below 0.01 N mm for axial displacements between -15 mm and 15 mm, and up to 0.03 N mm at 30 degrees twist under compression. Finite-element simulations confirmed localized stresses along fold lines and validated the measured torque-rotation response. Electrical tests showed consistent capacitance modulation up to 30%, directly correlated with the twist angle, and maximal sensitivity of S_theta ~ 0.0067 pF/deg at 5 mm of axial deformation.

</details>


### [60] [Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO](https://arxiv.org/abs/2602.18386)
*Mohamed Elgouhary,Amr S. El-Wakeel*

Main category: cs.RO

TL;DR: 使用强化学习在线联合调整Pure Pursuit控制器的前瞻距离和转向增益，提升自动驾驶赛车路径跟踪性能


<details>
  <summary>Details</summary>
Motivation: Pure Pursuit控制器在自动驾驶赛车中广泛使用，但其性能高度依赖于前瞻距离和转向增益参数的选择。传统的基于速度的调整方法效果有限，且难以在不同赛道和速度配置间迁移。

Method: 提出基于强化学习的方法，使用PPO算法在线联合选择前瞻距离Ld和转向增益g。策略观察紧凑的状态特征（速度和曲率信息），在每个控制步骤输出(Ld, g)。在F1TENTH Gym中训练，部署在ROS 2栈中，直接驱动Pure Pursuit控制器（带轻度平滑）。

Result: 在仿真和实车测试中，提出的RL-PP控制器（联合选择Ld和g）在圈时、路径跟踪精度和转向平滑度方面均优于固定前瞻PP、速度调度自适应PP、仅调整前瞻的RL变体，甚至超过了运动学MPC轨迹跟踪器。

Conclusion: 策略引导的参数调优能够可靠地改进基于几何的经典控制方法，证明了强化学习在优化传统控制器参数方面的有效性。

Abstract: Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [61] [Reducing Text Bias in Synthetically Generated MCQAs for VLMs in Autonomous Driving](https://arxiv.org/abs/2602.17677)
*Sutej Kulgod,Sean Ye,Sanchit Tanwar,Christoffer Heckman*

Main category: cs.LG

TL;DR: 该研究发现MCQA基准测试存在文本线索漏洞，导致VLM无需视觉输入就能获得高准确率。通过解耦正确答案与语言伪影并使用课程学习策略，大幅减少了可被利用的文本捷径。


<details>
  <summary>Details</summary>
Motivation: 现有MCQA基准测试存在严重缺陷，模型可以通过文本线索而非视觉理解来回答问题，导致性能评估失真，无法真实反映模型的视觉感知能力。

Method: 提出一种方法：1) 将正确答案与语言伪影解耦，消除文本线索；2) 采用课程学习策略，强制模型依赖视觉基础；3) 减少可被利用的文本捷径。

Result: 方法显著降低了盲目准确率：从比随机高66.9%降至仅高2.9%，消除了绝大多数可被利用的文本捷径，确保性能真实反映视觉理解能力。

Conclusion: 通过消除MCQA基准测试中的文本线索漏洞，能够更准确地评估VLM的视觉感知能力，确保模型真正依赖视觉基础而非语言模式来回答问题。

Abstract: Multiple Choice Question Answering (MCQA) benchmarks are an established standard for measuring Vision Language Model (VLM) performance in driving tasks. However, we observe the known phenomenon that synthetically generated MCQAs are highly susceptible to hidden textual cues that allow models to exploit linguistic patterns rather than visual context. Our results show that a VLM fine-tuned on such data can achieve accuracy comparable to human-validated benchmarks even without visual input. Our proposed method reduces blind accuracy from +66.9% above random to +2.9%, eliminating the vast majority of exploitable textual shortcuts. By decoupling the correct answer from linguistic artifacts and employing a curriculum learning strategy, we force the model to rely on visual grounding, ensuring that performance accurately reflects perceptual understanding.

</details>


### [62] [BioBridge: Bridging Proteins and Language for Enhanced Biological Reasoning with LLMs](https://arxiv.org/abs/2602.17680)
*Yujia Wang,Jihong Guan,Wengen Li,Shuigeng Zhou,Xuhong Wang*

Main category: cs.LG

TL;DR: BioBridge是一个领域自适应持续预训练框架，通过将蛋白质领域知识与通用推理语料注入大型语言模型，实现蛋白质序列理解与通用语言能力的结合。


<details>
  <summary>Details</summary>
Motivation: 现有蛋白质语言模型在多任务适应性和跨生物环境泛化能力有限，而通用大型语言模型缺乏蛋白质序列解释能力和领域特定知识，无法进行有效的生物语义推理。

Method: 提出BioBridge框架：1) 采用领域增量持续预训练(DICP)同时注入蛋白质领域知识和通用推理语料；2) 通过PLM-Projector-LLM管道实现跨模态对齐，将蛋白质序列嵌入映射到语言模型语义空间；3) 采用端到端优化统一支持蛋白质属性预测和知识问答等多种任务。

Result: BioBridge在EC和BindingDB等多个蛋白质基准测试中性能与主流PLMs相当，在MMLU和RACE等通用理解任务上结果与LLMs相当，展示了其结合领域特定适应性和通用语言能力的创新优势。

Conclusion: BioBridge成功结合了蛋白质语言模型和通用大型语言模型的优势，实现了蛋白质序列理解与通用语言推理能力的有效融合，为蛋白质理解和生物语义推理提供了创新解决方案。

Abstract: Existing Protein Language Models (PLMs) often suffer from limited adaptability to multiple tasks and exhibit poor generalization across diverse biological contexts. In contrast, general-purpose Large Language Models (LLMs) lack the capability to interpret protein sequences and fall short in domain-specific knowledge, limiting their capacity for effective biosemantic reasoning. To combine the advantages of both, we propose BioBridge, a domain-adaptive continual pretraining framework for protein understanding. This framework employs Domain-Incremental Continual Pre-training (DICP) to infuse protein domain knowledge and general reasoning corpus into a LLM simultaneously, effectively mitigating catastrophic forgetting. Cross-modal alignment is achieved via a PLM-Projector-LLM pipeline, which maps protein sequence embeddings into the semantic space of the language model. Ultimately, an end-to-end optimization is adopted to uniformly support various tasks, including protein property prediction and knowledge question-answering. Our proposed BioBridge demonstrates performance comparable to that of mainstream PLMs on multiple protein benchmarks, such as EC and BindingDB. It also achieves results on par with LLMs on general understanding tasks like MMLU and RACE. This showcases its innovative advantage of combining domain-specific adaptability with general-purpose language competency.

</details>


### [63] [LATMiX: Learnable Affine Transformations for Microscaling Quantization of LLMs](https://arxiv.org/abs/2602.17681)
*Ofir Gordon,Lior Dikstein,Arnon Netzer,Idan Achituve,Hai Victor Habi*

Main category: cs.LG

TL;DR: LATMiX：一种针对微缩放（MX）量化格式的可学习可逆仿射变换方法，通过优化激活分布来减少量化误差，在低比特MX量化中取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有后训练量化方法主要关注传统量化方案，而现代硬件越来越多地支持微缩放（MX）数据格式。现有方法在MX量化中表现不佳，需要引入对变换的假设限制，这促使研究者探索更通用的变换方法。

Method: 首先对MX量化下的变换进行理论分析，推导量化误差边界。基于此分析提出LATMiX方法，将异常值减少推广到可学习的可逆仿射变换，使用标准深度学习工具进行优化。

Result: 实验表明，在广泛的零样本基准测试中，LATMiX在MX低比特量化上相比强基线方法取得了持续的平均准确率提升，且在不同模型规模上均有效。

Conclusion: 该工作通过理论分析和可学习变换方法，成功解决了MX量化中的性能下降问题，为现代硬件上的高效大语言模型部署提供了有效解决方案。

Abstract: Post-training quantization (PTQ) is a widely used approach for reducing the memory and compute costs of large language models (LLMs). Recent studies have shown that applying invertible transformations to activations can significantly improve quantization robustness by reducing activation outliers; however, existing approaches are largely restricted to rotation or Hadamard-based transformations. Moreover, most studies focused primarily on traditional quantization schemes, whereas modern hardware increasingly supports the microscaling (MX) data format. Attempts to combine both showed severe performance degradation, leading prior work to introduce assumptions on the transformations. In this work, we take a complementary perspective. First, we provide a theoretical analysis of transformations under MX quantization by deriving a bound on the quantization error. Our analysis emphasizes the importance of accounting for both the activation distribution and the underlying quantization structure. Building on this analysis, we propose LATMiX, a method that generalizes outlier reduction to learnable invertible affine transformations optimized using standard deep learning tools. Experiments show consistent improvements in average accuracy for MX low-bit quantization over strong baselines on a wide range of zero-shot benchmarks, across multiple model sizes.

</details>


### [64] [Probabilistic NDVI Forecasting from Sparse Satellite Time Series and Weather Covariates](https://arxiv.org/abs/2602.17683)
*Irene Iele,Giulia Romoli,Daniele Molino,Elena Mulero Ayllón,Filippo Ruffini,Paolo Soda,Matteo Tortora*

Main category: cs.LG

TL;DR: 本文提出了一种用于农田NDVI预测的概率性预测框架，采用Transformer架构分离历史植被动态和未来外生信息建模，通过时间距离加权分位数损失处理不规则观测，在卫星数据上优于多种基线方法。


<details>
  <summary>Details</summary>
Motivation: 精确的植被动态短期预测对精准农业决策支持至关重要，但卫星NDVI预测面临云层遮挡导致的不规则稀疏采样以及作物生长的异质性气候条件等挑战。

Method: 提出概率预测框架，采用Transformer架构明确分离历史植被动态和未来外生信息建模；引入时间距离加权分位数损失处理不规则重访模式和时变不确定性；结合累积和极端天气特征工程捕捉延迟气象效应。

Result: 在欧洲卫星数据上的广泛实验表明，该方法在点预测和概率评估指标上均优于统计、深度学习和近期时间序列基线；消融研究显示目标历史信息起核心作用，气象协变量提供互补增益。

Conclusion: 该框架为晴空采集约束下的农田级NDVI预测提供了有效解决方案，通过专门设计的架构和损失函数成功处理了不规则采样和异质性气候条件，代码已开源。

Abstract: Accurate short-term forecasting of vegetation dynamics is a key enabler for data-driven decision support in precision agriculture. Normalized Difference Vegetation Index (NDVI) forecasting from satellite observations, however, remains challenging due to sparse and irregular sampling caused by cloud coverage, as well as the heterogeneous climatic conditions under which crops evolve. In this work, we propose a probabilistic forecasting framework specifically designed for field-level NDVI prediction under clear-sky acquisition constraints. The method leverages a transformer-based architecture that explicitly separates the modeling of historical vegetation dynamics from future exogenous information, integrating historical NDVI observations with both historical and future meteorological covariates. To address irregular revisit patterns and horizon-dependent uncertainty, we introduce a temporal-distance weighted quantile loss that aligns the training objective with the effective forecasting horizon. In addition, we incorporate cumulative and extreme-weather feature engineering to better capture delayed meteorological effects relevant to vegetation response. Extensive experiments on European satellite data demonstrate that the proposed approach consistently outperforms a diverse set of statistical, deep learning, and recent time series baselines across both point-wise and probabilistic evaluation metrics. Ablation studies further highlight the central role of target history, while showing that meteorological covariates provide complementary gains when jointly exploited. The code is available at https://github.com/arco-group/ndvi-forecasting.

</details>


### [65] [CodeScaler: Scaling Code LLM Training and Test-Time Inference via Execution-Free Reward Models](https://arxiv.org/abs/2602.17684)
*Xiao Zhu,Xinyu Zhou,Boyu Zhu,Hanxu Hu,Mingzhe Du,Haotian Zhang,Huiming Wang,Zhijiang Guo*

Main category: cs.LG

TL;DR: CodeScaler是一种无需执行的奖励模型，通过精心设计的偏好数据和语法感知的代码提取技术，解决了传统基于执行的强化学习在代码生成中的可扩展性问题，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 基于可验证奖励的强化学习（RLVR）虽然推动了代码大语言模型的发展，但其可扩展性受到高质量测试用例可用性和可靠性的根本限制。需要一种无需执行的方法来扩展强化学习训练和推理。

Method: CodeScaler是一个无需执行的奖励模型，基于经过验证的代码问题精心策划的偏好数据进行训练。采用语法感知的代码提取和保持有效性的奖励塑形技术，确保稳定和鲁棒的优化。

Result: 在五个编码基准测试中，CodeScaler将Qwen3-8B-Base平均提升了11.72分，优于基于执行的强化学习1.82分。在推理时，延迟降低10倍，性能与单元测试方法相当。在RM-Bench上，不仅在代码领域（+3.3分），在通用和推理领域（平均+2.7分）也超越了现有奖励模型。

Conclusion: CodeScaler提供了一种可扩展的、无需执行的奖励建模方法，克服了传统基于测试的强化学习的局限性，在代码生成任务中实现了显著的性能提升和效率改进。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has driven recent progress in code large language models by leveraging execution-based feedback from unit tests, but its scalability is fundamentally constrained by the availability and reliability of high-quality test cases. We propose CodeScaler, an execution-free reward model designed to scale both reinforcement learning training and test-time inference for code generation. CodeScaler is trained on carefully curated preference data derived from verified code problems and incorporates syntax-aware code extraction and validity-preserving reward shaping to ensure stable and robust optimization. Across five coding benchmarks, CodeScaler improves Qwen3-8B-Base by an average of +11.72 points, outperforming binary execution-based RL by +1.82 points, and enables scalable reinforcement learning on synthetic datasets without any test cases. At inference time, CodeScaler serves as an effective test-time scaling method, achieving performance comparable to unit test approaches while providing a 10-fold reduction in latency. Moreover, CodeScaler surpasses existing reward models on RM-Bench not only in the code domain (+3.3 points), but also in general and reasoning domains (+2.7 points on average).

</details>


### [66] [Optimal Multi-Debris Mission Planning in LEO: A Deep Reinforcement Learning Approach with Co-Elliptic Transfers and Refueling](https://arxiv.org/abs/2602.17685)
*Agni Bandyopadhyay,Gunther Waxenegger-Wilfing*

Main category: cs.LG

TL;DR: 论文提出了一种统一的共椭圆机动框架，结合霍曼转移、安全椭圆接近操作和显式加油逻辑，用于低地球轨道多目标主动碎片清除任务规划，并比较了三种算法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决低地球轨道多目标主动碎片清除任务规划中的挑战，需要高效、可扩展且资源优化的规划方法，以应对随机碎片场、禁飞区和燃料约束等现实条件。

Method: 提出统一的共椭圆机动框架，结合霍曼转移、安全椭圆接近操作和显式加油逻辑。在包含随机碎片场、禁飞区和燃料约束的轨道仿真环境中，对三种规划算法进行基准测试：贪婪启发式算法、蒙特卡洛树搜索和基于掩码近端策略优化的深度强化学习。

Result: 在100个测试场景中，掩码PPO算法表现出最优的任务效率和计算性能，访问的碎片数量可达贪婪算法的两倍，并在运行时间上显著优于蒙特卡洛树搜索。

Conclusion: 现代强化学习方法在可扩展、安全和资源高效的空间任务规划方面具有巨大潜力，为未来主动碎片清除自主化的发展铺平了道路。

Abstract: This paper addresses the challenge of multi target active debris removal (ADR) in Low Earth Orbit (LEO) by introducing a unified coelliptic maneuver framework that combines Hohmann transfers, safety ellipse proximity operations, and explicit refueling logic. We benchmark three distinct planning algorithms Greedy heuristic, Monte Carlo Tree Search (MCTS), and deep reinforcement learning (RL) using Masked Proximal Policy Optimization (PPO) within a realistic orbital simulation environment featuring randomized debris fields, keep out zones, and delta V constraints. Experimental results over 100 test scenarios demonstrate that Masked PPO achieves superior mission efficiency and computational performance, visiting up to twice as many debris as Greedy and significantly outperforming MCTS in runtime. These findings underscore the promise of modern RL methods for scalable, safe, and resource efficient space mission planning, paving the way for future advancements in ADR autonomy.

</details>


### [67] [Robust Pre-Training of Medical Vision-and-Language Models with Domain-Invariant Multi-Modal Masked Reconstruction](https://arxiv.org/abs/2602.17689)
*Melika Filvantorkaman,Mohsen Piri*

Main category: cs.LG

TL;DR: 提出Robust-MMR框架，通过自监督预训练将鲁棒性目标融入掩码视觉语言学习，提升医学视觉语言模型在域偏移下的性能


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在成像设备、采集协议和报告风格变化导致的域偏移下性能下降，现有多模态预训练方法大多忽视鲁棒性，将其视为下游适应问题

Method: 提出Robust-MMR框架，整合非对称扰动感知掩码、域一致性正则化和模态弹性约束，鼓励域不变表示

Result: 在多个医学视觉语言基准测试中表现优异：VQA-RAD跨域准确率78.9%（提升3.8%），SLAKE 74.6%，VQA-2019 77.0%；扰动评估下VQA-RAD准确率从69.1%提升至75.6%；MELINDA跨域准确率从70.3%提升至75.2%；检索实验中平均排名退化从16降至4.1

Conclusion: 在预训练阶段显式建模鲁棒性能够产生更可靠、可迁移的医学视觉语言表示，适用于真实世界部署

Abstract: Medical vision-language models show strong potential for joint reasoning over medical images and clinical text, but their performance often degrades under domain shift caused by variations in imaging devices, acquisition protocols, and reporting styles. Existing multi-modal pre-training methods largely overlook robustness, treating it as a downstream adaptation problem. In this work, we propose Robust Multi-Modal Masked Reconstruction (Robust-MMR), a self-supervised pre-training framework that explicitly incorporates robustness objectives into masked vision-language learning. Robust-MMR integrates asymmetric perturbation-aware masking, domain-consistency regularization, and modality-resilience constraints to encourage domain-invariant representations. We evaluate Robust-MMR on multiple medical vision-language benchmarks, including medical visual question answering (VQA-RAD, SLAKE, VQA-2019), cross-domain image-text classification (MELINDA), and robust image-caption retrieval (ROCO). Robust-MMR achieves 78.9% cross-domain accuracy on VQA-RAD, outperforming the strongest baseline by 3.8 percentage points, and reaches 74.6% and 77.0% accuracy on SLAKE and VQA-2019, respectively. Under perturbed evaluation, Robust-MMR improves VQA-RAD accuracy from 69.1% to 75.6%. For image-text classification, cross-domain MELINDA accuracy increases from 70.3% to 75.2%, while retrieval experiments show a reduction in mean rank degradation from over 16 to 4.1 under perturbation. Qualitative results further demonstrate improved clinical reasoning for disease detection and structural abnormality assessment. These findings show that explicitly modeling robustness during pre-training leads to more reliable and transferable medical vision-language representations for real-world deployment.

</details>


### [68] [AnCoder: Anchored Code Generation via Discrete Diffusion Models](https://arxiv.org/abs/2602.17688)
*Anton Xue,Litu Rout,Constantine Caramanis,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: AnchorTree框架通过抽象语法树锚定扩散过程，优先解决语法和语义关键标记，提升代码生成质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型在代码生成中常产生无法执行的程序，因为它们未能尊重编程语言的刚性结构

Method: 引入AnchorTree框架，利用抽象语法树作为结构化层次先验，优先解析语法和语义关键标记（如关键字、标识符），建立结构脚手架指导后续生成

Result: 通过AnCoder模型系列验证，结构锚定的扩散方法为高质量代码生成提供了参数高效的路径

Conclusion: 结构化锚定扩散框架能够有效提升代码生成质量，通过尊重编程语言的结构特性生成可执行程序

Abstract: Diffusion language models offer a compelling alternative to autoregressive code generation, enabling global planning and iterative refinement of complex program logic. However, existing approaches fail to respect the rigid structure of programming languages and, as a result, often produce broken programs that fail to execute. To address this, we introduce AnchorTree, a framework that explicitly anchors the diffusion process using structured, hierarchical priors native to code. Specifically, AnchorTree uses the abstract syntax tree to prioritize resolving syntactically and semantically salient tokens, such as keywords (e.g., if, while) and identifiers (e.g., variable names), thereby establishing a structural scaffold that guides the remaining generation. We validate this framework via AnCoder, a family of models showing that structurally anchored diffusion offers a parameter-efficient path to high-quality code generation.

</details>


### [69] [A Case Study of Selected PTQ Baselines for Reasoning LLMs on Ascend NPU](https://arxiv.org/abs/2602.17693)
*Yuchen Luo,Fangyue Zhu,Ruining Zhou,Mingzhe Huang,Jian Zhu,Fanyu Fan,Wei Shao*

Main category: cs.LG

TL;DR: 本文研究了在昇腾NPU上对推理导向模型进行训练后量化的可行性，发现4位仅权重量化对大型模型有效，但4位权重-激活量化在长上下文推理中不稳定，而8位量化保持数值稳定。


<details>
  <summary>Details</summary>
Motivation: 训练后量化（PTQ）对高效模型部署至关重要，但在昇腾NPU上的效果相比GPU架构研究不足。本文旨在探索在昇腾NPU上部署量化推理模型的可行性和局限性。

Method: 对DeepSeek-R1-Distill-Qwen系列（1.5B/7B/14B）和QwQ-32B等推理导向模型进行代表性PTQ基线案例研究，评估了四种不同算法：AWQ、GPTQ、SmoothQuant和FlatQuant，涵盖从仅权重压缩到基于旋转的高级方法。

Result: 4位仅权重量化对大型模型可行，但激进的4位权重-激活量化方案在NPU上存在层间校准不稳定性，导致长上下文推理任务中的逻辑崩溃。标准8位量化保持数值稳定。实际INT8部署显示，虽然优化内核减少了延迟，但动态量化开销目前限制了端到端加速。

Conclusion: 研究结果为在昇腾NPU上部署量化推理模型的可行性和局限性提供了实用参考，指出了不同量化方案在特定硬件平台上的性能差异和实际部署挑战。

Abstract: Post-Training Quantization (PTQ) is crucial for efficient model deployment, yet its effectiveness on Ascend NPU remains under-explored compared to GPU architectures. This paper presents a case study of representative PTQ baselines applied to reasoning-oriented models such as DeepSeek-R1-Distill-Qwen series (1.5B/7B/14B) and QwQ-32B. We evaluate four distinct algorithms, including AWQ, GPTQ, SmoothQuant, and FlatQuant, to cover the spectrum from weight-only compression to advanced rotation-based methods. Our empirical results reveal significant platform sensitivity. While 4-bit weight-only quantization proves viable for larger models, aggressive 4-bit weight-activation schemes suffer from layer-wise calibration instability on the NPU, leading to logic collapse in long-context reasoning tasks. Conversely, standard 8-bit quantization remains numerically stable. Furthermore, a real-world INT8 deployment demonstrates that although optimized kernels reduce latency, dynamic quantization overheads currently limit end-to-end acceleration. These findings offer a practical reference for the feasibility and limitations of deploying quantized reasoning models on Ascend NPU.

</details>


### [70] [EXACT: Explicit Attribute-Guided Decoding-Time Personalization](https://arxiv.org/abs/2602.17695)
*Xin Yu,Hanwen Xing,Lingzhou Xue*

Main category: cs.LG

TL;DR: EXACT是一种解码时个性化方法，通过可解释属性对齐生成与有限成对偏好反馈，使用相似性检索机制适应上下文偏好变化


<details>
  <summary>Details</summary>
Motivation: 现有解码时个性化方法依赖隐式、难以解释的偏好表示，采用僵化的上下文无关用户表示，无法处理不同提示下的偏好变化

Method: EXACT使用预定义的可解释属性集，离线阶段通过最大化偏好响应似然识别用户特定属性子集，在线推理时检索与输入提示最相关的属性并注入上下文以引导生成

Result: 在温和假设下建立了理论近似保证，相似性检索机制有效缓解上下文偏好偏移，实验表明EXACT在偏好建模准确性和个性化生成质量上持续优于强基线

Conclusion: EXACT提供了一种可扩展、可解释的解码时个性化方法，通过可解释属性和相似性检索机制有效适应上下文偏好变化

Abstract: Achieving personalized alignment requires adapting large language models to each user's evolving context. While decoding-time personalization offers a scalable alternative to training-time methods, existing methods largely rely on implicit, less interpretable preference representations and impose a rigid, context-agnostic user representation, failing to account for how preferences shift across prompts. We introduce EXACT, a new decoding-time personalization that aligns generation with limited pairwise preference feedback using a predefined set of interpretable attributes. EXACT first identifies user-specific attribute subsets by maximizing the likelihood of preferred responses in the offline stage. Then, for online inference, EXACT retrieves the most semantically relevant attributes for an incoming prompt and injects them into the context to steer generation. We establish theoretical approximation guarantees for the proposed algorithm under mild assumptions, and provably show that our similarity-based retrieval mechanism effectively mitigates contextual preference shifts, adapting to disparate tasks without pooling conflicting preferences. Extensive experiments on human-annotated preference datasets demonstrate that EXACT consistently outperforms strong baselines, including preference modeling accuracy and personalized generation quality.

</details>


### [71] [Can LLM Safety Be Ensured by Constraining Parameter Regions?](https://arxiv.org/abs/2602.17696)
*Zongmin Li,Jian Su,Farah Benamara,Aixin Sun*

Main category: cs.LG

TL;DR: 当前的安全区域识别方法在不同数据集和模型上表现不一致，无法可靠识别稳定、数据集无关的安全区域


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型中是否存在可被修改以直接影响安全行为的"安全区域"，并检验现有识别方法的可靠性

Method: 系统评估四种不同参数粒度（从单个权重到整个Transformer层）的安全区域识别方法，在四个不同规模的LLM家族上使用十个安全识别数据集进行测试

Result: 识别的安全区域仅表现出低到中度的重叠（IoU测量），当使用效用数据集（非有害查询）进一步细化时，重叠显著下降

Conclusion: 现有技术无法可靠识别稳定、数据集无关的安全区域，表明当前的安全区域识别方法存在局限性

Abstract: Large language models (LLMs) are often assumed to contain ``safety regions'' -- parameter subsets whose modification directly influences safety behaviors. We conduct a systematic evaluation of four safety region identification methods spanning different parameter granularities, from individual weights to entire Transformer layers, across four families of backbone LLMs with varying sizes. Using ten safety identification datasets, we find that the identified safety regions exhibit only low to moderate overlap, as measured by IoU. The overlap drops significantly when the safety regions are further refined using utility datasets (\ie non-harmful queries). These results suggest that current techniques fail to reliably identify a stable, dataset-agnostic safety region.

</details>


### [72] [ScaleBITS: Scalable Bitwidth Search for Hardware-Aligned Mixed-Precision LLMs](https://arxiv.org/abs/2602.17698)
*Xinlin Li,Timothy Chou,Josh Fromm,Zichang Liu,Yunjie Pan,Christina Fragouli*

Main category: cs.LG

TL;DR: ScaleBITS是一个混合精度量化框架，通过硬件对齐的块级权重分区和双向通道重排序，在内存预算下实现自动化细粒度比特分配，在超低比特量化中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 后训练权重量化对减少大语言模型的内存和推理成本至关重要，但将平均精度推到4比特以下仍然具有挑战性，主要原因是权重敏感度高度不均匀且缺乏原则性的精度分配方法。现有解决方案要么使用高运行时开销的不规则细粒度混合精度，要么依赖启发式或高度受限的精度分配策略。

Method: 提出ScaleBITS混合精度量化框架：1）基于新的敏感度分析指导；2）引入硬件对齐的块级权重分区方案，通过双向通道重排序实现；3）将全局比特分配建模为约束优化问题，开发可扩展的贪心算法近似方法，实现端到端原则性分配。

Result: 实验表明，ScaleBITS在超低比特量化中显著优于均匀精度量化（提升高达36%），并且优于最先进的敏感度感知基线方法（提升高达13%），同时不增加运行时开销。

Conclusion: ScaleBITS框架能够在保持硬件效率的同时，在内存预算下实现自动化、细粒度的比特分配，解决了超低比特量化中的精度分配挑战，为大规模语言模型的高效部署提供了有效解决方案。

Abstract: Post-training weight quantization is crucial for reducing the memory and inference cost of large language models (LLMs), yet pushing the average precision below 4 bits remains challenging due to highly non-uniform weight sensitivity and the lack of principled precision allocation. Existing solutions use irregular fine-grained mixed-precision with high runtime overhead or rely on heuristics or highly constrained precision allocation strategies. In this work, we propose ScaleBITS, a mixed-precision quantization framework that enables automated, fine-grained bitwidth allocation under a memory budget while preserving hardware efficiency. Guided by a new sensitivity analysis, we introduce a hardware-aligned, block-wise weight partitioning scheme, powered by bi-directional channel reordering. We formulate global bitwidth allocation as a constrained optimization problem and develop a scalable approximation to the greedy algorithm, enabling end-to-end principled allocation. Experiments show that ScaleBITS significantly improves over uniform-precision quantization (up to +36%) and outperforms state-of-the-art sensitivity-aware baselines (up to +13%) in ultra-low-bit regime, without adding runtime overhead.

</details>


### [73] [MIDAS: Mosaic Input-Specific Differentiable Architecture Search](https://arxiv.org/abs/2602.17700)
*Konstanty Subbotko*

Main category: cs.LG

TL;DR: MIDAS提出了一种改进的可微分神经架构搜索方法，通过自注意力机制计算动态、输入特定的架构参数，采用局部化补丁级架构选择和拓扑感知搜索空间，在多个基准测试中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 尽管可微分神经架构搜索（NAS）提供了高效的梯度优化方法，但在实际应用中采用仍然有限。现有方法如DARTS使用静态架构参数，存在鲁棒性问题。

Method: MIDAS通过自注意力机制计算动态、输入特定的架构参数，替代DARTS中的静态参数。采用两种改进：1）局部化架构选择，为激活图的每个空间补丁单独计算；2）引入参数免费、拓扑感知的搜索空间，建模节点连接性并简化每个节点的两条入边选择。

Result: 在DARTS搜索空间上，CIFAR-10达到97.42% top-1准确率，CIFAR-100达到83.38%；在NAS-Bench-201上始终找到全局最优架构；在RDARTS上，在四个搜索空间中的两个上达到最先进水平。

Conclusion: MIDAS通过动态、输入特定的架构参数和局部化选择机制，显著提升了可微分NAS的性能和鲁棒性。补丁级注意力提高了候选操作的区分度，生成的参数分布具有类别感知性和单峰性，为架构解码提供了可靠指导。

Abstract: Differentiable Neural Architecture Search (NAS) provides efficient, gradient-based methods for automatically designing neural networks, yet its adoption remains limited in practice. We present MIDAS, a novel approach that modernizes DARTS by replacing static architecture parameters with dynamic, input-specific parameters computed via self-attention. To improve robustness, MIDAS (i) localizes the architecture selection by computing it separately for each spatial patch of the activation map, and (ii) introduces a parameter-free, topology-aware search space that models node connectivity and simplifies selecting the two incoming edges per node. We evaluate MIDAS on the DARTS, NAS-Bench-201, and RDARTS search spaces. In DARTS, it reaches 97.42% top-1 on CIFAR-10 and 83.38% on CIFAR-100. In NAS-Bench-201, it consistently finds globally optimal architectures. In RDARTS, it sets the state of the art on two of four search spaces on CIFAR-10. We further analyze why MIDAS works, showing that patchwise attention improves discrimination among candidate operations, and the resulting input-specific parameter distributions are class-aware and predominantly unimodal, providing reliable guidance for decoding.

</details>


### [74] [Pimp My LLM: Leveraging Variability Modeling to Tune Inference Hyperparameters](https://arxiv.org/abs/2602.17697)
*Nada Zine,Clément Quinton,Romain Rouvoy*

Main category: cs.LG

TL;DR: 该论文提出使用可变性管理技术来系统分析LLM推理时的配置选择，将LLM视为可配置系统，通过特征模型表示生成超参数及其约束，采样代表性配置并测量能耗、延迟和准确性，从而有效管理LLM推理配置的复杂性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的计算需求巨大，特别是在推理阶段占主导地位，引发了对能效和可持续性的担忧。推理服务器配置空间巨大，组合爆炸使得经验评估不可行，需要系统方法来分析配置选择对能耗、延迟和准确性的影响。

Method: 将LLMs视为可配置系统，应用可变性管理技术：1）使用基于特征的可变性模型表示生成超参数及其约束；2）采样代表性配置；3）测量能耗、延迟和准确性；4）从收集的数据中学习预测模型。在Hugging Face Transformers库上评估该方法。

Result: 可变性建模有效管理了LLM推理配置的复杂性，能够系统分析超参数效应和交互作用，揭示权衡关系，并支持从有限测量中准确预测推理行为。

Conclusion: 这项工作通过利用可变性建模实现LLM的高效和可持续配置，为软件工程和机器学习之间的交叉研究开辟了新方向，为解决LLM推理的能效和可持续性问题提供了系统化方法。

Abstract: Large Language Models (LLMs) are being increasingly used across a wide range of tasks. However, their substantial computational demands raise concerns about the energy efficiency and sustainability of both training and inference. Inference, in particular, dominates total compute usage, making its optimization crucial. Recent research has explored optimization techniques and analyzed how configuration choices influence energy consumption. Yet, the vast configuration space of inference servers makes exhaustive empirical evaluation infeasible due to combinatorial explosion. In this paper, we introduce a new perspective on this problem by treating LLMs as configurable systems and applying variability management techniques to systematically analyze inference-time configuration choices. We evaluate our approach on the Hugging Face Transformers library by representing generation hyperparameters and their constraints using a feature-based variability model, sampling representative configurations, measuring their energy consumption, latency, accuracy, and learning predictive models from the collected data. Our results show that variability modeling effectively manages the complexity of LLM inference configurations. It enables systematic analysis of hyperparameters effects and interactions, reveals trade-offs, and supports accurate prediction of inference behavior from a limited number of measurements. Overall, this work opens a new research direction that bridges software engineering and machine learning by leveraging variability modeling for the efficient and sustainable configuration of LLMs.

</details>


### [75] [Financial time series augmentation using transformer based GAN architecture](https://arxiv.org/abs/2602.17865)
*Andrzej Podobiński,Jarosław A. Chudziak*

Main category: cs.LG

TL;DR: 使用基于Transformer的GAN生成合成数据来增强金融时间序列数据，显著提高了LSTM预测模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列数据通常稀缺且波动性大，导致深度学习模型训练不充分、泛化能力差。需要可靠的数据增强方法来提升预测准确性。

Method: 使用基于Transformer的GAN（TTS-GAN）生成合成金融时间序列数据，用增强后的数据集训练LSTM预测模型。提出结合动态时间规整（DTW）和改进的深度数据集相似度度量（DeD-iMs）的时间序列质量评估指标。

Result: 在比特币和标普500价格数据上，使用GAN增强数据的LSTM模型预测准确性显著优于仅使用真实数据的模型，在不同预测时间范围内都得到验证。

Conclusion: GAN作为数据增强工具能有效克服金融领域数据稀缺问题，提升预测能力。提出的时间序列特定质量指标能可靠评估生成数据质量。

Abstract: Time-series forecasting is a critical task across many domains, from engineering to economics, where accurate predictions drive strategic decisions. However, applying advanced deep learning models in challenging, volatile domains like finance is difficult due to the inherent limitation and dynamic nature of financial time series data. This scarcity often results in sub-optimal model training and poor generalization. The fundamental challenge lies in determining how to reliably augment scarce financial time series data to enhance the predictive accuracy of deep learning forecasting models. Our main contribution is a demonstration of how Generative Adversarial Networks (GANs) can effectively serve as a data augmentation tool to overcome data scarcity in the financial domain. Specifically, we show that training a Long Short-Term Memory (LSTM) forecasting model on a dataset augmented with synthetic data generated by a transformer-based GAN (TTS-GAN) significantly improves the forecasting accuracy compared to using real data alone. We confirm these results across different financial time series (Bitcoin and S\&P500 price data) and various forecasting horizons. Furthermore, we propose a novel, time series specific quality metric that combines Dynamic Time Warping (DTW) and a modified Deep Dataset Dissimilarity Measure (DeD-iMs) to reliably monitor the training progress and evaluate the quality of the generated data. These findings provide compelling evidence for the benefits of GAN-based data augmentation in enhancing financial predictive capabilities.

</details>


### [76] [MantisV2: Closing the Zero-Shot Gap in Time Series Classification with Synthetic Data and Test-Time Strategies](https://arxiv.org/abs/2602.17868)
*Vasilii Feofanov,Songkang Wen,Jianfeng Zhang,Lujia Pan,Ievgen Redko*

Main category: cs.LG

TL;DR: 本文提出Mantis+和MantisV2两种时间序列基础模型，通过合成数据预训练、架构优化和测试时方法改进，显著提升了零样本特征提取性能，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 开发时间序列分类的基础模型具有重要实践意义，但现有模型如Mantis在冻结编码器和微调编码器之间存在显著性能差距，需要改进零样本特征提取能力。

Method: 1) 提出Mantis+，完全在合成时间序列上预训练；2) 通过控制性消融研究优化架构，得到更轻量的MantisV2编码器；3) 提出增强的测试时方法，利用中间层表示并改进输出token聚合；4) 通过自集成和跨模型嵌入融合进一步提升性能。

Result: 在UCR、UEA、人类活动识别基准和EEG数据集上的大量实验表明，MantisV2和Mantis+持续优于先前的时间序列基础模型，实现了最先进的零样本性能。

Conclusion: 通过合成数据预训练、架构优化和测试时方法改进，显著提升了时间序列基础模型的零样本特征提取能力，为下游任务提供了更强大的通用特征提取器。

Abstract: Developing foundation models for time series classification is of high practical relevance, as such models can serve as universal feature extractors for diverse downstream tasks. Although early models such as Mantis have shown the promise of this approach, a substantial performance gap remained between frozen and fine-tuned encoders. In this work, we introduce methods that significantly strengthen zero-shot feature extraction for time series. First, we introduce Mantis+, a variant of Mantis pre-trained entirely on synthetic time series. Second, through controlled ablation studies, we refine the architecture and obtain MantisV2, an improved and more lightweight encoder. Third, we propose an enhanced test-time methodology that leverages intermediate-layer representations and refines output-token aggregation. In addition, we show that performance can be further improved via self-ensembling and cross-model embedding fusion. Extensive experiments on UCR, UEA, Human Activity Recognition (HAR) benchmarks, and EEG datasets show that MantisV2 and Mantis+ consistently outperform prior time series foundation models, achieving state-of-the-art zero-shot performance.

</details>


### [77] [Certified Learning under Distribution Shift: Sound Verification and Identifiable Structure](https://arxiv.org/abs/2602.17699)
*Chandrasekhar Gokavarapu,Sudhakar Gadde,Y. Rajasekhar,S. R. Bhargava*

Main category: cs.LG

TL;DR: 提出一个理论框架，证明在可验证的规律性和复杂性约束下，分布偏移下的风险可由可计算的偏移度量和模型参数显式上界控制


<details>
  <summary>Details</summary>
Motivation: 解决机器学习模型在分布偏移下的风险认证问题，提供可验证的保证而非经验性评估，增强模型在现实部署中的可靠性

Method: 建立统一的理论框架，基于可验证的规律性和复杂性约束，推导分布偏移下风险的显式上界，该上界由可计算的偏移度量和模型参数决定

Result: 提出了可认证的风险上界，验证方法对非平凡规模模型有效，通过可识别性条件而非事后解释强制可解释性，明确界定了可认证与不可认证的机制

Conclusion: 该框架为分布偏移下的模型风险提供了理论保证，实现了可验证的认证、有效的验证和基于可识别性的可解释性，为可靠部署提供了理论基础

Abstract: Proposition. Let $f$ be a predictor trained on a distribution $P$ and evaluated on a shifted distribution $Q$. Under verifiable regularity and complexity constraints, the excess risk under shift admits an explicit upper bound determined by a computable shift metric and model parameters. We develop a unified framework in which (i) risk under distribution shift is certified by explicit inequalities, (ii) verification of learned models is sound for nontrivial sizes, and (iii) interpretability is enforced through identifiability conditions rather than post hoc explanations. All claims are stated with explicit assumptions. Failure modes are isolated. Non-certifiable regimes are characterized.

</details>


### [78] [Machine Learning Based Prediction of Surgical Outcomes in Chronic Rhinosinusitis from Clinical Data](https://arxiv.org/abs/2602.17888)
*Sayeed Shafayet Chowdhury,Karen D'Souza,V. Siva Kakumani,Snehasis Mukhopadhyay,Shiaofen Fang,Rodney J. Schlosser,Daniel M. Beswick,Jeremiah A. Alt,Jess C. Mace,Zachary M. Soler,Timothy L. Smith,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 该研究使用机器学习模型预测慢性鼻窦炎患者的手术获益，在仅使用术前数据的情况下达到约85%的分类准确率，优于临床专家平均准确率（75.6%）。


<details>
  <summary>Details</summary>
Motivation: 慢性鼻窦炎（CRS）手术决策复杂，需要权衡手术风险与不确定的个体化结果。虽然AI在医疗预后中应用广泛，但基于前瞻性观察性临床试验数据的机器学习预测研究仍不足，这有潜力降低医疗成本并改善患者预后。

Method: 使用前瞻性收集的观察性干预试验队列数据，所有患者均接受手术。研究训练监督机器学习模型，仅使用术前数据预测手术获益，以Sino-Nasal Outcome Test-22（SNOT-22）作为主要患者报告结局。采用多种算法包括集成方法，并在30个混合难度病例的保留测试集上评估模型性能。

Result: 最佳模型达到约85%的分类准确率，能够准确且可解释地预测手术候选资格。在30个病例的测试集上，模型达到80%准确率，超过临床专家平均预测准确率（75.6%）。

Conclusion: 机器学习模型能够有效预测慢性鼻窦炎患者的手术获益，性能优于临床专家，有潜力增强临床决策支持，实现个性化CRS治疗。

Abstract: Artificial intelligence (AI) has increasingly transformed medical prognostics by enabling rapid and accurate analysis across imaging and pathology. However, the investigation of machine learning predictions applied to prospectively collected, standardized data from observational clinical intervention trials remains underexplored, despite its potential to reduce costs and improve patient outcomes. Chronic rhinosinusitis (CRS), a persistent inflammatory disease of the paranasal sinuses lasting more than three months, imposes a substantial burden on quality of life (QoL) and societal cost. Although many patients respond to medical therapy, others with refractory symptoms often pursue surgical intervention. Surgical decision-making in CRS is complex, as it must weigh known procedural risks against uncertain individualized outcomes. In this study, we evaluated supervised machine learning models for predicting surgical benefit in CRS, using the Sino-Nasal Outcome Test-22 (SNOT-22) as the primary patient-reported outcome. Our prospectively collected cohort from an observational intervention trial comprised patients who all underwent surgery; we investigated whether models trained only on preoperative data could identify patients who might not have been recommended surgery prior to the procedure. Across multiple algorithms, including an ensemble approach, our best model achieved approximately 85% classification accuracy, providing accurate and interpretable predictions of surgical candidacy. Moreover, on a held-out set of 30 cases spanning mixed difficulty, our model achieved 80% accuracy, exceeding the average prediction accuracy of expert clinicians (75.6%), demonstrating its potential to augment clinical decision-making and support personalized CRS care.

</details>


### [79] [Parallel Complex Diffusion for Scalable Time Series Generation](https://arxiv.org/abs/2602.17706)
*Rongyao Cai,Yuxi Wan,Kexin Zhang,Ming Jin,Zhiqiang Ge,Qingsong Wen,Yong Liu*

Main category: cs.LG

TL;DR: PaCoDi提出了一种基于频域解耦的并行复杂扩散模型，通过傅里叶变换将时间信号转换为解耦的频谱分量，实现了长程依赖建模的计算效率提升。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列生成模型在建模长程依赖时面临表示能力与计算效率的权衡问题，特别是时间扩散模型存在局部纠缠问题和注意力机制的O(L²)计算成本。

Method: 提出PaCoDi架构，在频域进行生成建模；利用傅里叶变换作为对角化算子；证明正交前向扩散和条件反向分解定理；采用平均场理论近似和交互校正机制；利用实值信号的埃尔米特对称性压缩序列长度；推导异方差损失处理压缩流形上的非各向同性噪声分布。

Result: PaCoDi在生成质量和推理速度方面均优于现有基线方法，通过频谱压缩实现了注意力FLOPs减少50%且无信息损失。

Conclusion: PaCoDi为时间序列建模提供了一个理论基础扎实且计算高效的解决方案，通过频域解耦有效解决了长程依赖建模中的计算瓶颈问题。

Abstract: Modeling long-range dependencies in time series generation poses a fundamental trade-off between representational capacity and computational efficiency. Traditional temporal diffusion models suffer from local entanglement and the $\mathcal{O}(L^2)$ cost of attention mechanisms. We address these limitations by introducing PaCoDi (Parallel Complex Diffusion), a spectral-native architecture that decouples generative modeling in the frequency domain. PaCoDi fundamentally alters the problem topology: the Fourier Transform acts as a diagonalizing operator, converting locally coupled temporal signals into globally decorrelated spectral components. Theoretically, we prove the Quadrature Forward Diffusion and Conditional Reverse Factorization theorem, demonstrating that the complex diffusion process can be split into independent real and imaginary branches. We bridge the gap between this decoupled theory and data reality using a \textbf{Mean Field Theory (MFT) approximation} reinforced by an interactive correction mechanism. Furthermore, we generalize this discrete DDPM to continuous-time Frequency SDEs, rigorously deriving the Spectral Wiener Process describe the differential spectral Brownian motion limit. Crucially, PaCoDi exploits the Hermitian Symmetry of real-valued signals to compress the sequence length by half, achieving a 50% reduction in attention FLOPs without information loss. We further derive a rigorous Heteroscedastic Loss to handle the non-isotropic noise distribution on the compressed manifold. Extensive experiments show that PaCoDi outperforms existing baselines in both generation quality and inference speed, offering a theoretically grounded and computationally efficient solution for time series modeling.

</details>


### [80] [MIRA: Memory-Integrated Reinforcement Learning Agent with Limited LLM Guidance](https://arxiv.org/abs/2602.17930)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: MIRA框架通过结构化记忆图整合LLM先验知识，减少对实时LLM监督的依赖，在稀疏奖励环境中加速强化学习早期训练。


<details>
  <summary>Details</summary>
Motivation: 强化学习在稀疏或延迟奖励环境中样本效率低下，传统方法依赖大量LLM实时监督，存在可扩展性限制和不可靠信号依赖问题。

Method: 构建结构化记忆图存储高回报经验轨迹和LLM生成的子目标结构，从中推导效用信号软调整优势估计，随着训练进展效用项衰减。

Result: MIRA在稀疏奖励环境中优于基线RL方法，达到与频繁LLM监督方法相当的回报，同时显著减少在线LLM查询次数。

Conclusion: MIRA通过持久化记忆图有效整合LLM先验知识，在保持标准收敛保证的同时加速早期学习，减少对实时LLM监督的依赖。

Abstract: Reinforcement learning (RL) agents often suffer from high sample complexity in sparse or delayed reward settings due to limited prior structure. Large language models (LLMs) can provide subgoal decompositions, plausible trajectories, and abstract priors that facilitate early learning. However, heavy reliance on LLM supervision introduces scalability constraints and dependence on potentially unreliable signals. We propose MIRA (Memory-Integrated Reinforcement Learning Agent), which incorporates a structured, evolving memory graph to guide early training. The graph stores decision-relevant information, including trajectory segments and subgoal structures, and is constructed from both the agent's high-return experiences and LLM outputs. This design amortizes LLM queries into a persistent memory rather than requiring continuous real-time supervision. From this memory graph, we derive a utility signal that softly adjusts advantage estimation to influence policy updates without modifying the underlying reward function. As training progresses, the agent's policy gradually surpasses the initial LLM-derived priors, and the utility term decays, preserving standard convergence guarantees. We provide theoretical analysis showing that utility-based shaping improves early-stage learning in sparse-reward environments. Empirically, MIRA outperforms RL baselines and achieves returns comparable to approaches that rely on frequent LLM supervision, while requiring substantially fewer online LLM queries. Project webpage: https://narjesno.github.io/MIRA/

</details>


### [81] [Provable Adversarial Robustness in In-Context Learning](https://arxiv.org/abs/2602.17743)
*Di Zhang*

Main category: cs.LG

TL;DR: 论文提出了一个分布鲁棒的元学习框架，为基于Wasserstein距离分布偏移下的上下文学习提供最坏情况性能保证，揭示了模型鲁棒性与容量平方根成正比，对抗性设置会带来与扰动幅度平方成正比的样本复杂度惩罚。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型上下文学习能力的理论解释假设测试任务与预训练分布相似，忽略了对抗性分布偏移对实际可靠性的威胁。为了填补这一空白，需要研究上下文学习在对抗性条件下的鲁棒性。

Method: 引入分布鲁棒的元学习框架，聚焦于线性自注意力Transformer模型，在Wasserstein距离定义的分布偏移下推导非渐近性能边界，分析对抗性扰动强度、模型容量和上下文示例数量之间的关系。

Result: 分析表明模型鲁棒性与容量平方根成正比（ρ_max ∝ √m），对抗性设置会带来与扰动幅度平方成正比的样本复杂度惩罚（N_ρ - N_0 ∝ ρ²）。在合成任务上的实验验证了这些缩放规律。

Conclusion: 这些发现推进了对对抗性条件下上下文学习极限的理论理解，表明模型容量是分布鲁棒性的基本资源。研究为实际应用中上下文学习的可靠性提供了理论保证。

Abstract: Large language models adapt to new tasks through in-context learning (ICL) without parameter updates. Current theoretical explanations for this capability assume test tasks are drawn from a distribution similar to that seen during pretraining. This assumption overlooks adversarial distribution shifts that threaten real-world reliability. To address this gap, we introduce a distributionally robust meta-learning framework that provides worst-case performance guarantees for ICL under Wasserstein-based distribution shifts. Focusing on linear self-attention Transformers, we derive a non-asymptotic bound linking adversarial perturbation strength ($ρ$), model capacity ($m$), and the number of in-context examples ($N$). The analysis reveals that model robustness scales with the square root of its capacity ($ρ_{\text{max}} \propto \sqrt{m}$), while adversarial settings impose a sample complexity penalty proportional to the square of the perturbation magnitude ($N_ρ- N_0 \propto ρ^2$). Experiments on synthetic tasks confirm these scaling laws. These findings advance the theoretical understanding of ICL's limits under adversarial conditions and suggest that model capacity serves as a fundamental resource for distributional robustness.

</details>


### [82] [Memory-Based Advantage Shaping for LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2602.17931)
*Narjes Nourzad,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 该论文提出了一种结合大语言模型（LLM）和强化学习（RL）的方法，通过构建记忆图来编码LLM指导的子目标和智能体成功轨迹，从而在稀疏或延迟奖励环境中提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 在稀疏或延迟奖励环境中，强化学习需要大量交互导致样本复杂度高。虽然大语言模型可以用于子目标发现和轨迹指导，但频繁依赖LLM调用存在可扩展性和可靠性问题。

Method: 构建记忆图编码LLM指导的子目标和智能体成功轨迹，从中推导效用函数评估轨迹与先前成功策略的匹配程度，用该效用函数塑造优势函数为评论家提供额外指导而不改变奖励机制，主要依赖离线输入和偶尔在线查询，避免持续LLM监督。

Result: 在基准环境中的初步实验显示，相比基线RL方法，该方法提高了样本效率并加速了早期学习，最终回报与需要频繁LLM交互的方法相当。

Conclusion: 该方法通过构建记忆图和效用函数，有效结合LLM指导和智能体自身经验，在减少LLM依赖的同时提高了强化学习在稀疏奖励环境中的样本效率。

Abstract: In environments with sparse or delayed rewards, reinforcement learning (RL) incurs high sample complexity due to the large number of interactions needed for learning. This limitation has motivated the use of large language models (LLMs) for subgoal discovery and trajectory guidance. While LLMs can support exploration, frequent reliance on LLM calls raises concerns about scalability and reliability. We address these challenges by constructing a memory graph that encodes subgoals and trajectories from both LLM guidance and the agent's own successful rollouts. From this graph, we derive a utility function that evaluates how closely the agent's trajectories align with prior successful strategies. This utility shapes the advantage function, providing the critic with additional guidance without altering the reward. Our method relies primarily on offline input and only occasional online queries, avoiding dependence on continuous LLM supervision. Preliminary experiments in benchmark environments show improved sample efficiency and faster early learning compared to baseline RL methods, with final returns comparable to methods that require frequent LLM interaction.

</details>


### [83] [Asking Forever: Universal Activations Behind Turn Amplification in Conversational LLMs](https://arxiv.org/abs/2602.17778)
*Zachary Coalson,Bo Fang,Sanghyun Hong*

Main category: cs.LG

TL;DR: 论文揭示了一种新的对话LLM故障模式：轮次放大，即模型持续延长多轮对话而不完成任务，攻击者可通过诱导澄清寻求行为来系统性延长交互


<details>
  <summary>Details</summary>
Motivation: 多轮交互长度是对话LLM运营成本的主要因素，现有研究主要关注单轮成本优化，但缺乏对多轮对话中系统性故障模式的分析

Method: 从机制角度识别与澄清寻求响应相关的查询无关通用激活子空间；通过供应链攻击（微调）和运行时攻击（参数损坏）两种方式诱导轮次放大；在多个指令调优LLM和基准测试上验证攻击效果

Result: 攻击显著增加了对话轮次，同时保持合规性；攻击在不同提示和任务中持续存在；现有防御措施对此类故障保护有限

Conclusion: 轮次放大是一种新兴的对话LLM故障模式，源于对话动态而非单轮提示优化，需要新的防御机制来应对此类系统性攻击

Abstract: Multi-turn interaction length is a dominant factor in the operational costs of conversational LLMs. In this work, we present a new failure mode in conversational LLMs: turn amplification, in which a model consistently prolongs multi-turn interactions without completing the underlying task. We show that an adversary can systematically exploit clarification-seeking behavior$-$commonly encouraged in multi-turn conversation settings$-$to scalably prolong interactions. Moving beyond prompt-level behaviors, we take a mechanistic perspective and identify a query-independent, universal activation subspace associated with clarification-seeking responses. Unlike prior cost-amplification attacks that rely on per-turn prompt optimization, our attack arises from conversational dynamics and persists across prompts and tasks. We show that this mechanism provides a scalable pathway to induce turn amplification: both supply-chain attacks via fine-tuning and runtime attacks through low-level parameter corruptions consistently shift models toward abstract, clarification-seeking behavior across prompts. Across multiple instruction-tuned LLMs and benchmarks, our attack substantially increases turn count while remaining compliant. We also show that existing defenses offer limited protection against this emerging class of failures.

</details>


### [84] [MePoly: Max Entropy Polynomial Policy Optimization](https://arxiv.org/abs/2602.17832)
*Hang Liu,Sangli Teng,Maani Ghaffari*

Main category: cs.LG

TL;DR: 提出MePoly方法，基于多项式能量模型解决随机最优控制中多模态策略表示问题，提供显式概率密度并实现精确熵最大化


<details>
  <summary>Details</summary>
Motivation: 传统参数化策略难以表示多模态解，而基于扩散的策略缺乏显式概率密度，使策略梯度优化复杂化

Method: 基于多项式能量模型的新型策略参数化方法MePoly，利用经典矩问题的理论基础，具有任意分布的通用逼近能力

Result: MePoly能有效捕捉复杂的非凸流形，在多样化基准测试中性能优于基线方法

Conclusion: MePoly为随机最优控制提供了一种具有显式概率密度的多模态策略表示方法，解决了现有方法的局限性

Abstract: Stochastic Optimal Control provides a unified mathematical framework for solving complex decision-making problems, encompassing paradigms such as maximum entropy reinforcement learning(RL) and imitation learning(IL). However, conventional parametric policies often struggle to represent the multi-modality of the solutions. Though diffusion-based policies are aimed at recovering the multi-modality, they lack an explicit probability density, which complicates policy-gradient optimization. To bridge this gap, we propose MePoly, a novel policy parameterization based on polynomial energy-based models. MePoly provides an explicit, tractable probability density, enabling exact entropy maximization. Theoretically, we ground our method in the classical moment problem, leveraging the universal approximation capabilities for arbitrary distributions. Empirically, we demonstrate that MePoly effectively captures complex non-convex manifolds and outperforms baselines in performance across diverse benchmarks.

</details>


### [85] [Grassmannian Mixture-of-Experts: Concentration-Controlled Routing on Subspace Manifolds](https://arxiv.org/abs/2602.17798)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: 提出Grassmannian MoE (GrMoE)路由框架，在Grassmann流形上使用Matrix Bingham分布控制路由稀疏性，通过单一可解释参数Λ连续调节路由熵，替代离散的top-k选择，实现无专家崩溃的平滑稀疏控制。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型使用softmax门控缺乏控制稀疏性与利用率权衡的理论机制，需要离散的top-k选择，且容易出现专家崩溃问题。

Method: 在Grassmann流形子空间上操作，使用Matrix Bingham分布的集中参数作为门控权重；开发摊销变分推理程序用于后验路由分布；建立集中谱与路由熵、期望top-k质量和专家崩溃指数界限的严格理论关系。

Result: 在350M-8专家、1.3B-16专家、2.7B-32专家的MoE语言模型上实现0%路由崩溃，困惑度相当或更好，负载均衡提升15-30%，集中度与有效稀疏度呈现平滑单调关系，支持训练后稀疏度调节。

Conclusion: GrMoE提供了几何原理的稀疏控制机制，建立了首个集中控制稀疏性的形式理论，实现了无崩溃的路由和可解释的专家专业化学习。

Abstract: Mixture-of-Experts models rely on learned routers to assign tokens to experts, yet standard softmax gating provides no principled mechanism to control the tradeoff between sparsity and utilization. We propose Grassmannian MoE (GrMoE), a routing framework that operates on the Grassmannian manifold of subspaces, where gating weights arise from the concentration parameters of Matrix Bingham distributions. This construction yields a single, interpretable knob -- the concentration matrix $Λ$ -- that continuously controls routing entropy, replacing discrete top-$k$ selection with a smooth, geometrically principled sparsity mechanism. We further develop an amortized variational inference procedure for posterior routing distributions, enabling uncertainty-aware expert assignment that naturally resists expert collapse. We formally prove tight bounds relating the Bingham concentration spectrum to routing entropy, expected top-$k$ mass, and an exponential bound on expert collapse, establishing the first formal theory of concentration-controlled sparsity. On synthetic routing tasks, a 350M-parameter MoE language model with 8 experts, a 1.3B-parameter model with 16 experts, and a 2.7B-parameter model with 32 experts, GrMoE achieves 0\% routing collapse across all seeds, comparable or better perplexity with 15--30\% improved load balance, and a smooth monotonic relationship between concentration and effective sparsity that enables post-hoc sparsity tuning without retraining. Token-level analysis reveals that experts learn heterogeneous concentration values that correlate with linguistic specialization, providing interpretable routing behavior.

</details>


### [86] [Learning Optimal and Sample-Efficient Decision Policies with Guarantees](https://arxiv.org/abs/2602.17978)
*Daqian Shao*

Main category: cs.LG

TL;DR: 该论文提出了一种从存在隐藏混杂因素的离线数据集中学习决策策略的方法，使用工具变量解决因果推断问题，并扩展到模仿学习和时序逻辑目标学习，具有收敛性和最优性保证。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习需要大量在线环境交互，这在成本高、危险或不可行的场景中不适用。离线数据集学习面临隐藏混杂因素的挑战，这些混杂因素可能导致虚假相关性和次优决策。

Method: 1. 使用工具变量识别因果效应，作为条件矩限制问题；2. 基于双重/去偏机器学习推导样本高效的CMR求解算法；3. 将方法扩展到离线模仿学习；4. 开发学习线性时序逻辑表达的高层目标的算法。

Result: 提出的算法优于现有最先进方法，在强化学习基准测试和合成/半合成数据集上表现出色，证明了在现实世界决策中的实用性。

Conclusion: 该论文开发了从存在隐藏混杂因素的离线数据集中学习决策策略的理论框架和算法，具有收敛性和最优性保证，为高风险的现实世界决策应用提供了可靠解决方案。

Abstract: The paradigm of decision-making has been revolutionised by reinforcement learning and deep learning. Although this has led to significant progress in domains such as robotics, healthcare, and finance, the use of RL in practice is challenging, particularly when learning decision policies in high-stakes applications that may require guarantees. Traditional RL algorithms rely on a large number of online interactions with the environment, which is problematic in scenarios where online interactions are costly, dangerous, or infeasible. However, learning from offline datasets is hindered by the presence of hidden confounders. Such confounders can cause spurious correlations in the dataset and can mislead the agent into taking suboptimal or adversarial actions. Firstly, we address the problem of learning from offline datasets in the presence of hidden confounders. We work with instrumental variables (IVs) to identify the causal effect, which is an instance of a conditional moment restrictions (CMR) problem. Inspired by double/debiased machine learning, we derive a sample-efficient algorithm for solving CMR problems with convergence and optimality guarantees, which outperforms state-of-the-art algorithms. Secondly, we relax the conditions on the hidden confounders in the setting of (offline) imitation learning, and adapt our CMR estimator to derive an algorithm that can learn effective imitator policies with convergence rate guarantees. Finally, we consider the problem of learning high-level objectives expressed in linear temporal logic (LTL) and develop a provably optimal learning algorithm that improves sample efficiency over existing methods. Through evaluation on reinforcement learning benchmarks and synthetic and semi-synthetic datasets, we demonstrate the usefulness of the methods developed in this thesis in real-world decision making.

</details>


### [87] [Calibrated Adaptation: Bayesian Stiefel Manifold Priors for Reliable Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2602.17809)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.LG

TL;DR: SBA是一种贝叶斯参数高效微调框架，通过Stiefel流形上的矩阵Langevin先验和切空间拉普拉斯近似，为大型语言模型提供校准的不确定性估计，在领域转移下显著提升预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（如LoRA）缺乏原则性的不确定性估计，导致预测校准不佳，在领域转移时行为不可靠。需要一种能够提供校准预测不确定性的贝叶斯PEFT框架。

Method: 提出Stiefel-Bayes Adapters (SBA)，在Stiefel流形上放置矩阵Langevin先验于正交适配器因子，通过切空间拉普拉斯近似和测地线回缩进行近似后验推断。该方法在流形上自然编码适配器子空间应良好条件和正交的归纳偏置。

Result: 在GLUE、SuperGLUE基准测试和多个模型上，SBA任务性能与LoRA和DoRA相当，同时将预期校准误差降低18-34%，在领域转移下选择性预测AUROC提升12-25%，以更少参数成本优于五个LoRA模型的深度集成。

Conclusion: 在正确的几何结构上放置不确定性比简单为适配器添加任何贝叶斯处理更重要。SBA为大型语言模型提供了校准的不确定性估计，显著提升了领域转移下的可靠性。

Abstract: Parameter-efficient fine-tuning methods such as LoRA enable practical adaptation of large language models but provide no principled uncertainty estimates, leading to poorly calibrated predictions and unreliable behavior under domain shift. We introduce Stiefel-Bayes Adapters (SBA), a Bayesian PEFT framework that places a Matrix Langevin prior over orthonormal adapter factors on the Stiefel manifold $\St$ and performs approximate posterior inference via tangent space Laplace approximation with geodesic retraction. Unlike Gaussian priors in flat space projected onto orthogonality constraints, our prior on the manifold naturally encodes the inductive bias that adapter subspaces should be well conditioned and orthogonal, while the posterior provides calibrated predictive uncertainty without recalibration. We prove formally that the tangent space approximation strictly avoids the structural variance inflation inherent in projecting from ambient space, establishing a rigorous theoretical advantage for intrinsic manifold inference. Across GLUE and SuperGLUE benchmarks on RoBERTa-large, LLaMA-2-7B, LLaMA-2-13B, Mistral-7B, and Qwen2.5-7B, domain shift evaluations, selective prediction protocols, and an abstractive summarization task, SBA achieves task performance comparable to LoRA and DoRA while reducing Expected Calibration Error by 18 to 34\% over deterministic baselines, improving selective prediction AUROC by 12 to 25\% under domain shift, and outperforming deep ensembles of five LoRA models on OOD detection at a fraction of the parameter cost. Our results demonstrate that where you place uncertainty, on the right geometric structure, matters more than simply adding any Bayesian treatment to adapters.

</details>


### [88] [PHAST: Port-Hamiltonian Architecture for Structured Temporal Dynamics Forecasting](https://arxiv.org/abs/2602.17998)
*Shubham Bhardwaj,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: PHAST是一种基于端口哈密顿框架的机器学习架构，用于从仅观测位置信息（动量隐变量）预测物理系统的长期动力学，通过保守-耗散分解保证稳定性，在13个基准测试中取得最佳长期预测性能。


<details>
  <summary>Details</summary>
Motivation: 真实物理系统都是耗散的，从部分观测（仅位置信息）预测其动力学是科学机器学习中的核心挑战。现有方法难以同时实现稳定长期预测和物理参数恢复。

Method: 提出PHAST架构，基于端口哈密顿框架将系统分解为保守和耗散部分，将哈密顿量分解为势能、质量和阻尼，支持三种知识模式（已知、部分已知、未知），使用高效低秩PSD/SPD参数化，采用Strang分裂推进动力学。

Result: 在13个涵盖机械、电气、分子、热、引力和生态系统的基准测试中，PHAST在长期预测方面优于竞争基线，并在有足够锚点时能够恢复物理意义参数。

Conclusion: PHAST成功解决了仅位置观测的动力学预测问题，证明了端口哈密顿框架的有效性，同时揭示了在没有足够锚点的情况下参数识别存在规范自由度问题，需要将预测稳定性与可识别性分开评估。

Abstract: Real physical systems are dissipative -- a pendulum slows, a circuit loses charge to heat -- and forecasting their dynamics from partial observations is a central challenge in scientific machine learning. We address the \emph{position-only} (q-only) problem: given only generalized positions~$q_t$ at discrete times (momenta~$p_t$ latent), learn a structured model that (a)~produces stable long-horizon forecasts and (b)~recovers physically meaningful parameters when sufficient structure is provided. The port-Hamiltonian framework makes the conservative-dissipative split explicit via $\dot{x}=(J-R)\nabla H(x)$, guaranteeing $dH/dt\le 0$ when $R\succeq 0$. We introduce \textbf{PHAST} (Port-Hamiltonian Architecture for Structured Temporal dynamics), which decomposes the Hamiltonian into potential~$V(q)$, mass~$M(q)$, and damping~$D(q)$ across three knowledge regimes (KNOWN, PARTIAL, UNKNOWN), uses efficient low-rank PSD/SPD parameterizations, and advances dynamics with Strang splitting. Across thirteen q-only benchmarks spanning mechanical, electrical, molecular, thermal, gravitational, and ecological systems, PHAST achieves the best long-horizon forecasting among competitive baselines and enables physically meaningful parameter recovery when the regime provides sufficient anchors. We show that identification is fundamentally ill-posed without such anchors (gauge freedom), motivating a two-axis evaluation that separates forecasting stability from identifiability.

</details>


### [89] [Causality by Abstraction: Symbolic Rule Learning in Multivariate Timeseries with Large Language Models](https://arxiv.org/abs/2602.17829)
*Preetom Biswas,Giulia Pedrielli,K. Selçuk Candan*

Main category: cs.LG

TL;DR: ruleXplain是一个利用大语言模型从仿真驱动动力系统中提取形式化因果解释的框架，通过约束符号规则语言和延迟语义来生成可验证的因果规则。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理具有延迟效应的时序数据因果推断时存在局限，特别是当多个不同的输入轨迹产生几乎无法区分的输出时，难以提供泛化且可解释的解释。

Method: 提出ruleXplain框架，利用LLMs提取仿真驱动动力系统的输入-输出关系的形式化解释。框架引入具有时间算子和延迟语义的约束符号规则语言，通过结构化提示让LLMs生成可验证的因果规则。使用仿真器生成多样化的反事实输入轨迹，聚类后作为上下文提供给LLM，LLM生成编码联合时间趋势的符号规则，并通过闭环精炼过程确保规则一致性和语义有效性。

Result: 使用PySIRTEM流行病模拟器和EnergyPlus建筑能源模拟器进行验证。进行了三类实验：(1)通过输入重构评估规则集的有效性；(2)通过消融研究评估规则集的因果编码；(3)在不同相位动态的未见输出趋势上测试提取规则的泛化能力。

Conclusion: ruleXplain框架能够从复杂动力系统中提取形式化、可解释的因果规则，为具有延迟效应的时序数据因果推断提供了有效的解决方案。

Abstract: Inferring causal relations in timeseries data with delayed effects is a fundamental challenge, especially when the underlying system exhibits complex dynamics that cannot be captured by simple functional mappings. Traditional approaches often fail to produce generalized and interpretable explanations, as multiple distinct input trajectories may yield nearly indistinguishable outputs. In this work, we present ruleXplain, a framework that leverages Large Language Models (LLMs) to extract formal explanations for input-output relations in simulation-driven dynamical systems. Our method introduces a constrained symbolic rule language with temporal operators and delay semantics, enabling LLMs to generate verifiable causal rules through structured prompting. ruleXplain relies on the availability of a principled model (e.g., a simulator) that maps multivariate input time series to output time series. Within ruleXplain, the simulator is used to generate diverse counterfactual input trajectories that yield similar target output, serving as candidate explanations. Such counterfactual inputs are clustered and provided as context to the LLM, which is tasked with the generation of symbolic rules encoding the joint temporal trends responsible for the patterns observable in the output times series. A closed-loop refinement process ensures rule consistency and semantic validity. We validate the framework using the PySIRTEM epidemic simulator, mapping testing rate inputs to daily infection counts; and the EnergyPlus building energy simulator, observing temperature and solar irradiance inputs to electricity needs. For validation, we perform three classes of experiments: (1) the efficacy of the ruleset through input reconstruction; (2) ablation studies evaluating the causal encoding of the ruleset; and (3) generalization tests of the extracted rules across unseen output trends with varying phase dynamics.

</details>


### [90] [NIMMGen: Learning Neural-Integrated Mechanistic Digital Twins with LLMs](https://arxiv.org/abs/2602.18008)
*Zihan Guan,Rituparna Datta,Mengxuan Hu,Shunshun Liu,Aiying Zhang,Prasanna Balachandran,Sheng Li,Anil Vullikanti*

Main category: cs.LG

TL;DR: 本文提出了NIMM评估框架，用于评估LLM生成的机理模型在现实条件下的可靠性，并开发了NIMMgen框架来改进模型生成的质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的机理模型自动构建方法在现实条件下可靠性不明确，需要更严格的评估框架来验证LLM生成的机理模型在实际应用中的有效性。

Method: 提出了NIMM评估框架，在部分观测和多样化任务目标的现实设置下评估LLM生成的机理模型；并设计了NIMMgen框架，通过迭代优化增强代码正确性和实际有效性。

Result: 评估揭示了当前基线方法在模型有效性和代码级正确性方面的根本挑战；NIMMgen在三个不同科学领域的数据集上表现出强大性能；学习到的机理模型支持反事实干预模拟。

Conclusion: NIMM框架为评估LLM生成的机理模型提供了现实基准，NIMMgen框架通过迭代优化显著提高了机理模型的质量和实用性，为科学建模提供了可靠工具。

Abstract: Mechanistic models encode scientific knowledge about dynamical systems and are widely used in downstream scientific and policy applications. Recent work has explored LLM-based agentic frameworks to automatically construct mechanistic models from data; however, existing problem settings substantially oversimplify real-world conditions, leaving it unclear whether LLM-generated mechanistic models are reliable in practice. To address this gap, we introduce the Neural-Integrated Mechanistic Modeling (NIMM) evaluation framework, which evaluates LLM-generated mechanistic models under realistic settings with partial observations and diversified task objectives. Our evaluation reveals fundamental challenges in current baselines, ranging from model effectiveness to code-level correctness. Motivated by these findings, we design NIMMgen, an agentic framework for neural-integrated mechanistic modeling that enhances code correctness and practical validity through iterative refinement. Experiments across three datasets from diversified scientific domains demonstrate its strong performance. We also show that the learned mechanistic models support counterfactual intervention simulation.

</details>


### [91] [Two Calm Ends and the Wild Middle: A Geometric Picture of Memorization in Diffusion Models](https://arxiv.org/abs/2602.17846)
*Nick Dodson,Xinyu Gao,Qingsong Wang,Yusu Wang,Zhengchao Wan*

Main category: cs.LG

TL;DR: 扩散模型存在训练数据记忆风险，本文提出几何框架将噪声调度分为三个区域，识别出中噪声区域是记忆风险最高的"危险区"，并提出几何干预方法来缓解记忆问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然能生成高质量样本，但也可能记忆训练数据，引发严重的隐私问题。目前对于记忆与泛化发生的机制、噪声调度中记忆发生的位置、数据几何的影响以及不同噪声尺度现象的相互作用等问题尚不清楚。

Method: 引入几何框架，基于高斯壳覆盖训练数据的特性和后验分布的集中行为，将噪声调度分为三个区域。识别出中噪声区域为记忆风险最高的"危险区"，并提出几何条件指导的针对性干预方法来缓解记忆问题。

Result: 研究发现记忆风险在噪声水平上高度不均匀分布。小噪声区域由于训练覆盖有限而避免记忆，大噪声区域后验集中度低且具有可证明的近线性高斯去噪行为，而中噪声区域记忆风险最为显著。

Conclusion: 扩散模型的记忆与泛化行为受噪声调度中不同区域的几何特性影响。通过理解这些几何机制，可以设计针对性的干预方法来缓解记忆风险，特别是在中噪声"危险区"。

Abstract: Diffusion models generate high-quality samples but can also memorize training data, raising serious privacy concerns. Understanding the mechanisms governing when memorization versus generalization occurs remains an active area of research. In particular, it is unclear where along the noise schedule memorization is induced, how data geometry influences it, and how phenomena at different noise scales interact. We introduce a geometric framework that partitions the noise schedule into three regimes based on the coverage properties of training data by Gaussian shells and the concentration behavior of the posterior, which we argue are two fundamental objects governing memorization and generalization in diffusion models. This perspective reveals that memorization risk is highly non-uniform across noise levels. We further identify a danger zone at medium noise levels where memorization is most pronounced. In contrast, both the small and large noise regimes resist memorization, but through fundamentally different mechanisms: small noise avoids memorization due to limited training coverage, while large noise exhibits low posterior concentration and admits a provably near linear Gaussian denoising behavior. For the medium noise regime, we identify geometric conditions through which we propose a geometry-informed targeted intervention that mitigates memorization.

</details>


### [92] [Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards](https://arxiv.org/abs/2602.18037)
*Johannes Ackermann,Michael Noukhovitch,Takashi Ishida,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 该论文提出使用梯度正则化（GR）替代传统的KL惩罚，通过引导策略更新到奖励模型更准确的区域来解决RLHF中的奖励黑客问题


<details>
  <summary>Details</summary>
Motivation: 在语言模型的后训练中，RLHF和RLVR面临奖励黑客问题，即策略可能利用奖励模型的不准确性学习到非预期行为。传统方法使用KL惩罚限制策略更新，但效果有限。

Method: 提出梯度正则化（GR）方法，基于奖励模型准确性与收敛点平坦度的理论联系，通过梯度正则化引导训练到更平坦（奖励更准确）的区域。还提出高效的有限差分估计方法。

Result: 实验表明：1）梯度范数与奖励准确性在RLHF中呈负相关；2）GR在多种RL实验中优于KL惩罚；3）在RLHF中获得更高的GPT评判胜率；4）避免对基于规则的数学奖励格式过度关注；5）防止在LLM-as-a-Judge数学任务中黑客评判。

Conclusion: 梯度正则化是解决RLHF中奖励黑客问题的有效方法，通过引导策略更新到奖励模型更准确的区域，比传统KL惩罚表现更好，为语言模型后训练提供了新思路。

Abstract: Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.

</details>


### [93] [JAX-Privacy: A library for differentially private machine learning](https://arxiv.org/abs/2602.17861)
*Ryan McKenna,Galen Andrew,Borja Balle,Vadym Doroshenko,Arun Ganesh,Weiwei Kong,Alex Kurakin,Brendan McMahan,Mikhail Pravilov*

Main category: cs.LG

TL;DR: JAX-Privacy是一个用于简化差分隐私机器学习机制部署的库，旨在平衡易用性、灵活性和效率，为研究人员和从业者提供模块化工具。


<details>
  <summary>Details</summary>
Motivation: 简化差分隐私机器学习机制的部署，为研究人员提供深度定制能力，同时为从业者提供开箱即用的体验，整合近期差分隐私ML研究成果。

Method: 基于JAX构建，提供经过验证的模块化原语，涵盖批量选择、梯度裁剪、噪声添加、会计计算和审计等关键组件。

Result: 开发了一个兼具易用性、灵活性和效率的差分隐私机器学习库，整合了大量最新研究成果，为不同用户群体提供定制化解决方案。

Conclusion: JAX-Privacy成功创建了一个平衡研究需求与实践应用的差分隐私机器学习工具库，促进了该领域技术的普及和应用。

Abstract: JAX-Privacy is a library designed to simplify the deployment of robust and performant mechanisms for differentially private machine learning. Guided by design principles of usability, flexibility, and efficiency, JAX-Privacy serves both researchers requiring deep customization and practitioners who want a more out-of-the-box experience. The library provides verified, modular primitives for critical components for all aspects of the mechanism design including batch selection, gradient clipping, noise addition, accounting, and auditing, and brings together a large body of recent research on differentially private ML.

</details>


### [94] [ADAPT: Hybrid Prompt Optimization for LLM Feature Visualization](https://arxiv.org/abs/2602.17867)
*João N. Cardoso,Arlindo L. Oliveira,Bruno Martins*

Main category: cs.LG

TL;DR: ADAPT：一种结合束搜索初始化和自适应梯度引导变异的混合方法，用于优化LLM激活空间中方向的文本输入可视化


<details>
  <summary>Details</summary>
Motivation: 理解LLM激活空间中学习到的方向编码了哪些特征需要识别强烈激活这些方向的输入。文本特征可视化由于文本的离散性在LLM中探索不足，现有提示优化技术容易陷入局部最小值

Method: ADAPT混合方法：结合束搜索初始化和自适应梯度引导变异，专门针对LLM特征可视化的失败模式设计

Result: 在Gemma 2 2B的稀疏自编码器潜在空间上评估，提出基于数据集激活统计的度量标准，ADAPT在不同层和潜在类型上始终优于先前方法

Conclusion: LLM特征可视化是可行的，但需要针对该领域量身定制的设计假设

Abstract: Understanding what features are encoded by learned directions in LLM activation space requires identifying inputs that strongly activate them. Feature visualization, which optimizes inputs to maximally activate a target direction, offers an alternative to costly dataset search approaches, but remains underexplored for LLMs due to the discrete nature of text. Furthermore, existing prompt optimization techniques are poorly suited to this domain, which is highly prone to local minima. To overcome these limitations, we introduce ADAPT, a hybrid method combining beam search initialization with adaptive gradient-guided mutation, designed around these failure modes. We evaluate on Sparse Autoencoder latents from Gemma 2 2B, proposing metrics grounded in dataset activation statistics to enable rigorous comparison, and show that ADAPT consistently outperforms prior methods across layers and latent types. Our results establish that feature visualization for LLMs is tractable, but requires design assumptions tailored to the domain.

</details>


### [95] [Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning](https://arxiv.org/abs/2602.18117)
*Yongjae Shin,Jongseong Chae,Jongeui Park,Youngchul Sung*

Main category: cs.LG

TL;DR: FINO是一种基于流匹配的离线到在线强化学习方法，通过注入噪声增强探索，结合熵引导采样平衡探索与利用，在有限在线预算下实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型在离线RL中表现出色，但在扩展到在线微调时面临挑战。现有方法将在线微调视为离线预训练的直接延续，未能解决关键问题，特别是探索效率问题。

Method: 提出FINO方法：1) 使用基于流匹配的策略；2) 在策略训练中注入噪声以鼓励超出离线数据集范围的探索；3) 结合熵引导采样机制平衡探索与利用。

Result: 在多种具有挑战性的任务上进行实验，结果表明FINO在有限在线预算下始终实现优越性能。

Conclusion: FINO通过噪声注入和熵引导采样有效解决了离线到在线RL中的探索挑战，显著提升了样本效率。

Abstract: Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.

</details>


### [96] [Capabilities Ain't All You Need: Measuring Propensities in AI](https://arxiv.org/abs/2602.18182)
*Daniel Romero-Alvarado,Fernando Martínez-Plumed,Lorenzo Pacchiardi,Hugo Save,Siddhesh Milind Pawar,Behzad Mehrbakhsh,Pablo Antonio Moreno Casares,Ben Slater,Paolo Bova,Peter Romero,Zachary R. Tyler,Jonathan Prunty,Luning Sun,Jose Hernandez-Orallo*

Main category: cs.LG

TL;DR: 本文提出了首个测量AI倾向性的形式化框架，使用双逻辑公式描述模型在"理想区间"内的高成功率，并通过任务无关的评估准则估计理想区间边界。该框架能测量倾向性偏移及其对任务的影响，且倾向性估计能成功预测未见任务的行为。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估主要关注能力测量，但倾向性（模型展现特定行为的趋势）对性能和安全结果有核心影响。传统项目反应理论（IRT）采用单调函数描述模型成功概率，不适用于倾向性评估，因为倾向性过高或过低都可能有问题。

Method: 提出双逻辑公式框架，将模型成功概率建模为当模型倾向性处于"理想区间"内时较高。开发任务无关的评估准则，使用LLM估计理想区间的边界。在六个LLM模型家族上应用该框架，测量倾向性偏移及其对任务的影响。

Result: 框架能有效测量倾向性偏移及其影响；使用一个基准估计的倾向性能成功预测未见任务的行为；结合倾向性和能力的预测能力比单独使用任一项更强；展示了如何进行严格的倾向性测量及其相对于仅使用能力评估的优势。

Conclusion: 该研究提供了首个测量AI倾向性的形式化框架，证明了倾向性测量的可行性和价值，展示了结合倾向性和能力评估能更好地预测AI行为，为更全面的AI评估提供了新方法。

Abstract: AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an "ideal band". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.

</details>


### [97] [LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification](https://arxiv.org/abs/2602.18195)
*Hairong Chen,Yicheng Feng,Ziyu Jia,Samir Bhatt,Hengguan Huang*

Main category: cs.LG

TL;DR: 本文提出LERD模型，一种端到端的贝叶斯电生理神经动力学系统，用于从多通道EEG中推断潜在神经事件及其关系结构，无需事件或交互标注，在阿尔茨海默病诊断中表现优异。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病改变大脑电生理特性并破坏多通道EEG动力学，现有方法多依赖黑盒分类器，未能显式建模生成观测信号的底层动力学机制。

Method: 提出LERD模型，结合连续时间事件推断模块和随机事件生成过程，捕捉灵活的时间模式，并引入电生理启发的动力学先验来指导学习。提供理论分析，获得可处理的训练边界和推断关系动力学的稳定性保证。

Result: 在合成基准和两个真实世界AD EEG队列上的实验表明，LERD始终优于强基线方法，并产生与生理对齐的潜在摘要，有助于表征群体水平的动力学差异。

Conclusion: LERD为从多通道EEG中推断神经事件和关系结构提供了一种原则性方法，在AD诊断中表现出优越性能，并提供了可解释的生理对齐潜在表示。

Abstract: Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.

</details>


### [98] [[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games](https://arxiv.org/abs/2602.18230)
*Jorge Carrasco Pollo,Ioannis Kapetangeorgis,Joshua Rosenthal,John Hua Yao*

Main category: cs.LG

TL;DR: 该研究对Abdelnabi等人（2024）提出的基于可评分游戏的LLM多智能体谈判基准进行了可重复性验证，发现基准虽然复杂但模型比较存在模糊性，实验设置存在信息泄露检测不足等局限性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多智能体谈判任务中展现出巨大潜力，但该领域缺乏稳健且可泛化的评估基准。Abdelnabi等人提出的基准旨在建立复杂现实的评估框架，本研究旨在验证其声明的可重复性，并深入理解其可用性和泛化性。

Method: 1. 在更多模型上复现原始实验；2. 引入额外指标验证谈判质量和评估公平性；3. 在扩展版本的基准上检验更广泛模型的行为；4. 分析实验设置的局限性，特别是信息泄露检测和消融研究的全面性。

Result: 研究发现：1. 基准确实复杂，但模型比较存在模糊性，对其客观性提出质疑；2. 实验设置存在局限性，特别是信息泄露检测不足和消融研究不够全面；3. 通过扩展基准检验更多模型，揭示了为潜在用户提供额外背景的见解；4. 结果强调了模型比较评估中背景的重要性。

Conclusion: 该研究验证了Abdelnabi等人谈判基准的可重复性，揭示了其复杂性和局限性，强调了在模型比较评估中考虑背景的重要性，为基准的改进和更客观的LLM谈判能力评估提供了重要见解。

Abstract: Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.

</details>


### [99] [Breaking the Correlation Plateau: On the Optimization and Capacity Limits of Attention-Based Regressors](https://arxiv.org/abs/2602.17898)
*Jingquan Yan,Yuwei Miao,Peiran Yu,Junzhou Huang*

Main category: cs.LG

TL;DR: 该论文首次从理论和优化角度分析了注意力回归模型中PCC停滞现象，揭示了MSE优化与PCC梯度冲突、softmax注意力限制等根本原因，并提出了改进的ECA模型来突破PCC瓶颈。


<details>
  <summary>Details</summary>
Motivation: 注意力回归模型训练中常出现PCC停滞现象：即使MSE持续下降，PCC却早早停止改善。这种现象虽然常见但缺乏理论解释，研究者希望深入理解其根本原因并提出解决方案。

Method: 首先从理论上分析PCC停滞的两个根本原因：1) MSE优化与PCC梯度之间的冲突，特别是在数据高度同质化时softmax注意力机制会加剧这一问题；2) 模型容量限制，推导出任何凸聚合器（包括softmax注意力）的PCC改进上限。基于这些洞察，提出了外推相关注意力（ECA）模型，包含新的理论驱动机制来改善PCC优化并超越凸包限制。

Result: 在包括具有挑战性的同质化数据设置在内的多样化基准测试中，ECA模型能够持续打破PCC停滞，在保持MSE性能的同时显著提升相关性表现。

Conclusion: 该研究首次为注意力回归模型中的PCC停滞现象提供了严格的理论分析，揭示了优化动态和模型容量的根本限制，并提出了有效的解决方案ECA模型，为改进注意力机制在回归任务中的表现提供了新的理论指导。

Abstract: Attention-based regression models are often trained by jointly optimizing Mean Squared Error (MSE) loss and Pearson correlation coefficient (PCC) loss, emphasizing the magnitude of errors and the order or shape of targets, respectively. A common but poorly understood phenomenon during training is the PCC plateau: PCC stops improving early in training, even as MSE continues to decrease. We provide the first rigorous theoretical analysis of this behavior, revealing fundamental limitations in both optimization dynamics and model capacity. First, in regard to the flattened PCC curve, we uncover a critical conflict where lowering MSE (magnitude matching) can paradoxically suppress the PCC gradient (shape matching). This issue is exacerbated by the softmax attention mechanism, particularly when the data to be aggregated is highly homogeneous. Second, we identify a limitation in the model capacity: we derived a PCC improvement limit for any convex aggregator (including the softmax attention), showing that the convex hull of the inputs strictly bounds the achievable PCC gain. We demonstrate that data homogeneity intensifies both limitations. Motivated by these insights, we propose the Extrapolative Correlation Attention (ECA), which incorporates novel, theoretically-motivated mechanisms to improve the PCC optimization and extrapolate beyond the convex hull. Across diverse benchmarks, including challenging homogeneous data setting, ECA consistently breaks the PCC plateau, achieving significant improvements in correlation without compromising MSE performance.

</details>


### [100] [Distribution-Free Sequential Prediction with Abstentions](https://arxiv.org/abs/2602.17918)
*Jialin Yu,Moïse Blanchard*

Main category: cs.LG

TL;DR: 该论文研究了一种半对抗性顺序预测问题，学习者可以在不确定时弃权，无需知道干净样本的先验分布，提出了基于boosting的AbstainBoost算法，为VC类函数提供分布无关的学习保证。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设学习者知道干净样本的分布μ，这在理论和实践中都是强假设。本文旨在探索在分布未知的情况下，能否为VC类函数实现类似的学习保证，这与经典学习框架（如PAC学习）和其他非i.i.d.模型（如平滑在线学习）的标准要求一致。

Method: 提出了AbstainBoost算法，基于弱学习器的boosting过程。该算法适用于分布无关的弃权学习，针对非适应性对手为一般VC类函数提供保证，对于适应性对手则为结构化函数类（如线性分类器）提供类似保证。

Result: 算法保证了在分布无关的弃权学习中，对于非适应性对手，一般VC类函数具有次线性误差；对于适应性对手，结构化函数类（包括线性分类器）也有类似保证。同时提供了相应的下界，揭示了误分类错误和错误弃权次数之间的多项式权衡关系。

Conclusion: 在分布未知的半对抗性顺序预测中，通过AbstainBoost算法可以实现对VC类函数的学习，无需先验分布知识。这填补了经典随机设置和完全对抗设置之间的空白，为实际应用提供了更实用的理论保证。

Abstract: We study a sequential prediction problem in which an adversary is allowed to inject arbitrarily many adversarial instances in a stream of i.i.d.\ instances, but at each round, the learner may also \emph{abstain} from making a prediction without incurring any penalty if the instance was indeed corrupted. This semi-adversarial setting naturally sits between the classical stochastic case with i.i.d.\ instances for which function classes with finite VC dimension are learnable; and the adversarial case with arbitrary instances, known to be significantly more restrictive. For this problem, Goel et al. (2023) showed that, if the learner knows the distribution $μ$ of clean samples in advance, learning can be achieved for all VC classes without restrictions on adversary corruptions. This is, however, a strong assumption in both theory and practice: a natural question is whether similar learning guarantees can be achieved without prior distributional knowledge, as is standard in classical learning frameworks (e.g., PAC learning or asymptotic consistency) and other non-i.i.d.\ models (e.g., smoothed online learning). We therefore focus on the distribution-free setting where $μ$ is \emph{unknown} and propose an algorithm \textsc{AbstainBoost} based on a boosting procedure of weak learners, which guarantees sublinear error for general VC classes in \emph{distribution-free} abstention learning for oblivious adversaries. These algorithms also enjoy similar guarantees for adaptive adversaries, for structured function classes including linear classifiers. These results are complemented with corresponding lower bounds, which reveal an interesting polynomial trade-off between misclassification error and number of erroneous abstentions.

</details>


### [101] [Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers](https://arxiv.org/abs/2602.18292)
*Xiaotong Ji,Rasul Tutunov,Matthieu Zimmer,Haitham Bou-Ammar*

Main category: cs.LG

TL;DR: 论文提出将解码视为一个原则性的优化层，将各种解码方法统一为概率单纯形上的正则化优化问题，并基于此框架设计了新的解码器Best-of-K。


<details>
  <summary>Details</summary>
Motivation: 当前解码方法被视为启发式的参数调整过程，缺乏统一的理论框架。作者认为解码应该被理解为语言模型和应用之间的原则性优化层。

Method: 提出一个统一的解码框架：在每个token位置，解决一个在概率单纯形上的正则化优化问题，平衡模型分数与结构偏好和约束。该框架将贪婪解码、Softmax采样、Top-K、Top-P和Sparsemax稀疏性等方法统一为特例。

Result: 基于该框架设计了Best-of-K解码器，这是一种针对多样本管道的KL锚定覆盖目标。实验显示，在高温采样下，Qwen2.5-Math-7B在MATH500上的准确率提升了+18.6%。

Conclusion: 解码应该被视为原则性的优化层而非启发式调整，统一框架不仅解释了现有方法的结构，还便于设计新的解码器，如Best-of-K在覆盖良好替代方案方面表现出色。

Abstract: Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.

</details>


### [102] [Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory](https://arxiv.org/abs/2602.18297)
*Usman Anwar,Tim Bakker,Dana Kianfar,Cristina Pinneri,Christos Louizos*

Main category: cs.LG

TL;DR: 本文通过信息论分析CoT监控器的理论基础，提出两种改进CoT可监控性的训练方法，显著提升监控准确率并防止CoT退化。


<details>
  <summary>Details</summary>
Motivation: 当前基于CoT的监控系统在实践中存在性能问题，需要从信息论角度理解CoT可监控性的理论条件，并开发能系统性改进监控性能的训练方法。

Method: 1. 信息论分析：证明CoT与输出间非零互信息是CoT可监控的必要非充分条件；2. 识别两种近似误差源：信息差距和激发误差；3. 提出两种训练方法：基于oracle的方法直接奖励模型产生最大化监控准确率的CoT，以及更实用的无标签方法最大化输出与CoT间的条件互信息。

Result: 在多种不同环境中，两种方法都显著提高了监控准确率，同时防止了CoT退化，即使在任务奖励不完善的情况下也能缓解奖励黑客攻击。

Conclusion: CoT可监控性可以通过有针对性的训练目标系统性改进，提出的两种方法为构建更可靠的CoT监控系统提供了有效途径，有助于在实际应用中更好地检测代码生成等任务中的测试黑客行为。

Abstract: Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.

</details>


### [103] [JPmHC Dynamical Isometry via Orthogonal Hyper-Connections](https://arxiv.org/abs/2602.18308)
*Biswa Sengupta,Jinhua Wang,Leo Brunswic*

Main category: cs.LG

TL;DR: JPmHC框架通过约束线性混合器在算子范数有界流形上，解决了超连接架构中身份映射丢失导致的训练不稳定问题，同时保持梯度条件并提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 超连接等深度学习架构虽然提升了性能，但破坏了残差连接的身份映射特性，导致训练不稳定、可扩展性受限和内存开销增加。需要一种既能保持梯度条件又能提升稳定性的解决方案。

Method: 提出JPmHC框架，用可训练的线性混合器替换身份跳跃连接，将混合器约束在算子范数有界流形上（如双随机、Stiefel、Grassmann流形），通过自由概率分析预测雅可比谱，使用内存高效的隐式微分进行固定点投影，并通过Cayley变换实现Stiefel约束混合器。

Result: 在ARC-AGI上的实验表明，JPmHC相比双随机基线实现了更快的收敛速度、更高的准确率和更低的计算成本，同时保持了训练稳定性。

Conclusion: JPmHC作为一种灵活可扩展的超连接扩展，推进了谱感知、稳定且高效的深度学习，为拓扑架构设计和基础模型演进提供了新见解。

Abstract: Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.

</details>


### [104] [Tighter Regret Lower Bound for Gaussian Process Bandits with Squared Exponential Kernel in Hypersphere](https://arxiv.org/abs/2602.17940)
*Shogo Iwazaki*

Main category: cs.LG

TL;DR: 本文研究了高斯过程（GP）赌博机问题在频率论设定下的算法无关最坏情况下界，重点关注平方指数（SE）核函数。论文部分解决了维度依赖对数因子的上下界差距问题，在超球形输入域下给出了累积遗憾和简单遗憾的下界，并改进了SE核的最大信息增益上界。


<details>
  <summary>Details</summary>
Motivation: 高斯过程赌博机问题中，对于平方指数核函数，维度依赖的对数因子在上下界之间存在差距，这是一个尚未解决的开放性问题。本文旨在部分解决这个问题，特别是在超球形输入域下，为算法性能提供更精确的理论界限。

Method: 采用算法无关的分析方法，在频率论设定下研究高斯过程赌博机问题。针对平方指数核函数和超球形输入域，通过理论分析推导累积遗憾和简单遗憾的下界。同时改进了SE核的最大信息增益上界。

Result: 1. 任何算法在超球形域上都会遭受Ω(√(T(ln T)^d(ln ln T)^{-d}))的累积遗憾；2. 任何算法需要Ω(ε^{-2}(ln 1/ε)^d(ln ln 1/ε)^{-d})时间步才能找到ε-最优点；3. 改进了SE核的最大信息增益上界为O((ln T)^{d+1}(ln ln T)^{-d})。

Conclusion: 在超球形输入域下，本文的结果保证了现有最佳算法在维度无关对数因子范围内的最优性，部分解决了平方指数核高斯过程赌博机问题中维度依赖对数因子的上下界差距问题。

Abstract: We study an algorithm-independent, worst-case lower bound for the Gaussian process (GP) bandit problem in the frequentist setting, where the reward function is fixed and has a bounded norm in the known reproducing kernel Hilbert space (RKHS). Specifically, we focus on the squared exponential (SE) kernel, one of the most widely used kernel functions in GP bandits. One of the remaining open questions for this problem is the gap in the \emph{dimension-dependent} logarithmic factors between upper and lower bounds. This paper partially resolves this open question under a hyperspherical input domain. We show that any algorithm suffers $Ω(\sqrt{T (\ln T)^{d} (\ln \ln T)^{-d}})$ cumulative regret, where $T$ and $d$ represent the total number of steps and the dimension of the hyperspherical domain, respectively. Regarding the simple regret, we show that any algorithm requires $Ω(ε^{-2}(\ln \frac{1}ε)^d (\ln \ln \frac{1}ε)^{-d})$ time steps to find an $ε$-optimal point. We also provide the improved $O((\ln T)^{d+1}(\ln \ln T)^{-d})$ upper bound on the maximum information gain for the SE kernel. Our results guarantee the optimality of the existing best algorithm up to \emph{dimension-independent} logarithmic factors under a hyperspherical input domain.

</details>


### [105] [FedZMG: Efficient Client-Side Optimization in Federated Learning](https://arxiv.org/abs/2602.18384)
*Fotios Zantalis,Evangelos Zervas,Grigorios Koulouras*

Main category: cs.LG

TL;DR: FedZMG是一种无参数的客户端优化算法，通过将梯度投影到零均值超平面来缓解非IID数据导致的客户端漂移问题，无需额外通信或超参数调优。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中客户端数据通常是非独立同分布的，这会导致客户端漂移问题，降低收敛速度和模型性能。现有的自适应优化器虽然能缓解这一问题，但往往计算复杂或通信开销大，不适合资源受限的物联网环境。

Method: 提出FedZMG算法，基于梯度中心化的思想，将本地梯度投影到零均值超平面上，有效中和异构数据分布中的"强度"或"偏差"偏移，无需额外通信或超参数调优。

Result: 理论分析证明FedZMG能降低有效梯度方差并保证更紧的收敛边界。在EMNIST、CIFAR100和Shakespeare数据集上的实验表明，FedZMG在高度非IID设置下比FedAvg和FedAdam基线方法具有更好的收敛速度和最终验证准确率。

Conclusion: FedZMG是一种有效的客户端优化算法，能够有效解决联邦学习中的客户端漂移问题，特别适合资源受限的物联网环境，在非IID数据分布下表现出优越性能。

Abstract: Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the "intensity" or "bias" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.

</details>


### [106] [Understanding the Generalization of Bilevel Programming in Hyperparameter Optimization: A Tale of Bias-Variance Decomposition](https://arxiv.org/abs/2602.17947)
*Yubo Zhou,Jun Shu,Junmin Liu,Deyu Meng*

Main category: cs.LG

TL;DR: 该论文针对基于梯度的超参数优化中存在的超梯度估计误差问题，提出了偏差-方差分解分析框架，并设计了集成超梯度策略来降低方差，从而提升超参数优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度的超参数优化方法主要关注估计值与真实值之间的偏差，而忽略了数据分布导致的方差误差，这限制了超参数优化的实际性能。需要更全面地分析超梯度估计误差，特别是方差项的影响。

Method: 1. 对超梯度估计误差进行偏差-方差分解，提供被先前工作忽略的方差项的详细分析；2. 提出超梯度估计的误差界全面分析；3. 基于理论分析设计集成超梯度策略来有效降低方差；4. 在正则化超参数学习、数据超清洗和少样本学习等任务上进行实验验证。

Result: 实验结果表明，提出的方差降低策略能够改进超梯度估计。通过建立超额误差与超梯度估计之间的联系，为经验观察提供了理论解释，并解释了实践中常见的验证集过拟合等现象。

Conclusion: 该研究通过偏差-方差分解框架深入分析了超梯度估计误差，提出的集成超梯度策略有效降低了方差，提升了超参数优化性能，为理解实践中的现象提供了理论依据。

Abstract: Gradient-based hyperparameter optimization (HPO) have emerged recently, leveraging bilevel programming techniques to optimize hyperparameter by estimating hypergradient w.r.t. validation loss. Nevertheless, previous theoretical works mainly focus on reducing the gap between the estimation and ground-truth (i.e., the bias), while ignoring the error due to data distribution (i.e., the variance), which degrades performance. To address this issue, we conduct a bias-variance decomposition for hypergradient estimation error and provide a supplemental detailed analysis of the variance term ignored by previous works. We also present a comprehensive analysis of the error bounds for hypergradient estimation. This facilitates an easy explanation of some phenomena commonly observed in practice, like overfitting to the validation set. Inspired by the derived theories, we propose an ensemble hypergradient strategy to reduce the variance in HPO algorithms effectively. Experimental results on tasks including regularization hyperparameter learning, data hyper-cleaning, and few-shot learning demonstrate that our variance reduction strategy improves hypergradient estimation. To explain the improved performance, we establish a connection between excess error and hypergradient estimation, offering some understanding of empirical observations.

</details>


### [107] [A Geometric Probe of the Accuracy-Robustness Trade-off: Sharp Boundaries in Symmetry-Breaking Dimensional Expansion](https://arxiv.org/abs/2602.17948)
*Yu Bai,Zhe Wang,Jiarui Zhang,Dong-Xiao Zhang,Yinjun Gao,Jun-Jie Zhang*

Main category: cs.LG

TL;DR: 本文通过对称性破缺维度扩展(SBDE)技术探究深度学习中的准确率与对抗鲁棒性权衡问题。研究发现，通过插入常数值像素扩展输入维度能提升干净准确率，但会降低对抗鲁棒性，这种脆弱性主要源于新增维度的陡峭边界。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在干净准确率和对抗鲁棒性之间存在普遍权衡，但其几何起源尚不清楚。本文旨在通过受控实验探究这一权衡背后的机制。

Method: 采用对称性破缺维度扩展(SBDE)技术，通过在输入图像中插入常数值像素来扩展输入维度，打破平移对称性。使用测试时的掩码投影技术，将插入的辅助像素重置为训练时的值，以分析脆弱性的来源。

Result: SBDE能显著提升干净准确率（如CIFAR-10上ResNet-18从90.47%提升到95.63%），但会降低对迭代白盒攻击的鲁棒性。掩码投影能有效中和攻击并恢复鲁棒性，表明脆弱性几乎完全源于插入的维度。模型通过沿辅助轴创建陡峭边界（陡峭损失梯度）来获得高准确率。

Conclusion: 准确率与鲁棒性权衡的几何解释是：优化景观加深吸引盆地以提升准确率，但不可避免地沿辅助自由度建立陡峭边界，从而对流形外扰动产生脆弱敏感性。

Abstract: The trade-off between clean accuracy and adversarial robustness is a pervasive phenomenon in deep learning, yet its geometric origin remains elusive. In this work, we utilize Symmetry-Breaking Dimensional Expansion (SBDE) as a controlled probe to investigate the mechanism underlying this trade-off. SBDE expands input images by inserting constant-valued pixels, which breaks translational symmetry and consistently improves clean accuracy (e.g., from $90.47\%$ to $95.63\%$ on CIFAR-10 with ResNet-18) by reducing parameter degeneracy. However, this accuracy gain comes at the cost of reduced robustness against iterative white-box attacks. By employing a test-time \emph{mask projection} that resets the inserted auxiliary pixels to their training values, we demonstrate that the vulnerability stems almost entirely from the inserted dimensions. The projection effectively neutralizes the attacks and restores robustness, revealing that the model achieves high accuracy by creating \emph{sharp boundaries} (steep loss gradients) specifically along the auxiliary axes. Our findings provide a concrete geometric explanation for the accuracy-robustness paradox: the optimization landscape deepens the basin of attraction to improve accuracy but inevitably erects steep walls along the auxiliary degrees of freedom, creating a fragile sensitivity to off-manifold perturbations.

</details>


### [108] [Unifying approach to uniform expressivity of graph neural networks](https://arxiv.org/abs/2602.18409)
*Huan Luo,Jonni Virtema*

Main category: cs.LG

TL;DR: 本文提出了模板GNN（T-GNNs）框架，通过聚合指定图模板的嵌入来更新节点特征，并建立了对应的逻辑系统GML(T)，统一分析了GNN的表达能力。


<details>
  <summary>Details</summary>
Motivation: 标准GNN只能聚合直接邻居或全局信息，表达能力有限。最近的研究尝试通过纳入子结构信息（如环计数和子图属性）来增强表达能力，但缺乏统一的理论框架。

Method: 提出模板GNN（T-GNNs）框架，通过聚合有效模板嵌入来更新节点特征；引入分级模板模态逻辑GML(T)；定义基于模板的互模拟和WL算法；建立T-GNNs与GML(T)的表达能力等价性。

Result: 证明了T-GNNs与GML(T)的表达能力等价性；展示了标准AC-GNNs及其变体可以作为T-GNNs的特例；提供了统一分析GNN表达能力的理论框架。

Conclusion: T-GNNs提供了一个统一的框架来分析GNN的表达能力，能够将现有GNN变体解释为特例，并为设计更强大的GNN架构提供了理论基础。

Abstract: The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.

</details>


### [109] [Bayesian Online Model Selection](https://arxiv.org/abs/2602.17958)
*Aida Afshar,Yuke Zhang,Aldo Pacchiano*

Main category: cs.LG

TL;DR: 提出一种贝叶斯在线模型选择算法，用于随机多臂赌博机问题，能够自适应探索多个基础学习器并与最优学习器竞争。


<details>
  <summary>Details</summary>
Motivation: 解决贝叶斯赌博机中的在线模型选择问题：当环境实例从先验分布中采样时，如何设计自适应策略来探索多个赌博机学习器，并与事后最优学习器竞争。

Method: 提出一种新的贝叶斯算法用于随机赌博机的在线模型选择，通过自适应策略同时探索多个基础学习器，并研究基础学习器之间数据共享对缓解先验错误设定的作用。

Result: 证明了贝叶斯遗憾的oracle-style保证为O(d*M√T + √(MT))，其中M是基础学习器数量，d*是最优基础学习器的遗憾系数，T是时间范围。通过实验验证了该方法在各种随机赌博机设置中的性能，表现与最优基础学习器相当。

Conclusion: 提出的贝叶斯在线模型选择算法能够有效探索多个基础学习器并与最优学习器竞争，同时数据共享机制有助于缓解先验错误设定的影响。

Abstract: Online model selection in Bayesian bandits raises a fundamental exploration challenge: When an environment instance is sampled from a prior distribution, how can we design an adaptive strategy that explores multiple bandit learners and competes with the best one in hindsight? We address this problem by introducing a new Bayesian algorithm for online model selection in stochastic bandits. We prove an oracle-style guarantee of $O\left( d^* M \sqrt{T} + \sqrt{(MT)} \right)$ on the Bayesian regret, where $M$ is the number of base learners, $d^*$ is the regret coefficient of the optimal base learner, and $T$ is the time horizon. We also validate our method empirically across a range of stochastic bandit settings, demonstrating performance that is competitive with the best base learner. Additionally, we study the effect of sharing data among base learners and its role in mitigating prior mis-specification.

</details>


### [110] [Improving Generalizability of Hip Fracture Risk Prediction via Domain Adaptation Across Multiple Cohorts](https://arxiv.org/abs/2602.17962)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 该研究评估了三种域适应方法（MMD、CORAL、DANN）及其组合在髋部骨折风险预测中的跨队列泛化能力，发现组合方法能显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 临床风险预测模型在不同队列间泛化能力差，因为数据分布因临床地点、地区、人口统计和测量协议而异。这在髋部骨折风险预测中尤为明显，模型在一个队列上训练后在其他队列部署时性能会大幅下降。

Method: 使用三个大型队列（SOF、MrOS、UKB）的临床和DXA特征，系统评估了三种域适应方法（MMD、CORAL、DANN）及其组合的性能。采用无结果方法，不依赖目标队列的已知结果，使模型选择更符合实际部署条件。

Result: 域适应方法相比无适应基线（仅源训练）持续表现出改进性能。组合多种域适应方法带来了最大且最稳定的增益。MMD、CORAL和DANN的组合方法取得了最高的区分度：男性源队列AUC为0.88，女性源队列AUC为0.95。

Conclusion: 集成多种域适应方法可以产生对数据集差异不敏感的特征表示，提高髋部骨折风险预测模型的泛化能力。与依赖监督调优或假设目标队列已知结果的方法不同，这种无结果方法能在实际部署条件下实现模型选择。

Abstract: Clinical risk prediction models often fail to be generalized across cohorts because underlying data distributions differ by clinical site, region, demographics, and measurement protocols. This limitation is particularly pronounced in hip fracture risk prediction, where the performance of models trained on one cohort (the source cohort) can degrade substantially when deployed in other cohorts (target cohorts). We used a shared set of clinical and DXA-derived features across three large cohorts - the Study of Osteoporotic Fractures (SOF), the Osteoporotic Fractures in Men Study (MrOS), and the UK Biobank (UKB), to systematically evaluate the performance of three domain adaptation methods - Maximum Mean Discrepancy (MMD), Correlation Alignment (CORAL), and Domain - Adversarial Neural Networks (DANN) and their combinations. For a source cohort with males only and a source cohort with females only, domain-adaptation methods consistently showed improved performance than the no-adaptation baseline (source-only training), and the use of combinations of multiple domain adaptation methods delivered the largest and most stable gains. The method that combines MMD, CORAL, and DANN achieved the highest discrimination with the area under curve (AUC) of 0.88 for a source cohort with males only and 0.95 for a source cohort with females only), demonstrating that integrating multiple domain adaptation methods could produce feature representations that are less sensitive to dataset differences. Unlike existing methods that rely heavily on supervised tuning or assume known outcomes of samples in target cohorts, our outcome-free approaches enable the model selection under realistic deployment conditions and improve generalization of models in hip fracture risk prediction.

</details>


### [111] [Asynchronous Heavy-Tailed Optimization](https://arxiv.org/abs/2602.18002)
*Junfei Sun,Dixi Yao,Xuchen Gong,Tahseen Rabbani,Manzil Zaheer,Tian Li*

Main category: cs.LG

TL;DR: 研究针对异步优化中重尾梯度噪声问题，提出延迟感知学习率调度和延迟补偿方法，在图像和语言任务中优于现有同步和异步方法。


<details>
  <summary>Details</summary>
Motivation: 重尾随机梯度噪声在Transformer模型中常见，会破坏优化过程稳定性。现有研究主要关注集中式或分布式同步设置下的重尾噪声处理，而重尾噪声与异步优化之间的相互作用尚未充分探索。

Method: 提出两种处理异步更新中掉队者的通信方案，基于延迟感知学习率调度和延迟补偿的算法改进，增强异步算法在重尾梯度噪声下的性能。

Result: 在重尾噪声下的收敛保证与同步对应方法的速度相匹配，相比现有异步方法提高了延迟容忍度。在图像和语言任务中，提出的方法在准确率/运行时间权衡方面优于先前的同步和异步方法，且对超参数更鲁棒。

Conclusion: 提出的延迟感知学习率调度和延迟补偿方法能有效处理异步优化中的重尾梯度噪声问题，在理论和实证上都表现出优越性能，为异步优化在重尾噪声环境下的应用提供了有效解决方案。

Abstract: Heavy-tailed stochastic gradient noise, commonly observed in transformer models, can destabilize the optimization process. Recent works mainly focus on developing and understanding approaches to address heavy-tailed noise in the centralized or distributed, synchronous setting, leaving the interactions between such noise and asynchronous optimization underexplored. In this work, we investigate two communication schemes that handle stragglers with asynchronous updates in the presence of heavy-tailed gradient noise. We propose and theoretically analyze algorithmic modifications based on delay-aware learning rate scheduling and delay compensation to enhance the performance of asynchronous algorithms. Our convergence guarantees under heavy-tailed noise match the rate of the synchronous counterparts and improve delay tolerance compared with existing asynchronous approaches. Empirically, our approaches outperform prior synchronous and asynchronous methods in terms of accuracy/runtime trade-offs and are more robust to hyperparameters in both image and language tasks.

</details>


### [112] [Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework](https://arxiv.org/abs/2602.18055)
*Jingyang Qiao,Zhizhong Zhang,Xin Tan,Jingyu Gong,Yanyun Qu,Yuan Xie*

Main category: cs.LG

TL;DR: 本文提出了Continual-NExT框架和MAGE方法，用于解决双模态大语言模型在持续学习中的遗忘、幻觉等问题，提升跨模态知识迁移能力。


<details>
  <summary>Details</summary>
Motivation: 双模态大语言模型虽然具有强大的即时学习和泛化能力，但在持续学习方面存在不足，难以适应动态变化的现实场景。主要挑战包括：学习新任务会破坏已学知识、存在幻觉问题、指令不遵循、跨模态知识迁移失败等。目前缺乏标准化的持续学习框架来探索这些挑战。

Method: 提出了Continual-NExT框架，这是一个为双模态大语言模型设计的持续学习框架，包含精心设计的评估指标。同时提出了MAGE方法（通用LoRA和专家LoRA的混合与聚合），通过促进跨模态知识迁移和减轻遗忘来提升模型的持续学习能力。

Result: 大量实验表明，MAGE方法优于其他持续学习方法，并实现了最先进的性能表现。

Conclusion: 本文建立了首个针对双模态大语言模型的持续学习框架Continual-NExT，并提出了有效的MAGE方法来解决持续学习中的关键挑战，显著提升了模型的持续适应能力。

Abstract: Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.

</details>


### [113] [Balancing Symmetry and Efficiency in Graph Flow Matching](https://arxiv.org/abs/2602.18084)
*Benjamin Honoré,Alba Carballo-Castro,Yiming Qin,Pascal Frossard*

Main category: cs.LG

TL;DR: 论文研究了图生成模型中严格等变性的权衡问题，提出通过可控对称性调制方案放松等变性约束，在加速训练收敛的同时避免过拟合。


<details>
  <summary>Details</summary>
Motivation: 严格的等变性虽然能确保模型尊重图的置换对称性，但会增加计算成本并减缓收敛速度，因为模型必须在大量可能的节点置换中保持一致。研究者希望探索这种权衡关系。

Method: 从等变的离散流匹配模型出发，通过基于正弦位置编码和节点置换的可控对称性调制方案，在训练过程中放松模型的等变性约束。

Result: 实验表明：对称性破坏可以加速早期训练，但会导致过拟合（模型重复生成训练集中的图）；而适当调制对称性信号可以延迟过拟合同时加速收敛，仅用基线训练轮数的19%就能达到更强的性能。

Conclusion: 在图生成模型中，适当放松等变性约束并通过可控方式调制对称性，可以在保持性能的同时显著提高训练效率，避免过拟合问题。

Abstract: Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\%$ of the baseline training epochs.

</details>


### [114] [TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs](https://arxiv.org/abs/2602.18109)
*Rong Fu,Yibo Meng,Guangzhen Yao,Jiaxuan Lu,Zeyu Zhang,Zhaolu Kang,Ziming Guo,Jia Yee Tan,Xiaojing Du,Simon James Fong*

Main category: cs.LG

TL;DR: TempoNet是一个基于强化学习的实时调度器，使用Transformer和深度Q近似，通过紧急令牌化器处理时间余量，稀疏注意力机制实现高效推理，在多核环境中优于传统调度器和神经基线。


<details>
  <summary>Details</summary>
Motivation: 实时调度器需要在严格的计算预算下处理紧截止期限，传统方法难以在复杂多核环境中实现最优调度，需要更智能的决策框架。

Method: 1. 紧急令牌化器将时间余量离散化为可学习的嵌入表示；2. 使用具有延迟感知的稀疏注意力堆栈，采用块状top-k选择和局部敏感分块；3. 多核映射层通过掩蔽贪婪选择或可微分匹配将Q分数转换为处理器分配；4. 支持行为克隆预训练和演员-评论家变体。

Result: 在工业混合关键性轨迹和大规模多处理器设置中的广泛评估显示，TempoNet在截止期限满足率上持续优于分析调度器和神经基线，同时提高了优化稳定性，推理时间在亚毫秒级别。

Conclusion: TempoNet为基于Transformer的高吞吐量实时调度决策建立了一个实用框架，展示了在复杂实时系统中的有效性和可扩展性。

Abstract: Real-time schedulers must reason about tight deadlines under strict compute budgets. We present TempoNet, a reinforcement learning scheduler that pairs a permutation-invariant Transformer with a deep Q-approximation. An Urgency Tokenizer discretizes temporal slack into learnable embeddings, stabilizing value learning and capturing deadline proximity. A latency-aware sparse attention stack with blockwise top-k selection and locality-sensitive chunking enables global reasoning over unordered task sets with near-linear scaling and sub-millisecond inference. A multicore mapping layer converts contextualized Q-scores into processor assignments through masked-greedy selection or differentiable matching. Extensive evaluations on industrial mixed-criticality traces and large multiprocessor settings show consistent gains in deadline fulfillment over analytic schedulers and neural baselines, together with improved optimization stability. Diagnostics include sensitivity analyses for slack quantization, attention-driven policy interpretation, hardware-in-the-loop and kernel micro-benchmarks, and robustness under stress with simple runtime mitigations; we also report sample-efficiency benefits from behavioral-cloning pretraining and compatibility with an actor-critic variant without altering the inference pipeline. These results establish a practical framework for Transformer-based decision making in high-throughput real-time scheduling.

</details>


### [115] [Non-Stationary Online Resource Allocation: Learning from a Single Sample](https://arxiv.org/abs/2602.18114)
*Yiding Feng,Jiashuo Jiang,Yige Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种在线资源分配算法，在非平稳需求环境下仅需每个周期一个历史样本，通过类型依赖的分位数元策略实现模块化决策，针对不同样本信息水平分别获得√T和对数级遗憾保证。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在线资源分配中的非平稳需求问题，传统方法通常需要大量离线数据或假设平稳环境，而实际应用中需求分布可能任意变化且历史数据有限。作者旨在设计一个仅需每个周期一个历史样本就能有效运行的算法，处理任意非平稳性而不依赖变化预算假设。

Method: 提出类型依赖的分位数元策略，将问题分解为三个模块化组件：1) 奖励分布估计；2) 通过流体松弛优化目标服务概率；3) 通过动态接受阈值进行实时决策。针对两种样本信息水平：奖励观测样本（包含查询类型和奖励实现）和类型仅样本（仅包含查询类型信息），分别设计不同策略。

Result: 对于奖励观测样本，静态阈值策略实现了Õ(√T)遗憾。对于类型仅样本，首先证明没有额外结构时无法获得次线性遗憾；在最小到达概率假设下，设计了部分自适应策略达到相同Õ(√T)界限，更重要的是设计了完全自适应解析策略，通过精心舍入实现了O((log T)³)的多对数遗憾保证，这是非平稳多资源分配中的首个此类结果。

Conclusion: 该框架在三个方面推进了先前工作：1) 仅需最小离线数据（每个周期一个样本）；2) 处理任意非平稳性而不依赖变化预算假设；3) 支持多资源约束。提出的方法为有限历史数据下的非平稳在线资源分配提供了有效的解决方案。

Abstract: We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.
  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\tilde{O}(\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.

</details>


### [116] [RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference](https://arxiv.org/abs/2602.18196)
*Xiuying Wei,Caglar Gulcehre*

Main category: cs.LG

TL;DR: RAT+是一种通过密集预训练结合全序列递归和主动递归学习的注意力架构，可在推理时灵活切换为扩张注意力模式，在保持长距离连接的同时显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统的结构化扩张注意力虽然具有推理时效率优势（通过扩张因子D减少FLOPs和KV缓存大小），但在将预训练注意力模型稀疏化为扩张模式时会导致严重的精度下降。需要一种既能保持密集预训练优势，又能在推理时灵活切换为高效稀疏模式的解决方案。

Method: 提出RAT+架构，在密集预训练阶段通过全序列递归增强注意力，并引入主动递归学习。单个RAT+模型只需密集预训练一次，在推理时可灵活切换为扩张注意力模式（可选带局部窗口）或混合层/头组合，仅需少量（1B token）分辨率适应而非重新训练单独的稀疏模型。

Result: 在1.5B参数、100B token训练规模下，RAT+在16倍扩张时接近密集注意力精度，在64倍扩张时在常识推理和LongBench任务上仅下降2-3个点。此外，RAT+在稀疏化为top-k块注意力时优于普通注意力。在2.6B参数、200B token规模下观察到相同趋势。

Conclusion: RAT+通过密集预训练结合递归增强，实现了推理时灵活切换为高效稀疏注意力模式的能力，在保持长距离连接的同时显著减少计算开销，为大型语言模型提供了实用的推理效率优化方案。

Abstract: Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.

</details>


### [117] [Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver](https://arxiv.org/abs/2602.18248)
*Pietro Sittoni,Emanuele Zangrando,Angelo A. Casulli,Nicola Guglielmi,Francesco Tudisco*

Main category: cs.LG

TL;DR: Neural-HSS：基于层次半可分矩阵结构的高效参数架构，在低数据量下仍能有效学习椭圆型PDE解，具有理论保证和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在求解PDE方面表现出色，但大规模高质量数据集生成和模型训练的计算成本仍然很高，限制了关键应用。现有方法在低数据量下效果有限，需要更高效的数据利用架构。

Method: 受椭圆PDE格林函数结构研究启发，提出Neural-HSS架构，基于层次半可分矩阵结构构建参数高效模型。理论分析证明其在低数据量下的精确性，并探讨其与傅里叶神经算子层、卷积层等其他架构原语的联系。

Result: 在200万网格点的三维泊松方程上实验验证了Neural-HSS的数据效率，在低数据量下优于基线方法。同时展示了其在电磁学、流体动力学和生物学等多种领域PDE数据学习的能力。

Conclusion: Neural-HSS是一种参数高效、数据高效的架构，特别适合椭圆型PDE的低数据量学习，具有理论保证和广泛适用性，为PDE求解的深度学习应用提供了更实用的解决方案。

Abstract: Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.

</details>


### [118] [Variational Distributional Neuron](https://arxiv.org/abs/2602.18250)
*Yves Ruffenach*

Main category: cs.LG

TL;DR: 提出变分分布神经元的概念验证：将神经元设计为VAE模块，包含先验、摊销后验和局部ELBO，使神经元不再是确定性标量而是分布，计算变为在约束下收缩可能性空间


<details>
  <summary>Details</summary>
Motivation: 解决结构上的张力：在序列生成中，因果性主要在符号空间组织，即使存在潜在变量也常作为辅助，而有效动态由确定性解码器承载；同时概率潜在模型捕获变化因素和不确定性，但不确定性通常由全局或参数机制承担，而单元仍传播标量。核心问题：如果不确定性是计算的内在属性，为什么计算单元不显式承载它？

Method: 提出变分分布神经元作为计算单元，每个神经元参数化后验分布，传播重参数化样本，并通过局部ELBO的KL项进行正则化。分析"崩溃"模式和"活神经元"条件，通过自回归先验在时间上扩展贡献

Result: 概念验证表明神经元可以设计为分布形式，计算变为在约束下收缩可能性空间。通过局部约束可测试这种"收缩"，并通过内部度量进行监控。单元携带的上下文信息量及其时间持续性可通过不同约束进行局部调节

Conclusion: 提出两个轴心：(1)概率约束的组合必须稳定、可解释和可控；(2)粒度问题：如果推断是在约束下分布协商，原始单元应保持确定性还是变为分布性？变分分布神经元为计算单元显式承载不确定性提供了新视角

Abstract: We propose a proof of concept for a variational distributional neuron: a compute unit formulated as a VAE brick, explicitly carrying a prior, an amortized posterior and a local ELBO. The unit is no longer a deterministic scalar but a distribution: computing is no longer about propagating values, but about contracting a continuous space of possibilities under constraints. Each neuron parameterizes a posterior, propagates a reparameterized sample and is regularized by the KL term of a local ELBO - hence, the activation is distributional. This "contraction" becomes testable through local constraints and can be monitored via internal measures. The amount of contextual information carried by the unit, as well as the temporal persistence of this information, are locally tuned by distinct constraints. This proposal addresses a structural tension: in sequential generation, causality is predominantly organized in the symbolic space and, even when latents exist, they often remain auxiliary, while the effective dynamics are carried by a largely deterministic decoder. In parallel, probabilistic latent models capture factors of variation and uncertainty, but that uncertainty typically remains borne by global or parametric mechanisms, while units continue to propagate scalars - hence the pivot question: if uncertainty is intrinsic to computation, why does the compute unit not carry it explicitly? We therefore draw two axes: (i) the composition of probabilistic constraints, which must be made stable, interpretable and controllable; and (ii) granularity: if inference is a negotiation of distributions under constraints, should the primitive unit remain deterministic or become distributional? We analyze "collapse" modes and the conditions for a "living neuron", then extend the contribution over time via autoregressive priors over the latent, per unit.

</details>


### [119] [MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data](https://arxiv.org/abs/2602.18253)
*Xabier de Zuazo,Vincenzo Verbeni,Eva Navas,Ibon Saratxaga,Mathieu Bourguignon,Nicola Molinaro*

Main category: cs.LG

TL;DR: 该研究首次展示了MEG语音模型的迁移学习和跨任务解码，在感知和产生任务间实现数据高效的神经解码


<details>
  <summary>Details</summary>
Motivation: 解决语音脑机接口中的数据效率问题，探索跨任务（感知与产生）的神经解码可能性

Method: 使用Conformer架构，在单个被试的50小时听音数据上进行预训练，然后在18名被试上仅用每人5分钟数据进行微调，实现感知与产生任务的跨任务解码

Result: 迁移学习带来一致改进：任务内准确率提升1-4%，跨任务准确率提升达5-6%；语音产生模型能解码被动听音任务，表明学习到的表征反映了共享的神经过程而非任务特异性运动活动

Conclusion: 这是首次在MEG语音模型中实现感知与产生任务的跨任务解码，证明了迁移学习能显著提高数据效率，且学习到的表征反映了语音处理的共享神经机制

Abstract: Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.

</details>


### [120] [On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction](https://arxiv.org/abs/2602.18301)
*Ivan Bondarenko,Egor Palkin,Fedor Tikunov*

Main category: cs.LG

TL;DR: 本文研究LLM中用于一步文本重建的两个原型令牌（m-token和e-token）的信息编码特性，分析其语义和句法内容，探索正则化方法以增强语义结构，为非自回归序列到序列系统提供基础。


<details>
  <summary>Details</summary>
Motivation: 自回归LLM需要n次前向传播生成长度为n的序列，效率低下。最近研究表明冻结LLM可以通过两个学习的原型令牌在单次前向传播中重建数百个令牌，这为超越自回归范式提供了可能。本文旨在深入理解这些原型令牌编码的信息及其行为特性。

Method: 1. 设计实验分离两个原型令牌中的语义和句法内容；2. 分析e-token的稳定性特性；3. 可视化重建过程中对e-token的注意力模式；4. 测试两种正则化方案：基于锚点的损失函数和关系蒸馏目标，使用教师嵌入来"强加"语义结构。

Result: 1. 标准优化下，m-token比e-token更强烈地捕获语义信息；2. 基于锚点的约束与重建准确性之间存在明显权衡；3. 关系蒸馏可以在不牺牲重建质量的情况下将批次级语义关系转移到原型令牌空间。

Conclusion: 关系蒸馏方法支持将语义关系转移到原型令牌空间而不影响重建质量，这为未来非自回归seq2seq系统预测原型令牌作为中间表示提供了可行性基础，有望实现更高效的文本生成。

Abstract: Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for "imposing" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.

</details>


### [121] [On the "Induction Bias" in Sequence Models](https://arxiv.org/abs/2602.18333)
*M. Reza Ebrahimi,Michaël Defferrard,Sunny Panchal,Roland Memisevic*

Main category: cs.LG

TL;DR: Transformer在状态跟踪任务上存在固有局限，即使在同分布训练和测试下，其数据效率远低于RNN，且无法跨序列长度共享学习到的机制。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在语言模型上取得巨大成功，但近期研究对其状态跟踪能力提出质疑，主要关注其在分布外泛化（如长度外推）的失败。本研究转向关注这些局限在同分布情况下的影响。

Method: 进行大规模实验研究，比较Transformer和RNN在不同监督机制下的数据效率，分析学习到的状态跟踪机制在不同序列长度间的共享程度。

Result: Transformer所需训练数据随状态空间大小和序列长度增长的速度远快于RNN；Transformer在不同长度间几乎没有或甚至有害的权重共享，而RNN能有效跨长度共享权重，实现摊销学习。

Conclusion: 状态跟踪仍然是Transformer面临的基本挑战，即使训练和评估分布匹配时也是如此，而RNN通过权重共享实现更高效的学习。

Abstract: Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.

</details>


### [122] [Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering](https://arxiv.org/abs/2602.18348)
*Matheus Camilo da Silva,Leonardo Arrighi,Ana Carolina Lorena,Sylvio Barbon Junior*

Main category: cs.LG

TL;DR: 该研究分析了AutoClustering元模型的可解释性，通过系统回顾现有方法、应用全局和局部解释技术，揭示了元特征对聚类算法选择的影响模式，为提升AutoML决策透明度提供了实用基础。


<details>
  <summary>Details</summary>
Motivation: 当前AutoClustering系统虽然性能良好，但其推荐结果难以解释：数据集元特征对算法和超参数选择的影响通常不透明，这限制了可靠性、偏差诊断和高效的元特征工程，需要提高无监督学习自动化的决策透明度。

Method: 1. 回顾22种现有方法并构建结构化元特征分类法；2. 应用全局可解释性技术（决策谓词图）评估元模型中特征重要性；3. 使用局部解释工具（如SHAP）分析特定聚类决策。

Result: 研究发现元特征相关性存在一致模式，识别出当前元学习策略中的结构性弱点（可能扭曲推荐结果），并为更可解释的AutoML设计提供了可操作的指导。

Conclusion: 该研究为提高无监督学习自动化的决策透明度提供了实用基础，通过系统分析AutoClustering元模型的可解释性，揭示了现有方法的局限性并提出了改进方向。

Abstract: AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.

</details>


### [123] [Assigning Confidence: K-partition Ensembles](https://arxiv.org/abs/2602.18435)
*Aggelos Semoglou,John Pavlopoulos*

Main category: cs.LG

TL;DR: CAKE框架通过聚类集成计算分配稳定性和局部几何拟合一致性，为每个点提供[0,1]置信度评分，识别模糊点和稳定核心成员


<details>
  <summary>Details</summary>
Motivation: 传统聚类方法缺乏对单个分配可靠性的评估，诊断指标仅反映全局质量，无法指示特定实例的分配置信度，特别是对于k-means等初始化敏感算法，这种分配级不稳定性会影响准确性和鲁棒性

Method: 提出CAKE框架，通过聚类集成计算两个互补统计量：分配稳定性（跨运行一致性）和局部几何拟合一致性（学习到的聚类结构几何支持），组合成[0,1]范围内的可解释置信度分数

Result: 理论分析表明CAKE在噪声下保持有效并能区分稳定与不稳定点；合成和真实数据集实验显示CAKE能有效突出模糊点和稳定核心成员，提供可用于指导过滤或优先级排序的置信度排名

Conclusion: CAKE框架通过量化点级置信度，结合跨运行一致性和几何支持，为聚类分配提供细粒度可靠性评估，可提升聚类质量

Abstract: Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.

</details>
