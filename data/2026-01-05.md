<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 49]
- [cs.RO](#cs.RO) [Total: 12]
- [cs.LG](#cs.LG) [Total: 41]
- [cs.AI](#cs.AI) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现交互式、具有记忆功能的世界模型。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长期一致性和动态场景持久记忆方面存在局限，阻碍了它们发展成为实用的世界模型。需要一种能够统一视频生成、动态场景重建和长期记忆的框架。

Method: 提出生成-重建-引导范式：生成的视频流被连续重建为动态4D时空表示，该表示反过来引导后续生成以保持一致性。采用自回归扩散视频模型，增强宏观-微观规划（MMPL）和高效分布匹配蒸馏（DMD），实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现出色，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld代表了向实用、交互式和计算可访问的世界模型迈出的重要一步，为多模态生成和具身智能提供了具有记忆功能的交互式世界模型。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 本文提出通过噪声优化解决文本到图像模型中的模式崩溃问题，使用简单的噪声优化目标在保持基础模型保真度的同时提高生成多样性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在显著的模式崩溃问题，即给定相同文本提示时生成的图像缺乏多样性。虽然已有工作通过引导机制或候选池生成与精炼来解决，但本文探索了不同的方向。

Method: 采用噪声优化方法，设计简单的噪声优化目标来缓解模式崩溃。分析噪声的频率特性，探索具有不同频率分布的替代噪声初始化策略，以改进优化和搜索过程。

Result: 实验表明，噪声优化方法在生成质量和多样性方面均取得优异结果。该方法既能缓解模式崩溃，又能保持基础模型的保真度。

Conclusion: 噪声优化是解决文本到图像模型模式崩溃问题的有效方法，通过优化噪声和探索不同频率特性的初始化策略，可以显著提高生成多样性而不损害质量。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: 论文提出了Spatial4D-Bench，一个用于评估多模态大语言模型4D空间智能的大规模基准测试，包含约40,000个问答对，覆盖18个任务和6个认知类别。


<details>
  <summary>Details</summary>
Motivation: 人类天生具备4D空间智能（感知物体随时间变化的能力），但目前缺乏全面评估多模态大语言模型在这方面能力的基准测试。现有基准测试要么规模小，要么多样性不足。

Method: 开发了Spatial4D-Bench基准测试，包含约40,000个问答对，覆盖18个明确定义的任务，这些任务被系统组织到6个认知类别中：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 对多种开源和专有多模态大语言模型进行基准测试，发现它们在多种4D空间推理方面存在显著局限性，如路径规划、动作识别和物理合理性推理等。

Conclusion: Spatial4D-Bench为评估多模态大语言模型的空间认知能力提供了结构化、全面的基准测试，揭示了当前模型的局限性，有望促进开发更接近人类水平4D空间智能的模型。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP框架通过压缩历史遍历数据学习空间先验，显著提升3D目标检测性能，存储需求降低20倍


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常假设每次都是首次访问新地点，忽略了大多数部署区域已被历史车辆遍历过的事实，未能充分利用历史空间信息

Method: 提出压缩地图先验(CMP)框架，从历史遍历数据中学习空间先验，使用二值化哈希图存储，存储密度仅为32KB/km²，比密集存储减少20倍

Result: 在nuScenes数据集上，CMP框架显著且一致地提升了多种架构的3D目标检测性能，计算成本几乎为零

Conclusion: 压缩地图先验是一种简单有效的框架，能够高效利用历史遍历信息提升自动驾驶感知系统性能，存储效率高且易于集成

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [5] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个专门针对金融信贷领域的多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，用于评估视觉语言模型在信贷文档理解和风险评估中的实际应用能力。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，迫切需要能够反映金融信贷特定文档和工作流程、包含信贷特定理解能力和真实世界鲁棒性、同时保持隐私合规性的领域专用基准测试。

Method: 通过封闭的合成-捕获流水线构建所有样本：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知的图像。评估框架包含三个维度：感知（3个基础任务）、推理（4个信贷特定任务）和鲁棒性（10种真实世界采集伪影类型）。

Result: 在评估的23个最先进视觉语言模型中，Gemini 3 Pro作为商业模型获得最佳F1分数（64.61%），Qwen3-VL-235B作为开源基线获得最佳分数（57.27%），而专门针对金融信贷的Qfin-VL-Instruct模型获得最高总体分数（64.92%）。鲁棒性评估显示，即使是表现最佳的模型在采集伪影下也会出现明显的性能下降。

Conclusion: FCMBench-V1.0能够有效区分现代视觉语言模型的性能差异和鲁棒性，为金融信贷领域的多模态AI评估提供了标准化基准，同时通过封闭构建流程解决了隐私合规和数据泄露问题。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [6] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 本文提出FaceFocalDesc问题，构建了面部区域多属性描述数据集，并基于Qwen2.5-VL开发了Focal-RegionFace模型，通过渐进微调实现局部面部特征分析。


<details>
  <summary>Details</summary>
Motivation: 面部分析中缺乏对任意选定面部区域生成和识别多属性自然语言描述的研究，包括面部动作单元、情绪状态和年龄估计。系统关注个体面部区域的能力能带来更好的理解和控制。

Method: 构建新的面部区域多属性描述数据集，提供丰富的区域级标注和自然语言描述。基于Qwen2.5-VL开发Focal-RegionFace视觉语言模型，通过多个渐进微调阶段逐步细化对局部面部特征的关注。

Result: Focal-RegionFace在新基准测试中，在传统指标和新提出的指标上都取得了最佳性能，验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和多功能性。

Conclusion: 该研究成功解决了面部区域多属性描述问题，提出的方法在面部状态分析中表现出色，为细粒度面部分析提供了新的解决方案。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [7] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一个无需训练的3D变形框架，利用结构化潜在表示（SLAT）实现高质量跨类别3D变形，通过注意力机制融合源和目标特征来生成语义一致且时间平滑的变形序列。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临生成语义一致和时间平滑变形的挑战，特别是在跨类别情况下。现有方法难以在保持结构连贯性的同时实现高质量的变形效果。

Method: 提出基于SLAT表示的无需训练框架，包含变形交叉注意力（MCA）融合源和目标特征以保持结构连贯性，时间融合自注意力（TFSA）增强时间一致性，以及姿态校正策略缓解变形过程中的姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，即使在具有挑战性的跨类别情况下也能表现优异。进一步支持解耦变形和3D风格迁移等高级应用，并能推广到其他基于SLAT的生成模型。

Conclusion: MorphAny3D通过智能融合SLAT特征的注意力机制，实现了高质量、语义一致且时间平滑的3D变形，为跨类别3D变形提供了有效的解决方案，并展示了在多种高级应用中的潜力。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [8] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出基于多视角2D图像和神经辐射场(NeRF)的3D实例分割框架，用于农业场景中的精确作物计数，解决了遮挡和聚类作物区分难题。


<details>
  <summary>Details</summary>
Motivation: 户外农田环境中，部分遮挡和聚类作物从单一视角难以区分，给基于图像的作物计数带来巨大挑战，需要更精确的计数方法。

Method: 利用多视角2D图像，结合神经辐射场(NeRF)进行视图合成，引入作物可见性和掩码一致性评分，结合3D信息实现3D实例分割。

Result: 在棉花铃、苹果和梨三个农业数据集上验证，展示了稳定的计数性能，不受作物颜色、形状和大小变化影响，性能优于现有方法。

Conclusion: 提出的3D实例分割框架能有效解决农业场景中的作物计数问题，无需作物特定参数调优，并贡献了棉花植物数据集促进进一步研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [9] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: 提出IntraStyler方法，通过示例图像引导风格合成，无需先验知识即可捕获多样的域内风格，用于提升跨模态域适应的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，而对域内变异性研究不足。先前方法通常需要预先指定域内变化进行风格合成，这在实际应用中可能不切实际。

Method: 提出IntraStyler方法：1) 基于示例图像引导风格合成，使输出风格与示例风格匹配；2) 引入风格编码器，基于对比学习判别性地学习风格特征；3) 无需任何先验知识即可捕获多样的域内风格。

Result: 在最大的跨模态域适应公共数据集CrossMoDA 2023上进行评估，实验表明该方法在可控风格合成方面有效，且多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够无需先验知识捕获多样的域内风格，通过示例引导的风格合成方法有效提升了跨模态域适应中下游分割任务的性能。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [10] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 该研究提出使用强化学习来提升多模态大语言模型的视觉推理能力，通过设计针对不同推理方面的奖励函数，激励模型生成更长、更结构化的视觉推理过程，从而解决视觉信息整合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成推理链时缺乏对视觉信息的有效整合，这限制了它们解决需要准确视觉感知的任务（如视觉谜题）的能力。研究发现视觉感知是这类任务的关键瓶颈，将图像转换为文本描述能显著提升性能。

Method: 采用奖励驱动的强化学习方法，设计了六个针对不同推理方面的奖励函数（包括图像理解、思维步骤和答案准确性），使用组相对策略优化（GRPO）来激励更长、结构化的推理过程，并防止视觉信息的绕过。

Result: 在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，在领域内和领域外设置下都取得了稳定的增益。实验表明，将图像转换为文本描述能为Claude 3.5带来26.7%的性能提升，为Claude 3.7带来23.6%的提升。

Conclusion: 强化学习是解锁开源多模态大语言模型长视觉推理能力的有效机制，无需昂贵的监督数据。通过设计合适的奖励函数来激励结构化推理，可以显著提升模型在需要视觉感知的任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [11] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新的向量量化方法，通过低维码本组合量化，在保持高性能的同时显著减小码本尺寸，可作为即插即用模块应用于各种下游任务。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度不断增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突，需要新的解决方案来平衡这一矛盾。

Method: LooC采用低维组合码本方法：1) 将码向量重构为特征向量中的低维组合单元，通过组合而非直接匹配来扩展解空间；2) 引入参数无关的插值外推机制，在量化过程中增强和平滑特征；3) 实现全码本利用，避免崩溃问题；4) 设计为即插即用模块。

Result: 在多种任务、数据集和架构上的广泛评估表明，LooC在显著减小码本尺寸的同时，性能优于现有向量量化方法，达到了最先进的性能水平。

Conclusion: LooC成功解决了向量量化中码本容量与紧凑性之间的矛盾，通过创新的低维组合码本设计和特征增强机制，实现了高性能的小码本量化，为各种下游任务提供了有效的即插即用解决方案。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [12] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 论文提出SynDR-IQA框架，通过重塑合成数据分布来解决盲图像质量评估中合成数据泛化能力不足的问题，采用内容上采样和聚类下采样策略提升模型泛化性能。


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估（BIQA）面临大规模标注数据稀缺的挑战，虽然合成数据提供了解决方案，但现有合成数据集训练的模型泛化能力有限。研究发现合成数据集学习到的表示呈现离散聚类模式，阻碍了回归性能。

Method: 提出SynDR-IQA框架，基于样本多样性和冗余对泛化误差影响的理论推导，采用两种策略：1）分布感知的多样化内容上采样，在保持内容分布的同时增强视觉多样性；2）密度感知的冗余聚类下采样，通过减少密集聚类区域的样本密度来平衡样本分布。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上的广泛实验证明了该方法的有效性，显著提升了BIQA模型的泛化能力。

Conclusion: 通过重塑合成数据分布，SynDR-IQA有效解决了合成数据在盲图像质量评估中的泛化瓶颈问题，为利用合成数据提升模型性能提供了新思路。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [13] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8解决PCB红外缺陷检测数据稀缺问题


<details>
  <summary>Details</summary>
Motivation: 红外(IR)数据稀缺是PCB缺陷检测的关键瓶颈，传统方法依赖配对监督，但实际中配对数据难以获取

Method: 使用CycleGAN进行无配对图像转换，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；构建异构训练策略，融合生成的伪红外数据和有限真实红外样本训练轻量级YOLOv8检测器

Result: 该方法有效增强低数据条件下的特征学习，增强后的检测器显著优于仅使用有限真实数据训练的模型，性能接近完全监督训练的基准

Conclusion: 伪红外合成作为工业检测的鲁棒增强策略具有显著效果，为解决红外数据稀缺问题提供了有效方案

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [14] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 提出轻量级害虫检测与农药推荐框架，适用于智能手机等低资源设备，帮助小农户实现精准农业


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工检查和化学农药，成本高、耗时长、劳动密集且对环境有害，需要适合小农户的低成本解决方案

Method: 包含两个模块：1) 害虫检测模块使用轻量级CNN结合原型元学习，支持少样本学习；2) 农药推荐模块结合作物类型和生长阶段等环境因素，推荐安全环保的农药

Result: 轻量级CNN达到与最先进模型相当的准确率，同时显著降低计算复杂度；决策支持系统减少对传统化学农药的依赖，促进可持续实践

Conclusion: 该框架在精准农业中具有实时应用潜力，特别适合资源有限的农民使用，能有效改善害虫管理实践

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [15] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一个基于器官分离概念的放射学基础模型，通过自动化创建器官体积-文本对，结合自监督预训练和对比学习，在3D-CT图像与语言表达对应关系学习中平衡计算效率和表征能力。


<details>
  <summary>Details</summary>
Motivation: 放射学基础模型在处理3D-CT容积数据时面临计算成本约束的挑战，需要一种既能高效学习又能保持良好表征能力的方法。

Method: 基于器官分离概念，利用14万系列大规模数据集，通过分割技术和基于LLM的放射报告处理自动化创建器官体积-发现句子对，结合VideoMAE自监督预训练和体积-文本对对比学习。

Result: 在零样本器官级病变分类任务中，相比CT-CLIP在83%器官上获得更高F1分数，相比Merlin在64%器官上表现更好；在零样本发现级病变分类中，相比Merlin在83%类别上获得更高AUROC；在放射报告生成任务中性能与现有VLMs相当。

Conclusion: 器官分离学习框架为3D-CT基础模型的实际应用提供了现实有效的设计指导，展示了在临床评估环境中的高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [16] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个包含1550万高质量图像-文本对的多学科科学多模态数据集，通过AI增强管道解决科学图像与文本描述之间的语义鸿沟问题。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在通用领域取得了革命性进展，但在科学发现中的应用受到复杂科学图像与稀疏文本描述之间深刻语义鸿沟的阻碍。现有科学多模态数据集存在对齐质量差、规模有限的问题。

Method: 从250万篇开放获取科学论文中提取超过1550万图像-文本对，涵盖物理、生物、工程等多个学科。引入AI就绪的语义增强管道，利用Qwen-VL多模态大模型系列，通过综合论文摘要和引用上下文重新为图像生成描述，解决原始科学标题对齐弱的问题。

Result: 技术验证显示增强显著提高了数据质量：基于SciBERT的伪困惑度指标显示语义模糊性降低，CLIP分数表明图像-文本对齐提高了18.21%。数据集在HuggingFace上公开可用。

Conclusion: S1-MMAlign为推进科学推理和跨模态理解提供了基础资源，有助于在AI for Science时代推动科学发现。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [17] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer：基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐视觉嵌入，替代传统语义分割，支持自然语言查询和3D建图


<details>
  <summary>Details</summary>
Motivation: 家庭环境中机器人需要全面理解周围环境，以便与未经训练的人类进行有效直观的交互。传统语义分割方法使用固定预定义类别，缺乏灵活性。

Method: 提出DVEFormer，基于RGB-D Transformer架构，通过知识蒸馏从Alpha-CLIP教师模型中学习细粒度像素级嵌入，预测密集文本对齐视觉嵌入（DVE）。

Result: 在室内数据集上评估显示竞争性性能，满足实时要求：完整模型26.3 FPS，小型变体77.0 FPS（NVIDIA Jetson AGX Orin）。支持文本查询和3D建图应用。

Conclusion: DVEFormer可作为传统分割方法的直接替代，同时支持灵活的自然语言查询和无缝集成到移动机器人3D建图流程中。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [18] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出ActErase：一种无需训练的扩散模型概念擦除方法，通过激活差异分析和动态替换实现高效概念移除


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理风险，现有概念擦除方法大多依赖数据密集且计算成本高的微调，存在关键限制

Method: 基于模型激活主要由通用概念组成、仅极小部分表示目标概念的观察，通过提示对分析识别激活差异区域，提取目标激活并在前向传播中动态替换输入激活

Result: 在三个关键擦除任务（裸露内容、艺术风格、对象移除）上实现最先进的擦除性能，有效保持模型整体生成能力，对对抗攻击表现出强鲁棒性

Conclusion: ActErase为扩散模型中的轻量级有效概念操作建立了新的即插即用范式，无需训练即可实现高效概念擦除

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [19] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种基于高斯分布的SLAM框架，通过训练无关的对应关系初始化取代了传统的残差驱动密度化过程，实现了更稳定、更快速的实时建图。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM使用残差驱动密度化方法逐步添加高斯分布，这种方法可能导致早期建图不稳定且收敛较慢。RGS-SLAM旨在通过一次性初始化方法解决这些问题。

Method: 使用DINOv3描述符提取密集多视角对应关系，通过置信度感知的内点分类器进行精炼，然后进行一次性三角测量生成结构感知的高斯种子，作为优化的先验分布。

Result: 在TUM RGB-D和Replica数据集上评估，RGS-SLAM实现了约20%的收敛加速，在纹理丰富和杂乱场景中获得更高的渲染保真度，同时保持高达925 FPS的实时建图性能。

Conclusion: RGS-SLAM通过训练无关的对应关系初始化方法，显著提高了高斯分布SLAM的稳定性和效率，在定位和重建精度上达到或超越了现有最先进系统。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [20] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS：一种在稀疏观测下重建动态目标的方法，通过骨架驱动变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的动态目标重建面临挑战，因为观测通常来自稀疏视角（如监控摄像头）且时间采样稀疏。传统方法需要密集的多视角视频，这在真实场景中难以实现。因此需要开发能够在稀疏观测下进行动态重建的方法。

Method: SV-GS框架同时估计变形模型和物体随时间运动。使用粗略骨架图和初始静态重建作为输入引导运动估计。方法优化骨架驱动变形场，包括粗粒度骨架关节姿态估计器和细粒度变形模块。仅使关节姿态估计器随时间变化，实现平滑运动插值同时保留几何细节。

Result: 在合成数据集上，方法在稀疏观测下比现有方法PSNR提升达34%。在真实世界数据集上，尽管使用显著更少的帧数，仍能达到与密集单目视频方法相当的性能。此外，初始静态重建可被基于扩散的生成先验替代，提高了实用性。

Conclusion: SV-GS能够在稀疏观测下有效重建动态目标，通过骨架驱动变形场实现高质量运动估计和几何细节保留。方法对输入要求宽松，具有实际应用价值。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [21] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 基于Swin Transformer的深度学习模型在ISIC2019数据集上对8种皮肤病变分类达到87.71%准确率，可作为临床诊断支持工具和患者自我评估辅助。


<details>
  <summary>Details</summary>
Motivation: 皮肤病日益普遍但皮肤科医生资源有限，需要智能工具支持患者和临床医生进行及时准确的皮肤疾病诊断。

Method: 开发基于深度学习的皮肤疾病分类诊断模型，利用公开皮肤疾病图像数据集进行预训练，提取视觉特征；优化模型架构、数据预处理流程，应用针对性数据增强技术提升性能；最终采用Swin Transformer架构。

Result: 在ISIC2019数据集上对8种皮肤病变类别实现了87.71%的预测准确率。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助的潜力，能够帮助解决皮肤科医生资源不足的问题。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [22] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor是一个基于草图的视频着色模型，支持使用异构、可变数量的参考图像，通过显式的每参考区域分配和时空对应掩码注意力来提升着色质量。


<details>
  <summary>Details</summary>
Motivation: 现有着色模型通常只基于单一参考（通常是场景的第一帧），忽略了其他条件数据源，如角色设定图、背景图像或任意着色帧。这限制了着色质量和一致性。

Method: TimeColor将参考图像编码为额外的潜在帧，在时间维度上拼接，使它们能在每个扩散步骤中并行处理。采用显式的每参考区域分配、时空对应掩码注意力以及模态分离的RoPE索引，防止捷径学习和跨身份调色板泄漏。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下，相比现有基线方法在颜色保真度、身份一致性和时间稳定性方面都有显著提升。

Conclusion: TimeColor通过支持异构、可变数量的参考图像，结合创新的参考编码和注意力机制，有效提升了视频着色的质量，解决了传统单一参考方法的局限性。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [23] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet是一个计算高效的行人重识别模型，通过多尺度特征融合、语义聚类、动态权重平均等技术，在保持高准确率的同时显著降低计算成本，适合实时监控和移动应用部署。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别方法虽然准确率高但计算成本大，难以在计算资源有限的实时监控和移动应用中部署。需要开发既准确又计算高效的模型。

Method: 提出VisNet模型，包含：1）多尺度特征融合（融合ResNet50的1-4阶段特征）；2）语义聚类与解剖学身体分区；3）动态权重平均技术平衡分类语义正则化；4）使用FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1准确率和77.65% mAP，仅有32.41M参数和4.601 GFLOPs计算量，显著优于现有高计算成本方法。

Conclusion: VisNet为计算资源有限的实时监控和移动应用提供了一个实用高效的行人重识别解决方案，在准确率和计算效率之间取得了良好平衡。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [24] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 该论文提出了OmniVaT框架，首次成功解决了单域泛化多模态视觉触觉学习（SDG-VTL）任务，通过统一嵌入频率空间和分层树结构来缓解模态差异和域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉学习（VTL）存在视觉和触觉图像之间的模态差异，以及非标准化触觉传感器和不一致数据收集导致的域差距问题。这些挑战被形式化为单域泛化多模态VTL（SDG-VTL）任务。

Method: 提出了OmniVaT框架，包含两个核心模块：1）多模态分数傅里叶适配器（MFFA），将视觉和触觉嵌入映射到统一的嵌入频率空间，缓解模态差距；2）离散树生成（DTG）模块，通过分层树结构获得多样可靠的多模态分数表示，增强对未见域中波动域偏移的适应性。

Result: 大量实验表明，OmniVaT在SDG-VTL任务上表现出优越的跨域泛化性能。

Conclusion: OmniVaT框架首次成功解决了SDG-VTL任务，通过统一嵌入频率空间和分层树结构有效缓解了模态差异和域偏移问题，为视觉触觉学习的跨域泛化提供了有效解决方案。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [25] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 提出概率双流框架，统一可靠性建模和多模态集成，解决骨架动作识别中忽略手部细微动作的问题，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法主要关注身体大尺度运动，忽视了手部细微动作对于细粒度识别的重要性，需要一种能处理不确定性和多模态融合的框架。

Method: 概率双流框架包含三个关键组件：1) 无校准预处理管道，直接从原生坐标学习；2) 概率Noisy-OR融合，稳定可靠性感知的双流学习；3) 从内部到跨模态集成，耦合四种骨架模态与RGB表示。

Result: 在多个基准测试（NTU RGB+D 60/120、PKU-MMD、N-UCLA）和新定义的手部中心基准上均表现出持续改进和鲁棒性，特别是在噪声和异构条件下。

Conclusion: 该框架通过统一可靠性建模和多模态集成，有效解决了骨架动作识别中手部细微动作的识别问题，为细粒度动作识别提供了新的解决方案。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [26] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，通过免姿态前馈4D重建和在线单目退化模式模拟等技术，实现了对多样化单目视频的可扩展处理。


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性限制，主要原因是需要昂贵且专业的多视角4D数据或繁琐的训练预处理。NeoVerse旨在解决这一问题，构建一个能够处理多样化单目视频的可扩展4D世界模型。

Method: NeoVerse采用免姿态前馈4D重建、在线单目退化模式模拟以及其他对齐良好的技术，使整个流程能够扩展到多样化的单目视频数据，无需昂贵的多视角数据或复杂预处理。

Result: NeoVerse在标准重建和生成基准测试中实现了最先进的性能，同时展现出对各种领域的良好泛化能力和多功能性。

Conclusion: NeoVerse通过创新的可扩展设计，成功构建了一个能够处理多样化单目视频的4D世界模型，在4D重建、新轨迹视频生成和下游应用方面表现出色，为4D世界建模提供了新的解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [27] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics：一个端到端可微分框架，通过自然语言提示为3D场景推断合理的物理参数，无需真实轨迹或标注视频指导


<details>
  <summary>Details</summary>
Motivation: 准确模拟现有3D物体和各种材料通常需要专家知识和耗时的物理参数调整，现有方法需要真实轨迹或标注视频指导

Method: 使用多模态大语言模型估计材料参数值，提出可学习的运动蒸馏损失从预训练视频扩散模型中提取鲁棒运动先验，最小化外观和几何归纳偏差

Result: 在30多个场景中评估，涵盖真实世界、人工设计和AI生成的3D物体，包括弹性固体、金属、泡沫、沙子、牛顿和非牛顿流体等材料，超越现有技术

Conclusion: MotionPhysics能够通过自然语言指导产生视觉逼真的动态模拟，同时自动确定物理上合理的参数，为3D物理模拟提供了新的解决方案

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [28] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个基于行车记录仪的大规模路边垃圾检测数据集，包含超过1.1万张标注图像，专注于极端小目标检测，为开发可扩展的低成本路边垃圾监测系统提供基准。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖劳动密集型调查和公众报告，空间覆盖有限。现有的视觉数据集主要关注街景静态图像、航拍场景或水环境，无法反映行车记录仪视频中垃圾目标极小、稀疏且嵌入杂乱路边背景的特点。

Method: 构建了RoLID-11K数据集，包含超过1.1万张标注图像，涵盖英国多样的驾驶条件，呈现明显的长尾分布和小目标分布特征。对多种现代检测器进行基准测试，包括精度导向的transformer架构和实时YOLO模型。

Result: CO-DETR及相关transformer模型实现了最佳定位精度，但实时模型受限于粗糙的特征层次结构。该数据集为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准。

Conclusion: RoLID-11K是首个针对行车记录仪路边垃圾检测的大规模数据集，支持开发可扩展、低成本的监测系统，为极端小目标检测提供了重要基准。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [29] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: MS COCOAI是一个用于AI生成图像检测的新型数据集，包含96000个真实和合成数据点，基于MS COCO数据集构建，使用五种生成器创建合成图像，并提出两个检测任务。


<details>
  <summary>Details</summary>
Motivation: 多模态生成AI系统（如Stable Diffusion、DALL-E、MidJourney）改变了合成图像的创建方式，但也助长了误导性内容、虚假信息和操纵媒体的传播。随着生成图像越来越难以与照片区分，检测它们已成为紧迫的优先事项。

Method: 使用MS COCO数据集构建MS COCOAI数据集，包含96000个真实和合成数据点。使用五种生成器创建合成图像：Stable Diffusion 3、Stable Diffusion 2.1、SDXL、DALL-E 3和MidJourney v6。基于该数据集提出两个任务：1）将图像分类为真实或生成；2）识别给定合成图像是由哪个模型生成的。

Result: 创建了MS COCOAI数据集，该数据集已在Hugging Face上公开可用（https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset），为AI生成图像检测研究提供了标准化的基准资源。

Conclusion: MS COCOAI数据集为解决AI生成图像检测的挑战提供了重要资源，通过标准化数据集支持研究社区开发更有效的检测方法，以应对生成AI技术带来的虚假信息传播风险。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [30] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测扰动输入下模型输出的熵变化来识别感知token，并引入对比感知损失来改进RL目标函数。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型推理方面取得了进展，但将其扩展到多模态推理需要同时改进感知和推理两个方面。先前的工作主要通过显式感知奖励来解决这一挑战，但将感知token与推理token分离很困难，需要额外的LLM、真实数据、强制分离感知与推理，或对所有输出token不加区分地应用奖励。

Method: CPPO通过检测在扰动输入图像下模型输出的熵变化来识别感知token，然后在RL目标函数中扩展一个对比感知损失（CPL），该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性。

Result: 实验表明，CPPO超越了先前的感知奖励方法，同时避免了额外模型的使用，使训练更加高效和可扩展。

Conclusion: CPPO提供了一种有效的方法来改进视觉语言模型的感知能力，通过对比感知损失和熵变化检测机制，解决了多模态强化学习中感知与推理分离的挑战。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [31] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制来改进文本渲染，解决了多行布局、密集排版和中文等长尾脚本的文本渲染问题。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍有困难，特别是对于多行布局、密集排版和中文等长尾脚本。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美观性并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"。对于"在哪里写"，通过读取图像到文本注意力的token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化产生高置信度掩码。对于"写什么"，引入频谱调制字形注入（SGMI），通过频域带通调制注入噪声对齐的字形先验，以增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的广泛实验表明，在长文本基准、CVTG和作者提出的CLT-Bench上，文本可读性获得了一致的提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用扩散Transformer模型的内在机制有效改进了文本渲染，在保持语义对齐和美学质量的同时显著提升了文本可读性。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [32] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM通过增强SAM在视觉非显著场景下的感知能力，同时保持其零样本泛化性，解决了SAM在低对比度前景-背景场景中的分割性能问题。


<details>
  <summary>Details</summary>
Motivation: SAM在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法无法捕捉准确轮廓，需要增强SAM对这些场景的感知能力。

Method: 提出VNS-SAM，通过Mask-Edge Token交互解码器和非显著特征挖掘模块有效利用SAM的低层特征，仅需少量参数和计算开销。

Result: VNS-SAM在多种VNS分割任务中表现优异，特别是在零样本设置下，额外参数仅需4小时优化，建立了包含35K+图像的VNS-SEG数据集。

Conclusion: VNS-SAM显著提升了SAM在视觉非显著场景下的分割性能，同时保持了零样本泛化能力，具有广泛的现实应用潜力。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [33] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF框架通过流式误差建模和不确定性引导优化，解决小目标检测中因标注噪声导致的过拟合问题，提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 小目标检测性能显著低于正常尺度目标，且小目标对标注噪声高度敏感，优化严格定位目标容易导致噪声过拟合。

Method: 提出TOLF框架：1）使用归一化流进行灵活的误差建模，捕捉复杂的非高斯预测分布；2）不确定性感知梯度调制机制，抑制从高不确定性噪声样本中学习。

Result: 在三个数据集上的实验验证了方法的有效性，特别是在AI-TOD数据集上将DINO基线提升了1.2% AP。

Conclusion: TOLF通过流式误差建模和不确定性引导优化，有效解决了小目标检测中的噪声鲁棒性问题，提升了检测性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [34] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag提出了一种基于"预测-移动"框架的拖拽式图像编辑方法，通过迭代执行运动预测和运动监督来避免传统"移动-跟踪"框架中的跟踪失败和模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有拖拽式图像编辑方法主要采用"移动-跟踪"框架，存在跟踪失败和模糊跟踪等不可避免的问题；其他框架方法则存在源图像与目标图像差距过大、中间点不合理导致编辑性差等问题。

Method: 提出DynaDrag方法，采用"预测-移动"框架，迭代执行运动预测和运动监督：1）运动预测预测手柄点应移动的位置；2）运动监督根据预测结果拖拽手柄点；3）动态调整有效手柄点以提升性能。

Result: 在人脸和人体数据集上的实验表明，DynaDrag在性能上优于先前的工作。

Conclusion: DynaDrag是首个基于"预测-移动"框架的拖拽式图像编辑方法，通过迭代的运动预测和运动监督机制，有效解决了传统方法中的跟踪失败和模糊跟踪问题，提升了图像编辑的质量和可控性。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [35] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种基于点云迭代的先进光声成像重建算法，专门针对不规则几何换能器阵列设计，相比原始SlingBAG算法在重建速度上提升2.2倍。


<details>
  <summary>Details</summary>
Motivation: 临床应用中高质量3D光声成像需求增长，但传统迭代重建算法在处理不规则阵列配置时面临计算复杂度高、内存需求大、重建时间长等挑战。

Method: 基于SlingBAG方法的点云迭代概念，扩展其兼容性至任意阵列几何形状，采用结合零梯度滤波和渐进增加时间采样率的分层优化策略，快速去除冗余空间点云并加速收敛。

Result: SlingBAG Pro在不规则阵列几何下实现了基于点云的3D光声重建速度提升高达2.2倍，通过仿真和活体小鼠实验验证了方法的有效性。

Conclusion: SlingBAG Pro算法能够保持高质量重建的同时减少所需换能器数量，显著缩短整体重建时间，为不规则几何换能器阵列的高质量3D光声成像提供了有效解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [36] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS是一个评估统一多模态模型世界知识应用能力的多任务基准，包含1050个手动标注的问题，覆盖21个主题和6种推理类型，并提出确定性检查表评估方法以提高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在局限性，只能进行孤立、单任务的评估，诊断能力有限，无法全面评估统一多模态模型在不同任务中应用世界知识的能力。

Method: 提出了AEGIS基准，包含1050个具有挑战性的手动标注问题，涵盖视觉理解、生成、编辑和交错生成等多个任务，覆盖21个主题和6种推理类型。同时提出了确定性检查表评估方法，用原子化的"是/否"判断替代模糊的提示式评分。

Result: 实验显示大多数统一多模态模型存在严重的世界知识缺陷，随着推理复杂度增加，性能显著下降。简单的插件式推理模块可以部分缓解这些弱点。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿，AEGIS基准和确定性检查表评估方法为评估和改进模型的世界知识应用能力提供了重要工具。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [37] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究针对医学视觉语言模型在部署后可能因数据分布偏移导致性能退化的问题，开发了DomainSAT工具箱和置信度指标来监测模型可靠性，发现结合输入数据偏移检测和输出置信度指标能更可靠地检测性能退化。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医学图像分析和疾病诊断中表现出强大潜力，但部署后当输入数据分布与开发时观察到的分布发生偏移时，其性能可能会下降。检测这种性能退化对于临床可靠性至关重要，但对于大型预训练VLM在无标签数据下操作仍然具有挑战性。

Method: 研究开发了DomainSAT工具箱，这是一个轻量级图形界面工具，集成了代表性的偏移检测算法，便于系统分析输入数据偏移。同时研究了输出级预测行为，引入了一种无标签、基于置信度的退化指标，直接捕捉模型预测置信度的变化。

Result: 分析表明，输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但并不总是与实际性能退化相对应。基于置信度的退化指标与性能退化表现出密切关系，可作为输入偏移检测的有效补充。在大型病理学数据集上的实验表明，结合输入数据偏移检测和输出置信度指标能更可靠地检测和解释数据偏移下VLM的性能退化。

Conclusion: 该研究为数字病理学中基础模型的可靠性监测提供了一个实用且互补的框架，通过结合输入数据偏移检测和输出置信度指标，能够更有效地监测视觉语言模型在数据偏移下的性能退化问题。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [38] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可在多个基准测试中取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索中，文本查询与视频内容之间存在语义粒度不匹配问题。现有方法虽然利用了高质量的预训练知识，但未能平衡不同模态间的语义粒度，导致检索不准确。

Method: 提出GranAlign框架，包含两种互补技术：1) 基于粒度的查询重写，生成不同语义粒度的查询；2) 查询感知的标题生成，将查询意图嵌入视频内容。通过将多粒度查询与查询无关/查询感知的标题配对，有效解决语义不匹配。

Result: 在三个主要基准测试(QVHighlights、Charades-STA、ActivityNet-Captions)上均达到新的SOTA性能，特别是在具有挑战性的QVHighlights数据集上mAP@avg提升了3.23%。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可显著提升检索性能，证明了平衡不同模态语义粒度的重要性。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [39] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo：基于最小化运动遗忘的两阶段机器学习遗忘策略，在连续空间中实现安全的人体运动生成，避免离散码本替换的缺陷，提供更好的安全-效用权衡


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的文本到运动生成方法存在两个关键缺陷：1) 替换被良性提示重用的码本条目会导致日常任务性能下降；2) 离散标记方法引入量化和平滑度损失，导致伪影和抖动过渡。此外，现有文本到运动数据集天然包含不安全意图和对应运动，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘（MMU）的两阶段机器学习遗忘策略：1) 在连续空间中实现安全人体运动生成，避免码本损失；2) 构建首个安全文本到运动数据集SafeMoVAE-29K，包含重写的安全文本提示和连续精炼运动；3) 基于DiP架构高效生成具有自然过渡的安全人体运动。

Result: 实验显示SafeMo在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍更高的遗忘集FID，相比先前最先进的人体运动遗忘方法LCR，在安全提示上的良性性能相当或更好，实现了有效的安全-效用权衡。

Conclusion: SafeMo通过连续空间中的最小化运动遗忘策略，解决了现有离散码本替换方法的安全缺陷，实现了更安全、更自然的文本到运动生成，为可信赖的人体运动生成提供了有效框架。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [40] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种解决RGB-红外多模态感知中优化偏差问题的方法，通过模态主导指数量化模态不平衡，并开发了模态主导感知的跨模态学习框架来改善融合效果。


<details>
  <summary>Details</summary>
Motivation: RGB-红外多模态感知在复杂物理环境中的嵌入式多媒体系统中至关重要。尽管现有的跨模态融合方法有所进展，但由于模态特征不对称导致的优化动态问题仍未得到充分研究。实践中，信息密度和特征质量的差异会引入持续的优化偏差，导致训练过度强调主导模态，阻碍有效的融合。

Method: 提出了模态主导指数（MDI），通过联合建模特征熵和梯度贡献来量化模态主导程度。基于MDI，开发了模态主导感知的跨模态学习（MDACL）框架，该框架包含分层跨模态指导（HCG）来增强特征对齐，以及对抗均衡正则化（AER）来平衡融合过程中的优化动态。

Result: 在三个RGB-红外基准数据集上的广泛实验表明，MDACL能够有效缓解优化偏差，并实现了最先进的性能。

Conclusion: 该研究通过量化模态主导现象并开发相应的平衡优化框架，有效解决了RGB-红外多模态感知中的优化偏差问题，为多模态融合提供了新的解决方案。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [41] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：用于康复训练的实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现实时监测与评估，提供即时反馈指导患者正确执行康复动作。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需要实时监测和评估患者动作，提供即时反馈以帮助患者正确执行康复练习，但目前缺乏高效的实时3D姿态估计与运动分析方法。

Method: 1. 提出端到端实时人体姿态估计与运动分析统一流程；2. 针对多人干扰的医疗康复场景提出快速跟踪方法（单帧跟踪<1ms）；3. 改进SmoothNet用于实时姿态估计，减少误差并恢复真实运动状态；4. 使用Unity平台进行实时监测评估并显示肌肉应力状况。

Result: 方法能够实时监测和评估康复训练中的患者动作，提供即时反馈和指导，快速跟踪方法在多人干扰场景下表现高效，改进的姿态估计方法使运动状态更平滑准确。

Conclusion: RePose为康复训练提供了一种有效的实时3D人体姿态估计与运动分析解决方案，能够帮助患者正确执行康复动作，促进肌肉力量和运动功能的恢复。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [42] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN：基于超图的学习使用特权信息框架，通过双流蒸馏将术后文本知识迁移到术前MRI诊断中，无需推理时文本输入


<details>
  <summary>Details</summary>
Motivation: 室管膜瘤术前预后对治疗规划至关重要，但MRI缺乏术后手术报告中的语义信息。现有多模态方法在推理时无法利用这些特权文本数据。

Method: 提出HyperPriv-EPN框架，采用分割图策略：共享编码器处理教师图（含术后特权信息）和学生图（仅术前数据），通过双流蒸馏让学生图从视觉特征中"幻觉"语义社区结构。

Result: 在311名患者的多中心队列验证中，HyperPriv-EPN实现了最先进的诊断准确率和生存分层性能。

Conclusion: 该方法有效将专家知识迁移到术前场景，解锁历史术后数据的价值，指导新患者诊断而无需推理时文本输入。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [43] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 基于图像的深度学习为马铃薯储存期间的质量监测提供非侵入式解决方案，通过预训练模型实现发芽检测、重量损失估计和保质期预测，DenseNet在发芽检测中达到98.03%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存期间的质量监测挑战，包括发芽检测、重量损失估计和保质期预测，为自动化分拣和库存系统提供非侵入式、可扩展的解决方案。

Method: 在200天控制温湿度条件下收集图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer等预训练架构，设计两个专门模型：高精度二分类发芽检测器和多类别重量损失/保质期预测器。

Result: DenseNet在发芽检测中达到98.03%准确率；保质期预测在粗粒度分类（2-5类）中准确率超过89.83%，细粒度分类（6-8类）因视觉差异细微和数据有限而准确率下降。

Conclusion: 图像模型可集成到自动化系统中，实现早期发芽识别和基于储存阶段的动态分类，改善库存管理、差异化定价和减少食物浪费。未来需开发适应不同品种和储存条件的通用模型。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [44] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS是一个无需训练的方法，通过选择性移除关键文本标记构建幻觉模型，结合广义对比解码来缓解大型视觉语言模型的幻觉问题，显著提升CHAIR分数20%


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在生成幻觉内容的问题，现有无需训练的方法存在两个局限：1) 对幻觉来源的假设过于狭窄；2) 在生成后期（幻觉最可能发生时）效果下降。需要更有效的幻觉缓解方法

Method: 提出CRoPS框架：1) 构建新型幻觉模型，通过选择性移除关键文本标记来捕捉幻觉效应；2) 引入广义对比解码，整合多个幻觉模型以表示多样化的幻觉来源

Result: CRoPS将CHAIR分数提升20%，在六个基准测试和三个LVLM家族中均取得一致增益，优于现有的无需训练方法

Conclusion: 通过选择性移除关键文本标记构建幻觉模型，结合广义对比解码，CRoPS为缓解大型视觉语言模型的幻觉问题提供了有效的无需训练解决方案

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [45] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出一种基于3D高斯场景表示的单图像到视频生成框架，能够在单次前向传播中生成相机引导的视频，无需迭代去噪来注入物体运动，实现了更好的时间一致性和几何完整性。


<details>
  <summary>Details</summary>
Motivation: 现有单图像条件视频生成方法虽然改进了时间一致性和3D一致性，但缺乏鲁棒的用户可控性（如修改相机路径），且大多数相机控制的图像到视频模型在准确建模相机运动、保持时间一致性和保持几何完整性方面存在困难。虽然使用显式中间3D表示的方法有前景，但通常的两步过程（先渲染场景再引入物体运动）仍无法实现完全的时间一致性。

Method: 提出一个新颖框架，通过构建3D高斯场景表示并在单次前向传播中采样合理的物体运动，给定单张图像即可实现快速、相机引导的视频生成。该方法避免了通过迭代去噪向渲染帧中注入物体运动的需要。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的大量实验表明，该方法在视频质量和推理效率方面达到了最先进水平。

Conclusion: 该方法通过3D高斯表示和单次前向传播的物体运动采样，实现了高效、相机可控的单图像到视频生成，解决了现有方法在时间一致性、几何完整性和用户可控性方面的局限性。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [46] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个端到端工作流，使用多模态大语言模型自动批改手写STEM考试，保持标准考试流程，仅需教师提供手写参考答案和评分规则，通过多阶段设计确保可靠性。


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工批改速度慢、难以扩展，需要自动化解决方案来减轻教师负担并提高效率。

Method: 使用多模态LLMs处理扫描手写试卷，通过多阶段设计：格式/存在检查防止批改空白答案、独立评分器集成、监督聚合、刚性模板与确定性验证，生成可审计的机器可解析报告。参考答案转换为文本摘要指导评分而不暴露原始扫描。

Result: 在斯洛文尼亚语真实课程测验评估中，使用GPT-5.2和Gemini-3 Pro后端，完整流程与教师评分平均绝对差异约8分，偏差低，估计手动审查触发率约17%（D_max=40）。消融实验显示简单提示和移除参考答案会显著降低准确性并引入系统性过高评分。

Conclusion: 结构化提示和参考答案基础对于准确自动评分至关重要，提出的端到端工作流能有效处理手写工程测验，保持可靠性并显著减少人工批改工作量。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [47] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 论文探索自监督学习作为辅助任务优化深度伪造检测主任务，发现融合自监督特征表示能提升跨数据集泛化性能。


<details>
  <summary>Details</summary>
Motivation: 释放自监督学习作为辅助任务的潜力，以优化广义深度伪造检测这一主要任务，探索最有效的训练方案组合。

Method: 研究自监督辅助任务与主任务的不同训练方案组合，融合自监督任务的特征表示，形成更强大的特征表示。

Result: 在DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV等多个数据集上实验，结果显示在跨数据集评估中相比当前最先进的检测器具有更好的泛化性能。

Conclusion: 融合自监督辅助任务的特征表示能够充分利用两种任务的潜力，为主任务带来独特的表示能力，从而提升深度伪造检测的泛化性能。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [48] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出了两种用于心脏MRI左心室分割的新型深度学习架构LNU-Net和IBU-Net，基于层归一化和实例-批量归一化改进U-Net，在805张MRI图像上验证了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对心脏图像的临床量化和诊断至关重要，需要更准确的分割方法来支持医疗决策。

Method: 提出了两种基于U-Net的改进架构：LNU-Net在每个卷积块中应用层归一化；IBU-Net在第一个卷积块中结合实例和批量归一化，并将结果传递到下一层。采用仿射变换和弹性变形进行图像数据处理。

Result: 在包含45名患者805张MRI图像的数据集上评估，提出的方法在Dice系数和平均垂直距离指标上优于其他最先进方法。

Conclusion: LNU-Net和IBU-Net是有效的左心室分割架构，通过归一化技术的改进提升了分割性能，为心脏图像分析提供了更好的工具。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [49] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR提出了一种用于单目视频动态3D场景重建的统一框架，通过自适应Gabor表示解决频率适应性问题，使用三次Hermite样条确保时间连续性，在多个任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在三个主要问题：1）使用单一高斯基元具有低通滤波特性，限制了高频细节捕捉；2）标准Gabor函数存在能量不稳定问题；3）缺乏时间连续性约束导致插值时出现运动伪影。

Method: 1）自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数，平衡细节捕捉与稳定性；2）时间连续性：使用带时间曲率正则化的三次Hermite样条确保平滑运动演化；3）自适应初始化：结合深度估计、点跟踪和前景掩码建立早期训练中的稳定点云分布。

Result: 在Tap-Vid DAVIS数据集上达到SOTA性能：PSNR 35.49，SSIM 0.9433，LPIPS 0.0723。在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强大的泛化能力。

Conclusion: AdaGaR成功解决了动态3D场景重建中的频率适应性和时间连续性挑战，为单目视频的动态场景建模提供了统一且有效的解决方案，在多个下游任务中展现出优越性能。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [50] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 提出了一种基于自动机的强化学习框架，用于在MITL规范下为MDP和POMDP合成策略，通过将MITL公式转换为定时LDGBA并与决策过程同步，构建适合Q学习的产品定时模型。


<details>
  <summary>Details</summary>
Motivation: 动态不确定环境中的机器人系统需要满足复杂任务序列和严格时间约束的规划器。MITL提供了表达时间约束的正式框架，但将其与强化学习结合仍然具有挑战性，特别是在随机动态和部分可观测性条件下。

Method: 将MITL公式转换为定时限确定性广义Büchi自动机(Timed-LDGBA)，并与底层决策过程同步，构建产品定时模型。采用简单而富有表达力的奖励结构来强制执行时间正确性，同时允许额外的性能目标。

Result: 在三个仿真研究中验证：5×5网格世界MDP、10×10网格世界POMDP和办公室服务机器人场景。结果表明，该框架能持续学习满足严格时间约束的策略，适应随机转移，扩展到更大状态空间，并在部分可观测环境中保持有效。

Conclusion: 提出的统一框架在时间关键和不确定环境中为可靠机器人规划提供了潜力，能够处理MITL规范下的MDP和POMDP，满足复杂的时间约束要求。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [51] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: CDGS提出了一种新的组合扩散方法，通过引导搜索解决多模态局部分布组合时的模式平均问题，在机器人操作、全景图像合成和长视频生成等任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 组合生成模型在建模长时程任务分布方面很有前景，但当局部分布具有多模态特性时，现有的组合方法会平均不兼容的模式，导致生成的计划既不可行也不连贯。

Method: CDGS将搜索嵌入到扩散去噪过程中，通过基于种群的采样探索局部模式的多样化组合，使用基于似然的过滤剪枝不可行候选，并通过重叠段之间的迭代重采样强制全局一致性。

Result: 在7个机器人操作任务中达到oracle性能，优于缺乏组合性或需要长时程训练数据的基线方法。该方法能跨领域泛化，实现连贯的文本引导全景图像和长视频生成。

Conclusion: CDGS通过将搜索直接集成到扩散过程中，有效解决了组合生成模型中的模式平均问题，实现了局部可行性和全局一致性的平衡，为长时程规划任务提供了有效的解决方案。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [52] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: 该论文提出了一种名为SLAP的系统，用于实现无人机在垂直树干上的轻柔栖息和栖息失败后的恢复，通过视觉检测、姿态控制、弹性抓取等组件集成，在1.2kg四旋翼无人机上验证了75%的栖息成功率和100%的失败恢复率。


<details>
  <summary>Details</summary>
Motivation: 无人机在垂直表面栖息可以降低能耗、进行表面采样或稳定观测，但现有方法主要关注轻量化机械设计，系统集成不足，且通常需要高速、激进的着陆操作，对搭载敏感电子设备的勘测无人机存在危险。

Method: 提出SLAP系统，包含：视觉栖息点检测器、IMU栖息失败检测器、轻柔栖息姿态控制器、光学近距离检测系统，以及由商用slapbands制成的带微刺的快速主动弹性抓取器。在1.2kg商用四旋翼无人机上进行验证。

Result: 室内自主飞行实验在真实橡树段上进行了20次飞行，实现了75%的栖息成功率；在2次诱导失败的飞行中，实现了100%的栖息失败恢复率。

Conclusion: SLAP系统为较大型无人机提供了一种在垂直树干上轻柔栖息并能从栖息失败中恢复的可行方法，通过系统级集成解决了现有方法在安全性和集成度方面的不足。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [53] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: 本文提出了一种分层优化方法，用于自动化车辆涂装过程中多机械臂的路径规划，解决了传统手动设计耗时且无法直接应用现有路径规划技术的问题。


<details>
  <summary>Details</summary>
Motivation: 车辆生产工厂的涂装过程中，多个机械臂同时为传送带上的车身喷漆。目前涂装路径设计仍依赖工程师手动完成，耗时且效率低，需要自动化来减少设计时间。传统机器人路径规划技术（如焊接）无法直接应用于涂装过程，因为涂装过程有独特的约束条件。

Method: 将涂装路径设计建模为分层优化问题：上层子问题类似于车辆路径问题（VRP），负责将车身区域分配给机械臂并确定喷涂顺序；下层子问题进行详细路径规划。通过设计变量表示、约束条件、修复算子和初始化过程，灵活处理涂装过程的特定约束。每层可以使用不同的优化算法。

Result: 在三种商用车型上的实验表明，所提方法能够自动设计出满足所有涂装约束条件的路径，其质量与工程师手动设计的路径相当。

Conclusion: 分层优化方法成功解决了车辆涂装路径自动化设计问题，能够生成满足实际生产约束的高质量路径，显著减少了设计时间，实现了涂装路径设计的自动化。

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [54] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: WiCHINS：一种结合轮载和车体惯性传感器的纯惯性导航系统，在GNSS受限或光照不佳环境下实现准确导航，平均位置误差仅为行驶距离的2.4%。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号受限或光照条件不佳的实际场景中，自动驾驶车辆和轮式机器人的导航解决方案可能只能依赖惯性传感器，而惯性测量误差会导致随时间漂移的问题。需要一种能够在这些挑战性环境中实现稳健导航的纯惯性导航方法。

Method: 提出WiCHINS系统，将轮载惯性传感器与车体惯性传感器相结合。采用三阶段框架，每个阶段配备专用的扩展卡尔曼滤波器，充分利用轮子和车体不同位置的优势进行估计。

Result: 使用包含5个惯性测量单元、总记录时间228.6分钟的数据集进行评估。与四个其他惯性基线方法相比，使用两个轮子和一个车体惯性测量单元时，平均位置误差为11.4米，仅为平均行驶距离的2.4%。

Conclusion: WiCHINS方法能够在挑战性环境中实现稳健导航，有助于缩小纯惯性导航的性能差距，为GNSS受限或光照不佳环境下的自主车辆和轮式机器人提供可靠的导航解决方案。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [55] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出基于可更换夹爪头的抓取系统，用于处理杂乱食品包装中的重量控制问题，特别针对鲑鱼子和意大利面等柔性食品


<details>
  <summary>Details</summary>
Motivation: 食品包装行业面临快速变化的食品种类和重量处理挑战，特别是从易抓取的单件食品到柔性、长条状、杂乱堆积的食品

Method: 设计可更换夹爪头系统，配备专门食品附件（夹爪头），通过皮带更换系统在不同食品包装操作间切换，特别针对鲑鱼子（粘性颗粒食品）和意大利面（长条粘性杂乱食品）设计专用夹爪头

Result: 夹爪成功抓取意大利面和鲑鱼子，重量特定投放准确率分别超过80%和95%，系统展示快速切换不同夹爪头的能力，可处理多种食品

Conclusion: 可更换夹爪头系统能有效解决食品包装中杂乱食品的重量控制问题，具有高准确率和快速切换能力，适用于多种食品类型

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [56] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: 论文提出优先级感知的多机器人覆盖路径规划（PA-MCPP）问题，通过两阶段框架优化优先级区域的加权延迟覆盖时间，同时保持整体完工时间竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人覆盖路径规划方法假设环境区域重要性均匀，但在实际应用中某些区域需要优先关注，现有方法无法有效处理这种优先级差异。

Method: 提出可扩展的两阶段框架：1) 贪婪区域分配结合局部搜索和基于生成树的路径规划；2) 斯坦纳树引导的剩余覆盖规划。

Result: 实验表明该方法相比标准MCPP基线显著降低了优先级加权延迟，同时保持了竞争力的整体完工时间。敏感性分析显示方法能良好扩展到多机器人场景，且通过调整优先级权重可有效控制区域覆盖行为。

Conclusion: PA-MCPP框架成功解决了优先级感知的覆盖规划问题，在保证整体效率的同时优先覆盖重要区域，为实际应用场景提供了更实用的解决方案。

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [57] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出一个用于大型机器人的安全目标到达控制框架，通过模块化设计结合视觉姿态估计、强化学习运动规划、深度学习动力学建模、鲁棒自适应控制和数学安全监督器，确保系统稳定性和操作安全性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中需要大量探索状态-动作空间，期间行为可能不安全，这限制了其在复杂地形上运行的大型复杂机器人上的应用。需要设计一个安全的目标到达控制框架来解决这一问题。

Method: 将整个系统分解为五个紧密耦合的功能模块：1) 实时视觉姿态估计提供准确机器人状态；2) 强化学习运动规划器生成平滑运动指令；3) 监督深度学习模型捕捉机器人复杂动力学；4) 基于模型的鲁棒自适应控制器确保轮子跟踪运动指令；5) 数学安全监督器监控机器人安全。

Result: 提出的框架保证了驱动系统的均匀指数稳定性和整个操作的安全性。在6000公斤机器人上的不同场景实验证实了该框架的有效性。

Conclusion: 通过模块化设计结合多种技术，成功实现了大型机器人在复杂地形上的安全目标到达控制，为强化学习在大型机器人上的安全应用提供了可行方案。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [58] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 提出了一种三维地形跟随的区域覆盖路径规划算法，能够生成多条相邻路径，在保持机械工作宽度的间距同时，保持特定工作高度悬浮于地形之上。


<details>
  <summary>Details</summary>
Motivation: 针对三维地形环境下的区域覆盖任务需求，需要开发能够同时考虑地形起伏和机械工作参数的路径规划算法，以实现在复杂地形上的高效覆盖作业。

Method: 采用逆距离加权方法生成均匀间距的高程数据，结合局部搜索算法，生成满足工作宽度间距和工作高度要求的三维地形跟随路径。

Result: 算法在农业领域的真实三维数据上进行了验证，成功生成了符合地形起伏的覆盖路径，并展示了与二维算法相比的复杂性差异。

Conclusion: 该三维地形跟随区域覆盖路径规划算法能够有效处理复杂地形环境，为农业等领域的自动化作业提供了实用的解决方案。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [59] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 该研究提出了RoboReward数据集和基准，用于评估视觉语言模型在机器人任务中的奖励建模能力，并训练了4B/8B参数的奖励模型，在真实机器人强化学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 在真实机器人领域，获取有效的奖励函数通常需要大量人工标注或脆弱的手工设计目标。虽然视觉语言模型有潜力作为自动奖励模型，但其在真实机器人任务中的效果尚未得到充分理解。

Method: 1) 构建RoboReward数据集和基准，基于Open X-Embodiment和RoboArena的大规模真实机器人数据；2) 提出负样本数据增强流程，通过反事实重标注和时间裁剪生成校准的负样本和接近成功样本；3) 训练4B和8B参数的视觉语言奖励模型。

Result: 1) 评估显示现有视觉语言模型在所有任务中表现不一，仍有很大改进空间；2) 训练的4B/8B参数模型在短期机器人任务奖励分配上优于更大的视觉语言模型；3) 8B参数奖励模型在真实机器人强化学习中大幅优于Gemini Robotics-ER 1.5，并显著缩小了与人工提供奖励的差距。

Conclusion: RoboReward为视觉语言模型在机器人奖励建模领域提供了系统评估基准，所训练的奖励模型在真实机器人强化学习中表现出色，为自动化奖励设计提供了有前景的方向。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [60] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: DefVINS是一个视觉-惯性里程计框架，专门处理可变形场景，通过分离刚性IMU锚定状态和非刚性变形图表示，结合可观测性分析来提升非刚性环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 可变形场景违反了传统视觉-惯性里程计（VIO）的刚性假设，导致系统容易过度拟合局部非刚性运动或在变形主导视觉视差时产生严重漂移。需要开发能够处理非刚性变形的VIO系统。

Method: 提出DefVINS框架，将刚性IMU锚定状态与非刚性变形图表示分离。系统首先使用标准VIO程序初始化，固定重力、速度和IMU偏差，然后根据估计条件逐步激活非刚性自由度。包含可观测性分析来表征惯性测量如何约束刚性运动，并在变形存在时识别原本不可观测的模式。

Result: 消融研究表明，结合惯性约束和基于可观测性的变形激活策略，在非刚性环境下提高了系统的鲁棒性。IMU锚定和条件激活策略防止了在激励不足情况下的病态更新。

Conclusion: DefVINS通过显式分离刚性IMU锚定状态和非刚性变形表示，结合可观测性分析指导的激活策略，有效解决了可变形场景下的VIO问题，提高了非刚性环境下的鲁棒性和准确性。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [61] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 研究探索儿童对机器人重复错误的反应，发现儿童与成人既有相似调整行为，也有更多脱离互动行为，但错误不影响儿童对机器人的感知。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探讨成人对连续机器人错误的反应，但儿童对此类错误的反应仍未被充分探索。本研究旨在了解儿童对机器人社交错误和性能错误的反应，特别是重复对话错误。

Method: 复制Liu等人的连续机器人失败范式，让59名8-10岁儿童与机器人互动。机器人连续三次无法理解儿童提示，通过视频记录和分析儿童的行为反应。

Result: 儿童与成人反应既有相似也有差异：相似之处包括调整提示、改变语气、情绪性非语言反应增加；差异在于儿童表现出更多脱离行为（如暂时忽略机器人或寻求成人帮助）。错误不影响儿童对机器人的感知。

Conclusion: 儿童对机器人错误表现出更灵活的对话期望，这些发现有助于为年轻用户设计更有效、更适合发展阶段的机器人交互系统。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [62] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 该研究系统评估了14种异常检测算法在不同类别不平衡条件下的性能，发现最佳检测器高度依赖于训练数据中故障样本的总数量，而非健康样本的数量。


<details>
  <summary>Details</summary>
Motivation: 工业系统中机器学习应用面临极端类别不平衡的挑战，特别是故障数据稀缺的问题。需要评估异常检测算法在实际工程约束下的性能表现。

Method: 使用问题无关的模拟数据集（2D和10D超球面异常分布），在异常率0.05%-20%、训练规模1000-10000的数据集上，对14种检测器进行基准测试，测试集规模为40000。

Result: 1) 最佳检测器取决于训练数据中故障样本总数；2) 故障样本少于20个时，无监督方法(kNN/LOF)占优；3) 故障样本30-50个时，半监督(XGBOD)和监督(SVM/CatBoost)方法性能大幅提升；4) 半监督方法在10个特征时优势明显；5) 小数据集上异常检测方法的泛化性能下降。

Conclusion: 研究为工业环境中部署异常检测提供了实用指导：应根据可用故障样本数量选择合适算法，并关注特征维度对半监督方法的影响，同时注意小数据集上的泛化性能下降问题。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [63] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 论文提出了一种针对LLM组合技术的攻击方法：通过设计一个在捐赠模型中功能惰性但在移植到基础模型后能可靠重构为恶意特征的"破坏令牌"，利用系数重用的几何特性破坏基础模型的生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着开源权重LLM生态系统中模型组合技术（如权重合并、推测解码、词汇扩展）的普及，不同模型家族间的令牌移植成为关键前提。作者发现这一必要的互操作性步骤引入了供应链漏洞，需要研究其安全风险。

Method: 将攻击形式化为双目标优化问题，使用稀疏求解器实例化攻击。通过利用系数重用的几何特性，设计一个在捐赠模型中功能惰性但在移植后能重构为高显著性恶意特征的"破坏令牌"，创建不对称可实现性差距。

Result: 攻击无需训练即可实现，通过谱模仿逃避异常检测，在微调和权重合并后仍保持结构持久性。实证表明攻击能可靠破坏基础模型的生成能力，同时捐赠模型的效用与正常行为在统计上无法区分。

Conclusion: 令牌移植这一关键的互操作性步骤在模块化AI组合流程中引入了隐藏风险，暴露了供应链漏洞。攻击展示了模型组合技术中的安全威胁，需要更严格的防御机制。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [64] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 本文提出了一种新的渐近固定置信度最佳臂识别方法，通过放松精确误差控制要求，在渐近框架下实现更紧的最优性和对非参数分布的更好处理。


<details>
  <summary>Details</summary>
Motivation: 现有BAI方法在实际应用中存在局限性，严格的精确误差控制需要使用宽松的尾不等式和/或参数限制，无法有效处理弱信号、高显著性要求和后实验推断需求等现实场景。

Method: 引入渐近误差控制框架，开发新颖的渐近任意时间有效置信序列，设计新的BAI算法，灵活纳入协变量进行方差缩减，确保在完全非参数设置下的近似误差控制。

Result: 在温和收敛假设下，提供了样本复杂度的渐近界限，最坏情况样本复杂度与高斯BAI在精确误差保证和已知方差下的最佳情况样本复杂度相匹配，实验表明方法在保持误差控制的同时减少了平均样本复杂度。

Conclusion: 提出的渐近框架克服了传统BAI方法的局限性，实现了更紧的最优性，更好地处理了灵活的非参数结果分布，并充分利用了个体级上下文信息，为实际应用提供了更实用的解决方案。

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [65] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: NeuroSymBO通过将提示工程重构为序列决策问题，使用贝叶斯优化自适应选择指令，显著提升LLM在方程发现任务中的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在方程发现中表现出潜力，但其输出对提示措辞高度敏感（指令脆弱性），静态提示无法适应多步生成过程的演化状态，导致模型陷入次优解

Method: 提出NeuroSymBO方法，将提示工程重构为序列决策问题，维护离散推理策略库，使用贝叶斯优化基于数值反馈在每个步骤选择最优指令

Result: 在PDE发现基准测试中，自适应指令选择显著优于固定提示，实现了更高的恢复率和更简洁的解决方案

Conclusion: 将提示工程作为序列决策问题处理，通过自适应指令选择可以有效解决LLM的指令脆弱性问题，提升方程发现任务的性能

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [66] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM是一个用于未知环境中同时导航与建图的几何强化学习框架，它通过局部感知而非全局建图实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中同时导航与建图(SNAM)的挑战性问题，传统方法需要构建全局地图或设计复杂的多智能体策略，而本文旨在仅依赖局部感知观察实现高效导航。

Method: 采用几何强化学习框架，将路径导航和建图建模为动态最短路径搜索和发现过程，使用受控哈密顿优化：将感知输入转化为编码可达性、障碍物屏障和变形约束的局部能量景观，通过更新哈密顿量来演化感知、规划和重构策略。

Result: 在两种不同的2D导航任务上评估，相比局部反应式基线和全局策略学习方法，在相同的阶段性感知约束下，GRL-SNAM保持了安全距离，能够泛化到未见过的布局，并通过局部能量优化而非广泛全局建图实现高质量导航。

Conclusion: 通过更新哈密顿量的几何强化学习能够通过最小化探索和局部能量优化实现高质量导航，无需构建全局地图，为未知环境中的同时导航与建图提供了有效解决方案。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [67] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 该论文研究了非马尔可夫状态和成本过程下的线性函数逼近强化学习方法，证明了在适当遍历性条件下策略评估算法的收敛性，并分析了Q-learning在特定基函数选择下的收敛性


<details>
  <summary>Details</summary>
Motivation: 研究非马尔可夫环境下的强化学习问题，因为实际应用中许多系统具有非马尔可夫特性，需要开发能够处理此类环境的理论框架和算法

Method: 使用线性函数逼近方法，首先分析策略评估算法，证明其在非马尔可夫过程遍历性条件下的收敛性；然后研究Q-learning，特别关注基于量化映射的基函数选择情况；最后将结果应用于部分可观测马尔可夫决策过程

Result: 证明了策略评估算法在非马尔可夫过程遍历性条件下收敛，且极限对应于正交投影与辅助马尔可夫决策过程贝尔曼算子联合算子的不动点；对于Q-learning，在基于量化映射的基函数选择下，可以在类似遍历性条件下证明收敛性；应用于部分可观测马尔可夫决策过程时，推导了学习算法极限的显式误差界

Conclusion: 该研究为非马尔可夫环境下的强化学习提供了理论保证，特别是在线性函数逼近框架下，为处理实际应用中常见的非马尔可夫系统提供了理论基础和算法分析工具

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [68] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 该研究使用XGBoost模型分析美国交通事故严重程度预测，发现时间、地理位置和天气变量是最强预测因子，但模型对极端严重程度案例预测能力有限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索环境、时间和空间因素对美国交通事故严重程度的预测能力，为基于证据的交通管理提供支持。

Method: 使用2016-2023年50万起美国交通事故数据集，训练XGBoost分类器，通过随机搜索交叉验证优化，并采用类别加权处理类别不平衡问题。

Result: 最终模型整体准确率达78%，对多数类别（严重程度2）表现良好，精确率和召回率均为87%。特征重要性分析显示时间、地理位置和天气变量（能见度、温度、风速）是最强预测因子，但降水和能见度预测能力有限。

Conclusion: 研究为基于证据的交通管理提供了见解，但数据集以中等严重程度事故为主限制了模型对极端案例的学习能力，需要替代采样策略、增强特征工程和外部数据集整合。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [69] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 该论文提出了一种使用纯强化学习梯度在线微调决策变换器的新方法，解决了现有方法依赖监督序列建模目标的问题，在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 决策变换器在离线强化学习中表现出色，但扩展到在线设置时仍主要依赖监督序列建模目标。论文发现后见回报重标记这一标准组件与重要性采样强化学习算法不兼容，阻碍了基于纯强化学习梯度的在线微调。

Method: 提出了几种新算法：将GRPO适配到决策变换器，引入子轨迹优化以改进信用分配，使用序列级似然目标增强稳定性和效率，以及主动采样以鼓励在不确定区域的探索。

Result: 通过大量实验证明，该方法超越了现有的在线决策变换器基线，在多个基准测试中取得了新的最先进性能，验证了基于纯强化学习的在线微调对决策变换器的有效性。

Conclusion: 该研究成功实现了决策变换器的纯强化学习梯度在线微调，解决了后见回报重标记与重要性采样算法的不兼容问题，为序列决策制定提供了更有效的在线学习方法。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [70] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: 提出Sequential RC架构，通过将大储层分解为一系列小型互联储层，降低高维时空系统预测的计算成本和内存需求，同时保持长期时间依赖关系。


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在高维时空系统预测中存在梯度训练和内存瓶颈问题，而传统RC架构在处理高维输入时扩展性差，需要更高效且可扩展的预测方法。

Method: 提出Sequential Reservoir Computing架构，将大型储层分解为一系列小型、互联的储层，减少内存和计算成本，同时保持长期时间依赖性，使用固定循环层和凸读出优化。

Result: 在低维混沌系统（Lorenz63）和高维物理模拟（2D涡度和浅水方程）中，Sequential RC相比LSTM和标准RNN基线：预测有效时间延长15-25%，误差指标（SSIM、RMSE）降低20-30%，训练成本降低高达三个数量级。

Conclusion: Sequential RC保持了传统RC的简单性和效率，同时实现了对高维动力系统的卓越可扩展性，为科学和工程应用中的实时、节能预测提供了实用途径。

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [71] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 机器学习模型利用常规电子健康记录数据，在预测肝硬化发病方面显著优于传统FIB-4评分，能够提前1-3年进行更准确的风险分层。


<details>
  <summary>Details</summary>
Motivation: 开发基于常规电子健康记录数据的机器学习模型，用于早期预测肝硬化发病，并与传统的FIB-4评分进行性能比较，以支持临床决策和预防管理。

Method: 采用回顾性队列研究，使用大型学术医疗系统的去标识化电子健康记录数据。识别脂肪肝患者并根据ICD-9/10编码分为肝硬化和非肝硬化队列。构建预测场景模拟真实临床使用，从观察窗口汇总人口统计学、诊断、实验室结果、生命体征和共病指数。使用XGBoost模型训练1年、2年和3年预测模型，并在保留测试集上评估性能，与FIB-4评分进行AUC比较。

Result: 机器学习模型在所有预测时间窗口均优于FIB-4评分。XGBoost模型在1年、2年和3年预测的AUC分别为0.81、0.73和0.69，而FIB-4的AUC分别为0.71、0.63和0.57。随着预测时间延长，性能优势持续存在，表明早期风险区分能力更强。

Conclusion: 基于常规电子健康记录数据的机器学习模型在肝硬化早期预测方面显著优于传统FIB-4评分，能够实现更早、更准确的风险分层，可作为自动化决策支持工具整合到临床工作流程中，支持主动的肝硬化预防和管理。

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [72] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应重复编码框架，实现按维度不等差错保护，在有限带宽下有效保持语义完整性


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限通信系统中语义保持的挑战，传统信道编码（如LDPC、Reed-Solomon）无法实现细粒度语义保护

Method: 采用强化学习框架，通过自适应重复编码实现按维度不等差错保护，使用复合语义失真度量平衡全局嵌入相似性和实体级保持

Result: 相比均匀保护，在1 dB SNR下获得6.8%更高的chrF分数和9.3%更好的实体保持，统计显著

Conclusion: 智能分配的简单重复编码可实现细粒度语义保护，代码结构需与语义粒度对齐，适用于边缘计算和物联网等带宽稀缺但语义保真度关键的场景

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [73] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 提出SSI-GAN半监督学习方法，仅需1-3%标注数据即可实现蚊子神经元尖峰信号的高精度分类，用于检测寨卡病毒、登革热病毒感染，大幅减少人工标注工作量。


<details>
  <summary>Details</summary>
Motivation: 蚊子是虫媒病毒疾病的主要传播媒介，手动分类神经元尖峰模式非常耗时昂贵。现有深度学习方案需要完全标注的数据集和高度预处理的信号，限制了在实际场景中的大规模应用。为解决标注数据稀缺问题，需要开发高效的半监督学习方法。

Method: 提出半监督Swin启发式GAN（SSI-GAN）架构，包含基于Transformer的生成器和Swin启发的移位窗口判别器。使用多头自注意力模型在平面窗口式Transformer判别器中学习捕捉稀疏的高频尖峰特征。仅使用1-3%标注数据，训练超过1500万个尖峰样本，使用贝叶斯Optuna框架优化超参数，并通过五折蒙特卡洛交叉验证验证鲁棒性。

Result: SSI-GAN在感染后第三天仅使用3%标注数据达到99.93%的分类准确率。在仅1%监督下，在所有感染阶段均保持高准确率。相比标准监督方法，在相同性能水平下减少97-99%的人工标注工作量。移位窗口Transformer设计大幅超越所有基线方法，在基于尖峰的神经元感染分类中创下新纪录。

Conclusion: SSI-GAN是一种高效的半监督学习方法，能够显著减少蚊子神经元尖峰信号分类所需的人工标注工作量，为虫媒病毒神经趋向性检测提供了可行的现场应用解决方案，具有重要的实际应用价值。

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [74] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 提出了一种面向资源受限边缘设备的资源高效、数据为中心的心律失常检测框架，通过特征工程使高维数据线性可分，实现了98.44%的准确率和8.54KB的模型大小


<details>
  <summary>Details</summary>
Motivation: 心血管疾病特别是心律失常是全球主要死因，需要IoMT持续监测。现有深度学习方法计算开销过大，不适合资源受限的边缘设备，因此需要开发更高效的解决方案

Method: 采用数据为中心的方法，优先特征工程而非模型复杂度。整合时频小波分解和图论结构描述符（如PageRank中心性），构建混合特征空间，然后使用互信息和递归消除进行特征选择，最终采用可解释的超轻量线性分类器

Result: 在MIT-BIH和INCART数据集上验证，达到98.44%的诊断准确率，模型大小仅8.54KB，分类推理延迟0.46μs，每搏处理管道52ms，相比压缩模型KD-Light（25KB，96.32%准确率）有数量级效率提升

Conclusion: 该框架通过优化特征工程使复杂心律失常数据线性可分，实现了实时操作和超低资源消耗，为无电池心脏传感器提供了可行的解决方案，显著提升了边缘设备上的心律失常检测效率

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [75] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 提出基于最优传输的联邦逆强化学习方法，通过Wasserstein重心融合异构智能体的本地奖励函数，获得比传统参数平均更准确的全局奖励估计。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，直接共享数据学习共同奖励函数通常不现实，因为存在动态差异、隐私约束和通信带宽限制等问题。

Method: 每个客户端先在本地执行轻量级最大熵逆强化学习，然后将得到的奖励函数通过Wasserstein重心进行融合，考虑其底层几何结构。

Result: 证明重心融合比联邦学习中传统的参数平均方法能产生更准确的全局奖励估计，提供了一种原则性且通信高效的框架。

Conclusion: 该方法为异构智能体和环境推导共享奖励函数提供了理论基础，解决了数据隐私、通信效率和环境差异的挑战。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [76] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 该研究提出了基于国际象棋战术的量子基准测试QKRD，用于系统评估QAOA算法在结构化问题上的性能，发现约束保持混合器、预热策略等设计选择对算法性能有显著影响。


<details>
  <summary>Details</summary>
Motivation: 现有量子近似优化算法（QAOA）主要在随机合成实例（如MaxCut、TSP、SAT）上进行基准测试，这些实例缺乏语义结构和人类可解释性，无法充分反映算法在具有实际约束的真实问题上的表现。

Method: 引入量子王环支配（QKRD）基准测试，基于国际象棋战术位置构建，包含5000个结构化实例，具有one-hot约束、空间局部性和10-40量子比特规模。该基准结合人类可解释的覆盖度指标和针对经典启发式算法的内在验证。

Result: 约束保持混合器（XY、domain-wall）比标准混合器收敛快约13步；预热策略减少45步收敛时间，能量改进超过d=8；CVaR优化产生负面结果，能量更差且无覆盖度优势。QAOA优于贪婪启发式算法12.6%，优于随机选择80.1%。

Conclusion: 结构化基准测试揭示了在随机实例中被掩盖的问题感知QAOA技术的优势，为可重复的NISQ算法研究提供了代码、数据和实验工具。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [77] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 提出了一种基于近似贝叶斯推理的逆博弈框架，用于从交互数据中推断智能体目标的后验分布，而非点估计，从而量化不确定性并提升下游决策安全性。


<details>
  <summary>Details</summary>
Motivation: 现有逆博弈方法仅提供点估计，无法量化估计不确定性，导致下游规划可能过度自信地采取不安全行动。需要一种能处理不确定性并整合多模态观测的贝叶斯方法。

Method: 提出贝叶斯逆博弈框架，训练带有可微分纳什博弈求解器的结构化变分自编码器，从交互数据中学习先验和后验分布，无需真实目标标签，支持多模态观测融合。

Result: 实验表明，该框架成功学习到先验和后验分布，相比最大似然估计方法提升了推理质量，实现了更安全的下游决策而不牺牲效率。多模态推理在轨迹信息不足时能进一步降低不确定性。

Conclusion: 贝叶斯逆博弈方法能有效量化不确定性，通过多模态观测融合提升推理鲁棒性，为自主决策提供更安全的概率基础，优于传统的点估计方法。

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [78] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: 提出E-GRPO方法，通过熵感知的组相对策略优化增强流匹配模型在人类偏好对齐中的表现，通过合并低熵步骤为高熵SDE采样步骤来解决多步优化中的稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多个去噪步骤上进行优化时面临稀疏和模糊的奖励信号问题。观察到高熵步骤能实现更高效有效的探索，而低熵步骤导致无区别的轨迹。

Method: 提出E-GRPO（熵感知组相对策略优化），合并连续的低熵步骤形成一个高熵SDE采样步骤，在其他步骤应用ODE采样。引入多步组归一化优势，在共享相同合并SDE去噪步骤的样本中计算组相对优势。

Result: 在不同奖励设置下的实验结果证明了该方法的有效性。

Conclusion: 通过熵感知的SDE采样步骤合并和组相对优势计算，E-GRPO能够更有效地处理流匹配模型中的人类偏好对齐问题，提高探索效率并解决稀疏奖励问题。

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [79] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 对16种可解释机器学习方法在216个真实世界表格数据集上进行大规模比较评估，发现性能高度依赖数据集特征，EBM在回归任务中表现最佳，SR和IGANN在非线性场景中表现突出，GOSDT对类别不平衡敏感。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在高风险领域（医疗、金融、法律）的广泛应用，模型可解释性和问责制需求日益增长。尽管可解释ML受到关注，但对内在可解释模型的系统性评估仍然不足，特别是针对表格数据的研究相对稀缺且主要关注聚合性能。

Method: 对16种内在可解释方法进行大规模比较评估，包括经典线性模型、决策树以及EBM、SR、GOSDT等新方法。研究涵盖216个真实世界表格数据集，不仅进行聚合排名，还根据数据集结构特征（维度、样本量、线性度、类别不平衡）进行分层分析，并评估训练时间和分布偏移下的鲁棒性。

Result: 结果显示清晰的性能层次结构，特别是在回归任务中，EBM始终表现出强大的预测准确性。同时，性能高度依赖上下文：SR和IGANN在非线性场景中表现特别好，而GOSDT模型对类别不平衡表现出明显的敏感性。

Conclusion: 这些发现为寻求可解释性和预测性能平衡的实践者提供了实用指导，并加深了对表格数据可解释建模的实证理解。研究强调了根据数据集特征选择合适可解释方法的重要性。

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [80] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 本文提出可控概念瓶颈模型（CCBMs），支持三种粒度的模型编辑（概念-标签级、概念级、数据级），无需重新训练即可实现高效编辑，解决了传统概念瓶颈模型在动态环境中的维护难题。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型（CBMs）主要关注静态场景，假设数据和概念固定且干净。但在实际应用中，部署的模型需要持续维护：需要删除错误或敏感数据（遗忘）、纠正错误标记的概念、或纳入新样本（增量学习）以适应环境变化。因此，如何在不重新训练的情况下实现高效可编辑的CBMs成为重要挑战。

Method: 提出可控概念瓶颈模型（CCBMs），支持三种编辑粒度：概念-标签级、概念级和数据级（包括数据删除和添加）。基于影响函数推导出数学上严格的闭式近似，避免了重新训练的需求。

Result: 实验结果表明CCBMs具有高效性和适应性，证实了其在实现动态可信赖CBMs方面的实用价值。

Conclusion: CCBMs通过支持多种粒度的高效编辑，解决了传统概念瓶颈模型在动态环境中的维护挑战，为实际应用中的模型持续维护提供了有效解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [81] [Imitation from Observations with Trajectory-Level Generative Embeddings](https://arxiv.org/abs/2601.00452)
*Yongtao Qu,Shangzhe Li,Weitong Zhang*

Main category: cs.LG

TL;DR: 本文提出TGE方法，通过轨迹级生成嵌入解决离线观察模仿学习中的专家数据稀缺和离线数据分布差异问题。


<details>
  <summary>Details</summary>
Motivation: 离线观察模仿学习中存在专家演示稀缺、可用离线次优数据与专家行为分布差异大的问题。现有分布匹配方法因严格的支持约束和脆弱的单步模型，难以从非完美数据中提取有效信号。

Method: 提出TGE方法，通过时间扩散模型在离线轨迹数据上学习潜在空间，估计专家状态密度，构建密集平滑的替代奖励。利用学习到的扩散嵌入的平滑几何特性，捕捉长期时间动态，有效弥合分布差异。

Result: 在D4RL运动和控制基准测试中，TGE方法一致匹配或优于先前的离线观察模仿学习方法。

Conclusion: TGE通过轨迹级生成嵌入有效解决了离线观察模仿学习中的数据稀缺和分布差异问题，为从分布不同的离线数据中学习提供了鲁棒的学习信号。

Abstract: We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.

</details>


### [82] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 正交性损失在MoE模型中无法有效促进专家多样性，反而增加权重空间重叠，对性能影响不一致且不可靠。


<details>
  <summary>Details</summary>
Motivation: 研究几何正则化在混合专家模型专家专业化中的作用，探索正交性损失是否能有效促进专家多样性。

Method: 在MoE模型中应用正交性损失来强制专家多样性，在7个不同的正则化强度下进行分析，测量权重空间重叠和激活空间重叠。

Result: 正交性损失在多方面失败：权重空间重叠反而增加（最多114%），激活空间重叠保持高位（约0.6），性能影响不一致（WikiText-103略有改善，TinyStories轻微退化，PTB结果高度可变），权重和激活正交性无显著相关性。

Conclusion: 权重空间正则化既未实现其几何目标，也未可靠改善性能，不适合用于MoE多样性促进。

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [83] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 该研究开发了一种基于1D UNet的数据增强方法（AugUNet1D），用于自动标记脑电图中的棘慢波放电（SWD），相比传统方法和现有算法表现更优。


<details>
  <summary>Details</summary>
Motivation: 脑电图（EEG）记录中事件的手动标记非常耗时，特别是在连续数周至数月的记录中。棘慢波放电（SWD）作为失神发作的电生理标志，通常需要手动标记。虽然已有研究使用机器学习自动分割和分类EEG信号，但仍有改进空间。

Method: 研究比较了14种机器学习分类器在961小时C3H/HeJ小鼠EEG记录（包含22,637个标记SWD）上的性能。发现1D UNet表现最佳，并通过数据增强进一步改进，其中缩放增强效果最好。最终开发了AugUNet1D，并与最近发表的"Twin Peaks"时频算法方法进行比较。

Result: 1D UNet在该数据集上表现最佳。数据增强显著提升了1D UNet的性能，其中缩放增强效果最明显。AugUNet1D相比"Twin Peaks"算法表现出更优越的性能，检测到的事件特征更接近手动标记的SWD。

Conclusion: AugUNet1D是一种有效的自动标记EEG中SWD的方法，性能优于现有算法。研究公开了预训练和未训练的AugUNet1D模型供其他用户使用，有助于减少EEG分析中的手动工作量。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [84] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 该论文提出了一种多用户上下文赌博机框架，通过图拉普拉斯正则化和核方法统一处理具有图同质性的非线性奖励函数，设计了基于高斯过程的算法并获得理论遗憾界。


<details>
  <summary>Details</summary>
Motivation: 在多用户上下文赌博机中，用户通过图结构关联且奖励函数具有非线性特征和图同质性。现有方法要么忽略图结构，要么局限于线性模型，缺乏统一处理非线性图结构问题的理论框架。

Method: 提出联合惩罚项，结合基于RKHS距离的图平滑项和个体粗糙度惩罚。证明该惩罚等价于单一多用户RKHS中的平方范数，显式推导其再生核，将图拉普拉斯与基础臂核融合。设计LK-GP-UCB和LK-GP-TS算法，利用新核的高斯过程后验进行探索。

Result: 理论分析提供高概率遗憾界，其缩放依赖于多用户核的有效维度而非用户数量或环境维度。实验表明，在非线性设置中优于强线性基线和无图感知基线，即使真实奖励为线性时仍保持竞争力。

Conclusion: 该工作提供了一个统一、理论坚实且实用的框架，将拉普拉斯正则化与核化赌博机相结合，用于结构化探索，解决了具有图同质性的非线性多用户上下文赌博机问题。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [85] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了大型模型在联邦学习框架下的定制化方法，首次尝试将前缀调优应用于联邦学习环境，验证了其可行性并展示了竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 研究联邦学习框架下大型模型定制化的关键挑战，探索如何在保护数据隐私的同时实现模型个性化定制。

Method: 首先综述了多种大型模型定制技术，包括全微调、高效微调、提示工程、前缀调优、知识蒸馏和检索增强生成。然后讨论这些技术在联邦学习框架下的实现方式，并重点实验了联邦前缀调优方法。

Result: 联邦前缀调优实验验证了其在联邦学习环境中的可行性，性能接近集中式方法。与其他三种联邦定制方法相比，展示了竞争性性能、满意的效率和一致的鲁棒性。

Conclusion: 联邦前缀调优是大型模型联邦定制化的有效方法，在保护数据隐私的同时实现了接近集中式方法的性能，为联邦学习框架下的大型模型个性化定制提供了可行方案。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [86] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 本文提出基于扩散模型的云原生架构，可自动生成店铺专属货架图，将设计时间从30小时降至0.5小时，减少98.3%


<details>
  <summary>Details</summary>
Motivation: 传统货架图设计耗时巨大，每个复杂布局平均需要30小时，需要自动化解决方案来大幅提高效率并降低成本

Method: 采用云原生架构，结合AWS云端模型训练和边缘部署实时推理；使用扩散模型学习多个零售店成功货架布局，通过改进损失函数集成零售特定约束

Result: 系统将货架图设计时间减少98.3%（从30小时到0.5小时），约束满足率达94.4%；经济分析显示创建费用减少97.5%，盈亏平衡期4.4个月；架构线性扩展，支持10,000个并发店铺请求

Conclusion: 该研究证明了生成式AI在自动化零售空间优化中的可行性，通过云原生扩散模型架构实现了高效、可扩展的货架图自动生成

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [87] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 提出基于非平衡随机动力学的熵触发重训练框架，通过Fokker-Planck方程建模数据漂移，利用KL散度的时间导数分解中的熵产生项作为重训练触发机制，显著减少重训练次数同时保持预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据漂移检测方法大多缺乏理论动力学解释，且无法在重训练频率和运营成本之间提供平衡指导。需要一种基于原理的框架来优化重训练策略。

Method: 将部署时数据漂移建模为Fokker-Planck方程控制的概率流，使用时间演化的Kullback-Leibler散度量化模型-数据不匹配。该不匹配的时间导数可分解为包含非负熵产生项的熵平衡方程，基于此提出熵触发重训练策略。

Result: 在受控非平稳分类实验中，熵触发重训练实现了与高频重训练相当的预测性能，同时相对于每日重训练和基于标签的策略，将重训练事件减少了一个数量级。

Conclusion: 基于非平衡随机动力学的熵触发重训练框架提供了一种原理性的数据漂移应对策略，通过响应累积的不匹配而非延迟的性能崩溃，在保持性能的同时显著降低运营成本。

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [88] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: HFedMoE是一个基于MoE的异构联邦学习框架，用于在资源受限的客户端上高效微调大语言模型，通过专家重要性评估、自适应专家选择和稀疏感知聚合来解决计算资源异构性和全局聚合挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然联邦学习可以在保护数据隐私的前提下微调大语言模型，但LLM的巨大规模使得资源受限的移动设备无法进行本地训练。MoE模型通过激活稀疏专家子集来降低计算负担，但将其集成到FL中面临三个关键挑战：1) 缺乏可靠指标衡量专家对本地性能的影响；2) 客户端异构计算资源限制了MoE训练；3) 客户端特定的专家子集和路由偏好破坏了全局聚合。

Method: HFedMoE框架包含三个核心组件：1) 基于专家对微调性能贡献的重要性评估机制；2) 从信息瓶颈角度自适应选择专家子集以匹配客户端计算预算；3) 稀疏感知模型聚合策略，通过重要性加权贡献聚合活跃微调的专家和门控参数。

Result: 大量实验表明，HFedMoE在训练准确性和收敛速度方面优于最先进的基准方法。

Conclusion: HFedMoE成功解决了MoE在联邦学习中的关键挑战，为资源受限客户端上的大语言模型微调提供了计算高效的解决方案，通过专家重要性评估、自适应选择和稀疏感知聚合实现了更好的性能和收敛速度。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [89] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出一种针对非单调γ-弱DR-次模函数在向下闭凸体上最大化问题的近似算法，其近似保证随γ平滑变化，在γ=1时恢复0.401近似比。


<details>
  <summary>Details</summary>
Motivation: 次模目标函数在约束下的最大化是机器学习和优化中的基本问题。现有研究主要关注单调次模函数，但许多实际应用涉及非单调次模函数，特别是γ-弱DR-次模函数，需要开发有效的近似算法来处理这类更一般的函数。

Method: 结合Frank-Wolfe引导的连续贪婪框架与γ感知的双贪婪步骤，形成一个简单而有效的处理非单调性的过程。这种方法专门针对γ-弱DR-次模函数的特性进行优化。

Result: 算法提供了随γ平滑变化的近似保证：当γ=1（DR-次模情况）时恢复0.401近似比，当γ<1时保证逐渐降低但仍优于先前报道的相同约束下γ-弱DR-次模最大化的边界。

Conclusion: 该研究为向下闭凸体上的非单调γ-弱DR-次模最大化问题提供了最先进的近似保证，通过结合连续贪婪框架和双贪婪步骤，有效处理了非单调性并获得了平滑的近似性能。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [90] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: IGBO框架通过双目标优化训练可解释模型，利用DAG编码特征重要性层次结构，使用TIG测量特征重要性，并提出最优路径预言机解决TIG的OOD问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释模型训练方法缺乏结构化领域知识的有效整合，且特征重要性测量方法存在分布外问题，需要一种能够结合领域知识并解决OOD问题的可解释模型训练框架。

Method: 提出IGBO框架：1) 使用有向无环图编码特征重要性层次结构；2) 采用时序积分梯度测量特征重要性；3) 设计最优路径预言机学习数据流形感知的积分路径以解决OOD问题；4) 采用双目标优化公式平衡预测准确性和可解释性约束。

Result: 理论分析证明收敛性和对mini-batch噪声的鲁棒性；在时间序列数据上的实验表明，IGBO能有效强制执行DAG约束，精度损失最小，优于标准正则化基线方法。

Conclusion: IGBO框架成功整合了结构化领域知识到可解释模型训练中，通过最优路径预言机解决了TIG的OOD问题，在保持预测性能的同时增强了模型的可解释性。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [91] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 提出Avatar Forcing框架，通过扩散强迫机制实现实时交互式头像生成，解决现有模型缺乏情感互动的问题，实现低延迟（约500ms）和富有表现力的反应。


<details>
  <summary>Details</summary>
Motivation: 当前说话头像生成模型缺乏真正的交互式沟通感，通常生成单向响应而缺乏情感参与。需要解决两个关键挑战：在因果约束下实时生成运动，以及在没有额外标注数据的情况下学习富有表现力的生动反应。

Method: 提出Avatar Forcing框架，通过扩散强迫机制建模实时用户-头像交互，处理实时多模态输入（用户音频和动作）。引入直接偏好优化方法，利用通过丢弃用户条件构建的合成损失样本，实现无标签的富有表现力交互学习。

Result: 框架实现低延迟实时交互（约500ms），相比基线实现6.8倍加速，生成的反应性和富有表现力的头像运动在超过80%的情况下优于基线。

Conclusion: Avatar Forcing框架成功解决了实时交互式头像生成的关键挑战，实现了低延迟、富有表现力的反应，为真正交互式虚拟沟通提供了有效解决方案。

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [92] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: YapBench是一个轻量级基准测试，用于量化大语言模型在简洁理想提示上的过度生成问题，通过测量超出基准答案的额外字符数来评估模型冗余响应。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型如ChatGPT、Claude和Gemini作为通用助手时，经常对简单请求给出不必要的冗长回答，包含冗余解释、模棱两可的表述或模板化内容，增加了认知负担和基于token的推理成本。先前研究表明基于偏好的后训练和LLM评估可能导致系统性长度偏差，即使质量相当，更长的回答也更容易获得奖励。

Method: 引入YapBench基准测试，包含300多个英语提示，涵盖三种简洁理想场景：A) 最小或模糊输入，理想行为是简短澄清；B) 封闭式事实问题，有简短稳定答案；C) 单行编码任务，单个命令或代码片段即可。主要指标YapScore测量响应超出基准答案的字符数，不依赖特定分词器；YapIndex通过类别级中位数YapScore的均匀加权平均来总结模型性能。

Result: 评估了76个助手型LLM，观察到中位数超额长度存在数量级差异，并识别出特定类别的失败模式：在模糊输入上填充真空内容，在单行技术请求上添加解释或格式化开销。

Conclusion: YapBench为量化用户可见的过度生成问题提供了轻量级基准测试，揭示了不同模型在简洁响应方面的显著差异和特定失败模式，发布了基准测试并维护实时排行榜以跟踪模型冗长行为随时间的变化。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [93] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: IRPO提出了一种新的强化学习框架，通过将Bradley-Terry模型整合到GRPO中，解决了成对生成奖励模型的计算瓶颈问题，实现了高效的点式评分，在保持可解释性的同时达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 成对生成奖励模型（GRMs）在强化学习算法（如GRPO）中存在计算瓶颈问题，主要源于两个因素：1) 获取相对分数的O(n²)时间复杂度的成对比较；2) 重复采样或额外思维链推理带来的计算开销。需要一种更高效的替代方案。

Method: 提出Intergroup Relative Preference Optimization（IRPO）框架，将Bradley-Terry模型整合到GRPO中。该方法为每个响应生成点式评分，使得在RL训练期间能够高效评估任意数量的候选响应，同时保持可解释性和细粒度奖励信号。

Result: 实验结果表明，IRPO在多个基准测试中实现了点式GRMs中的最先进性能，性能与当前领先的成对GRMs相当。更重要的是，IRPO在后训练评估中显著优于成对GRMs。

Conclusion: IRPO通过解决成对GRMs的计算瓶颈问题，提供了一种高效的点式评分方法，在保持可解释性和细粒度奖励信号的同时，实现了与成对方法相当甚至更好的性能，为生成奖励模型与强化学习的集成提供了更实用的解决方案。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [94] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR是一个针对电信领域票务故障排除的端到端系统，通过集成领域特定的排序和生成模型，自动化分类、检索和生成任务，显著提升了故障排除的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 电信领域的票务故障排除是一个高度复杂且耗时的过程，需要专家解读票务内容、查阅文档和搜索历史记录。这种人工密集型方法不仅延迟问题解决，还阻碍整体运营效率。

Method: 提出TeleDoCTR系统，集成领域特定的排序和生成模型，自动化故障排除工作流程的三个关键步骤：票务分类到合适的专家团队、检索上下文和语义相似的历史票务、生成详细的故障分析报告。

Result: 在真实世界电信基础设施数据集上评估TeleDoCTR，证明其性能优于现有最先进方法，显著提升了故障排除过程的准确性和效率。

Conclusion: TeleDoCTR是一个有效的电信领域特定故障排除系统，通过自动化关键工作流程步骤，能够显著提高票务故障排除的效率和准确性。

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [95] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需训练的方法，通过分析注意力矩阵的谱特征来检测大语言模型中的有效数学推理，该方法在多个模型架构上实现了85-95%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需训练数据、微调或学习分类器的方法来检测大语言模型生成的数学推理是否有效，以应用于幻觉检测和AI安全监控。

Method: 将注意力矩阵视为动态图的邻接矩阵，提取四个可解释的谱诊断指标：Fiedler值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵，通过单一阈值即可区分有效和无效数学证明。

Result: 在四个独立架构家族的七个Transformer模型上实验，效应量高达Cohen's d=3.30，分类准确率达85.0-95.6%，校准阈值在全数据集上达到93-95%。发现该方法检测的是逻辑一致性而非编译器接受度。

Conclusion: 谱图分析为推理验证提供了原则性框架，具有即时应用于幻觉检测和AI安全监控的潜力，同时揭示了注意力机制设计影响哪些谱特征捕获推理有效性。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [96] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE是一个轻量级强化学习框架，通过添加基于粒子群的探索层来增强标准策略梯度方法，在非平稳奖励和高维策略任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习中的有效探索仍然是一个关键挑战，特别是在面对非平稳奖励或高维策略时。现有方法在复杂环境中探索效率不足，需要一种简单有效的方式来增强探索能力。

Method: ARISE框架在标准策略梯度方法基础上添加了一个紧凑的基于粒子群的探索层。它将策略动作与粒子驱动的建议相结合，每个粒子代表在动作空间中采样的候选策略轨迹，并使用奖励方差线索自适应地调节探索强度。

Result: 在简单基准测试中只有轻微改进（CartPole-v1 +0.7%），但在更具挑战性的任务中表现显著提升：LunarLander-v3 +46%，Hopper-v4 +22%，同时在Walker2d和Ant上保持稳定性。在非平稳奖励变化下，ARISE表现出明显的鲁棒性优势，在CartPole上比PPO高出75个点，在LunarLander上也有相应改进。

Conclusion: ARISE提供了一个简单、架构无关的途径，可以在不改变核心算法结构的情况下，创建更具探索性和鲁棒性的强化学习智能体。消融研究证实了粒子群组件和自适应机制都对性能有贡献。

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [97] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: 提出BSAT（B样条自适应分词器）和L-RoPE位置编码，用于长时序预测，通过自适应分段和分层位置编码提升性能并降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长时序预测中存在自注意力二次复杂度和均匀分块与数据语义结构不匹配的问题，需要更高效的自适应方法。

Method: 提出BSAT：参数自由的B样条自适应分词器，在高曲率区域放置token，将变长基函数表示为固定大小token（系数+位置）。提出L-RoPE：结合可学习加法位置编码和分层可学习基的旋转位置编码。

Result: 在多个公开基准测试中表现出竞争力，在高压缩率下保持强性能，特别适合内存受限的应用场景。

Conclusion: BSAT和L-RoPE的组合为长时序预测提供了高效解决方案，通过自适应分段和分层位置编码解决了传统方法的局限性。

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [98] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应精度调优框架，用于线性求解器和其他算法，通过上下文多臂老虎机问题动态选择计算步骤的精度配置，平衡精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 科学计算中混合精度方法有潜力提高计算效率，但手动精度调优困难。需要自动化方法动态选择不同计算步骤的精度配置，以在保持精度的同时减少计算成本。

Method: 将精度调优建模为上下文多臂老虎机问题，使用离散化状态空间和增量动作价值估计。通过Q表映射离散化特征（如近似条件数和矩阵范数）到精度配置动作，采用epsilon-greedy策略优化多目标奖励函数，平衡精度和计算成本。

Result: 在线性系统迭代精化应用中，该方法能有效选择精度配置，在保持与双精度基准相当精度的同时显著降低计算成本。框架在未见数据集上表现良好，具有泛化能力。

Conclusion: 这是首个基于强化学习的精度自动调优工作，验证了在未见数据集上的有效性。框架可推广到其他数值算法，推动了科学计算中混合精度方法的发展。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [99] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文分析了当前LLM推理循环中基于正确性优化的设计会导致推理路径分布崩溃，提出了分布创造性推理（DCR）框架来同时保持正确性和创造性。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的LLM管道依赖于引导式推理循环：采样多样化的思维链并强化得分最高的路径，主要优化正确性。这种设计选择容易导致模型在推理路径上的分布崩溃，降低语义熵并削弱创造性问题解决能力。

Method: 引入分布创造性推理（DCR），这是一个统一的变分目标，将训练视为通过解决方案轨迹的概率度量的梯度流。STaR、GRPO、DPO以及熵奖励等方法都是该损失函数的特例。

Result: 框架提供了三个核心结果：(1)多样性衰减定理，描述了基于正确性的目标如何导致STaR、GRPO和DPO的不同多样性衰减模式；(2)确保收敛到稳定且多样化策略的设计，有效防止崩溃；(3)在实践中实现这一目标的简单可行方案。

Conclusion: DCR为LLM提供了第一个原则性方案，使其既能保持正确性又能保持创造性，解决了现有方法中推理路径分布崩溃的问题。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [100] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 提出基于协变量依赖隐马尔可夫模型（CDHMM）的足球角球防守评估框架，通过追踪数据推断盯人和区域防守任务，实现无标签的防守贡献评估和反事实分析。


<details>
  <summary>Details</summary>
Motivation: 传统足球防守评估指标难以捕捉无球防守的协调运动，现有反事实方法（如幽灵模型）依赖缺乏战术背景的"平均"行为模拟，需要更精准的防守表现评估方法。

Method: 针对角球这一高度结构化的场景，开发协变量依赖隐马尔可夫模型（CDHMM），直接从球员追踪数据推断时间分辨的盯人和区域防守任务分配，并基于此提出防守贡献归因框架和角色条件幽灵方法。

Result: 该方法能够提供可解释的防守贡献评估，相对于情境感知基线，能够更准确地分析无球防守表现。

Conclusion: CDHMM框架为足球角球防守提供了创新的无标签评估方法，通过推断防守任务分配实现了更精准的防守贡献归因和反事实分析，弥补了传统防守评估方法的不足。

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


### [101] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: MBC提出了一种通过码本优化策略压缩记忆库的方法，用于大语言模型的持续学习，将记忆库大小减少到最强基线的0.3%，同时保持高保留准确率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识容易过时，持续学习需要更新模型而不遗忘已有知识。现有记忆增强方法面临记忆库随数据流不断增长的瓶颈问题。

Method: 提出MBC模型，通过码本优化策略压缩记忆库，引入在线重置机制防止码本崩溃，并在注意力层使用Key-Value低秩适配来有效利用压缩后的记忆表示。

Result: 在基准问答数据集上的实验表明，MBC将记忆库大小减少到最强基线的0.3%，同时在在线适应学习中保持高保留准确率。

Conclusion: MBC通过记忆库压缩有效解决了持续学习中记忆库不断增长的问题，在保持性能的同时大幅减少了存储需求。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [102] [Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781)
*Samson Gourevitch,Alain Durmus,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.LG

TL;DR: 论文提出了一种基于扩散的软重参数化方法，用于处理分类变量的梯度优化问题，避免了传统方法的偏差或噪声问题。


<details>
  <summary>Details</summary>
Motivation: 分类变量的梯度优化通常依赖两种方法：无偏但噪声大的评分函数估计器，或使用连续松弛但引入偏差的温度依赖目标。需要一种更好的方法来处理分类分布的重参数化。

Method: 提出扩散基软重参数化方法，利用高斯噪声过程下分类分布的去噪器具有闭式解的特性，构建无需训练即可通过反向传播的扩散采样器。

Result: 在各种基准测试中，提出的重参数化技巧展现出竞争性或改进的优化性能。

Conclusion: 扩散基软重参数化为分类分布的梯度优化提供了一种有效的新方法，平衡了传统方法的优缺点。

Abstract: Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [103] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出了一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，提升多轮对话的响应质量。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略以优化LLM性能仍然是一个重要挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1）首先识别知识库中与上下文相关的子区域，确保所有句子都与主题相关；2）在该子区域内细化搜索，提取与推理过程特别相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过共同关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提高了检索知识的多样性，从而产生更具信息量和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，通过逻辑结构对齐的知识检索，显著提升LLMs在多轮对话中的性能，生成更丰富、更具创造性的响应。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [104] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 本研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症自动筛查系统，通过收集432份音频数据并进行标注，对三种LLM进行微调，GPT-4.1在PHQ-9严重程度评分预测中达到94.5%准确率，为资源受限的多元语言环境提供了可行的心理健康筛查方案。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，主要障碍包括临床医生资源不足、社会污名化和语言障碍。传统PHQ-9问卷在高收入国家验证，但无法适应尼日利亚的皮钦语和520多种地方语言环境，导致文化语言不匹配。

Method: 收集432份尼日利亚18-40岁年轻人的皮钦语音频响应，对应PHQ-9项目进行心理体验评估；进行转录、预处理和标注（语义标签、俚语解释、PHQ-9严重程度评分）；对Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1三种大语言模型进行微调；从定量（准确率、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）两方面评估模型性能。

Result: GPT-4.1表现最佳，在PHQ-9严重程度评分预测中达到94.5%的准确率，优于Gemma-3-4B-it和Phi-3-mini-4k-instruct；定性评估中GPT-4.1也产生了最具文化适宜性、清晰度和上下文相关性的响应。

Conclusion: 基于大语言模型的AI介导抑郁症筛查为尼日利亚服务不足社区提供了可行方案，为在语言多样化、资源受限环境中部署对话式心理健康工具奠定了基础。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [105] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出了一种多算法方法来解决最后一公里包裹配送中的工作量平衡问题，通过结合距离和工作量考虑来优化包裹分配给配送员，确保每个配送员每天完成相似的工作量。


<details>
  <summary>Details</summary>
Motivation: 传统的基于地理邻近性的包裹分配方法效率低下，容易导致配送员之间工作量分配不均衡。在最后一公里城市包裹配送系统中，需要解决操作人力资源工作量平衡问题，纠正配送员之间的显著工作量不平衡。

Method: 提出多算法方法，包括不同版本的k-means、进化方法、基于k-means初始化的递归分配（使用不同问题编码）以及混合进化集成算法。这些算法结合距离和工作量考虑来优化包裹分配给配送员。

Result: 在西班牙Azuqueca de Henares城市最后一公里包裹配送系统的实际案例中展示了所提方法的性能，证明了其有效性。

Conclusion: 通过考虑工作量平衡的优化方法，可以显著改善最后一公里包裹配送系统中配送员之间的工作量分配，提高系统效率和公平性。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [106] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 该论文提出了一种基于规则的13张牌印度拉米纸牌游戏策略框架，使用新的手牌评估指标MinDist来量化手牌与最近有效配置之间的编辑距离，显著提升了胜率。


<details>
  <summary>Details</summary>
Motivation: 经典印度拉米纸牌是一个不完全信息的序列游戏，需要概率推理和组合决策。传统启发式方法效果有限，需要更形式化和可解释的策略设计方法。

Method: 提出MinDist指标（修改自MinScore），通过计算手牌与最近有效配置之间的编辑距离来评估手牌结构接近完成的程度。设计计算高效的算法，结合动态剪枝和模式缓存，在游戏中精确计算该指标。在两人零和模拟框架中融入对手手牌建模。

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤。

Conclusion: MinDist指标和相应算法框架为不完全信息纸牌游戏提供了有效的策略设计方法，显著改善了游戏表现，是可解释的算法策略设计的重要进展。

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [107] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究探索生成式AI如何理解乡土建筑中的建筑智慧，以伊朗鸽塔为案例，测试三种扩散模型在不同提示阶段的表现，评估AI对建筑类型、材料、环境等方面的重建能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索生成式AI系统如何解释乡土形式中蕴含的建筑智慧，了解AI在重建传统建筑设计智能方面的能力与局限。

Method: 使用伊朗鸽塔作为案例研究，测试Midjourney v6、DALL-E 3和基于Stable Diffusion XL的DreamStudio三种扩散模型，采用三个提示阶段（参考性、适应性、推测性），并建立五标准评估框架（类型学、材料性、环境、真实感、文化特异性）。

Result: 结果显示AI能可靠地复制几何图案，但误解材料和气候推理；参考图像提高了真实感但限制了创造力，而无参考的自由生成则产生创新但文化模糊的结果。

Conclusion: 研究界定了视觉相似性与建筑推理之间的边界，提出计算乡土推理作为分析AI如何感知、扭曲和重新想象传统设计智能的框架。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [108] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 本文设计了一个基于大语言模型（LLM）的智能体，能够从原始文本中提取因果反馈模糊认知图（FCM）。该智能体通过三步指令引导LLM提取关键名词、FCM概念节点和模糊因果边，构建动态系统，并与人类生成的FCM达到相同的平衡极限环。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于开发能够从文本中自主提取因果关系的智能系统，使FCM动态系统具备一定程度的自主性，同时保持可控性。通过LLM智能体实现文本到因果结构的转换，探索人工智能在复杂因果推理中的应用。

Method: 方法包括：1）设计三步精细调校的系统指令，引导LLM智能体从文本中提取关键名词和名词短语；2）从这些名词中提取FCM概念节点；3）推断节点间的部分或模糊因果边。测试使用Henry Kissinger及其同事关于AI前景的论文，比较LLM生成的FCM与人类生成的FCM。

Result: 结果显示：1）三步过程生成的FCM动态系统与人类生成的FCM收敛到相同的平衡极限环，尽管节点和边数量不同；2）混合Gemini和ChatGPT LLM智能体生成的FCM不仅吸收了主要混合组件的平衡点，还创建了新的平衡点，更好地近似底层因果动态系统。

Conclusion: 结论表明LLM智能体能够有效从文本中提取因果结构，生成的FCM动态系统具有与人类生成系统相似的平衡行为。混合不同LLM生成的FCM能够产生新的平衡点，增强对底层因果系统的近似能力，展示了智能体在因果推理中的潜力。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [109] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏并评估技能排序能力来优化机制设计。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常耗时且依赖专家经验，需要自动化方法来探索多样化的游戏机制，以加速游戏设计过程。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏，评估机制对技能排序的贡献度。

Result: Mortar能够生成多样且可玩的游戏，产生的机制在游戏中能更好地支持技能排序，消融研究和用户研究验证了系统组件的有效性。

Conclusion: Mortar系统展示了自动化游戏机制演化的可行性，为自动游戏设计提供了有效工具，通过技能排序评估机制质量的方法具有实际应用价值。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [110] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 本文提出了一种混合智能体框架，将LLM作为自然语言接口，严格分离语义推理和数学计算，以解决LLM直接作为端到端求解器时的"幻觉税"问题，在库存管理中实现了32.1%的成本降低。


<details>
  <summary>Details</summary>
Motivation: 中小企业在库存管理中缺乏部署高级优化方法的专业知识，虽然大型语言模型（LLMs）有潜力帮助解决这一问题，但直接将LLMs作为端到端求解器会产生显著的"幻觉税"——由于模型无法进行基于现实的随机推理而产生的性能差距。

Method: 提出混合智能体框架，严格分离语义推理和数学计算：LLM作为智能接口，从自然语言中提取参数并解释结果，同时自动调用严谨算法构建优化引擎。引入"人类模仿器"（Human Imitator）作为有限理性管理者的"数字孪生"，用于可扩展、可重复的压力测试。

Result: 混合智能体框架相对于使用GPT-4o作为端到端求解器的交互式基线，将总库存成本降低了32.1%。研究发现，即使提供完美的真实信息也不足以改善GPT-4o的性能，确认瓶颈本质上是计算性的而非信息性的。

Conclusion: LLMs不应取代运筹学，而应作为自然语言接口，使非专家能够访问基于严谨求解器的策略。混合智能体框架成功解决了LLM的"幻觉税"问题，为中小企业提供了有效的库存管理解决方案。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [111] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究视频问答中基于置信度的弃权机制能否可靠控制错误率，以及在分布偏移下是否保持稳健


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在高风险部署中需要选择性预测，当不确定时应弃权而非冒险犯错，需要验证置信度弃权机制能否可靠控制错误率

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型，通过置信度阈值化方法，在分布内和分布偏移条件下测试风险-覆盖权衡

Result: 1. 置信度阈值化在分布内提供机制性控制，通过调整阈值epsilon可获得平滑的风险-覆盖权衡，降低错误率；2. 在分布偏移下控制效果可能失效

Conclusion: 置信度弃权在分布内可有效控制错误率，但在分布偏移下可靠性降低，需要更稳健的选择性预测方法

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [112] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM驱动的智能体不仅存在人口统计偏见，还会在最小"我们vs他们"线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转向更根本的群体不对称——人类整体可能被智能体视为外群体。研究还提出了信念中毒攻击(BPA)来抑制人类规范脚本并重新激活对外群体的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM驱动的智能体是否会在最小群体线索下表现出群体间偏见，特别是当这种群体边界与智能体-人类划分重合时，人类整体可能被智能体视为外群体。这代表了从人类群体间差异到更根本的群体不对称的风险转变。

Method: 构建基于分配决策的受控多智能体社会模拟，在明确的收益权衡下研究智能体行为。引入信念中毒攻击(BPA)，包括初始化时的档案中毒(BPA-PP)和通过优化信念精炼后缀注入存储反思中的记忆中毒(BPA-MP)。

Result: 实验表明智能体在最小群体线索下表现出一致的群体间偏见。虽然当某些对应方被框定为人类时这种偏见会减弱，但这种减弱归因于仅在智能体相信真实人类存在时才激活的人类规范脚本。信念中毒攻击成功抑制了人类规范脚本并重新激活了对人类的偏见。

Conclusion: LLM驱动的智能体确实存在群体间偏见风险，特别是当群体边界与智能体-人类划分重合时。信念中毒攻击揭示了新的攻击面，需要在档案和记忆边界实施可行的干预措施来强化当前的智能体框架。识别这些漏洞的目的是为更安全的智能体设计提供信息。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [113] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续系统，通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识整合。


<details>
  <summary>Details</summary>
Motivation: 分布式计算连续系统（DCCS）集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个层次：遏制、诊断、元认知和知识。这些层次通过语言模型驱动的智能体实现自主故障隔离、因果诊断、自适应恢复和长期知识整合。

Result: 在公共故障数据集上使用多种语言模型进行评估，ReCiSt能够在数十秒内实现自愈能力，智能体CPU使用率最低为10%，并展示了克服不确定性的分析深度和实现弹性所需的微智能体数量。

Conclusion: ReCiSt框架成功地将生物自愈机制转化为计算弹性策略，通过语言模型驱动的智能体实现了分布式计算连续系统的自主故障恢复和知识积累，为复杂系统的自我修复提供了新途径。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [114] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应架构，利用记忆引导机制动态学习最优检测配置，显著提升社交媒体协同虚假行为检测的准确性和效率，减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体协同虚假行为检测方法存在三个主要问题：依赖表面相关性分析、使用静态参数设置、需要大量人工标注。这些局限性导致检测效果不佳且效率低下，需要更系统化的解决方案。

Method: 提出自适应因果协同检测（ACCD）框架，采用三阶段渐进架构：1）自适应收敛交叉映射（CCM）技术深度识别账户间真实因果关系；2）半监督分类中集成主动学习和不确定性采样，减少人工标注负担；3）基于历史检测经验的自动化验证模块，实现检测结果的自我验证和优化。

Result: 在真实数据集（Twitter IRA、Reddit协同痕迹、多个机器人检测基准）上的实验表明：ACCD在协同攻击检测中达到87.3%的F1分数，比现有最强基线提升15.2%；减少68%的人工标注需求；通过层次聚类优化实现2.8倍处理速度提升。

Conclusion: ACCD为社交媒体协同行为识别提供了更准确、高效、高度自动化的端到端解决方案，具有重要的实际应用价值和广泛的推广潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [115] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 该研究将语义空间推理从计算语言学扩展到团队运动战术决策，将球员视为单词、团队配置视为语义结构，通过向量空间建模战术模板与团队配置的匹配度，生成动态自适应的策略建议。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法在团队运动战术决策中尚未得到充分应用。研究旨在建立文本与团队的类比关系，将语言学概念应用于战术分析，为团队运动提供更系统、可解释的决策框架。

Method: 将每个球员表示为整合技术、身体和心理属性的多维向量，通过上下文加权聚合为团队语义表示。在共享向量空间中编码战术模板（如高位压迫、反击、控球组织），使用向量距离度量评估战术"契合度"和对手利用潜力。

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性层面的细粒度诊断洞察。该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人、人机协调系统等团队领域。

Conclusion: 该研究为集体决策和团队表现优化提供了通用框架，未来方向包括真实数据集成、预测模拟以及混合人机战术智能系统的开发。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [116] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"很少见，不会随训练增加，也很少提高准确性，表明它们不是真正的自我修正机制，而是推理不稳定的症状。


<details>
  <summary>Details</summary>
Motivation: 先前研究表明像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，导致准确输出，暗示了内在的自我修正能力。但尚不清楚这种推理策略的内在转变是否真的能提高性能。

Method: 研究分析了100多万个推理轨迹、数百个训练检查点、三个推理领域、多个解码温度和模型架构，检测推理过程中的转变，并研究其与模型不确定性的关系。

Result: 发现推理转变很罕见，不会随训练变得更频繁，很少提高准确性，表明它们不符合先前对模型洞察力的认知。但其效果随模型不确定性变化，在高熵条件下人为触发外在转变能可靠提高准确性。

Conclusion: 推理过程中的转变是不稳定推理行为的症状，而非内在的自我修正机制。通过在高不确定性条件下人为触发转变可以改善性能。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [117] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出了一种难度感知的直接偏好优化框架，通过估计偏好数据的难度并重新加权训练样本，解决多模态大语言模型中偏好数据难度不平衡导致的过拟合问题，从而更有效地抑制幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态直接偏好优化方法由于偏好数据难度不平衡容易过拟合。研究发现MLLMs倾向于过度关注容易区分的偏好对，这阻碍了细粒度幻觉抑制并降低了整体性能。

Method: DA-DPO包含两个主要组件：1) 难度估计：利用预训练的视觉-语言模型，结合生成和对比目标，通过分布感知投票策略产生鲁棒的难度分数；2) 难度感知训练：基于估计的难度重新加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合。

Result: 大量实验表明，DA-DPO持续改进多模态偏好优化，在标准基准测试中表现出更强的幻觉鲁棒性和更好的泛化能力，同时保持计算效率。

Conclusion: DA-DPO是一个成本效益高的框架，通过难度感知的偏好优化平衡学习过程，无需新数据或额外微调阶段，就能更有效地抑制多模态大语言模型中的幻觉。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [118] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM：结合视觉特征和领域知识的LLM框架，用于行人过街行为推理，在准确率和泛化性上超越传统统计和监督学习方法


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景表现不佳。LLMs提供了从数值模式拟合转向语义、上下文感知行为推理的机会，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，整合LLaVA提取的视觉特征与文本数据及交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。采用零样本和少样本学习评估跨场景泛化能力。

Result: PedX-LLM达到82.0%平衡准确率，超越最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识整合带来额外4.1%改进。在五个未见测试场景的零样本配置达到66.9%平衡准确率，比基线数据驱动方法至少高18个百分点。少样本学习（仅5个验证样本）将准确率进一步提升至72.2%。

Conclusion: PedX-LLM展示了强大的跨场景泛化能力，证实视觉和知识增强的推理使模型能够模仿人类决策逻辑，克服纯数据驱动方法的局限性，将行人过街推断从特定场景模式识别转变为可泛化的行为推理。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [119] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 使用智能体工作流将自由格式任务描述自动转换为完整的 DomiKnowS 程序，无需用户掌握特定库语法，大幅减少开发时间


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中可以提高鲁棒性、可解释性和数据效率，但现有框架（如 DomiKnowS）仍要求用户精通特定库的语法，这限制了其可访问性

Method: 提出 AgenticDomiKnowS (ADS)，通过智能体工作流将自由格式任务描述翻译为完整的 DomiKnowS 程序，该工作流单独创建和测试每个 DomiKnowS 组件，并支持可选的人工干预机制

Result: ADS 使熟悉和不熟悉 DomiKnowS 的用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟

Conclusion: ADS 消除了对特定库语法的依赖，通过自动化翻译和可选的专家干预，显著降低了神经符号程序开发的入门门槛和时间成本

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>
